<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>访客如何使用档案馆</title><url>/post/how_to_use/</url><categories/><tags/><content type="html">前言 帕里特档案馆（重建中，旧篇总计 283，迁移完成 15），是个个人档案馆。
档案馆的内容主要是本人的学习笔记、对学到的东西的解释和思考、对实操过程的记录。
这些玩意本质上是当时的我给以后的我的留言。它们不是教程，更不是论文。
写它们的目的是，如果以后的我忘记了这块的内容，那么希望现在的我可以把以后的我教会。
本人能力有限，因此不能保证所有的内容的时效性和正确性。还请各位到访的访客务必小心。
本人能力有限，因此不能保证所有的内容的时效性和正确性。还请各位到访的访客务必小心。
本人能力有限，因此不能保证所有的内容的时效性和正确性。还请各位到访的访客务必小心。
另外，如果访客您觉得毫无干货或者内容非常水，那么非常抱歉。
如何使用档案馆 档案馆的内容分为三个部分：
文本 代码，借助 github 图，借助 draw.io 如果文本使用到了代码或者图，通常在文本的最前面会有一个标题为 资料 的部分。
如果是类似 {xxx}/aaa/bbb/ 这种格式的，就是 github 上的项目的代码，需要去 github 上查看。 其中 {demo-c}、{tcp-service-c} 是私有仓库，暂不对外开放。
关于项目的代码中的符号命名，详见 符号命名 这一篇。
实际开发中符号命名规则应该和团队的风格保持统一，这套符号命名规则是本人的个人喜好。
如果访客您非要说不符合哪里哪里的规范，怎么怎么有问题，那么访客您说的都对。
如果是类似 xxx.drawio.html 这种格式的，就是 draw.io 生成的 html，直接打开就可以预览。 参考到的外部资料通常在文本的最后面会有一个标题为 reference（参考） 的部分。</content></entry><entry><title>Golang 实现简单的 Web 框架 -- middleware(中间件)</title><url>/post/computer-science/programming-language/framework/web/golang/middleware_v2/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>web</tag><tag>http</tag><tag>middleware(中间件)</tag><tag>golang</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
前言 在看这篇之前，建议先看一下 Golang 实现简单的 Web 框架 &ndash; router(路由)资料 {demo-golang}/demo/web/middleware/ web.drawio.html 前置（后置）工作成对出现 承接上一篇的问题，在前一篇里讨论前置（后置）工作的时候，都是以&quot;前置（后置）工作是可以独立执行的整体&quot;为前提讨论的。如果它们之间有合作关系，也就是需要相互传递数据，那么怎么办呢？这里可以使用封装的思路，设计一个全链路通用的数据结构。然后所有的前置（后置）工作和最终的处理方法都接收这个数据结构作为参数。
在最外层 ServeHTTP 方法最开始的地方创建一个这样的数据结构，先封装 ServeHTTP 方法的两个参数，然后在后面调用到的所有方法那里一层一层传下去。如果后面的工作需要前面的工作的数据，就可以借助这个数据结构进行传递。
type 全链路通用的数据结构 struct { // ServeHTTP 方法的两个参数 http.ResponseWriter *http.Request // 其他参数 } 这里沿用上一篇中，访问 /user/id 的时候的结果。结合上面说的全链路通用的数据结构，最终地执行逻辑可以总结成下面这样。注意一定是引用传递，值传递进去的是一个副本，方法里面修改副本是不会影响外面的这个本体的。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 构造一个全链路通用的数据结构，封装 ServeHTTP 方法的两个参数 // 前置工作 user (引用传递全链路通用的数据结构) // 前置工作 user-id (引用传递全链路通用的数据结构) // `/user/id` 的处理逻辑 (引用传递全链路通用的数据结构) // 后置工作 user (引用传递全链路通用的数据结构) } 这个结构可以解决需要互相传递数据的问题。比如，如果&quot;后置工作 user&quot;需要使用&quot;前置工作 user&quot;生成的数据，那就可以借助全链路通用的数据结构，&ldquo;前置工作 user&quot;在执行的时候往里面塞点东西，这样后面的流程就可以用了。看上去没有什么大的漏洞。
处理异常 前面所有的流程里面，都是以代码正常执行为前提进行设计的，尚且没有考虑异常处理，因为异常处理本身确实就比较烦。
有 try-catch 结构的语言，直接一个大的 try-catch 包起来。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 构造一个全链路通用的数据结构，封装 ServeHTTP 方法的两个参数 try { // 前置工作 user (引用传递全链路通用的数据结构) // 前置工作 user-id (引用传递全链路通用的数据结构) // `/user/id` 的处理逻辑 (引用传递全链路通用的数据结构) // 后置工作 user (引用传递全链路通用的数据结构) } catch () { } } 没有 try-catch 结构的语言，只能在最后接收参数的地方判断一下返回值的内容，根据返回值的内容进行相应的处理。Golang 在最前面还可以加个 recover 恢复块。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 构造一个全链路通用的数据结构，封装 ServeHTTP 方法的两个参数 defer func(){ recover() } // 前置工作 user (引用传递全链路通用的数据结构) // 前置工作 user-id (引用传递全链路通用的数据结构) // `/user/id` 的处理逻辑 (引用传递全链路通用的数据结构) // 后置工作 user (引用传递全链路通用的数据结构) if 全链路通用的数据结构里的标记位 == x { // 标记位等于 x 就怎么怎么样 } else if 全链路通用的数据结构里的标记位 == y { // 标记位等于 y 就怎么怎么样 } } 屏蔽复杂度 前面的设计已经解决了绝大部分的问题。但是还有一点缺陷，全链路通用的数据结构里面会杂糅大量的数据。这些数据对于后面的整个流程来说是必须的，但是对于其中某一些流程来说，不是必须的。
比如，&ldquo;前置工作 user&quot;和&quot;后置工作 user&quot;想要进行沟通，所以在全链路通用的数据结构里面放了一个值。但是，这个值对于&quot;前置工作 user-id&quot;和 /user/id 的处理逻辑来说就是没用的。
这里还可以优化。怎么优化呢？&ldquo;前置工作 user&quot;和&quot;后置工作 user&quot;不是想要进行沟通嘛，那么能不能直接把这两个部分连起来，变成类似下面这样的结构呢。这样的话，前面需要放到全链路通用的数据结构里的值是不是就不要了。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 构造一个全链路通用的数据结构，封装 ServeHTTP 方法的两个参数 func 前置工作 user + 后置工作 user (引用传递全链路通用的数据结构) { // 前置工作 user 的处理逻辑 func 剩下的 (引用传递全链路通用的数据结构) { // 前置工作 user-id (引用传递全链路通用的数据结构) // `/user/id` 的处理逻辑 (引用传递全链路通用的数据结构) } // 后置工作 user 的处理逻辑 } } 怎么实现呢？首先需要注意到，这里需要传进去的已经不是那个全链路通用的数据结构了。需要传进去的是上面的伪代码中，中间的那个部分，也就是下面这部分，它是个方法。
func 剩下的 (引用传递全链路通用的数据结构) { // 前置工作 user-id (引用传递全链路通用的数据结构) // `/user/id` 的处理逻辑 (引用传递全链路通用的数据结构) } 乍一看不怎么好搞。但是，如果补一个&quot;后置工作 user-id&quot;给&quot;前置工作 user-id&rdquo;，是不是就变得和上面&quot;前置工作 user&quot;和&quot;后置工作 user&quot;一样了。
func 剩下的 (引用传递全链路通用的数据结构) { // 前置工作 user-id (引用传递全链路通用的数据结构) // `/user/id` 的处理逻辑 (引用传递全链路通用的数据结构) // （补一个）后置工作 user-id (引用传递全链路通用的数据结构) } 所以，这里可以假设有一个什么都不干的&quot;后置工作 user-id&quot;和它对应，那么整个代码就可以变成这样了，一个类似套娃的结构。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 构造一个全链路通用的数据结构，封装 ServeHTTP 方法的两个参数 func 前置工作 user + 后置工作 user (引用传递全链路通用的数据结构) { // 前置工作 user 的处理逻辑 func 前置工作 user-id + 空的后置工作 user-id (引用传递全链路通用的数据结构) { // 前置工作 user-id // `/user/id` 的处理逻辑 (引用传递全链路通用的数据结构) // （补一个）后置工作 user-id } // 后置工作 user 的处理逻辑 } } 这样，除了最里面的处理逻辑，外面的前置（后置）工作的部分，就都可以抽象成同一个结构了，是可以随意组合或者调整顺序的。
中间件 上面这玩意就是所谓的中间件的概念了，见图：web.drawio.html 6-2-2。也就是常听到的洋葱模型，见图：web.drawio.html 6-2-4。或者同心圆模型，见图：web.drawio.html 6-2-5。
本人更喜欢同心圆模型。前面两个模型的示意图，都没有明显的把嵌套的关系展现出来，更多的展示的是层层递进的关系。而同心圆模型，精准地反映了嵌套的关系，一层一层的进去之后，不管怎么走，都要再一层一层的原路出来。
下面用 Golang 实现一下这个结构 首先上面有两个部分需要定义：前置（后置）工作、处理逻辑
// HTTPHandleFunc 处理逻辑 type HTTPHandleFunc func(p7ctx *HTTPContext) // HTTPMiddleware 前置（后置）工作 type HTTPMiddleware func(next HTTPHandleFunc) HTTPHandleFunc 具体的处理逻辑，定义成下面这样。
func UserId (*HTTPContext) { // get user by id } 具体的前置（后置）工作的实现方式，就像下面这样。
func DemoMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { // before DemoMiddleware next(p7ctx) // after DemoMiddleware } } } 这里假设定义两个前置（后置）工作。
func AMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { // before AMiddleware next(p7ctx) // after AMiddleware } } } func BMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { // before BMiddleware next(p7ctx) // after BMiddleware } } } 然后这么链起来，B 在内层，A 在外层。
// 最内层的处理逻辑 chain := func UserId() // 套第一层 mb := BMiddleware() chain = mb(chain) // 套第二层 ma := AMiddleware() chain = ma(chain) // 执行 chain(ctx) 怎么装起来的见图：web.drawio.html 6-4。最后的效果等价于下面这样的伪代码。
// before AMiddleware // before BMiddleware serve(p7ctx) // after BMiddleware // after AMiddleware 可路由的中间件 可路由的中间件就是在路由树的基础上，分别给每个路由树结点设置中间件。这样在匹配过程中，如果结点上设置了中间件，那么就把这些中间件记录下来。在路由匹配到某个路由结点获取到路由的处理方法之后，把最终的处理方法和这些中间件按照定义好的顺序套起来即可。
]]></content></entry><entry><title>Golang 实现简单的 Web 框架 -- router(路由)</title><url>/post/computer-science/programming-language/framework/web/golang/router_v2/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>web</tag><tag>http</tag><tag>router(路由)</tag><tag>golang</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {demo-golang}/demo/web/router/ web.drawio.html 什么是 WEB 框架 简单的理解，WEB 框架就是工程师们在反复开发 WEB 系统的后台服务时，对于&quot;如何处理重复的代码&quot;这个问题，想出的一种解决方案。核心目标就是为了减少重复的代码，提高代码可读性和可维护性，提高编程的效率。
如果用比喻的话。WEB 框架就相当一个毛坯房，只有房屋的结构，但是里面没有装修。对于不同的业务系统来说，他们的内部处理的具体业务虽然是不同的（烘焙店和奶茶店会根据各自的需要进行相应的装修），但是具体业务依赖的代码工具（比如：参数校验、日志等）有可能是一样的（烘焙店和奶茶店都需要地基、房屋框架、墙面、屋顶）。
如果通过这些概念还是不怎么好理解什么是 WEB 框架，那么有一个更简单的理解。工程师们想偷懒（提高编程的效率），所以他们创造了一套工具（WEB 框架），减少复制粘贴代码的次数，减轻&quot;一处要变，到处要改&quot;带来的工作量。
那么问题来了，现在是知道有 WEB 框架这么个工具了，但是这个工具是怎么被创造出来的呢？想要理解这个问题，那就必须回到 WEB 框架这个概念还没有出现的&quot;蛮荒时代&quot;去。下面将结合代码来说明这个问题，代码将会使用 Golang 处理 HTTP 1.1 的请求。
从 TCP 开始 别看见 TCP 就紧张，这里不要求深入了解 TCP 的细节，只需要知道 TCP 是一个字节流协议就可以了。字节流协议，它的意思就是说，传输数据的时候，它是以字节为单位的，传输的过程像流水一样，一个字节接着一个字节的。见图：web.drawio.html 2-2。
HTTP 1.1 是基于 TCP 协议实现的，所以 HTTP 1.1 也可以说是一种字节流协议。这里为什么要说这个呢？主要是想强调一下，在计算机的&quot;眼里&quot;，HTTP 报文它不是一个整体，而是一个一个字符。HTTP 1.1 报文大概的格式见图：web.drawio.html 2-4-2、2-4-4。
既然发出去的 HTTP 报文就是一串字符，那么如果不说明这串字符怎么解读，那这串字符就毫无意义。所以客户端和服务端会通过约定请求行的 method 和 url 来区分不同的报文。可以区分不同的报文之后，后面的 请求头部和请求体才有意义。分析 HTTP 报文是什么类型，然后根据类型提取报文中的数据的过程就是解析 HTTP 报文的过程。
Golang 的 net 包和 net/http 包 在 net 包里，提供了对 TCP 的支持。而 net/http 包就是基于 net 包，实现了对 HTTP 协议的解析。这里就不费劲的从 TCP 开始搞了，怎么使用 TCP 和解析 HTTP 报文对理解 WEB 框架其实没啥帮助。所以直接从 net/http 包开始。
再继续之前，建议先看一下 Golang 开启 HTTP 服务。下面会直接从 Handler 接口的 ServeHTTP 方法切入。在 ServeHTTP 方法的第二个参数 *Request 里面，就可以拿到已经解析好的 HTTP 请求。
type Handler interface { ServeHTTP(ResponseWriter, *Request) } 从最简单的场景开始 如果啥都不考虑，那大可以直接用 if-else 的结构去判断 method 和 url，然后在 if-else 分支里面写各自的处理逻辑。如果把处理逻辑封装到方法面去，那这样的代码的逻辑其实是非常清晰的。
func ServeHTTP(http.ResponseWriter, *http.Request) { if Request.Method == &#34;GET&#34; { if Request.URL == &#34;/user/id&#34; { // /user/id 的处理逻辑 } else if Request.URL == &#34;/user/name&#34; { // /user/name 的处理逻辑 } } else if Request.Method == &#34;POST&#34; { if Request.URL == &#34;/order/create&#34; { // /order/create 的处理逻辑 } else if Request.URL == &#34;/order/delete&#34; { // /order/delete 的处理逻辑 } } } 即使后面报文的类型越来越多，无非也就是 if-else 的分支多了一点。可以再对 url 的处理做一次封装，代码就可以拆开来了。
func ServeHTTP(http.ResponseWriter, *http.Request) { if Request.Method == &#34;GET&#34; { handleGet() } else if Request.Method == &#34;POST&#34; { handlePost() } } func handleGet(){ if Request.URL == &#34;/user/id&#34; { // /user/id 的处理逻辑 } else if Request.URL == &#34;/user/name&#34; { // /user/name 的处理逻辑 } else if xxx { } else if xxx { } } func handlePost(){ if Request.URL == &#34;/order/create&#34; { // /order/create 的处理逻辑 } else if Request.URL == &#34;/order/delete&#34; { // /order/delete 的处理逻辑 } else if xxx { } else if xxx { } } 就目前来看这种给 method 和 url 都写一个 if-else 的分支的写法，似乎并没有什么非常明显的弊端。这种结构也可以使用 map 结构代替。可以是一层的：map[method+url]处理方法，或者嵌套的：map[method]{map[url]处理方法}。
处理逻辑执行前需要一些前置（后置）工作 这里讨论的是前置（后置）工作相同的情况。如果每个处理逻辑需要执行的前置（后置）工作不同，那就退回到上面那种情况去了。前置（后置）工作相同的情况有几种：所有的处理逻辑都需要，部分处理逻辑需要。
所有的处理逻辑都需要 这种场景非常好处理，直接在最外面写就好了。哪怕是多个或者有顺序要求的场景。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 前置工作 a // 前置工作 b if Request.Method == &#34;GET&#34; { handleGet() } else if Request.Method == &#34;POST&#34; { handlePost() } // 后置工作 c } 部分处理逻辑需要 这种场景乍一看可以沿用&quot;所有的处理逻辑都需要&quot;的方案，把前置（后置）工作下放到每个 if-else 的分支里面去就好了。但是这么做是有问题的。
假设 /user/id 和 /user/name 都需要&quot;前置工作 user&quot;，/user/id 自己还需要&quot;前置工作 user-id&quot;，/user/name 自己还需要&quot;后置工作 user-name&quot;。如果按照上面的写法，代码会写成下面这样子。
func handleGet(){ if Request.URL == &#34;/user/id&#34; { // 前置工作 user // 前置工作 user-id // /user/id 的处理逻辑 } else if Request.URL == &#34;/user/name&#34; { // 前置工作 user // /user/name 的处理逻辑 // 后置工作 user-name } } 乍一看问题不大，但是如果后面有 /user/a、/user/b 一直到 /user/z 呢。如果要求每个 /user/ 开头的都需要&quot;前置工作 user&quot;。这时候上面这种写法，// 前置工作 user 就要写 n 次，很麻烦。如果后面要求变了，要求每个 /user/ 开头的都需要&quot;前置工作 user2&quot;，或者这里就需要改 n 个地方，更麻烦。
所以要想办法，把这个公共的模块提取出去。比如变成下面这样，把有这种要求的 url 前缀单独拿到一个 if-else 的分支里去。
func handleGet(){ if Request.URL like &#34;/user/%&#34; { // 前置工作 user if Request.URL == &#34;/user/id&#34; { // 前置工作 user-id // /user/id 的处理逻辑 } else if Request.URL == &#34;/user/name&#34; { // /user/name 的处理逻辑 // 后置工作 user-name } // 后置工作 user } else { if Request.URL == &#34;/order/id&#34; { // /order/id 的处理逻辑 } } } 乍一看问题不大，如果要求每个 /user/ 开头的从都需要&quot;前置工作 user&quot;变成都需要&quot;前置工作 user2&quot;，那么只需要改一处。但是如果前缀的层级很多呢，比如像加一个 /user/info/a，那上面这种写法就要变成。
func handleGet(){ if Request.URL like &#34;/user/%&#34; { // 前置工作 user if Request.URL like &#34;/user/info/%&#34; { // 前置工作 user-info if Request.URL == &#34;/user/info/a&#34; { // /user/info/a 的处理逻辑 } } else { if Request.URL == &#34;/user/id&#34; { // 前置工作 user-id // /user/id 的处理逻辑 } else if Request.URL == &#34;/user/name&#34; { // /user/name 的处理逻辑 // 后置工作 user-name } } // 后置工作 user } else { if Request.URL == &#34;/order/id&#34; { // /order/id 的处理逻辑 } } } 这样下去 if-else 的层级就越来越深了。if-else 的层级太深，不利于代码的可读性和可维护性。更重要的是，这样的代码改的时候找起来非常的麻烦。所以这个问题是需要规避的。那么怎么规避呢？可以使用有层次的结构。
比如：假设图书馆里有大量的书需要分类。那么可以先按书内容的类别，分到不同的楼层去。然后再按书的作者，分到不同的书架上去。如果想处理某一类的书，可以只在某个楼层内部操作，不会影响到别的楼层。如果想处理某一类的某个作者的书，可以只在某个楼层的某个书架上操作，不会影响到这个楼层的别的书架，更不会影响到别的楼层。
这里把这种结构画出来就很直观了。见图：web.drawio.html 4-2。这种结构在数据结构里对应的就是树形结构。把上面的 method、url、前置（后置）工作对应进去再画一张图。见图：web.drawio.html 4-4。
路由树 到这里所谓的路由树的概念就呼之欲出了。上面的那棵树的结点中记录了全路径，但是这其实是不需要的。当命中 like &quot;/user/%&quot; 分支往下走的时候，后面的 url 最前面的那段就肯定是 /user/。所以这里就可以借助前缀的思路，用 / 作为分隔标志，将上面的那棵树转化成前缀树。见图：web.drawio.html 4-6-2。注意有个根结点（/ 结点）。
这样当一个 HTTP 请求过来的时候，先通过 method 判断应该到哪一棵路由树里去找。然后用 / 将 url 分开，依次去路由树里匹配，如果结点上有前置（后置）工作就需要记录下来。最后找到目标结点时，按照前置工作、处理逻辑、后置工作的顺序依次执行。
比如，在 web.drawio.html 4-6-2 这颗树里，访问 /user/id 的时候。依次会访问：/ 结点；user 结点，记录下前置工作 user 和后置工作 user；id 结点，记录下&quot;前置工作 user-id&quot; 和 /user/id 的处理逻辑。见图：web.drawio.html 4-6-4。
执行的时候，从逻辑上考虑的话，应该是前面的结点的前置任务应该在前面，前面的结点的后置任务应该在后面。所以上面就应该按照&quot;前置工作 user&quot;、&ldquo;前置工作 user-id&rdquo;、/user/id 的处理逻辑、&ldquo;后置工作 user&rdquo; 的顺序依次执行。见图：web.drawio.html 4-6-4。
路由树的高级玩法 静态的路由匹配可以用上面的 if-else 分支或者路由树解决。但是一些高级玩法，比如：路径参数路由、正则匹配路由、通配符路由，这样的就没办法整。这里以路径参数路由为例。
比如，有 user/:id 这样一个路由，:id 的位置可以是任意的数字，对应的方法是 GetUserById(id)。最终达到的效果是：如果访问的是 user/1，那调用的时候就是 GetUserById(1)；如果访问的是 user/2，那调用的时候就是 GetUserById(2)；如果访问的是 user/a，那调用的时候就要报错。这样的就是路径参数路由。
对于这种 :id 的位置可以变的路由。if-else 分支肯定无解。因为，:id 可变，意味着这里会对应无穷多个 if-else 分支。路由树有没有解呢？路由树可以解决，路由树只需要在 user 结点上增加一个特殊的结点 :id ，专门用于处理路径参数路由即可。见图：web.drawio.html 4-8-2。
访问 /user/1 的时候。依次会访问：/ 结点；user 结点。到了 user 结点之后，按照默认逻辑下面要找的是 1 结点，但是 user 结点下面只有 info 结点、id 结点，无法匹配。这个时候就可以尝试匹配 :id 结点，看看 1 符不符合 :id 结点的要求。
这里 :id 的位置可以是任意的数字，所以 1 是符合要求的，所以 /user/1 最终调用的就应该是 :id 结点的处理逻辑。见图：web.drawio.html 4-8-4。同理 /user/a 会因为匹配不到路由最终报错。见图：web.drawio.html 4-8-6。
路径参数路由的这种设计思路也可以用到正则匹配路由和通配符路由上去，都是设置特殊的结点。但是需要注意的是，这三个玩意匹配的时候可能都能匹配上，所以需要人为的定义这三个特殊的路由，哪个优先匹配，哪个最后匹配。
前置（后置）工作成对出现 上面讨论前置（后置）工作的时候，都是以&quot;前置（后置）工作是可以独立执行的整体&quot;为前提讨论的。如果它们之间有合作关系，也就是需要相互传递数据，那么怎么办呢？这个放到下一篇里说：Golang 实现简单的 Web 框架 &ndash; middleware(中间件)]]></content></entry><entry><title>并发问题</title><url>/post/computer-science/concurrency_issues/</url><categories><category>computer-science(计算机科学)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>concurrent(并发)</tag></tags><content type="html"><![CDATA[并行和并发 首先，假设有一个&quot;用手拿起桌子上的杯子&quot;的动作。这个动作的内部被分成了&quot;伸手-&gt;抓住杯子-&gt;拿起来&quot;这样有先后关系的多个子动作，每一个子动作可以单独被执行。现在，假设有一个人，就叫他慧，他有两个手（如果是触手怪的话就可以有好多手了）。慧的面前有一张桌子，桌子上有两个杯子（多个杯子）。
并行是什么呢，慧的左右手同时做&quot;用手拿起桌子上的杯子&quot;的动作，两个手同时进行，各做各的互不干扰。左手做&quot;伸手&quot;子动作的同时，右手也可以做&quot;伸手&quot;子动作。并行强调，两个或以上的动作，从外面看上去是同时进行的，从内部看，每个时刻可以有多个子动作在进行。
并发是什么呢，慧的左右手同时做&quot;用手拿起桌子上的杯子&quot;的动作，两个手同时进行，但是每次只能完成一个子动作。左手做&quot;伸手&quot;子动作的时候，右手是不能动的。并发强调，两个或以上的动作，从外面看上去是同时进行的，但是从内部看，每个时刻只能有一个子动作在进行。
并发问题 用比喻解释 在上面的假设中，假设了两个手和两个杯子。两个手做动作的时候，各自拿一个杯子。这是没有问题的，两个动作都可以独立完成。但是如果假设的时候，是两个手和一个杯子。两个手做动作的时候，拿的是同一个杯子。这就有问题了，两个动作会冲突。
并行场景下，左右手都完成了抓住了杯子子动作，那么左手进行拿起来子动作的时候，右手怎么办。并发场景下，左手完成了拿起来子动作，右手完成了伸手子动作，那么右手进行抓住杯子子动作的时候，抓什么。这个场景中的冲突就是并发问题出现的原因。
用代码解释 用最典型的 i++ 再来解释一下并发问题。把上面的名词换一下就行了：动作相当于程序代码；子动作相当于 CPU 指令；慧相当于 CPU；杯子相当于临界资源。
i++ 看上去是一条语句，但是在指令层面，它至少分为三步：1、从变量 i 的内存地址上读取数据；2、对数据做 +1 运算；3、把运算结果放到变量 i 的内存地址上去。
假设 i 是个全局变量，内存地址是 0x10 值是 0，现在有两个线程：线程 a 和线程 b 同时执行 i++。这里预期的结果应该是 i=2，但是实际执行过程中会发生下面这种情况。
时间流逝方向 线程 a 线程 b ↓ 等待 CPU 调度 等待 CPU 调度 ↓ 被给予 CPU 资源 等待 CPU 调度 ↓ 从 0x10 上读取数据（0） 等待 CPU 调度 ↓ 对数据做 +1 运算 等待 CPU 调度 ↓ 被剥夺 CPU 资源 被给予 CPU 资源 ↓ 等待 CPU 调度 从 0x10 上读取数据（0） ↓ 等待 CPU 调度 对数据做 +1 运算 ↓ 等待 CPU 调度 把运算结果（1）放到 0x10 上去 ↓ 被给予 CPU 资源 运行结束，归还 CPU 资源 ↓ 把运算结果（1）放到 0x10 上去 - ↓ 运行结束，归还 CPU 资源 - 因为线程 a 还没有把运算结果放到 0x10 上去，所以线程 b 从 0x10 上拿到的依然是 0。假设线程 b 没有被剥夺 CPU 资源，完整地跑完了三条指令，那么 i 应该是 1。线程 b 结束运行，归还 CPU 资源。
线程 a 得到 CPU 资源，继续执行。这个时候线程 a 执行的是最后一步，把运算结果（1）放到 0x10 上去。这样就出问题了，实际的结果是 i=1，和期望的结果 i=2 不一致。
所以并发问题一定要从指令层面保证不会出问题，而不是语句层面。
解决方案 并发问题的解决方案的基本思路都是保证临界资源在同一时刻只能被一个对象操作。这个对象可以是多线程环境中的一个线程，分布式系统中的一个客户端（其实也可以认为是线程）。
加锁或者 CAS，都是一样的思路。加锁就是多线程抢同一把锁，CAS 就是多线程抢同一个标志位。只有抢到锁或者标志位的线程，才能操作临界资源。这个时候临界资源就相当于是独享的，就不会出现并发问题。
锁机制 常用的锁机制有两种：悲观锁、乐观锁。
悲观锁假定会发生并发冲突，在操作数据之前，需要保证只有自己能操作数据。如果有其他想要操作数据的，它们会被挡住。悲观锁大多依靠底层提供的锁机制。
乐观锁假定不会发生并发冲突，先假定只有自己在操作数据，需要提交的时候，再检查是不是真的只有自己在操作数据。如果有其他在操作数据的，自己会被挡住。乐观锁大多是基于数据版本记录机制实现。
CAS CAS（Compare And Swap）操作是原子操作，包含三个操作数：内存中的值（内存位置 V）、原值（预期原值 A）、新值（新值 B）。如果内存中的值与原值相等，那么处理器会将内存中的值更新为新值。如果内存中的值与原值不相等，处理器不做任何操作。
锁和 CAS+自旋 单纯地看一次操作的效率的话，CAS 的效率肯定是比锁高的。但是并发场景中，不能只看一次操作的效率，而是要看整体操作的效率。
如果并发量很少，也就是冲突不明显的时候。比如锁和 CAS 都是一次就成功。那么整体的效率，CAS 是比锁要高的。
如果并发量很大，也就是冲突明显的时候。锁一次不成功，就会阻塞，然后进入通知队列等着被唤醒了，CPU 就可以空出来干别的事情。但是 CAS 一次不成功，会不停的重试，直到成功。
这个时候问题就来了，假设并发数量是 10000，那么 1 个成功了，那么剩下来的 9999 个，一定是不可能成功的。但是它们依然在不停的重试，一直消耗 CPU 的资源。
并发安全 不会出现并发问题，那就可以说是并发安全的。
]]></content></entry><entry><title>队列（Golang 实现）</title><url>/post/computer-science/programming-language/golang/queue/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag><tag>queue(队列)</tag><tag>concurrent(并发)</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {demo-golang}/demo/queue/ queue.drawio.html 并发安全队列 并发安全队列就是不会出现并发问题的队列。
关于并发问题的一些东西在这篇里：并发问题阻塞队列和非阻塞队列 个人认为，一个队列是阻塞队列还是非阻塞队列，应该根据队列本身的设计判断。队列需不需要阻塞，是设计上决定的，和用锁还是用 CAS 是没关系的，这两个结构是为了解决并发问题的。
如果设计队列的时候，队列有最大容量。而且队列本身的设计中有阻塞的逻辑。这样的队列就是阻塞队列。比如，在入队阶段，判断队列容量已满的时候，不是直接返回入队失败，而是等待队列空出位置后在入队，那么这里就需要设计阻塞的逻辑。
反之，如果设计队列的时候，队列有最大容量，但是队列本身的设计中没有阻塞的逻辑，或者队列没有最大容量，那就是非阻塞队列。比如，在入队阶段，判断队列容量已满的时候，直接返回入队失败，那么这里就不需要设计阻塞的逻辑。
并发安全的有最大容量的队列 代码详见：
{demo-golang}/demo/queue/concurrent_blocking_queue.go。 {demo-golang}/demo/queue/wait_cond.go。 这里沿用上面的定义。想要一个并发安全的有最大容量的队列的两个要求：1、并发安全；2、有最大容量。这里用锁+环形数组实现。因为有最大容量的限制，所以肯定是需要阻塞的逻辑的。
从最简单的入队出队逻辑开始。入队：检查容量-&gt;(等待有空位：比如循环检查容量)-&gt;入队。出队：检查容量-&gt;(等待有数据：比如循环检查容量)-&gt;出队。这种结构可以满足有最大容量的要求，但是因为对临界资源（队列数据）的访问是没有限制的，所以这肯定不是并发安全的。
既然要保护临界资源，那么首先想到的肯定是加锁。Golang 里面就是 sync.Mutex 了。直接加锁行不行呢？入队：加锁-&gt;检查容量-&gt;(等待有空位：比如循环检查容量)-&gt;入队-&gt;解锁。出队：加锁-&gt;检查容量-&gt;(等待有数据：比如循环检查容量)-&gt;出队-&gt;解锁。这样的逻辑显然会在&quot;等待有空位&quot;和&quot;等待有数据&quot;这两个步骤产生死锁。
如果队列满了，&ldquo;等待有空位&quot;这里就无法入队，导致锁放不掉。这里锁放不掉，出队那里就加不了锁，无法出队。如果队列为空，&ldquo;等待有数据&quot;这里就无法出队，导致锁放不掉。这里锁放不掉，入队那里就加不了锁，无法入队。
所以加锁之后，&ldquo;等待有空位&quot;和&quot;等待有数据&quot;这个两步骤需要修改。&ldquo;等待有空位&quot;需要先解锁，这样出队那里就可以加锁。然后等待有空位。等到有空位之后，再加锁，然后入队。&ldquo;等待有数据&quot;需要先解锁，这样入队那里就可以加锁。然后等待有数据。等到有数据之后，再加锁，然后出队。
大概的过程见图：queue.drawio.html 2-2、2-4
Golang 里面提供了这种工具 sync.Cond。可以先看一眼官方提供的 sync.Cond.Wait() 里面的逻辑。执行逻辑很简单，大概是：获取一个用于等通知的结构；把拿着的锁放掉；阻塞，等通知；等到通知了，把锁加回来。
func (c *Cond) Wait() { c.checker.check() t := runtime_notifyListAdd(&amp;c.notify) c.L.Unlock() runtime_notifyListWait(&amp;c.notify, t) c.L.Lock() } 有了这个结构。出队的那个地方出队的时候，发一个信号给&quot;等待有空位&quot;就行。入队的那个地方入队的时候，发一个信号给&quot;等待有数据&quot;就行。这样并发问题也就解决了。加锁可以在并发场景中保护队列数据的正确性，但是用 sync.Mutex 和 sync.Cond 有一个缺点，这玩意无法控制超时。
用 sync.Mutex 执行 sync.Mutex.Lock() 之后，gorouting 就陷进去了，直到它拿到锁，否则是不会出来的。用 sync.Cond 也一样。执行 sync.Cond.Wait() 之后，gorouting 一样会陷进去，直到它被 sync.Cond.Signal() 或者 sync.Cond.Broadcast() 发出的信号唤醒，否则也是不会出来的。
所以这里需要的是一个可以被控制的等待加锁的结构。也就是说要一个 sync.Mutex.Luck(time) 或者 sync.Cond.Wait(time) 这样的东西。如果一定时间拿不到锁，或者等不到信号，要能从阻塞状态退出来。
仔细观察一下 Wait() 的代码。里面加锁和解锁的步骤是必须的，所以核心问题其实就找到了。需要修改原有的等通知的逻辑，让这里变成既可以等待信号，同时也可以被 context 超时控制的结构。在 Golang 里面，等待信号可以使用 channel（管道）。这玩意可以变相的做到，既可以被阻塞，也可以在需要的时候被唤醒。
可以把读一个空的管道理解成阻塞，把从管道里读到东西理解成唤醒。如果需要模拟阻塞，那么就读一个空的管道就可以了。唤醒这里需要一点技巧，这里不能用往管道里写数据的方式去唤醒阻塞中的 gorouting。因为不知道到底有多少个 gorouting 在等着读数据，也就是不知道要写多少次数据。写少了，会有等着的 gorouting 读不到数据，会泄露。写多了自己会阻塞，也会泄露。
这里可以用直接关闭管道的思路，读取已经关闭的管道会读到零值。那么关闭一个有很多 gorouting 都在读取的管道，就相当于完成了一次 Broadcast()。但是这种操作无法实现 Signal()。新的方法里面的逻辑大概就是下面这样（伪代码）。
func (p7this *Cond) WaitWithTimeout(ctx context.Context) error { // 获取一个用于等通知的 channel // 把拿着的锁放掉 select { case &lt;-ctx.Done(): // 超时，这里就不用把锁加回来了。外层应该拿到这里的异常，然后执行异常处理逻辑。 return ctx.Err() case &lt;-通知信号: // 等到通知了，说明有 gorouting 调用了 Broadcast() 关闭了 channel，把锁加回来。 // 这个地方并没有完全解决超时的问题，因为这里加锁的逻辑还是有可能被阻塞的。 } } 并发安全的没有最大容量的队列 代码详见：
{demo-golang}/demo/queue/concurrent_nonblocking_queue.go。 这里沿用上面的定义。想要一个并发安全的没有最大容量的队列的两个要求：1、并发安全；2、没有最大容量。这里用链表+CAS+自旋实现。因为没有最大容量，所以是不需要设计阻塞逻辑的。
还是从最简单的入队出队逻辑开始。因为没有最大容量，所以入队时是没有限制的。出队这里，和入队哪里保持一致，不设计阻塞逻辑。所以队列为空的时候，就直接返回一个异常就行。当然，出队如果想设计成一直等到有数据再出队的逻辑也不是不行。
所以基本的逻辑就可以定下来了。入队：入队。出队：检查队头-&gt;出队。和前面一样，因为对临界资源（队列数据）的访问是没有限制的，所以这肯定不是并发安全的。
如果选择用加锁的方式保护临界资源，那么基本思路就和前面的那个&quot;并发安全的有最大容量的队列&quot;是一样的。这里就不重复了，这里换另一个处理思路，用 CAS+自旋达到和锁一样的效果。改造后的步骤也不是很复杂。入队：准备好数据-&gt;使用 CAS 入队。出队：检查队头-&gt;使用 CAS 出队。
CAS 入队怎么入呢？入队的时候，最关心的是队尾，因为新结点会连接到原来的队尾结点上去，变成新的队尾结点。所以只要保护住&quot;替换队尾结点&quot;这个步骤，就能避免出现并发问题。所以 CAS 操作的目标就可以确定了，原来的队尾结点和新结点。
func (p7this *Queue) Enqueue(ctx context.Context, data) error { // 先把新的结点准备好 // 然后通过 CAS 操作挂到链表的尾部 for { // 通过原子操作把队尾拿出来 // CAS 操作，如果当前的队尾指针就是上面取到的指针，那么把队尾换成新的结点 if atomic.CompareAndSwapPointer(队尾, 取到的队尾, 新结点) { // CAS 返回成功，说明队尾没变，可以直接修改 // 把新结点接到原来的队尾结点上去 } // CAS 返回失败，说明队尾变了，其他想要入队的，已经抢先入队而且完成了，那就要重头再来 } } CAS 出队怎么出呢？出队的时候，最关心的是队头，因为队头结点出队之后，队头结点的下一个结点会接替原来的队头结点成为新的队头结点。所以只要保护住&quot;接替原来的队头结点&quot;这个步骤，就能避免出现并发问题。所以 CAS 操作的目标就可以确定了，原来的队头结点和队头结点的下一个结点。
func (p7this *Queue) Dequeue(ctx context.Context) (data, error) { for { // 检查队列是否为空 // 通过原子操作把队头拿出来 if atomic.CompareAndSwapPointer(队头, 取到的队头, 队头结点的下一个结点) { // CAS 返回成功，说明队头没变，可以直接修改 // 直接把结点上的数据取出来，然后出队就行了 } // CAS 返回失败，说明队头变了，其他想要出队的，已经抢先出队而且完成了，那就要重头再来 } } 思路比较简单，就是理解起来很不直观，这里需要借助调度时候的时序图来理解。详细的入队出队的调度过程见图。入队：queue.drawio.html 4-6、4-6-2、4-6-4、4-6-4-2、4-6-4-4。出队：queue.drawio.html 4-8、4-8-2、4-8-4、4-8-4-2、4-8-4-4。注意里面红色标记的结点，因为协程会在任意时刻被剥夺 CPU 资源，所以会出现部分步骤没完成的场景。
延迟队列 代码详见：
{demo-golang}/demo/queue/delay_queue.go {demo-golang}/demo/queue/priority_queue.go {demo-golang}/demo/queue/wait_cond_v2.go 延迟队列就是进入队列的元素有时间属性，在时间到之前不能出队。入队的时候没有什么限制，问题在出队这里。简单的搞法，直接整一个轮询不停地全量扫描，这是可以达到目的的，就是会占用 CPU 资源。
但是如果队列里面的元素很多，那全量扫描的时间，说不定队列里面已经有元素到时间了。所以最好对队列元素进行排序，搞成有优先级的，这样每次只需要检查第一个元素就行了。
这里借助时间属性给元素确定优先级，那么时间小的就应该排在前面。加上需要不停地进行插入和删除操作，普通的数组就不太合适了，比较合适的数据结构是小根堆。
优先队列可以解决全量扫描的问题，但是暴力轮询的问题还没有解决。如果不暴力轮询，那么中间就需要加入阻塞等待的机制，这个就稍微麻烦一点了。
首先，阻塞固定的时间是肯定不行的，在这段时间里面，队头元素说不定已经到时间了。所以阻塞的时间肯定要根据队头元素来，队头元素还有多久到时间，那就阻塞多久。这种思路可以解决队列元素不变的情况。但是如果等待过程中，入队了一个优先级更高的元素。那么这个思路也是有问题的，阻塞之后来不及出来了。
所以这里需要监听两种信号，一种是队头元素到时间的信号，另一种是入队信号。监听到入队信号之后，检查一下入队的元素的优先级，如果优先级更高就需要调整阻塞的时间。
整体思路和前面的那个&quot;并发安全的有最大容量的队列&quot;是一样的，就是队列数据的存储结构不一样，然后就是增加了针对延时的逻辑。大概的过程见图：queue.drawio.html 6-2、6-4
reference（参考） 极客时间Go实战训练营 并发等待队列实现 ]]></content></entry><entry><title>Golang 的 context 包的使用</title><url>/post/computer-science/programming-language/golang/context/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {demo-golang}
/demo/context/ context 也叫上下文，可用于携带数据或者控制调度流程。在常见的设计中，会把 context.Context 作为方法的第一个参数。
五个常用的方法 Background() 这个方法用于创建流程的第一个上下文。后续的上下文，如果没有特殊的情况，都是由它派生出来的。
WithValue() 这个方法用于挂载一个键值对到上下文上去。通常用于传递整条链路都需要用的参数。在使用的时候需要注意，WithValue() 的第三个参数的类型是 any。后面通过 Context.Value() 取出来的数据，需要进行类型转换后才能使用。
代码见：{demo-golang}/demo/context/context_test.go 的 f8ContextWithValue()
WithCancel() context.WithDeadline()，context.WithTimeout() 这三个方法一起看，它们的用途是差不多的，都是通过控制取消的信号，来控制流程。区别在于 WithCancel() 只能手动控制取消。WithDeadline() 和 WithTimeout() 可以设置到期时间，到期它会自动取消，也可以在到期之前手动控制取消。
代码见：{demo-golang}/demo/context/context_test.go 的 f8ContextWithCancel()
WithCancel() 在上下文取消之前 Context.Done() 和 Context.Err() 是拿不到信号的。取消之后 Context.Done() 可以读到信号，Context.Err() 会返回 context.Canceled。
这里看一下 WithDeadline()。WithTimeout() 里面其实是调了 WithDeadline()。
func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { return WithDeadline(parent, time.Now().Add(timeout)) } 代码见：{demo-golang}/demo/context/context_test.go 的 f8ContextWithDeadline() 和 f8ContextWithDeadlineV2()。
使用 WithDeadline() 的时候有一个时序的问题，超时和取消，哪个先发生。这个对 Context.Done() 没有影响，但是对 Context.Err() 是有的。如果超时发生在取消之前，那异常就是 context.DeadlineExceeded。如果超时发生在取消之后，那异常就是 context.Canceled。</content></entry><entry><title>Golang 的 sync 包的使用</title><url>/post/computer-science/programming-language/golang/sync/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag><tag>concurrent(并发)</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {demo-golang}
/demo/sync/ 调度器 代码见：{demo-golang}/demo/sync/goroutine_test.go
调度器在需要的时候，只会对正在运行的 goroutine 发出通知，试图让它停下来。但是调度器不会也不能强行让一个 goroutine 停下来。所以如果循环中的语句过于简单的话，那么当前的 goroutine 就可能不会正常响应（或者说没有机会响应）调度器的停止通知。
sync.Mutex sync.Mutex 就是互斥锁或者互斥量。sync.Mutex 使用过程中有几点需要注意：不要重复加锁、不要忘记解锁、不要对未锁定的锁解锁、不要对已解锁的锁解锁。
另外，sync.Mutex 是一个结构体类型，属于值类型中的一种。所以不要在多个函数之间直接传递。把它传给一个方法、将它从方法中返回、把它赋给其他变量、让它进入某个 channel，都会导致副本的产生。原值和它的副本，以及多个副本之间都是完全独立的，它们都是不同的 sync.Mutex。
sync.RWMutex sync.RWMutex 就是读写锁，可以单独加读锁或者写锁，其余的和 sync.Mutex 差不多。
sync.Cond 代码见：{demo-golang}/demo/sync/cond_test.go
sync.Cond 可以理解为条件变量，需要结合 sync.Mutex 或者 sync.RWMutex 一起使用。用于控制 goroutine 的动作。不满足条件时，阻塞 goroutine。满足条件时，唤醒一个阻塞中的 goroutine 或者唤醒全部阻塞中的 goroutine。
sync.Cond 主要有三个方法：Wait()、Signal()、Broadcast()
Wait() 会阻塞当前 goroutine，并当前的 goroutine 添加到通知队列的队尾，直到通知到来。阻塞时，会解锁当前条件变量基于的互斥锁。通知到来时，会唤醒当前 goroutine，重新锁定当前条件变量基于的互斥锁。
Signal() 从通知队列的队首开始，找第一个符合条件的 goroutine 唤醒。而 Broadcast() 则会唤醒通知队列所有符合条件的 goroutine。
另外，在使用时，应该使用 for 语句包裹条件变量的 Wait() 方法。这里有两个典型场景。
场景1：并发环境下，可能有多个 goroutine 在等待同一个共享资源。如果一个 goroutine 被唤醒后，发现拿不到共享资源，那么就应该再次调用 Wait()，继续等待。
场景2：需要的共享资源数量大于 1 个，也就是说只拿到一个共享资源是不满足条件的。这种情况下 goroutine 被唤醒后，需要先检查可以被占用的共享资源能不能满足自己的需求。如果不能满足需求，那么就应该再次调用 Wait()，继续等待。
比如需要的共享资源数量是 2。假设，现在有 goroutine0 到 0 个共享资源，goroutine2 拿到 1 个共享资源。这两个 goroutine 都不满足条件，都在等待。这个时候，goroutine4 释放了 1 个共享资源。
如果用的是 Signal()，假设它唤醒了 goroutine0，这个时候就算占用了 goroutine4 释放的 1 个共享资源，也是不能满足要求的，所以还是需要继续等待。不如唤醒 goroutine2，它就缺一个。所以这种情况就可以使用 Broadcast() 通知所有等待中的 goroutine。
WaitGroup 代码见：{demo-golang}/demo/sync/wait_group_test.go
WaitGroup 可以结合 channel 控制限制开启的 gorouting 数量。
用 channel 模拟令牌桶的思路，每次循环在开启 gorouting 之前需要先获取到令牌。gorouting 执行完之后，需要归还令牌，然后循环就可以继续创建新的 gorouting 了。</content></entry><entry><title>Docker Compose 怎么用</title><url>/post/computer-science/application/docker/docker_compose/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>docker</tag><tag>docker-compose</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 Docker version v20.10.17 Docker Compose version v2.7.0
Docker Compose 是什么 Docker Compose 是用于定义和运行多个 Docker 容器的工具。 使用 YML 文件配置需要的所有服务后，可以同时创建并启动所有服务。
Docker Compose 怎么用 第一步：编辑 docker-compose.yaml services: mysql8: image: mysql:8.0 container_name: mysql8-dev # restart: always command: --default-authentication-plugin=mysql_native_password environment: MYSQL_ROOT_PASSWORD: root # volumes: # - ./script/mysql/init.sql:/docker-entrypoint-initdb.d/init.sql ports: - &#34;13306:3306&#34; redis7: image: redis:7.0 container_name: redis7-dev environment: - ALLOW_EMPTY_PASSWORD=yes ports: - &#39;16379:6379&#39; image：指定用哪个 docker 镜像，如果本地没有的话，启动的时候会去 DockerHub 拉。 container_name：指定容器名称。如果不指定的话，当多个 docker compose 都需要创建同一个容器的时候，会报重名的错误。如果指定的话，多个 docker compose 会共享那个指定了名称的容器。 restart：需不需要重启容器。 ports：指定端口映射。冒号前面的是本机的端口，冒号后面的是容器内的端口。 第二步：启动 打开 PowerShell，进入 docker-compose.yaml 文件所在的目录，执行 docker compose up 或者 docker compose up -v 命令就可以启动了。带 -v 参数表示命令在后台运行，不会再控制台输出日志。想要关闭的时候直接 Ctrl+C 就可以了。
]]></content></entry><entry><title>Golang 实现简单的自定义 RPC 协议</title><url>/post/computer-science/programming-language/golang/rpc/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag><tag>protocol(协议)</tag><tag>rpc</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
前言 在看这篇之前，建议先看下面这篇：
关于 RPC 的基本认知
在动手实现自定义 RPC 之前，先搞清楚 RPC 是什么，以及 RPC 的原理。
资料 {micro-service-go}
/v20/ rpc.drawio.html 先来看看有几块东西 RPC 的意思是远程过程调用。既然是调用，那么这玩意肯定有一个调用方，一个被调用方，也就是说会有客户端和服务端。然后又是远程调用，那客户端和服务端应该不在同一个服务里，那么它们之间要用就需要用到网络，那么他们之间就必须要商量一个通信的方式，也就是需要一个通信协议。差不多就这三个玩意：客户端、服务端、协议。
理论上，可以基于 TCP 协议构造一个 RPC 协议，也可以基于 HTTP 协议构造一个 RPC 协议，这个其实没有严格的规定。进行协议设计的时候需要注意的是：如果是基于 HTTP 协议设计，那么里面会包含 HTTP 和 TCP 两个协议，会多一层转换的开销；如果是直接基于 TCP 协议设计，虽然少一层转换的开销，但是编码难度上去了。在实际应用中，需要做好协议性能和开发难度的权衡。
这几块东西是怎么工作的 RPC 有一个核心的描述：它想像使用本地服务一样使用远端服务。也就是说，如果在 a 服务上有另一个类 B，在远端服务 b 上有一个类 A，这个类 B 想直接 new 一个类 A 出来，然后调用方法。通常情况下这么干肯定是不行的，因为 a 服务上并没有类 A 的代码。但是如果把类 A 的代码在 a 服务上再写一份，那就没意义了。
RPC 这里想要的是 a 服务上有一个类 A 的壳子，这个类 A 的壳子可以直接 new 出来，然后调用壳子上的方法。调用壳子上的方法的时候，这个壳子上的方法做的事情是，把调用者传进来的参数收集起来，然后交给远端服务 b 上真正的类 A 去处理，拿到处理结果后，返回给调用者。调用者只是感觉上和使用本地服务没什么区别。
为了保证 a 服务和远端服务 b 上的类 A 是一样的，这里需要引入一个公共的抽象。a 服务基于这个公共的抽象实现一个壳子，远端服务 b 基于这个公共的抽象实现真正的功能。这里的两方是可以使用不同的语言的，a 服务上收集到的调用参数可以进行序列化处理然后再传到远端服务 b，只要远端服务 b 能根据序列化的数据还原出调用参数就行。
来总结一下这几块东西是怎么工作的：
客户端需要实现一个壳子。 壳子需要收集调用参数，把调用参数序列化，然后传给远端服务 b。 远端服务 b 在接到数据之后，需要用序列化后的数据还原出调用参数，处理完成后把结果返回回去。 壳子收到远端服务 b 的处理结果后，把处理结果返回给调用者。 这里面还有几处细节：
双方的通信的方式，也就是协议还没有约定。 远端服务 b 在接到数据之后，需要知道调用哪个类的哪个方法，这个是壳子需要告诉远端服务 b 的。 远端服务 b 处理出错了怎么办，也就是异常还没有处理。 RPC 调用的大概过程 用流程图（见图：rpc.drawio.html 4-2）来描述 RPC 调用的大概过程比较合适。
大概的实现 几个抽象 服务：就是壳子和真正的功能的抽象，两端需要基于这个抽象传递方法的入参和出参。 序列化：序列化可以用任意的算法，比如 JSON 或 protobuf。抽象是为了方便后续扩展新的序列化算法，上层不需要知道参数是怎么序列化的。 协议：协议可以用任意的协议，比如自定义 JSON 协议或自定义 RPC 协议。抽象是为了方便后续扩展新的协议，上层不需要知道数据是怎么发出去的。 网络请求：网络请求可以使用任意的形式，比如 TCP 或 HTTP，比如每次都新建连接或使用连接池。对网络请求层进行抽象是为了可以替换不同的实现，上层不需要知道网络请求是怎么实现的。 请求参数和响应参数：对这两个东西进行抽象是为了方便对 RPC 流程进行抽象。要不然请求的那个地方会是任意类型的，不方便添加中间件之类的结构。 协议 协议设计见图：rpc.drawio.html 6-2
最前面的定长的部分，这几个字段属于非常常见的字段了，很多协议里都可以看到这种设计。
请求（响应）头长度用于标记请求（响应）头的长度，这里的请求头包括前面定长的部分。 请求（响应）体长度用于标记请求（响应）体的长度。 这两个玩意合起来用于从 TCP 里读取一个完整的报文。也就是从 TCP 里读取的时候，先读前面 8 个字节，然后解析出这两个长度，这样就可以知道这一个报文的长度了。 版本号、序列换算法、压缩算法这三个属于标记位，用于提示客户端或者服务端，协议的内容怎么解析。
请求头里用 \r\n 分隔每一条数据。最前面两个固定为：service name 和 method name，后面则是剩下的元数据。比如，链路追踪 id 和超时时间之类的。service name 和 method name 单独拿出来放最前面是考虑到：1、这两个属于必须字段；2、如果有网关的存在，网关直接解析最前面这两个字段就可以进行转发，不用解析整个请求头。
响应头里只有一个放异常的位置。因为返回响应的时候一般都是原路返回的，所以 service name 和 method name 是不必要的。然后元数据，本来就是上游传过去的，没必要传回来，而且一般也不会有穿别的元数据回来的需要。所以请求头里的玩意，在响应头里都可以去掉。
壳子 客户端这边最重要的就是壳子了。如果客户端里需要大量使用 RPC 的话，那么每个方法都要作 RPC 改造。但是每个方法要做的事情都是一样的：收集调用信息，发起 RPC 调用，得到结果，返回给调用者。所以这里应该要进行封装。问题来了，各个方法它是不一样的，这东西怎么封装呢。这里就需要使用约定加反射的技巧。这里使用的是 Golang 别的语言依葫芦画瓢就行了。
首先约定 RPC 方法的入参只有两个：上下文和一个结构体指针。结构体里面装着方法需要的所有的参数。方法的出参也是两个：一个结构体指针和异常。结构体里面装着方法返回的所有的结果。这样子反射就好操作了。对于入参，通过反射获取入参的上下文参数，然后进行格式化，作为协议里的元数据。通过反射获取入参的结构体，然后进行序列化，作为协议请求报文里的请求体。对于出参，通过反射获取出参的结构体，然后进行序列化，作为协议响应报文里的响应体。通过反射获取异常，然后进行格式化，作为协议里的元数据。
异常 上面提到，异常是放到元数据那里的。为什么异常要放到元数据的位置呢。这是因为不管是 TCP 协议还是 HTTP 协议，它们都属于字节流协议。请求过来的时候，不会被分隔成独立的协议数据报文，这个也就是经常问的那个 TCP 粘包的问题。协议内部也是一样的，如果把出参的结构体和异常都放到响应体里面，那就需要有分隔它们的手段。要不然这两玩意粘在一起，直接序列化是要报错的。
大概就差不多了 具体的直接看代码就好了。</content></entry><entry><title>诺维科夫自洽性原则</title><url>/post/physics/time/novikov/</url><categories><category>time(时间)</category></categories><tags><tag>physics(物理学)</tag><tag>time(时间)</tag></tags><content type="html">诺维科夫自洽性原则 诺维科夫自洽性原则（Novikov self-consistency principle），是一个物理学术语。是由前苏联数学家，诺维科夫，在 1980 年代提出的，有关时间悖论的规则。
这个原则的核心概念是：人可以回到过去，但是不能因此改变历史的进程。我们的世界是已经被改变的最终结局。
我对这玩意的理解是 假设一个人 A 在时间节点 α 上，在某件事情 a 上，做了某个选择 1。然后在时间节点 β （α &amp;lt; β）上，他后悔了，选择用时间旅行，去把在时间节点 α 上，在某件事情 a 上做的选择 1，修正成选择 2。
到这里矛盾就出现了。如果在时间节点 α 上，选择 1 真的被修正成选择 2，那么 A 这个人观测到的历史就应该是，他在时间节点 α 上，在某件事情 a 上，做了某个选择 2。这样的话，他不会后悔，也就没有了时间旅行。
还有一种可能，A 在时间节点 α 上，在某件事情 a 上，做了某个选择 1，就是在时间节点 β 上的 A 进行时间旅行造成的，进行时间旅行的 A 变成了历史的一部分。
换个角度再来理解一下 假设在时间节点 β 上的 A（就叫他 Aβ），回到了时间节点 α 上，做选择的也不是他 Aβ 啊，做选择的是在时间节点 α 上的那个 A（就叫他 Aα）。所以如果时间旅行存在，在 Aβ 观测到的历史里应该有 Aβ 的存在，但是现在没有，到这里矛盾就出现了。
再换个角度理解一下 对于已经观测过过去的历史的人，过去的时间已经是确定的事实，而未来是不确定的。如果通过时间旅行，回到某段已经观测过的历史进程中。
虽然对于时间旅行者而言，从穿越时间点到未来这次穿越发生的时间点之间的这段时间都应该属于未来，但是由于其结果已经被时间旅行者观测过，所以即使时间旅行者试图改变历史，也会得到相同的结果。
所以诺维科夫自洽性原则也可以理解成：时间线是唯一的。
关于平行宇宙的问题 如果假设平行宇宙（多元宇宙、多重宇宙、世界泡）存在的话。宇宙从时间节点 α 上应该会分裂成两个宇宙，宇宙一和宇宙二。这里假设宇宙一对应选择 1，宇宙二对应选择 2。还是宇宙一中在时间节点 β 上的 A，进行了时间旅行。
结合上面的两个角度，如果想解决矛盾，那应该是从时间节点 α 上又分裂出了一个新的宇宙，宇宙三。在这个新的宇宙里，宇宙三的 Aα 能观测到宇宙一的 Aβ。但是这种情况，宇宙一什么都没有改变。
关于欺骗世界的说法 这种说法属于一种比较中二病的说法，故事情节看上去改变了世界，但是里面其实玩了一点花招。
如果某个故事的背景是设定在诺维科夫自洽性原则下的，那么这个故事的世界观就是过去不可变。但是人本身的感官是不能收集所有的信息的，也就是人通过感官获得的信息不一定就是真正的客观现实。所以以人的视角创造的历史就是可以被改变的。
所以在这种情况下，这类故事会先以人的视角观测一些现象，然后加上一些心理学上的预设，诱导读者 往某个看上去合理的历史上想，但是这其实不是真正的历史。然后当要开始所谓的欺骗世界的时候，就可以给之前给出的一些现象，另外一套解释。看上去就像是欺骗了世界，从而达到一种看上去像是改变了历史的表象。
比如，主角看到队友被捅了几刀，然后倒在血泊之中。队友临死之前让主角跑路，然后主角就头也不回的跑了。这种情况中，主角其实没有足够的信息判断队友死了没有。被捅了几刀，有没有可能是玩具刀；那个所谓的血泊，有没有可能是假的。
时间跳针 时间跳针是游戏《量子破碎》（《Quantum Break》）中的概念，类似 《JOJO的奇妙冒险》 里的绯红之王，或者很多作品里的形态各异但是本质上差不多的&amp;quot;时停&amp;quot;的概念。
时间已经经过了一段时间，但是没有能力的个体感觉到的只是一瞬。
reference（参考） 一个七年前的游戏，竟展现了2022年时间将彻底终结（量子破碎）〖游戏不止〗
预言2022年世界静止的游戏，最终的结局是什么样？（量子破碎）〖游戏不止〗
诺维科夫自洽性原则
诺维科夫
如何理解诺维科夫自洽性原则的解释？
蘑菇食草的回答</content></entry><entry><title>关于 RPC 的基本认知</title><url>/post/computer-science/protocol/rpc/</url><categories><category>protocol(协议)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>protocol(协议)</tag><tag>rpc</tag></tags><content type="html">资料 rpc.drawio.html RPC 是什么 RPC 是 Remote Procedure Call 的简写，翻译成中文叫远程过程调用。用这玩意的目的，简单的理解就是，想像使用本地服务一样使用远端服务。这个怎么理解呢？
这里先假定有一个类 A 在 a 服务上，这个类 A 实现了一个方法。如果现在在 a 服务上有另一个类 B 要调用这个方法，那么通常是直接 new 一个类 A 出来，然后调用方法就行了。现在如果这个类 A 在远端服务 b 上，怎么办呢？
通常情况是 a 服务通过网络，请求 b 服务来达到目的。比如，可以通过发起一次 TCP 进行访问，可以通过短连接的 HTTP 进行访问，当然长链接的 Socket 的也行。这些请求方式各不相同，原因是它们对于两个服务之间的沟通方式有着不同约定，这些约定也就是协议。
那么 RPC 协议是啥样的呢？RPC 协议希望，即使类 A 在远端服务 b 上，a 服务上的类 B 依然可以使用 new 一个类 A 出来，然后调用接口的方式达到目的。这里在 a 服务上的类 A 的使用方式看上去本地调用一样，但是背地里它是通过网络请求，请求了 b 服务，调用了 b 服务上真正的类 A 的接口拿到结果，然后返回给调用者的。
RPC 的原理 RPC 首先需要定义一个协议，也就是约定两个服务之间的沟通方式。这个协议主要是为了把本地服务的接口调用的信息传递给远端服务。也就是 a 服务上的类 A 假装自己就是 b 服务上的类 A，这样上游调用的时候，类 A 就可以拿到调用的信息（调了哪个接口，传了哪些参数），然后把这些调用信息传递给 b 服务上真正的类 A 去执行。
这个过程大概可以简单的分成下面几个步骤：
a 服务上的类 A 需要把自己伪装成 b 服务上的类 A，从外面看上去是一样的。 a 服务上的类 A 在被调用的时候需要把调用的信息收集起来，然后通过网络传给 b 服务。 b 服务接收到请求之后需要通过传过来的调用的信息，分析出这个请求调的是类 A，传了哪些参数。 b 服务 new 一个类 A 出来，使用传过来的参数调用接口拿到结果。 b 服务拿到结果之后，给 a 服务传回去。a 服务上的类 A 拿到结果之后，对上游做出响应。</content></entry><entry><title>在 Golang 中使用 mockgen 工具进行单元测试</title><url>/post/computer-science/programming-language/golang/mockgen/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag><tag>test</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
安装 GitHub的 README 就是文档。
使用 go install github.com/golang/mock/mockgen@v1.6.0 命令安装。装完就可以用了，直接命令行窗口输入 mockgen 命令，会得到下面的输出。
mockgen has two modes of operation: source and reflect. Source mode generates mock interfaces from a source file. It is enabled by using the -source flag. Other flags that may be useful in this mode are -imports and -aux_files. Example: mockgen -source=foo.go [other options] Reflect mode generates mock interfaces by building a program that uses reflection to understand interfaces. It is enabled by passing two non-flag arguments: an import path, and a comma-separated list of symbols. Example: mockgen database/sql/driver Conn,Driver -aux_files string (source mode) Comma-separated pkg=path pairs of auxiliary Go source files. -build_flags string (reflect mode) Additional flags for go build. -copyright_file string Copyright file used to add copyright header -debug_parser Print out parser results only. -destination string Output file; defaults to stdout. -exec_only string (reflect mode) If set, execute this reflection program. -imports string (source mode) Comma-separated name=path pairs of explicit imports to use. -mock_names string Comma-separated interfaceName=mockName pairs of explicit mock names to use. Mock names default to &#39;Mock&#39;+ interfaceName suffix. -package string Package of the generated code; defaults to the package of the input with a &#39;mock_&#39; prefix. -prog_only (reflect mode) Only generate the reflection program; write it to stdout and exit. -self_package string The full package import path for the generated code. The purpose of this flag is to prevent import cycles in the generated code by trying to include its own package. This can happen if the mock&#39;s package is set to one of its inputs (usually the main one) and the output is stdio so mockgen cannot detect the final output package. Setting this flag will then tell mockgen which import to exclude. -source string (source mode) Input Go source file; enables source mode. -version Print version. -write_package_comment Writes package documentation comment (godoc) if true. (default true) 2022/12/12 10:00:27 Expected exactly two arguments 生成 mock 文件 参数很多但是一般就用两个：-package 指定生成的 go 文件的包名； -destination= 指定生成的 go 文件的位置和文件名。比如，给 go-redis 的 Cmdable 接口生成 mock，就可以在项目的根目录输入下面的命令。
mockgen -package=mock -destination=&quot;mock/redis_cmdable.mock.go&quot; github.com/go-redis/redis/v9 Cmdable
这个命令就表示给 go-redis 的 Cmdable 接口生成 mock。生成的 go 文件的包名为 package mock。生成的文件在 ./mock/ 目录，文件名为 redis_cmdable.mock.go。
如果上面的命令没有生成文件，就先试试不加参数的能不能执行：mockgen github.com/go-redis/redis/v9 Cmdable。这个命令会使用默认配置生成 mock 文件。
如果碰到下面这种报错：
prog.go:12:2: no required module provides package github.com/golang/mock/mockgen/model; to add it: go get github.com/golang/mock/mockgen/model prog.go:12:2: no required module provides package github.com/golang/mock/mockgen/model; to add it: go get github.com/golang/mock/mockgen/model prog.go:14:2: no required module provides package github.com/go-redis/redis/v9: go.mod file not found in current directory or any parent directory; see &#39;go help modules&#39; prog.go:12:2: no required module provides package github.com/golang/mock/mockgen/model: go.mod file not found in current directory or any parent directory; see &#39;go help modules&#39; 2022/12/10 16:40:01 Loading input failed: exit status 1 就执行一下 go get github.com/golang/mock/mockgen/model 命令就行了。
在单元测试里使用 func TestXXX(p7s6t *testing.T) { // 开头这里是固定这么写的 p7s6t.Parallel() p7ctrl := gomock.NewController(p7s6t) defer p7ctrl.Finish() // 这个方法是 mockgen 生成的 p7cmdable := mock.NewMockCmdable(p7ctrl) // 定义 redis 语句执行的结果 p7cmd := redis.NewCmd(context.Background(), nil) p7cmd.SetVal(&#34;OK&#34;) // 把上面定义的执行结果，指定给一个语句 p7cmdable.EXPECT().Eval(gomock.Any(), {redis 语句}, 语句需要的参数 1, 语句需要的参数 2, ..., gomock.Any()).Return(p7cmd) } 这么就定义好了调用 redis 执行指定的 redis 语句的 mock 数据。注意，测试的时候调用的语句和语句需要的参数必须是一样的。而且上面这种定义方式这里只能调用一次。
p7cmdable := mock.NewMockCmdable(p7ctrl) p7cmd := redis.NewCmd(context.Background(), nil) p7cmd.SetErr(context.DeadlineExceeded) p7cmdable.EXPECT().Eval(gomock.Any(), {redis 语句 1}, 语句需要的参数 1, 语句需要的参数 2, ..., gomock.Any()).Times(2).Return(p7cmd) p7cmd2 := redis.NewCmd(context.Background(), nil) p7cmd2.SetVal(&#34;OK&#34;) p7cmdable.EXPECT().Eval(gomock.Any(), {redis 语句 2}, 语句需要的参数 1, 语句需要的参数 2, ..., gomock.Any()).Return(p7cmd2) 可以用 Times() 方法指定语句的调用次数，如果无限次的话就用 AnyTimes()。如果需要设置多种语句执行的结果，那就像上面那样，挨个定义，挨个设置就行。
用 Times() 的时候，不知道需不需要控制调用次数。这里用的时候发现，如果设置的调用次数没用完测试就结束了，那单元测试会报错。调整一下调用次数和被测试的程序保持一致就行。
controller.go:269: missing call(s) to 中间一大堆，应该就是调用次数没用完那个 redis 语句 controller.go:269: aborting test due to missing call(s) ]]></content></entry><entry><title>使用 WSL 和 Goland 进行 Golang 开发</title><url>/post/computer-science/application/wsl/golang/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>WindowsSubsystemForLinux(wsl)</tag><tag>linux</tag><tag>golang</tag><tag>goland</tag></tags><content type="html"><![CDATA[环境 CPU AMD64(x86_64) Windows 11 家庭版 WSL2 Ubuntu-20.04
安装 WSL Windows 里需要安装 Hyper-V 虚拟机。有没有安装 Hyper-V 可以通过在命令行窗口（CMD、PowerShell）里输入 systeminfo 命令查看。
... Hyper-V 要求: 已检测到虚拟机监控程序。将不显示 Hyper-V 所需的功能。 完全未安装 WSL 时，执行 wsl --install 才会一键安装，这里是手动安装。先以管理员模式运行 PowerShell。
可以通过 wsl --list --verbose 命令或者简写的 wsl -l -v 命令，查看机器上已经安装的 WSL
PS C:\WINDOWS\system32&gt; wsl -l -v NAME STATE VERSION * docker-desktop-data Stopped 2 docker-desktop Stopped 2 通过 wsl --list --online 命令，查看可用发行版列表。
以下是可安装的有效分发的列表。 请使用“wsl --install -d &lt;分发&gt;”安装。 NAME FRIENDLY NAME Ubuntu Ubuntu Debian Debian GNU/Linux kali-linux Kali Linux Rolling openSUSE-42 openSUSE Leap 42 SLES-12 SUSE Linux Enterprise Server v12 Ubuntu-16.04 Ubuntu 16.04 LTS Ubuntu-18.04 Ubuntu 18.04 LTS Ubuntu-20.04 Ubuntu 20.04 LTS 然后通过 wsl --install -d Ubuntu-20.04 命令安装 Ubuntu-20.04。
等着下载好，如果进度条不动或者出错了，Ctrl+C 然后重新执行就行。
正在下载: Ubuntu 20.04 LTS 安装过程中出现错误。分发名称: &#39;Ubuntu 20.04 LTS&#39; 错误代码: 0x80072eff 正在下载: Ubuntu 20.04 LTS 正在安装: Ubuntu 20.04 LTS 已安装 Ubuntu 20.04 LTS。 正在启动 Ubuntu 20.04 LTS… 装好后自动会打开一个命令行窗口。
Please create a default UNIX user account. The username does not need to match your Windows username. For more information visit: https://aka.ms/wslusers Enter new UNIX username: 这里需要设置用户名和密码，root 不能用，所以换 kelipute，密码就 123456。
Please create a default UNIX user account. The username does not need to match your Windows username. For more information visit: https://aka.ms/wslusers Enter new UNIX username: root adduser: The user `root&#39; already exists. Enter new UNIX username: kelipute New password: Retype new password: passwd: password updated successfully Installation successful! To run a command as administrator (user &#34;root&#34;), use &#34;sudo &lt;command&gt;&#34;. See &#34;man sudo_root&#34; for details. Welcome to Ubuntu 20.04 LTS (GNU/Linux 5.10.16.3-microsoft-standard-WSL2 x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage System information as of Thu Dec 8 13:04:08 CST 2022 System load: 0.0 Processes: 8 Usage of /: 0.4% of 250.98GB Users logged in: 0 Memory usage: 0% IPv4 address for eth0: 172.27.168.157 Swap usage: 0% 0 updates can be installed immediately. 0 of these updates are security updates. The list of available updates is more than a week old. To check for new updates run: sudo apt update This message is shown once once a day. To disable it please create the /home/kelipute/.hushlogin file. kelipute@keliputeC2021A:~$ 如果不关闭 Linux 子系统的话，在 Windows 的命令行窗口执行 wsl -l -v 命令，就可以看到刚才装的 Ubuntu-20.04，状态是 Running 的。
NAME STATE VERSION * docker-desktop-data Stopped 2 Ubuntu-20.04 Running 2 docker-desktop Stopped 2 Linux 子系统的命令行窗口，后续可以从 Windows 的开始菜单，搜索 Ubuntu 打开。
安装和配置 Golang 在 $HOME 目录（cd ~） 下载一个 Linux 环境的 go 安装包。
sudo wget https://studygolang.com/dl/golang/go1.19.4.linux-amd64.tar.gz 把下载下来的压缩包解压到 /usr/local/ 目录。这里不用自己建一个 go 目录，压缩包里有。
sudo tar zxf go1.19.4.linux-amd64.tar.gz -C /usr/local/ 打开配置文件：vim ~/.profile。在最后面追加 Golang 的环境配置。
export PATH=$PATH:$GOROOT/bin export GOROOT=/usr/local/go export GOPATH=$HOME/go export GO111MODULE=on export GOPROXY=https://goproxy.cn,direct 保存之后执行 source ~/.profile 命令，让配置生效。
这个时候理论上就可以使用 go 命令了，可以使用 go version 命令输出 go 的版本，测试一下。
go version go1.19.4 linux/amd64 配置 goland 菜单栏 File =&gt; Settings&hellip; =&gt; Build,Execution,Deployment =&gt; Run Targets
创建一个 WSL 的，这里创建的是 WSL Ubuntu-20.04。下面的配置，Go Executable 选 /usr/local/go/bin/go。GOPATH 选 /home/kelipute/go。都是上面在 WSL 里面配置的 go 的环境变量。
然后配置 Goland 右上角的 Run 和 Debug 按钮。偷懒的办法，先本地点一下 Run 或者 Debug。让 Goland 自动创建一个配置，然后进去 Edit Configurations&hellip; 修改。
选中对应的配置，右边 Run on 默认是 Local machine 这里改成刚才创建的 WSL Ubuntu-20.04，然后把下面的 Build on remote target 勾上。保存之后，这个时候再点 Run 或者 Debug 用的就是 WSL 里面的环境了。
build 报错 run 的时候报错 ... dial tcp 172.217.160.113:443: connect: connection refused ... 这个是 go mod 下不了包，在 WSL 里面改代理就行。
debug 报错 debug 断点调试的时候报错 ... # runtime/cgo cgo: C compiler &#34;gcc&#34; not found: exec: &#34;gcc&#34;: executable file not found in $PATH ... 这个提示表示没安装 gcc。使用 sudo apt install gcc 命令在 WSL 里面安装 gcc 就行。装完之后可以用 gcc -v 命令输出一下 gcc 版本，测试一下。
gcc -v Using built-in specs. COLLECT_GCC=gcc COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/9/lto-wrapper OFFLOAD_TARGET_NAMES=nvptx-none:hsa OFFLOAD_TARGET_DEFAULT=1 Target: x86_64-linux-gnu Configured with: ../src/configure -v --with-pkgversion=&#39;Ubuntu 9.3.0-10ubuntu2&#39; --with-bugurl=file:///usr/share/doc/gcc-9/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++,gm2 --prefix=/usr --with-gcc-major-version-only --program-suffix=-9 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib=auto --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none,hsa --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu Thread model: posix gcc version 9.3.0 (Ubuntu 9.3.0-10ubuntu2) reference（参考） WSL 2 安装Goland WSL2下开发调试goland配合wsl2直接调用wsl2里go环境的方法]]></content></entry><entry><title>Golang 实现简单的 ORM 框架 -- 其他辅助工具</title><url>/post/computer-science/programming-language/framework/orm/golang/middleware/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>orm</tag><tag>middleware(中间件)</tag><tag>mysql</tag><tag>golang</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {orm-go}
/v20/ orm.drawio.html 注意：orm.drawio.html 里面的这个类图和流程图都是和 v20 版本的代码对应的最终形态。 中间件 ORM 框架的中间件和 web 框架的中间件的原理是一样的，这里就不重复了。这里需要考虑的是中间件注册在哪里，查询构造器上显然是不合适的，这里可以考虑和方言抽象一样，放到数据库抽象上去。在执行查询之前，先去数据库实例上把中间件拿出来，然后把执行查询的逻辑放在最里面。
另外，需要定义中间件入参和出参的数据格式。这里和 web 框架一样，要不然套不起来。但是这里比 web 框架会复杂一点，在 web 框架那里入参和出参是一样的，整条链路上都只需要处理 TCP 连接的输入流和输出流。ORM 框架这里，输入的参数有 4 种，即 4 种查询构造器。输出的参数有两种，即数据库执行 SQL 返回的两大类结果。
所以需要把 4 中查询构造器封装到中间件入参里面，入参包括查询构造器的类型和查询构造器的本体。把数据库执行 SQL 返回的两大类结果封装到中间件出参里面，出参包括数据库执行 SQL 返回的两大类结果以及异常。这里又有一个问题了，SQL 语句执行完了，怎么处理返回回来的被封装的两大类结果。
可以注意到，SELECT 和 INSERT、UPDATE、DELETE 是分别对应数据库执行 SQL 返回的两类结果的，而且前面执行 SQL 的时候也是分别使用 query() 和 exec() 的。所以在最外面，也就是进入中间件链条的位置，是可以知道执行的到底是哪类 SQL 语句的。所以对于数据库返回的结果，就可以在这里进行类型断言。</content></entry><entry><title>Golang 实现简单的 ORM 框架 -- INSERT、UPDATE、DELETE</title><url>/post/computer-science/programming-language/framework/orm/golang/insert_update_delete/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>orm</tag><tag>mysql</tag><tag>sqlite3</tag><tag>golang</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {orm-go}
/v20/ orm.drawio.html 注意：orm.drawio.html 里面的这个类图和流程图都是和 v20 版本的代码对应的最终形态。 前言 这篇是接着 SELECT 后面的。INSERT、UPDATE、DELETE 三个加起来都没有 SELECT 复杂。其中 INSERT 因为涉及到不同数据库的方言的处理，相对 UPDATE 和 DELETE 会更复杂一点。
本篇主要涉及：INSERT 语句的构造过程、不同数据库 INSERT 语句不一样的问题的处理方式、UPDATE 语句的构造过程、DELETE 语句的构造过程。
分析 INSERT 语句的使用场景 和 SELECT 的分析套路一样。
这里实现的是一个简单的 ORM，INSERT 的部分就先处理下面这几种。
INSERT INTO 表(列) VALUES(值) INSERT INTO 表(列) VALUES(值1),(值2) INSERT INTO 表(列) VALUES(值) ON DUPLICATE KEY UPDATE 列=VALUES(值) INSERT INTO 表(列) VALUES(值) ON DUPLICATE KEY UPDATE 列=值 从上面的 SELECT 语句结构可以看出，SELECT 语句大致可以分成几个部分。
INSERT INTO 表(列) VALUES(值) ON DUPLICATE KEY UPDATE (表达式) 然后再去看一下 MySQL 的官方文档中对 INSERT 语句的定义和说明。
MySQL INSERT Statement MySQL 8 官方文档中，关于 INSERT 语句的描述：
13.2.6 INSERT Statement
把文档给出的结构和上面的那几种比较一下，提取出文档中相关的描述部分，大概是下面这部分。
INSERT [INTO] tbl_name [(col_name [, col_name] ...)] { {VALUES | VALUE} (value_list) [, (value_list)] ... } [ON DUPLICATE KEY UPDATE assignment_list] assignment: col_name = value | [tbl_name.]col_name assignment_list: assignment [, assignment] ... 构造 INSERT 语句 从最简单的开始 先从最简单的 INSERT INTO 表(列) VALUES(值) 开始。
表和列很熟悉了，直接从元数据里搞。值也是一样的，构建元数据的时候，只通过反射获取了结构体属性的类型，值就是把结构体属性上的值也拿出来。然后按照把语句拼起来就可以了。INSERT 单个值的搞定了，多个值的循环单个值的步骤就行了。
提取查询构造器 在构造 INSERT 语句的时候会发现，在构造 SELECT 语句的时候使用到的一些构造的方法，在构造 INSERT 语句的时候也会用的到。所以这里可以提取一个抽象出来，就叫它 SQL 查询构造器好了。这样后面 UPDATE 和 DELETE 语句构造的时候也可以用的上，不用重复的去写。创建 SELECT 查询构造器或者 INSERT 查询构造器这些具体的构造器的时候，组合一个 SQL 查询构造器进去就行了。
处理 ON CONFLICT ON CONFLICT 在 MySQL 里面就是指的 ON DUPLICATE KEY UPDATE 也可以叫 UPSERT。这里单独拿出来说它是因为 ORM 框架一般不会只支持一种数据库。当需要支持多种数据库的时候，不同数据库的 SQL 语法之间冲突的部分就需要处理。这里用 MySQL 和 SQLite3 做演示。
在 MySQL 里面，语句是这样的：
INSERT INTO 表(列) VALUES(值) ON DUPLICATE KEY UPDATE 列=VALUES(列) INSERT INTO 表(列) VALUES(值) ON DUPLICATE KEY UPDATE 列=值 SQLite 官方文档中，关于 INSERT 语句和 ON CONFLICT 的描述：
INSERT
The ON CONFLICT Clause
在 SQLite3 里面，语句是这样的：
INSERT INTO 表(列) VALUES(值) ON CONFLICT (列) DO UPDATE SET 列=excluded.列; INSERT INTO 表(列) VALUES(值) ON CONFLICT (列) DO UPDATE SET 列=值; 这两个数据库的 ON CONFLICT 语法结构是不一样的，所以在构造 SQL 语句的之后需要分开处理。这里需要对两个数据库的 ON CONFLICT 进行抽象。然后通过观察每个数据库的 SQL 语句，也就是 ON CONFLICT 后面的两种赋值方式，也会得到一个抽象。同样的，MySql 官方文档里也已经告诉你了，这个抽象叫 assignment_list（这里叫赋值表达式）。这个东西 UPDATE 语句里面也会用到，后面再说。
处理的时候先处理完 INSERT 前面一样的部分，然后再处理 ON CONFLICT 的部分。这个地方处理的时候，会有一个从处理公共部分的 INSERT 查询构造器跳到处理不同部分的 ON CONFLICT 查询构造器的步骤。这里可以用在 INSERT 查询构造器里面定义一个抽象的方式，然后构造 INSERT 查询构造器的时候把 ON CONFLICT 查询构造器传进来。
另外一个思路是，INSERT 查询构造器处理完公共部分之后，把自己交给一个 ON CONFLICT 查询构造器。完了 ON CONFLICT 查询构造器处理完之后，在把他自己交给刚才的 INSERT 查询构造器，由 INSERT 查询构造器继续后面的执行 SQL 和处理结果集的步骤。
关于方言抽象的注入 从上面的过程可以发现，方言抽象是需要注入到 INSERT 查询构造器里面的。这就意味着每次创建新的 INSERT 查询构造器的时候，都需要根据到底是生成哪个数据库的 SQL 语句进而注入对应的方言抽象的实例。这显然是非常麻烦的，有一个更好的位置可以放这个方言抽象，这个位置就是数据库抽象。
仔细想一下，不管是哪种具体的查询构造器，构造出来的语句最终都是要靠数据库实例去执行的。而且方言本身也是因为需要使用不同的数据库从而产生的设计，所以把方言放到数据库抽象里面是最合适的。查询构造器在构造 SQL 的时候，就可以直接调用数据库实例里面的方言实例去处理不同数据库里面冲突的部分。
INSERT 语句就差不多了 UPDATE UPDATE 就比较简单了。同样的，把文档放在这里，然后把相关的描述部分提取出来。
13.2.15 UPDATE Statement
UPDATE table_reference SET assignment_list [WHERE where_condition] table_reference 和 where_condition 在 SELECT 那里处理过，assignment_list 在 INSERT 那里处理过。
注意这个 assignment（赋值语句） assignment 接口有两种实现。一个是列，对应 列=VALUES(列) 这种语句。另一种是常规的赋值语句，对应 列=值 这种的。这里注意一下 列=VALUES(列) 这种的，这种语句在 INSERT 的不同的数据库方言里和 UPDATE 语句里面，它的实现又是各不相同的。目前的实现是先把 assignment 接口断言成列，然后不同的数据库方言和 UPDATE 自己实现自己的逻辑。
DELETE DELETE 更简单。同样的，把文档放在这里，然后把相关的描述部分提取出来。
13.2.2 DELETE Statement
DELETE FROM tbl_name [WHERE where_condition] table_reference 在 SELECT 那里处理过，assignment_list 在 INSERT 那里处理过。
执行语句 这三个语句的执行和 SELECT 不一样，它们是没有处理结果集一说的，都是返回影响了多少行。顶多 INSERT 有一个返回插入的行的 id 的功能。所以这里需要再写一套和数据库交互的逻辑，因为返回值不一样。如果是在 Golang 里面，执行 SQL 调用的方法就是不一样的，SELECT 用的是 query() 这三个用的是 exec()。
全流程结束 到这里，生成 INSERT、UPDATE、DELETE 语句、执行语句、处理返回值，就都处理完了。同样的，设计上的东西，看类图、流程图会更加直观。细节上的实现，直接看代码，这个靠说是说不太清楚的。</content></entry><entry><title>Golang 实现简单的 ORM 框架 -- SELECT</title><url>/post/computer-science/programming-language/framework/orm/golang/select/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>orm</tag><tag>mysql</tag><tag>golang</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {orm-go}/v20/ orm.drawio.html 注意：orm.drawio.html 里面的这个类图和流程图都是和 v20 版本的代码对应的最终形态。 前言 注意，这里实现的是一个简单的 ORM 框架，并不是一个完备的 ORM 框架，主要目的是研究原理和设计。
ORM 框架的核心功能主要有两个：1、把数据结构转换成 SQL 语句。2、处理 SQL 语句的执行结果。其他的功能，都是在这两个功能的基础上，再增加亿点点细节而已。
数据结构转换成 SQL 语句这没啥好说的，在这个简单的 ORM 框架里面就是把 Golang 的结构体转换成对应的 SQL 语句。处理 SQL 语句的执行结果主要指的是，简化手动操作，自动把 SELECT 语句执行的结果装到对应的结构体里去。
另外，这两个功能的实现过程都会用到反射操作和内存操作，需要先有这两个方面的知识。
本篇主要涉及：SELECT 语句的分析和抽象、SELECT 语句的构造过程、元数据的构造、结果集的处理。
分析 SELECT 语句的使用场景 这里实现的是一个简单的 ORM，SELECT 的部分就先处理下面这几种。
SELECT &hellip; FROM &hellip; SELECT &hellip; FROM &hellip; WHERE &hellip; SELECT &hellip; FROM &hellip; WHERE &hellip; GROUP BY &hellip; HAVING &hellip; SELECT &hellip; FROM &hellip; WHERE &hellip; ORDER BY &hellip; SELECT &hellip; FROM &hellip; WHERE &hellip; LIMIT &hellip; OFFSET &hellip; SELECT &hellip; AS &hellip; FROM &hellip; AS &hellip; WHERE &hellip; SELECT &hellip; FROM JOIN SELECT &hellip; FROM 子查询 SELECT &hellip; FROM &hellip; WHERE &hellip; IN &hellip; 从上面的 SELECT 语句结构可以看出，SELECT 语句大致可以分成几个部分。
SELECT {*|列|聚合函数} AS 别名 FROM {表|JOIN|子查询} AS 别名 WHERE 条件 GROUP BY 列 HAVING 条件 ORDER BY 列 LIMIT 数字 OFFSET 数字 这样大概的内容和处理流程就有了。就是构建 SELECT 语句需要哪些东西，构建的大概流程是什么样的。然后再去看一下 MySQL 的官方文档中对 SELECT 语句的定义和说明。
MySQL SELECT Statement MySQL 8 官方文档中，关于 SELECT 语句的描述：
13.2.10 SELECT Statement把文档给出的结构和上面的那几种比较一下，提取出文档中相关的描述部分，大概是下面这部分。
SELECT [DISTINCT] select_expr [, select_expr] ... [FROM table_references] [WHERE where_condition] [GROUP BY {col_name}, ...] [HAVING where_condition] [ORDER BY {col_name} [ASC | DESC], ...] [LIMIT {row_count | row_count OFFSET offset}] [FOR UPDATE] } 还需要关注以下关于别名的部分：
列的别名： A select_expr can be given an alias using AS alias_name.
表的别名： A table reference can be aliased using tbl_name AS alias_name or tbl_name alias_name. For each table specified, you can optionally specify an alias.
tbl_name [[AS] alias] 还需要关注一下 JOIN 的部分：
13.2.11.2 JOIN Clause主要是下面这部分，描述的是 JOIN 的结构。
table_reference: { table_factor | joined_table } table_factor: { tbl_name [[AS] alias] | table_subquery [AS] alias [(col_list)] | ( table_references ) } joined_table: { table_reference {JOIN} table_factor [join_specification] | table_reference {LEFT|RIGHT} JOIN table_reference join_specification | table_reference NATURAL [INNER | {LEFT|RIGHT} [OUTER]] JOIN table_factor } join_specification: { ON search_condition | USING (join_column_list) } 也就是说 JOIN 的结构大概可以描述成下面这几种，而且还可以嵌套。
表 JOIN 表 （表 JOIN 表） JOIN 表 表 JOIN 子查询 子查询 JOIN 子查询 还需要关注一下（Sub Query）子查询的部分：
13.2.13 Subqueries简单的理解，JOIN 和子查询都是构建了一个临时的表，和常规的表不同的是，这里的表名和表里的列都不是固定的，而是动态生成的。
到这里 SELECT 语句的构成分析的就差不多了，下面是对 SELECT 语句的构成进行合理的抽象。
分析和抽象 其实抽象的工作是比较容易的，官方文档中的描述已经把抽象给出来了。在这个简单的 ORM 框架里面，大概是下面这几个。
select_expr 对应列和聚合函数 table_references 对应表、JOIN、子查询 where_condition 对应查询条件 col_name 对应列 这里还需要再看一下关于表达式和聚合函数的部分：
9.5 Expressions12.20 Aggregate Functions到这里，在这个简单的 ORM 框架里需要实现的部分，就都差不多都了解了，下面就可以开始动手了。
构造语句 从最简单的开始 先从最简单的 SELECT 列 FROM 表 开始。首先需要构造一个处理 SELECT 语句的对象，封装相关的数据和方法，一般叫它查询构造器（这里叫 SELECT 查询构造器，为了和 INSERT、UPDATE、DELETE 区分开）。
这里上来就会遇到问题，语句里的列和表怎么来。在 ORM 框架中，这里的列和表，不是手动写入的，而是通过解析结构体得到的。既然是通过解析结构体，那么就需要有解析的规则。解析规则由 ORM 框架定义，是解析结构体的属性、还是解析结构体的属性的注释、还是解析 Golang 结构体的属性上的 tag、还是混合模式。
结构体需要按照 ORM 框架定义的解析规则去写，要不然 ORM 框架对着没有按规则来的结构体也是抓瞎的。虽然注释和 tag 可以自定义的随便写，但是结构体它至少会有属性，所以这里可以做一个兜底的策略。这个简单的 ORM 框架里的解析规则为：默认解析结构体的属性，如果结构体的属性上有 tag 就解析 tag。
解析出来的玩意，专业一点的叫法，叫 metadata（元数据），内容是结构体和数据库表的映射关系。包括结构体名和数据库表名的对应关系，结构体的属性名和数据库表的字段名的对应关系，里面还会有一些辅助的信息，这个后面再说。
元数据 在 Golang 里面，可以通过反射解析结构体。通过反射的一些列操作，可以得到结构体名、结构体的属性、还有挂在这些玩意上面的其他信息。这里通过转换结构体名得到数据库表名，拿到结构体名之后，直接驼峰命名转蛇形命名就行。
还可以通过解析注释或者定义接口的方式获取数据库表名。注释就不多说了，通过 AST 解析结构体的注释就行。定义接口，就是定义一个获取数据库表名的接口，然后具体对应数据库表的结构体去实现这个接口。
这样在 SQL 构建的过程中，通过类型断言可以确认结构体是否实现了这个接口，如果实现了这个接口就调用接口取获取自定义的数据库表名。
需要注意的是，元数据里关于结构体的属性名和数据库表的字段名的对应关系的数据，在两个方向上的都需要。因为元数据不止构造 SQL 语句的时候需要正向用，处理结果集的时候也需要用，只不过方向是反过来的，通过数据库字段名，找到对应的结构体属性名。
元数据这块的内容是独立的，可以和 SQL 语句构造的内容隔离开来，自己成为一个独立的模块，这里叫它元数据注册中心。
回到 SQL 语句的构造 解决完元数据的问题，那么语句里的列和表就都有了，这个语句就很好构造了。把传进来的结构体解析之后，把列和表捞出来塞到语句里就行。
对于列来说，后面还可以结合元数据，做一下列存不存在之类的校验。但是如果列写了别名或者是一个复杂查询啥的，校验起来会有点麻烦。
下面搞 WHERE 语句后面的 SELECT 列 FROM 表 WHERE 查询条件。
在动手设计之前，需要先观察一下查询条件的结构。这里列举几个常用的查询条件。
列{=|&gt;|&lt;|!=}值 列=值 AND 列=值 列=值 OR 列=值 列=值 AND (列=值 OR 列=值) 列 LIKE 值 列 IN (值) 这里可以观察到，查询条件的结构，大体上是嵌套起来的左中右的结构。中间是操作符，左边是列或者值，右边一般都是值。
这里看上去是一样的，但是实际上有两层抽象。第一层是：左=列，中间=操作符，右边=值；第二层是：左=第一层抽象 中间=操作符，右=第一层抽象。所以这里需要处理的对象不仅有第一层抽象的 column（列）和 value（值）。还有对第一层抽象的抽象，也就是 expression（表达式）。而且可以得出一个结论，列和值都是表达式的一种。由此可以推论，列和值可以是对象，但是表达式肯定是个接口。
这种左中右的结构，可以联想到树的结构，中间是一个根结点，左右是两个叶子结点。大概的形状见图：orm.drawio.html 2-0。常规的等于、大于、小于、不等于等数学运算和与、或两个逻辑运算可以直接通过这个结构表示。包括 LIKE 和 IN 也可以用这个结构。问题在于 NOT 逻辑运算和原生语句。NOT 只有一边，原生语句直接没有结构。其实这两个玩意，树形结构也是可以兼容的。
NOT 直接让他没有左边就可以了，处理的时候判断一下左边是不是空的就行。大概的形状见图：orm.drawio.html 2-2。
原生语句看上去是自定义的，不符合树的结构，但是可以换个思路，把语句拆开看，其实它已经包含了列和值，所以它就是一个完整的第一层抽象。只不过它只有左边，不需要中间和右边（语句放右边，不需要左边和中间也行）。大概的形状见图：orm.drawio.html 2-4。
代码中处理的时候用递归就行，先递归处理左边的非空叶子，然后处理中间的操作符，然后递归处理右边的非空叶子。每次递归的结果，两边加括号包起来，这样不容易出错。遇到空的位置，空格就不管了。括号和空格多了就多了，只要保证语法没问题就行。
基本的 WHERE 用这个结构就差不多了，需要注意 WHERE IN 那里不仅可以直接填数据，还可能涉及到子查询，这后面再说。
下面处理 GROUP BY SELECT 列 FROM 表 GROUP BY 列 HAVING 查询条件。
GROUP BY 其实很简单了，这玩意有两个部分。前面的列很简单了，没啥好说的。后面的 HAVING 和上面的 WHERE 是一样的。官方文档里面这两个位置都是 where_condition 把上面 WHERE 的逻辑直接拿过来复用就可以。
下面处理 ORDER BY SELECT 列 FROM 表 ORDER BY 列。
这玩意也没啥好说的，就是个列，加上升序或者降序的标志。
下面处理 LIMIT 和 OFFSET SELECT 列 FROM 表 LIMIT 20 OFFSET 100。
这两个也没啥好说的，就是两个数字。
处理 SELECT 后面的 SELECT 列 FROM 表。 SELECT 列 AS 新名字 FROM 表。 SELECT 聚合函数 FROM 表。 SELECT 聚合函数 AS 新名字 FROM 表。 SELECT 后面就两大类东西：列和聚合函数，还会涉及到别名。另外，这里还可以插入原生表达式。
从形态上看，列和聚合函数完全不一样，但是它们都可以放在 SELECT 后面，所以这里肯定有一个抽象。其实官方文档里也已经告诉你了，这个抽象叫 select_expr（这里叫查询表达式）。
这里分开处理这两个玩意。列很简单了，就是列。聚合函数需要一个单独的对象，对象里面放上聚合函数的名字还有聚合函数操作的那个列。别名就目前的场景而言其实很简单，就直接对象里给一个字符串设置一下就好了。加上表、JOIN、子查询的别名之后，这里的别名会变的复杂一点。原生表达式就更简单了，直接把表达式原封不动的放在这里就行了。
到这里，在单个表上的操作基本就都搞定了。下面开始搞 JOIN 和子查询。
JOIN SELECT 列 FROM JOIN。
实现简单的 JOIN 其实不怎么复杂，主要功能包括起别名、选择列、复杂一点的是 JOIN 可以嵌套。
常用的 JOIN 结构大概就是下面这几个：
表 A JOIN 表 B ON &hellip; 表 A AS 新名字 JOIN 表 B AS 新名字 ON &hellip; 表 A JOIN (表 B JOIN 表 C ON &hellip;) ON &hellip; 之前处理 FROM 后面那个位置的时候是直接用的数据库表名，但是那个位置其实可以放的玩意有表名、JOIN、子查询，这明摆了是要有一个抽象的，官方文档也告诉你了，叫 table_references（这里叫表表达式）。但是这三种对象的处理方式肯定是不一样的，语句形态差的都很远，基本没有共同点，所以铁定是分开各写各的。
观察一下上面的几个 JOIN 的样例，又是个左中右的结构，只不过这里的左右两边是一样的，都是 table_references。处理思路和上面的 WHERE 那里处理查询条件的思路是一样的，都是用递归，先处理递归左边的非空叶子，再递归处理右边的非空叶子。另外 JOIN 还有 ON 子句，官方文档里 ON 后面跟的是 search_condition。它和 WHERE 后面的 where_condition 是差不多的，这里不做复杂处理，所以直接拿过来复用。
这里可以换个思路理解，把带有 JOIN 的查询分成两块。JOIN 单独拿出来看，它最终其实就会变成个临时表。把别名当做表名，左右两个 table_references 的列就是临时表的列，这样问题就又回到了之前处理单个数据库表的问题。后面解决子查询的时候，思路也是这样的。
选择列和上面 SELECT 那里处理查询表达式的地方差不多。但是加入 JOIN 之后，列的处理会变得复杂一点，以前的列都是默认在同一个表里的，加入 JOIN 之后，表就不是一个了。所以列里面，必须把自己属于哪个表存着，这样构造列的时候，需要先构造前面的前缀，而且前缀这玩意可以有别名。也就是表和 JOIN 包括后面的子查询都要有别名，列从原来依托于元数据直接构造变成依托于 table_references 构造。
子查询 子查询看着很复杂，但是构成子查询的元素，上面都已经处理过了。前面说过，子查询就是一个临时表，把别名当做表名，左右两个 table_references 的列就是临时表的列，如果子查询设置了查询表达式，那么临时表的列就是查询表达式里面写的那些列。
整体思路和 JOIN 的思路是差不多的，区别的地方在于对列的处理方式不同。处理 JOIN 的时候，查询表达式里的列可能来自不同的表。但是在子查询这里，所有的列都来自子查询的临时表。
语句构建结束 在编码的时候使用 Builder 设计模式实现，基本思路就是将和 SELECT 语句有关的数据的填充和使用这些数据构造 SELECT 语句的部分隔离开。其最终形态就是常见的 ORM 框架的一堆用起来很流畅的链式调用，最后一个 First() 方法或者 Get() 方法，然后查询构造器构建 SQL、执行 SQL、处理结果集一气呵成之后返回结果集。
到这里简单的 SELECT 语句的构建思路就差不多了。下面就是执行语句和处理结果集了。
执行语句 执行语句分为两种，一种是直接执行，一种是事务执行。这两个的区别也很简单就是拿到数据库实例之后，要不要开事务。这个地方可以做两个抽象，一个是数据库的抽象，一个是事务的抽象。其中事务的抽象可以包括数据库的抽象，和装饰器有点像，事务对象可以理解成把数据库的抽象拿过来，用事务功能装饰一下。
这两个抽象其实可以再抽象出一个共同的部分，就是执行 SQL 的部分。无论是数据库的抽象还是事物的抽象，最后都会完成执行 SQL 的操作。这个部分可以再抽象一下，抽象成一个会话，一个会话就表示用户的一次数据库交互操作。
这样编码的时候可以使用依赖注入的方式，把数据库抽象或者事务抽象注入到 SELECT 查询构造器里面。SELECT 查询构造器在构造完 SQL 语句后，就可以继续使用链式调用的方式，调用会话抽象去执行语句。
处理结果集 结果集的处理也不难，前面构造的元数据里不是已经有反方向的映射关系了嘛。先通过数据库返回的结果集里面的结果的字段名，结合元数据，把所有的变量类型先确定好。然按照变量类型构造一个接收数据库返回的结构，接收的时候注意顺序。
成功接收到数据库的返回结果后，先通过元数据构造一个对应的空的结构体。然后通过数据库返回的字段名，结合元数据，反向去找结构体的属性。然后通过反射或者内存操作，把值塞到结构体对应的属性上去。
全流程结束 到这里，构造元数据、生成 SELECT 语句、执行语句、处理返回值，就都处理完了。设计上的东西，看类图、流程图会更加直观。细节上的实现，直接看代码，这个靠说是说不太清楚的。
]]></content></entry><entry><title>符号命名</title><url>/post/computer-science/programming-language/symbol_naming/</url><categories><category>programming-language(编程语言)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag></tags><content type="html">前言 实际开发中符号命名规则应该和团队的风格保持统一，这套符号命名规则是本人的个人喜好。 如果访客您非要说不符合哪里哪里的规范，怎么怎么有问题，那么访客您说的都对。
命名 本人的符号（变量名、方法名）命名方式和主流的命名方式比起来有一些奇怪。 区别主要在于各种各样标记类型的前缀。 声明的变量名和方法名、定义的类型名，都会带前缀。加前缀的目的，主要是为一些特殊的类型作标记，编码过程中引起重视。
比如，一个 map，map 的内容是指向结构体的指针，前缀就是 m3p7s6（var m3p7s6user map[string]*User）。
基本类型就不管了。比如，一个切片，切片的内容是 int 类型，前缀就是 s5（var s5UserId []int）。
另外，如果是临时变量，t4 一定在最前面。
如果变量需要对外开放（声明为 public），则前缀全部为大写。
如果变量不需要对外开放（声明为 protected、private），则前缀全部为小写。
如果变量名是一个单词，则单词首字母用小写（var name string）。
如果变量名是两个或以上的单词，则第一个单词首字母用小写，后面的单词首字母用大写（var s5UserId []int）。
如果有前缀，则单词首字母可用小写也可用大写（var s5name, s5Name []string）。
Golang 命名目录时，多单词用中划线连接。 import 引入时，多单词用下划线连接。 目录里的 hkn 后缀，用于回避关键字，比如：maphkn。 符号命名全部都用驼峰（camel case）。 数据库命名全部都用蛇形（snake case）。 符号命名前缀：
t4，temp，临时变量 c5，const，常量 p7，pointer，指针 a5，array，数组 s5，slice，切片 m3，map，map c7，channel，管道 s6，struct，结构体 i9，interface，接口 f8，function，方法 版本号 版本号可能是 x.y 或者 x.y.z。大版本号从 2 开始，小版本号从 0 开始，以 2 为步长递增。
第 1 版：v2.0.0（v2.0） 第 1 版小改一次：v2.0.2（v2.2） 第 1 版小改一次：v2.0.4（v2.4） 第 1 版大改一次：v2.2.0（v2.6） 第 1 版小改一次：v2.2.2（v2.8） 第 2 版：v4.0.0（v4.0） 通常 x.y 用的多，本人的各种 demo 代码版本一般情况下达不到需要使用 x.y.z 这样的规模。 而且版本号一般不会超过 10，常见的是：v20、v22、v40、v200、v202、v220、v400。</content></entry><entry><title>【过期，留做对比】Golang 实现复杂的 Web 框架</title><url>/post/computer-science/programming-language/framework/web/golang/complex/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>web</tag><tag>http</tag><tag>router(路由)</tag><tag>middleware(中间件)</tag><tag>golang</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
前言 在看这篇之前，建议先看下面这几篇：
Golang 开启 HTTP 服务Golang 实现简单的 Web 框架 &ndash; router(路由)Golang 实现简单的 Web 框架 &ndash; middleware(中间件)路由树是 web 框架的核心。其他的功能，都是在路由树的基础上，再增加亿点点细节而已。
资料 {web-framework-go}/v40 实现功能 主要实现： 路由树（静态、通配符、路径参数、正则表达式）、路由组 全局中间件、可路由的中间件 次要实现： 内存池（请求上下文对象复用） 服务管理（管理多个子服务） 优雅退出、退出时的回调方法 计划实现： 用户认证（中间件实现） 文件操作（上传、下载） 单元测试、集成测试、性能测试 设计文档 路由树 首先是路由树结点的设计。结点的基础数据包括：结点类型、这个路由结点代表的那段路径、命中路由之后的的处理逻辑。
静态路由子结点使用 map 结构存储，查询时直接就可以通过路由段查询子结点。
通配符子结点、路径参数子结点、正则表达式子结点，这三个结点属于特殊结点，而且存在冲突关系，所以单独存储。
为了支持可路由的中间件，路由结点上还需要有存储中间件的地方，这样就可以为每个结点单独设置中间件。
另外，服务在运行的时候只要命中的是同一个路由，那么用到的中间件一定也是相同的，在服务启动的时候就可以把中间件遍历好，然后缓存下来。
// routingNode 路由结点 type routingNode struct { // nodeType 结点类型 nodeType int // part 这个路由结点代表的那段路径 part string // path 从根路由到这个路由结点的全路径 path string // f4handler 命中路由之后的处理逻辑 f4handler HTTPHandleFunc // m3routingTree 路由子树，子结点的 path =&gt; 子树根结点 m3routingTree map[string]*routingNode // p7paramChild 路径参数结点 p7paramChild *routingNode // paramName 路径参数路由和正则表达式路由，都会提取路由参数的名字 paramName string // p7regexpChild 正则表达式结点 p7regexpChild *routingNode // p7regexp 正则表达式 p7regexp *regexp.Regexp // p7anyChild 通配符结点 p7anyChild *routingNode // s5f4middleware 结点上注册的中间件 s5f4middleware []HTTPMiddleware // s5f4middlewareCache 服务启动后，命中结点时，需要用到的所有中间件 s5f4middlewareCache []HTTPMiddleware } 路由树的构造和遍历并不复杂，使用递归逻辑处理即可。不用担心递归带来的性能问题。
对于路由树的递归操作，都发生在服务启动时，这个时候会遍历路由树然后将结果缓存下来。
服务启动后，当请求访问过来时，就可以直接使用缓存里的结果，而不用每次都去遍历路由树。
路由组 路由组就是个语法糖。相当于路由组方法会在路由组内的每个成员注册的时候，附加路由组的路由前缀和路由组定义的中间件。
// Group 添加一组路由 func (p7this *HTTPHandler) Group(path string, s5f4mw []HTTPMiddleware, s5routeData []RouteData) { for _, rd := range s5routeData { t4path := path if &#34;/&#34; != rd.Path { t4path = path + rd.Path } p7this.addRoute(rd.Method, t4path, rd.F4handle, s5f4mw...) } } 中间件 全局中间件和可路由中间件是分开放的。全局中间件存储在核心处理逻辑上。可路由中间件存储在路由树结点上。
// HTTPHandlerInterface 核心处理逻辑的接口定义 type HTTPHandlerInterface interface { http.Handler ... } // HTTPHandler 核心处理逻辑 type HTTPHandler struct { ... // s5f4middleware 全局中间件 s5f4middleware []HTTPMiddleware ... } 当请求访问过来时，第一站到的是核心处理逻辑，核心处理逻辑会完成全局中间件的组装和执行。
func (p7this *HTTPHandler) ServeHTTP(i9w http.ResponseWriter, p7r *http.Request) { ... // 倒过来组装，先组装的在里层，里层的后执行 // 最里层应该是找路由然后执行业务代码 t4chain := p7this.doServeHTTP for i := len(p7this.s5f4middleware) - 1; i &gt;= 0; i-- { t4chain = p7this.s5f4middleware[i](t4chain) } // 写入响应数据这个中间件应该由框架开发者处理 // 它是最后一个环节，应该在最外层 t4m := FlashRespMiddleware() t4chain = t4m(t4chain) t4chain(p7ctx) } 在通过全局中间件之后，进入查询路由树的步骤。查询结果里会有路由树结点上的可路由中间件。
使用和全局中间件一样的套路，完成一遍可路由中间件的组装和执行。最后调用路由上的处理逻辑，开始真正的业务逻辑。
func (p7this *HTTPHandler) doServeHTTP(p7ctx *HTTPContext) { ... p7ri := p7this.findRoute(p7ctx.P7request.Method, p7ctx.P7request.URL.Path) ... // 这里用同样的套路，处理路由上的中间件，最后执行业务代码 t4chain := p7ri.p7node.f4handler for i := len(p7ri.p7node.s5f4middlewareCache) - 1; i &gt;= 0; i-- { t4chain = p7ri.p7node.s5f4middlewareCache[i](t4chain) } t4chain(p7ctx) } 优雅退出 想实现优雅退出，程序就不能阻塞在不可控的位置。这里可以直接把服务丢到协程里去。
然后在最外面，实现一个信号等待的逻辑，这样就可以通过信号控制程序的运行状态。
func (p7this *ServiceManager) Start() { // 启动服务 log.Println(&#34;服务启动中。。。&#34;) for _, p7s := range p7this.s5p7HTTPService { t4p7s := p7s go func() { if err := t4p7s.Start(); nil != err { if http.ErrServerClosed == err { log.Printf(&#34;子服务 %s 已关闭\n&#34;, t4p7s.name) } else { log.Printf(&#34;子服务 %s 异常退出，err:%s\r\n&#34;, t4p7s.name, err) } } }() } log.Println(&#34;服务启动完成。&#34;) // 监听 ctrl+c 信号 c4signal := make(chan os.Signal, 2) signal.Notify(c4signal, os.Interrupt) select { case &lt;-c4signal: ... } } 在可以主动介入程序运行之后，就可以设计主动拒绝新请求的逻辑了。这样可以实现服务不完全停止的情况下，拒绝对外服务。
因为服务停止不仅仅是不对外服务这么简单，在服务真正的停止之前，还有很多善后的工作需要做。
// HTTPHandler 核心处理逻辑 type HTTPHandler struct { ... // isRunning 服务是否正在运行 isRunning bool } func (p7this *HTTPHandler) doServeHTTP(p7ctx *HTTPContext) { // 如果服务已经关闭了就直接返回 if !p7this.isRunning { p7ctx.I9writer.WriteHeader(http.StatusInternalServerError) _, _ = p7ctx.I9writer.Write([]byte(&#34;服务已关闭&#34;)) return } ... } 虽然服务停止前有很多善后的工作需要做，但是理论上不会持续很久。
为了防止意外卡死的情况出现，可以再加一层超时强制停止的逻辑。必要的时候，也可以设计主动强制关闭的入口。
func (p7this *ServiceManager) Start() { ... // 监听 ctrl+c 信号 c4signal := make(chan os.Signal, 2) signal.Notify(c4signal, os.Interrupt) select { case &lt;-c4signal: log.Printf(&#34;接收到关闭信号，开始关闭服务，限制 %d 秒内完成。。。\r\n&#34;, p7this.shutdownTimeOut/time.Second) // 再次监听 ctrl+c 信号 go func() { select { case &lt;-c4signal: log.Println(&#34;再次接收到关闭信号，服务直接退出。&#34;) os.Exit(1) } }() time.AfterFunc(p7this.shutdownTimeOut, func() { log.Println(&#34;优雅关闭超时，服务直接退出。&#34;) os.Exit(1) }) p7this.Shutdown() } } 在拒绝新请求之后，由于有可能还有旧的请求没有处理完，所以是不能立刻就关闭服务的，需要等待一段时间。
func (p7this *ServiceManager) Shutdown() { ... log.Println(&#34;停止接收新请求。&#34;) for _, p7hs := range p7this.s5p7HTTPService { p7hs.Stop() } log.Printf(&#34;等待正在执行的请求结束，等待 %d 秒。。。&#34;, p7this.shutdownWaitTime/time.Second) time.Sleep(p7this.shutdownWaitTime) ... } 服务正式关闭服务之后，可能还有一些收尾的工作需要处理，然后才能彻底退出程序。
比如：系统里如果有缓存的话，可能需要把缓存进行持久化处理；系统关闭时，需要上报数据其他服务等。
这个可以通过回调实现，和中间件的用法类似。不过最后执行的时候，是所有的回调是并发执行的，而不是像中间件一样套起来，一次执行的。
func (p7this *ServiceManager) Shutdown() { ... log.Println(&#34;开始执行子服务的关闭回调。。。&#34;) for _, p7hs := range p7this.s5p7HTTPService { log.Printf(&#34;执行子服务 %s 的关闭回调，限制 %d 秒内完成。。。&#34;, p7hs.name, p7this.shutdownCallbackTimeOut/time.Second) for _, f4cb := range p7hs.s5f4shutdownCallback { t4f4cb := f4cb wg.Add(1) go func() { defer wg.Done() t4ctx, t4cancel := context.WithTimeout(context.Background(), p7this.shutdownCallbackTimeOut) defer t4cancel() t4f4cb(t4ctx) }() } } wg.Wait() ... } 到这里核心的部分就差不多了，细节上的实现可以看代码。
]]></content></entry><entry><title>程序员的定位</title><url>/post/computer-science/programmer/</url><categories><category>computer-science(计算机科学)</category></categories><tags><tag>computer-science(计算机科学)</tag></tags><content type="html">程序员的自我修养 原则一： 技术、语言、框架，本质都是工具。工具的价值，在于提升使用者的效率。
原则二: 如果一种语言或者一个框架很牛逼，那么荣耀属于创造它的人，与使用者没有半毛钱关系。 针对恰当的需求，使用恰当的技术、语言、框架，并且做到按时交付以及高质量，才是使用者的荣耀。
原则三: 大部分人并不是天生有选择恐惧症，也不是天生的杠精。所有关于选择的迷惑或者争吵，大都因为：1、标准不唯一，没有设定清晰的标准；2、标准之间没有优先级或者权重。
慕课网，隔壁王校长
Go语言框架：Beego vs Gin</content></entry><entry><title>使用 Hugo 和 GitHub Pages 搭建站点</title><url>/post/computer-science/application/hugo/install_publish/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>Hugo</tag><tag>GitHub-Pages</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 hugo 0.103.1
Hugo 文档 gohugoio/hugo英文文档中文文档安装 Hugo 在 Hugo Releases页面下载对应操作系统的版本。这里下载的是 hugo_0.103.1_windows-amd64.zip。
下载完成后，解压到想要的位置。这里使用的目录是 D:\hugo\bin。然后将这个目录添加到 系统变量 path 中（我的电脑 -&gt; 属性 -&gt; 高级系统设置 -&gt; 环境变量 -&gt; 系统变量 -&gt; path）。
搞定之后，可以打开控制台，输出一下版本信息，验证一下安装是否成功。或者试试 hugo help 命令，看看能不能输出帮助信息。
&gt; hugo version hugo v0.103.1-b665f1e8f16bf043b9d3c087a60866159d71b48d windows/amd64 BuildDate=2022-09-18T13:19:01Z VendorInfo=gohugoio 如果有需要的话，需要安装 extended 版本的。这里下载的是 hugo_extended_0.103.1_windows-amd64.zip。
&gt; hugo version hugo v0.103.1-b665f1e8f16bf043b9d3c087a60866159d71b48d+extended windows/amd64 BuildDate=2022-09-18T13:19:01Z VendorInfo=gohugoio 创建站点 使用命令创建一个站点，如果没问题的话，hugo 会在当前目录下创建一个名字是 project-name 的目录。
&gt; hugo new site {project-name} 新建的站点没有任何内容，可以使用命令创建一个内容页面。新创建的文件会在目录 content/ 里。创建内容页面的时候也可以带上目录。
&gt; hugo new helloworld.md &gt; hugo new posts/helloworld.md 安装主题 这里就是和别的站点工具不一样的地方了，比如 hexo 和 jekyll，如果没有安装主题的话，是会有一个默认的主题的。
但是 hugo 没有默认主题，需要去主题库下载一个，然后添加到站点里并配置好，这样才能启动站点。如果没有安装主题就启动的话，会报没有模板的错误。
可以去 官方的主题库找一个喜欢的。然后按照主题提供的文档配置一下。
Hugo NexT Hugo NexT这个主题是从 Hexo NexT 移植过来的。
GitHub 项目地址 hugo-next/hugo-theme-next。
按着 Hexo NexT 主题提供的的文档走，把主题配置到站点中。
别忘了先 git init，然后使用命令下载主题 git submodule add https://github.com/hugo-next/hugo-theme-next.git themes/hugo-theme-next。
如果需要升级主题的话，就进入 {path-to-project}/themes/github-style 目录，执行 git pull 命令，拉取最新的代码。
然后把 {path-to-project}themes/hugo-theme-next/exampleSite/ 目录下所有的文件复制到 {path-to-project}/ 目录下覆盖。
最后删除原来的配置文件 config.toml，然后就可以使用命令 hugo server 启动服务了。
另外需要注意的是，这个主题需要 hugo extended 版本，如果用的不是 extended 版本，启动的时候会报下面这样的错，提示去安装 extended 版本。
&gt; hugo server Start building sites … hugo v0.103.1-b665f1e8f16bf043b9d3c087a60866159d71b48d windows/amd64 BuildDate=2022-09-18T13:19:01Z VendorInfo=gohugoio WARN 2022/09/20 21:12:38 Hugo NexT 主题使用了 SCSS 框架，请到官方地址下载 Hugo Extended 版本：https://github.com/gohugoio/hugo/releases ERROR 2022/09/20 21:12:38 Because that use SCSS framework in Hugo NexT, Please download Hugo extended version on offical site: https://github.com/gohugoio/hugo/releases Error: Error building site: TOCSS: failed to transform &#34;main.scss&#34; (text/x-scss). Check your Hugo installation; you need the extended version to build SCSS/SASS.: this feature is not available in your current Hugo version, see https://goo.gl/YMrWcn for more information github-style（选看） github-style这个主题是 github 的页面风格。
GitHub 项目地址 MeiK2333/github-style。
按着 github-style 主题提供的的文档走，把主题配置到站点中。
别忘了先 git init，然后使用命令下载主题 git submodule add git@github.com:MeiK2333/github-style.git themes/github-style。
如果需要升级主题的话，就进入 {path-to-project}/themes/github-style 目录，执行 git pull 命令，拉取最新的代码。
在 content/ 里创建 post/ 目录，后面所有的内容页面都放到这个目录下面，要不然站点里不会展示。
最后在配置文件 config.toml 里设置主题 theme = &quot;github-style&quot;。然后就可以使用命令 hugo server 启动服务了。
站点是没有问题的，可以正常地跑起来。但是这个主题貌似没有实现标签分类，也可能是本人没有找到，所以就放弃继续使用了。
部署到 GitHub Pages 使用命令 hugo -t {theme-name} 来把发布用的目录编译出来。这里就是 hugo -t hugo-theme-next。
默认情况下会编译到 {path-to-project}/publish/ 目录。 可以通过编辑配置文件，在配置文件里添加 publishDir: docs，来修改这个目录。
push 到 github.io 的时候，如果使用的是 publish/ 目录。那么要 push publish/ 目录上去，然后设置 GitHub Pages 的 Branch 为 master 和 /(root)。
如果使用的是 docs/ 目录，那么就要 push 整个项目上去，然后设置 GitHub Pages 的 Branch 为 master 和 docs/。
文本头部信息 draft: true date: 2000-01-01 08:00:00 +0800 lastmod: 2002-01-01 08:00:00 +0800 title: &#34;title&#34; summary: &#34;summary&#34; toc: true categories: - categories(分类) tags: - tags1(标签1) - tags2(标签2) draft：是不是草稿，true=是；false=不是。启动的时候带 --buildDrafts 选项就可以看到草稿的内容。 date：创建时间 lastmod：最后修改时间 title：文本标题 summary：文本概述 toc：是不是显示文章目录，true=是；false=不是。 categories：文本分类，一般一个 tags：文本标签，可以多个 reference（参考） hugo个人博客搭建并部署到GitHub【 for Windows】]]></content></entry><entry><title>【过期，留做对比】Golang 实现简单的 Web 框架 -- middleware(中间件)</title><url>/post/computer-science/programming-language/framework/web/golang/middleware/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>web</tag><tag>http</tag><tag>middleware(中间件)</tag><tag>golang</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {demo-golang}
/demo/web/middleware/ web.drawio.html 中间件 web 框架的中间件可以理解成一种 AOP 方案的实现。可以借助各路教程中常见的洋葱模型来理解中间件的整体结构，这里我用的是同心圆模型。
中间件的同心圆模型结构示例见图：web.drawio.html 4-2。这玩意的核心思路就一个，一层一层的进去，一层一层的出来。另外，需要保证每层的数据格式都是一样的。定义数据格式可以保证，第一顺序可以换，第二可以加层或者减层。
定义中间件的时候需要关注两个重要的组成部分：路由对应的处理方法和中间件的处理方法。
路由对应的处理方法就是，中间件一层一层的进去之后，最里面那层和业务衔接的地方的定义。这里需要处理的是，把中间件的数据格式解包，交给业务逻辑去处理。拿到处理的结果后，在包装成中间件的数据格式，然后丢出去。
中间件的处理方法就是，中间件最外面一层的外面，进入中间件的地方的定义。因为进了第一层之后，每层都是一样的，所以这里只关注最外面一层。这里需要处理的是，把请求数据包装成中间件的数据格式，然后丢进去。拿到处理的结果后，把结果处理成请求想要的响应数据，然后响应回去。
这两个部分定义一起规定了中间件该怎么定义，中间件定义需要围绕这两个定义去实现，要不然调用链条串不起来。
// HTTPHandleFunc 路由对应的处理方法的定义 type HTTPHandleFunc func(p7ctx *HTTPContext) // HTTPMiddleware 中间件的处理方法的定义 type HTTPMiddleware func(next HTTPHandleFunc) HTTPHandleFunc 具体的中间件的实现方式，就像下面这样。
func DemoMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { // before DemoMiddleware next(p7ctx) // after DemoMiddleware } } } 这里假设定义两个中间件。
func AMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { // before AMiddleware next(p7ctx) // after AMiddleware } } } func BMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { // before BMiddleware next(p7ctx) // after BMiddleware } } } 然后这么链起来，B 在内层，A 在外层。
// serve 是最内层业务代码 chain := serve // 组装中间件 mb := BMiddleware() chain = mb(chain) ma := AMiddleware() chain = mb(chain) // 执行 chain(ctx) 最后的效果等价于下面这样的伪代码。
// before AMiddleware // before BMiddleware serve(p7ctx) // after BMiddleware // after AMiddleware 可路由的中间件 可路由的中间件就是在路由树的基础上，分别给每个路由树结点设置中间件。
这样在路由匹配到某个路由结点之后，不仅可以获取到路由的处理方法，还可以获取到路由上设置的中间件。
然后把这些中间件，按照定义好的顺序，套起来即可。</content></entry><entry><title>【过期，留做对比】Golang 实现简单的 Web 框架 -- router(路由)</title><url>/post/computer-science/programming-language/framework/web/golang/router/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>web</tag><tag>http</tag><tag>router(路由)</tag><tag>golang</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {demo-golang}/demo/web/router/ web.drawio.html 路由 在实现路由树之前，首先需要理解路由是干什么的。路由的作用简单地说就是，通过某个请求的请求路径找到对应的处理方法然后处理这个请求。
简单的路由可以使用 map 结构，就是单纯的字符串匹配。map 的 key 就是路由的路径，value 就是路由的处理方法。
像这样 &quot;user/num&quot; =&gt; func userNum()。如果路由命中了 user/num，就调用 func userNum() 去处理。
这个结构很简单了，接收到请求时，用请求的路径直接去 map 里找有没有对应的处理方法。能找到就处理，找不到就找不到，就 404。
简单的路由匹配可以解决，但是复杂一点的功能。比如：路径参数路由、正则匹配路由、通配符路由这样的需求，map 结构就没办法整。
比如 &quot;user/:id&quot; =&gt; func userId() 这样的，我 :id 的位置可以变，这 key 要怎么写，不好搞了嘛。
所以对于后面那些功能，就不能用 map 这种强一对一的结构。就需要换一个思路，观察一下 user/:id 和 user/num。
这两个的差别在于后面的部分，前面是一样的 user，这可以联想到分叉的结构。比如：一棵树的两个树杈、一根树枝上的两个叶子。
所以这里就可以考虑用树形结构来改造一下，把 key 拆了，公共的部分作为根结点，不同的部分作为叶子结点。
这样变成树结构之后，路由的解析步骤，就变成一层一层的了，就可以满足上面那些功能的要求，当一对一匹配不到的时候，就可以看看有没有别的路可以走。
也就是路由树的结点在存储静态子结点的同时，还可以额外设置特殊子结点。在找不到静态路由时，可以继续判断有没有特殊结点可以选择。
比如上面的 user/:id 和 user/num，当来一个 user/1 的时候，我直接打，命不重任何一个。
但是 :id 是一个特殊结点，它可以判断 1 是不是满足它的匹配条件，满足匹配条件的就放它过，也就是路由匹配上了。
路由树的结构示例见图：web.drawio.html 2-2。
路由树的设计没有强制的要求，不是非的像图里那样。按照实际场景的需求，只要设计出路由树的构建和查询规则合理即可。
路由组 路由组其实就是额外提供的方便使用的接口而已，相当于对路由的注册功能做了一层包装。
路由组的内部，会把定义到路由组上的路由路径前缀和中间件，附加到路由组内的每一个路由上去。
]]></content></entry><entry><title>关于帕里特档案馆和西柊慧音</title><url>/about/</url><categories/><tags/><content type="html">帕里特档案馆（重建中，旧篇总计 283，迁移完成 15），是个个人档案馆。
档案馆的内容主要是本人的学习笔记、对学到的东西的解释和思考、对实操过程的记录。
这些玩意本质上是当时的我给以后的我的留言。它们不是教程，更不是论文。
写它们的目的是，如果以后的我忘记了这块的内容，那么希望现在的我可以把以后的我教会。
本人能力有限，因此不能保证所有的内容的时效性和正确性。还请各位到访的访客务必小心。
另外，如果访客您觉得毫无干货或者内容非常水，那么非常抱歉。
站点基于 hugo 0.103.1 extended 版本
搭建。使用的主题是 Hugo NexT
。
站点预计会部属在 github pages 和 gitee pages 上。
如果有问题，欢迎批评指正。同时也欢迎建设性意见。
和本人的交流方式，QQ：786907650；微信号：wxid_k3uqy9xeryn422。昵称和头像都是一样的。
有意交流者，请至少备注是谁和从哪来。</content></entry><entry><title>Golang 开启 HTTP 服务</title><url>/post/computer-science/programming-language/golang/http/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag><tag>http</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {demo-golang}
/demo/web/http/ 开启 HTTP 服务 在 Go 中有多种方式，可以开启 HTTP 服务。但是总的来说基本就下面两大类思路（本质上其实是一类）。
直接使用 net 包从 TCP 开始自行实现。 使用官方提供的封装好的 net/http 包。 使用 net/http 包的时候，需要关注的最核心的部分，就是 Handler 接口 (src/net/http/server.go)。
type Handler interface { ServeHTTP(ResponseWriter, *Request) } 开启 HTTP 服务和 HTTP 请求被处理的流程大致如下：
直接或间接地创建 Server 结构体 (src/net/http/server.go) 的实例。 调用 Server 的 ListenAndServe 方法。 ListenAndServe 方法调用 net.Listen 方法 (src/net/dial.go)，启动 TCP 服务。 net.Listen 方法返回一个 net.Listener 接口 (src/net/dial.go) 的实例。 调用 net.Listener 的 Accept 方法，就可以获取连接上来的 TCP 连接。 新开启一个协程，把这个 TCP 连接丢进去处理。自己则继续监听有没有别的 TCP 连接。 处理流程继续往下，会遇到这行代码：serverHandler{c.server}.ServeHTTP(w, w.req)。 这里调用的就是 Handler 接口的 ServeHTTP 方法。再往下就进入业务处理流程或者框架的入口了。</content></entry><entry><title>2-3-4 树</title><url>/post/computer-science/data-structure/2-3-4_tree/</url><categories><category>data-structure(数据结构)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>data-structure(数据结构)</tag><tag>b-tree</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 Cygwin gcc version 11.2.0
前言 在看 2-3-4 树之前，建议先看 2-3 树。相似的操作在 2-3-4 树不会重复详细的描述。
资料 2-3-4_tree.drawio.html 2-3-4 树 2-3-4 树就是 4 阶 B-树 2-3-4 树和红黑树是等价的： 2-3-4 树的结点个数 = 红黑树的黑色结点个数。 把 2-3-4 树的三结点和四结点拆开，就可以变成红黑树。 把红黑树的红结点移动到和父结点同层，就会变成 2-3-4 树。 2-3-4 树的性质 1、满足二叉查找树的基本性质。
2、结点可以存放一个元素、两个元素。
假设结点结构从左到右分别为：子树 1、元素 1、子树 2、元素 2、子树 3、元素 3、子树 4。 对于存放一个元素的结点。其形态为：子树 1、元素 1、子树 2。 子树 1 存放比 元素 1 小的元素； 子树 2 存放比 元素 1 大的元素。 对于存放两个元素的结点，其形态为：子树 1、元素 1、子树 2、元素 2、子树 3。 子树 1 存放比 元素 1 和 元素 2 都小的元素； 子树 2 存放在 元素 1 和 元素 2 之间的元素； 子树 3 存放比 元素 1 和 元素 2 都大的元素。 对于存放三个元素的结点，其形态为：子树 1、元素 1、子树 2、元素 2、子树 3、元素 3、子树 4。 子树 1 存放比 元素 1、元素 2、元素 3 都小的元素； 子树 2 存放在 元素 1 和 元素 2 之间的元素； 子树 3 存放在 元素 2 和 元素 3 之间的元素； 子树 4 存放比 元素 1、元素 2、元素 3 都大的元素。 3、2-3-4 树是绝对平衡的二叉查找树，所有叶子结点都在同一层上。从根结点到任意一个叶子结点所经过的结点数是相同的。
2-3-4 树的插入 下面列举的情况并不一定覆盖所有的场景，但是典型场景都有了，没有提到的场景可以根据典型场景推导。
只上溢不旋转的情况 1、空树。（类似 2-3 树的第 1 种情况）
2、二结点。（类似 2-3 树的第 2 种情况）
3、三结点。
添加结点 =&gt; 变四结点。（见图：2-3-4_tree.drawio.html 2-2-6）
4、没有父结点的四结点。
添加结点 =&gt; 变五结点 =&gt; 上溢（层数增加）。（见图：2-3-4_tree.drawio.html 2-4-2）
5、有父结点的四结点（父结点不是四结点）。
添加结点 =&gt; 变五结点 =&gt; 上溢（层数不增加）。（见图：2-3-4_tree.drawio.html 2-4-4）
这种情况，四结点是父结点哪个子结点，都是一样的处理逻辑，上溢一次。
这里，父结点可以是二结点也可以是三结点。
6、有父结点的四结点（父结点是四结点）。
添加结点 =&gt; 变五结点 =&gt; 上溢（父结点变五结点）=&gt; 父结点上溢（层数增加）。（见图：2-3-4_tree.drawio.html 2-6）
这种情况，四结点是父结点哪个子结点，都是一样的处理逻辑，上溢两次。
可以通过旋转抵消上溢的情况 1、有父结点的四结点（父结点是四结点、兄弟结点不是四结点）。
添加结点 =&gt; 变五结点 =&gt; 兄弟结点有空位 =&gt; 旋转结点到兄弟结点（抵消上溢，层数不增加）。
这种情况，如果只上溢的话，会上溢两次（自己上溢一次、父结点上溢一次），树的深度增加了，可能影响查询效率。
但是这个时候其实 2-3-4 树是不满的，兄弟结点是有空位的。这时候就可以通过旋转，重新平衡 2-3-4 树。
根据 2-3-4 树有空位的兄弟结点的位置，旋转的情况分为六种，处理方式是差不多的：
向右旋转一次（见图：2-3-4_tree.drawio.html 4-2-2） 向左旋转一次（见图：2-3-4_tree.drawio.html 4-2-4） 向右旋转两次（见图：2-3-4_tree.drawio.html 4-6） 向左旋转两次（无图，参考向右旋转两次的图）。 向右旋转三次（无图，参考向右旋转两次的图）。 向左旋转三次（无图，参考向右旋转两次的图）。 2、有父结点的四结点（父结点是四结点、兄弟结点是四结点、祖父结点是四结点、叔叔结点不是四结点）。
添加结点 =&gt; 变五结点 =&gt; 父结点和兄弟结点都没有空位，无法旋转，只能上溢（父结点变五结点） =&gt; 叔叔结点有空位 =&gt; 旋转结点到叔叔结点（抵消上溢，层数不增加）。
这种情况，如果只上溢的话，会上溢三次（自己上溢一次、父结点上溢一次、祖父结点上溢一次），树的深度增加了，可能影响查询效率。
但是这个时候其实 2-3-4 树是不满的，叔叔结点是有空位的。这时候就可以通过旋转，重新平衡 2-3-4 树。
这里第一次的上溢是避免不了的。上溢之后，重新以父结点为参照，这时就可以看做上面第一种情况。
根据 2-3-4 树有空位的叔叔结点的位置，旋转的情况分为六种，处理方式是差不多的：
（上溢一次后）向右旋转一次（无图，参考向右旋转三次的图）。 （上溢一次后）向左旋转一次（无图，参考向右旋转三次的图）。 （上溢一次后）向右旋转两次（无图，参考向右旋转三次的图）。 （上溢一次后）向左旋转两次（无图，参考向右旋转三次的图）。 （上溢一次后）向右旋转三次（见图：2-3-4_tree.drawio.html 4-8） （上溢一次后）向左旋转三次（无图，参考向右旋转三次的图）。 2-3-4 树的删除 下面列举的情况并不一定覆盖所有的场景，但是典型场景都有了，没有提到的场景可以根据典型场景推导。
删除叶子结点 1、删除三结点的结点。（类似 2-3 树的第 1 种情况）
2、删除四结点的结点。
直接删掉就好了，不会破坏 2-3-4 树的性质。（见图：2-3-4_tree.drawio.html 6-2-4）
3、删除二结点的结点（父结点是二结点、兄弟结点是二结点）。（类似 2-3 树的第 2 种情况）
4、删除二结点的结点（父结点是三结点、兄弟结点是二结点）。（类似 2-3 树的第 3 种情况）
5、删除二结点的结点（父结点是四结点，兄弟结点是二结点）。（类似第 3 种情况）
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（其中一个结点，层次不变） =&gt; 下溢结点和兄弟结点融合。（见图：2-3-4_tree.drawio.html 6-4-6）
6、删除二结点的结点（父结点是二结点、兄弟结点是三结点）。（类似 2-3 树的第 4 种情况）
7、删除二结点的结点（父结点是三结点、兄弟结点是三结点）。（类似 2-3 树的第 5 种情况）
8、删除二结点的结点（父结点是四结点、兄弟结点是三结点）。（类似第 6 种情况）
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3-4_tree.drawio.html 6-6-6）
另外，还有向左旋转三次的情况（见图：2-3-4_tree.drawio.html 6-10-4），向右旋转三次的处理方式是一样的。
9、删除二结点的结点（父结点是二结点、兄弟结点是四结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3-4_tree.drawio.html 6-8-2）
这种情况，删掉结点之后，自己这个位置就是空的了。也就是父结点变得少一个子树，这会破坏 2-3-4 树的性质。
和上面第 3 种情况不同的是，在第 3 种情况中，兄弟结点是二结点，借不出结点。而这里可以借一个结点过来，把这个子树补上，这样就不破坏 2-3-4 树的性质了。
图里的例子是向左旋转一次的情况，向右旋转一次的处理方式是一样的。
10、删除二结点的结点（父结点是三结点、兄弟结点是四结点）。（类似第 9 种情况）
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3-4_tree.drawio.html 6-8-4）
11、删除二结点的结点（父结点是四结点、兄弟结点是四结点）。（类似第 9 种情况）
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3-4_tree.drawio.html 6-8-6）
12、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是二结点、叔叔结点是二结点）。（类似 2-3 树的第 6 种情况）
13、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是三结点、叔叔结点是二结点）。（类似 2-3 树的第 7 种情况）
祖父结点是四结点的处理逻辑是一样的。
14、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是三结点、叔叔结点是三结点）。（类似 2-3 树的第 8 种情况）
叔叔结点是四结点的处理逻辑是一样的。
删除的不是叶子结点 这种情况需和平衡二叉树一样，找到中序遍历的前驱结点或者后继结点，把这两个结点互换位置，这个时候要删除的结点会被换到叶子结点的位置，然后再删除。
2-3-4 树转换成红黑树 1、三结点其中一个元素转化为红黑树的红结点，左右哪个元素都可以。四结点中两边的元素转化为红黑树的红结点。 2、拆分三结点和四结点，和父结点连接的一定是黑结点 （见图：2-3-4_tree.drawio.html 12-2） reference（参考） 掌握了2-3-4树也就掌握了红黑树，不信进来看看，建议收藏！ 理解2-3-4树bilibili&ndash;木子喵neko【neko】红黑树/插入【算法编程#11】【neko】红黑树/删除【算法编程#12】]]></content></entry><entry><title>2-3 树</title><url>/post/computer-science/data-structure/2-3_tree/</url><categories><category>data-structure(数据结构)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>data-structure(数据结构)</tag><tag>b-tree</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 Cygwin gcc version 11.2.0
资料 2-3_tree.drawio.html 2-3 树 2-3 树就是 3 阶 B-树。 把 2-3 树的三结点拆开，就可以变成红黑树。 2-3 树的性质 1、满足二叉查找树的基本性质。
2、结点可以存放一个元素、两个元素。
假设结点结构从左到右分别为：子树 1、元素 1、子树 2、元素 2、子树 3。 对于存放一个元素的结点，其形态为：子树 1、元素 1、子树 2。 子树 1 存放比 元素 1 小的元素； 子树 2 存放比 元素 1 大的元素。 对于存放两个元素的结点，其形态为：子树 1、元素 1、子树 2、元素 2、子树 3。 子树 1 存放比 元素 1 和 元素 2 都小的元素； 子树 2 存放在 元素 1 和 元素 2 之间的元素； 子树 3 存放比 元素 1 和 元素 2 都大的元素。 3、2-3 树是绝对平衡的二叉查找树，所有叶子结点都在同一层上。从根结点到任意一个叶子结点所经过的结点数是相同的。
2-3 树的插入 下面列举的情况并不一定覆盖所有的场景，但是典型场景都有了，没有提到的场景可以根据典型场景推导。
只上溢不旋转的情况 1、空树。
添加结点 =&gt; 变二结点。（见图：2-3_tree.drawio.html 2-2-2）
2、二结点。
添加结点 =&gt; 变三结点。（见图：2-3_tree.drawio.html 2-2-4）
3、没有父结点的三结点。
添加结点 =&gt; 变四结点 =&gt; 上溢（层数增加）。（见图：2-3_tree.drawio.html 2-4-2）
4、有父结点的三结点（父结点不是三结点）。
添加结点 =&gt; 变四结点 =&gt; 上溢（层数不增加）。（见图：2-3_tree.drawio.html 2-4-4）
这种情况，三结点是父结点哪个子结点，都是一样的处理逻辑，上溢一次。
5、有父结点的三结点（父结点是三结点）。
添加结点 =&gt; 变四结点 =&gt; 上溢（父结点变四结点）=&gt; 父结点上溢（层数增加）。（见图：2-3_tree.drawio.html 2-6）
这种情况，四结点是父结点哪个子结点，都是一样的处理逻辑，上溢两次。
可以通过旋转抵消上溢的情况 1、有父结点的三结点（父结点是三结点、兄弟结点不是三结点）。
添加结点 =&gt; 变四结点 =&gt; 兄弟结点有空位 =&gt; 旋转结点到兄弟结点（抵消上溢，层数不增加）。
这种情况，如果只上溢的话，会上溢两次（自己上溢一次、父结点上溢一次），树的深度增加了，可能影响查询效率。
但是这个时候其实 2-3 树是不满的，兄弟结点是有空位的。这时候就可以通过旋转，重新平衡 2-3 树。
根据 2-3 树有空位的兄弟结点的位置，旋转的情况分为四种，处理方式是差不多的：
向右旋转一次（见图：2-3_tree.drawio.html 4-2-2） 向左旋转一次（见图：2-3_tree.drawio.html 4-2-4） 向右旋转两次（见图：2-3_tree.drawio.html 4-4） 向左旋转两次（无图，参考向右旋转两次的图）。 2、有父结点的三结点（父结点是三结点、兄弟结点是三结点、祖父结点是三结点、叔叔结点不是三结点）。
添加结点 =&gt; 变四结点 =&gt; 父结点和兄弟结点都没有空位，无法旋转，只能上溢（父结点变四结点） =&gt; 叔叔结点有空位 =&gt; 旋转结点到叔叔结点（抵消上溢，层数不增加）。
这种情况，如果只上溢的话，会上溢三次（自己上溢一次、父结点上溢一次、祖父结点上溢一次），树的深度增加了，可能影响查询效率。
但是这个时候其实 2-3 树是不满的，叔叔结点是有空位的。这时候就可以通过旋转，重新平衡 2-3 树。
这里第一次的上溢是避免不了的。上溢之后，重新以父结点为参照，这时就可以看做上面第一种情况。
根据 2-3 树有空位的叔叔结点的位置，旋转的情况分为四种，处理方式是差不多的：
（上溢一次后）向右旋转一次（见图：2-3_tree.drawio.html 4-6-2） （上溢一次后）向左旋转一次（无图，参考向右旋转一次的图） （上溢一次后）向右旋转两次（见图：2-3_tree.drawio.html 4-6-4） （上溢一次后）向左旋转两次（无图，参考向右旋转两次的图）。 2-3 树的删除 下面列举的情况并不一定覆盖所有的场景，但是典型场景都有了，没有提到的场景可以根据典型场景推导。
删除叶子结点 1、删除三结点的结点。
直接删掉就好了，不会破坏 2-3 树的性质。（见图：2-3_tree.drawio.html 6-2）
2、删除二结点的结点（父结点是二结点、兄弟结点是二结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（唯一的结点，层次减少） =&gt; 父结点和兄弟结点融合。（见图：2-3_tree.drawio.html 6-4-2）
这种情况，删掉结点之后，自己这个位置就是空的了。也就是父结点变得少一个子树，这会破坏 2-3 树的性质。
处理方式是，就把父结点放到下面一层去，和兄弟结点融合成一个结点，这样就不会破坏 2-3 树的性质了。
图里的例子是父结点的子树 1 被删空了，子树 2 被删空的情况是一样的处理方式。
3、删除二结点的结点（父结点是三结点、兄弟结点都是二结点）。（类似第 2 种情况）
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（其中一个结点，层次不变） =&gt; 下溢结点和兄弟结点融合。（见图：2-3_tree.drawio.html 6-4-4）
4、删除二结点的结点（父结点是二结点、兄弟结点是三结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3_tree.drawio.html 6-6-2）
这种情况，删掉结点之后，自己这个位置就是空的了。也就是父结点变得少一个子树，这会破坏 2-3 树的性质。
和上面第 2 种情况不同的是，在第 2 种情况中，兄弟结点是二结点，借不出结点。而这里可以借一个结点过来，把这个子树补上，这样就不破坏 2-3 树的性质了。
图里的例子是向左旋转一次的情况，向右旋转一次的处理方式是一样的。
另外，还有向左旋转两次的情况（见图：2-3_tree.drawio.html 6-10-2），向右旋转两次的处理方式是一样的。
5、删除二结点的结点（父结点是三结点、兄弟结点是三结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3_tree.drawio.html 6-6-4）
图里的例子是向左旋转一次的情况，向右旋转一次的处理方式是一样的。
6、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是二结点、叔叔结点是二结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（父结点和兄弟结点融合） =&gt; 祖父结点少一个子树 =&gt; 祖父结点下溢（唯一的结点，层次减少） =&gt; 祖父结点和叔叔结点融合。（见图：2-3_tree.drawio.html 6-12-2）
这种情况，初始场景类似上面第 2 种情况，解决方案也是类似第 2 种情况的：下溢 + 融合。初始场景处理完之后，重新以父结点为参照，又是类似上面第 2 种情况，再来一遍就好了。
7、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是三结点、叔叔结点是二结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（父结点和兄弟结点融合） =&gt; 祖父结点少一个子树 =&gt; 祖父结点下溢（其中一个结点，层次不变） =&gt; 下溢结点和叔叔结点融合。（见图：2-3_tree.drawio.html 6-12-4）
这种情况，初始场景类似上面第 2 种情况，解决方案也是类似第 2 种情况的：下溢 + 融合。初始场景处理完之后，重新以父结点为参照，类似上面第 3 种情况，解决方案也是类似第 3 种情况的：下溢 + 融合。
8、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是三结点、叔叔结点是三结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（父结点和兄弟结点融合） =&gt; 祖父结点少一个子树 =&gt; 叔叔结点可以借一个结点 =&gt; 旋转结点到祖父结点的删除结点的位置。（见图：2-3_tree.drawio.html 6-14）
这种情况，初始场景类似上面第 2 种情况，解决方案也是类似第 2 种情况的：下溢 + 融合。初始场景处理完之后，重新以父结点为参照，类似上面第 4 种情况，解决方案也是类似第 4 种情况的：旋转。
删除的不是叶子结点 这种情况需和平衡二叉树一样，找到中序遍历的前驱结点或者后继结点，把这两个结点互换位置，这个时候要删除的结点会被换到叶子结点的位置，然后再删除。
2-3 树转换成红黑树 1、三结点其中一个元素转化为红黑树的红结点，左右哪个元素都可以。 2、拆分三结点，和父结点连接的一定是黑结点。 （见图：2-3_tree.drawio.html 10-2） reference（参考） 二三树、B树(多路平衡查找树)、B+树二叉树，红黑树，23树，B树，B+树2-3树的删除bilibili&ndash;天羽神奈2-3树的定义与搜索图解2-3树插入节点方法2-3树删除节点图解及示例]]></content></entry><entry><title>Virtual Memory（虚拟内存）</title><url>/post/computer-science/operating-system/memory/virtual_memory/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>memory(内存)</tag></tags><content type="html">资料 virtual_memory.drawio.html 虚拟内存涉及的知识点（笔记里不一定有） virtual memory（虚拟内存） memory protection（内存保护） dynamic memory allocation（动态分配内存） virtual memory address（虚拟内存地址） physical memory address（物理内存地址） memory management unit（MMU、内存管理单元） segmented memory management（段式管理） segment（段） segment table（段表） memory fragmentation（内存碎片） page memory management（页式管理） page（页） page table（页表） missing page interruption（缺页中断） multi-level page table（多级页表） Translation Lookaside Buffer（TLB、页表缓存） segmented paged memory management（段页式管理） 虚拟内存 单片机的 CPU 可以直接操作物理内存地址。但是，在这种情况下是无法同时运行多个程序的。
如果多个程序都操作了同一块物理内存，那么他们就可能会互相影响，最终可能导致程序崩溃。
操作系统使用虚拟内存将进程与物理内存进行隔离，为每个进程分配独立的一套虚拟内存地址，这样每个进程就互不干涉。
虚拟内存地址（virtual memory address）：程序使用的内存地址 物理内存地址（physical memory address）：硬件里面的内存地址 虚拟内存地址和物理内存地址的映射由操作系统为进程提供，进程不需要管数据到底存在哪块物理内存上。
进程使用的虚拟地址，会通过 CPU 芯片中的内存管理单元（Memory Management Unit、MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存。
另外，虚拟内存可以使得进程的运行内存超过物理内存大小。因为程序运行符合局部性原理，不是所有的内存都是同时在使用的。
操作系统主要有两种管理内存的方式：内存分段（Segmentation）和内存分页（Paging）。
段式管理 程序由若干个逻辑分段组成，如：代码分段、数据分段、栈段、堆段等。（见图：virtual_memory.drawio.html 2-2）
虚拟地址由段选择子和段内偏移量两部分组成。
段选择子保存在段寄存器。段选择子里的段号用作段表的索引。段表保存段基地址、段界限和特权等级等。（见图：virtual_memory.drawio.html 2-4）
虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。
段式管理的不足 段式管理的不足主要有两点：1、内存碎片；2、内存交换的效率低。
内存碎片有两种：
外部碎片：多个不连续的小物理内存，导致新的程序由于内存不够无法被装载。 内部碎片：程序所有的数据都被装载到了物理内存，但是这个程序有部分的数据可能并不是很常使用，这会导致内存的浪费。 内存交换可以解决外部碎片的问题。可以把程序占用的内存写到硬盘上，然后再从硬盘上读回到内存。在 Linux 中，内存交换空间（Swap 空间），这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。
对于多进程的系统来说，用分段的方式，很容易产生内存碎片。内存交换又受硬盘速度限制，效率低。
页式管理 整个虚拟内存空间和物理内存空间都被切成一个个固定尺寸大小的内存空间（内存页）。
分页可以让内存交换时，读写的数据少一点。在 Linux 中，每一页的大小为 4KB。
虚拟地址与物理地址之间通过页表来映射。（见图：virtual_memory.drawio.html 4-2）
页表存储在内存里，每个进程都有自己的页表。（见图：virtual_memory.drawio.html 4-4）
从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址，所以页表一定要覆盖全部虚拟地址空间。内存管理单元负责将虚拟内存地址转换成物理地址。
虚拟地址分为两部分：页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址。
页表里的页表项中除了物理地址之外，还有一些标记属性的数据，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。
对于一个内存地址转换，分三个步骤：
1、把虚拟内存地址，切分成页号和偏移量。 2、根据页号，从页表里面，查询对应的物理页号。 3、拿物理页号，加上前面的偏移量，就得到了物理内存地址。 当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常。然后进入系统内核空间，分配物理内存，更新进程页表，最后再返回用户空间，恢复进程的运行。
页式管理的优点 由于内存空间都是预先划分好的，所以释放的内存都是以页为单位释放的，不会产生无法给进程使用的小内存。
如果内存空间不够，操作系统会把其他正在运行的进程中的最近没被使用的内存页面给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。
一旦需要的时候，再加载进来，称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。
分页的方式使得在加载程序的时候，不需要一次性都把程序加载到物理内存中。只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。
简单分页的缺陷 简单分页有空间上的缺陷。
在 32 位的环境下，虚拟地址空间共有 4GB（2^32）。假设一个页的大小是 4KB（2^12），每个页表项 4 个字节。
那么 4GB 空间就需要 100 万（2^20）个页，大概 4MB 来存储页表。每个进程都有自己的虚拟地址空间（页表）。那么，100 个进程就需要 400MB 来存储页表。
多级页表（Multi-Level Page Table）可以解决简单分页的空间上的缺陷。
多级页表 多级页表把 100 多万个页表项再分页，用一个一级页表 4KB 表示全部的虚拟地址空间，一级页表一共有 1024 个页表项。每个一级页表项对应一个二级页表，每个二级页表也有 1024 个页表项。
（见图：virtual_memory.drawio.html 4-6）
二级页表可以在需要时进行创建。每个进程都有 4GB 的虚拟地址空间，而对于大多数程序来说，其使用到的空间远未达到 4GB，所以大多数的页表项都是空的。这样就可以节省下很多的空间。
多级页表解决了空间上的问题，但是转换工序带来了时间上的开销。
对于 64 位的系统，多级页表变成了四级目录，分别是：
PGD（page global directory、全局页目录项） PUD（page upper directory、上层页目录项） PMD（page middle directory、中间页目录项） PTE（page table entry、页表项）。 页表缓存 根据局部性原理，程序在一段时间内的执行会集中在整个程序的其中一个部分。相应地，执行所访问的存储空间也局限于某个内存区域。
利用这一特性，可以在 CPU 里放一块缓存，用来存放最常访问的页表项。这个缓存就是页表缓存（Translation Lookaside Buffer、TLB、快表、转址旁路缓存等）
段页式管理 内存分段和内存分页可以组合起来在同一个系统中使用。
先将程序划分为多个逻辑段，接着再把每个段划分为多个页。地址结构由段号、段内页号、页内位移三部分组成。
每个程序一张段表，每个段一张页表，段表中的地址是页表的起始地址，而页表中的地址则是物理页号。
（见图：virtual_memory.drawio.html 6-2）
段页式地址变换中要得到物理地址须经过三次内存访问：
访问段表，得到页表起始地址 访问页表，得到物理页号 将物理页号与页内位移组合，得到物理地址 可用软、硬件相结合的方法实现，虽然增加了硬件成本和系统开销，但提高了内存的利用率。
reference（参考） Crash Course Computer Science（计算机科学速成课） bilibili
CrashCourse 字幕组
Youtube 原视频
小林coding
图解系统</content></entry><entry><title>AVL-Tree（平衡二叉树）</title><url>/post/computer-science/data-structure/avl_tree/</url><categories><category>data-structure(数据结构)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>data-structure(数据结构)</tag><tag>binary-search-tree(二叉查找树)</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 Cygwin gcc version 11.2.0
资料 {demo-c}/data-structure/balanced_binary_tree.c balanced_binary_tree.drawio.html 平衡二叉树 AVL-Tree（balanced binary tree、平衡二叉树）是一种特殊的二叉排序树。
平衡二叉树的性质 1、满足二叉查找树的基本性质。 2、每个结点的左右子树的高度之差的绝对值（平衡因子）最多为 1。 平衡二叉树的插入 左旋和右旋 （见图：balanced_binary_tree.drawio.html 2-2）
4 种需要平衡的场景 1、LL 型
LL 型，直接右旋 x 结点。（见图：balanced_binary_tree.drawio.html 4-2）
2、LR 型
LR 型，直接右旋 x 结点，依然不平衡。（见图：balanced_binary_tree.drawio.html 4-4-2）
需要先左旋 y 结点，再右旋 x 结点。（见图：balanced_binary_tree.drawio.html 4-4-4）
3、RR 型
RR 型，直接左旋 x 结点。（见图：balanced_binary_tree.drawio.html 6-2）
4、RL 型
RL 型，直接左旋 x 结点，依然不平衡。（见图：balanced_binary_tree.drawio.html 6-4-2）
需要先右旋 y 结点，再左旋 x 结点。（见图：balanced_binary_tree.drawio.html 6-4-4）
平衡二叉树的删除 平衡二叉树的删除和二插叉查找树的删除步骤是差不多的。
区别在于，平衡二叉树删除结点之后，需要依次向上检查每一个结点是否平衡。
reference（参考） 平衡二叉树（AVL树）及C语言实现</content></entry><entry><title>在 Linux 中安装 MySQL</title><url>/post/computer-science/application/vmware/mysql/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>vmware</tag><tag>vmware-workstation</tag><tag>linux</tag><tag>ubuntu</tag><tag>mysql</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 VMware Workstation Pro 16 Ubuntu 22.04
前言 没有 Linux 环境的，可以装个虚拟机，然后在里面玩玩： 在 VMware 虚拟机中安装 Linux更新源 &gt; apt update Reading package lists... Done E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied) E: Unable to lock directory /var/lib/apt/lists/ W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied) W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied) Permission denied，非生产环境，一般直接 sudo 就行。
&gt; sudo apt update ... Reading package lists... Done Building dependency tree... Done Reading state information... Done 159 packages can be upgraded. Run &#39;apt list --upgradable&#39; to see them. 看到这个就成功了。
安装 MySql 8 &gt; sudo apt install mysql-server ... mysqld will log errors to /var/log/mysql/error.log mysqld is running as pid 3171 Created symlink /etc/systemd/system/multi-user.target.wants/mysql.service → /lib /systemd/system/mysql.service. Setting up mysql-server (8.0.29-0ubuntu0.22.04.2) ... Processing triggers for man-db (2.10.2-1) ... Processing triggers for libc-bin (2.35-0ubuntu3) ... 看到这个就成功了。安装完成，会直接启动。
可以通过查看 MySQL 版本确认一下。
&gt; mysql -V mysql Ver 8.0.29-0ubuntu0.22.04.2 for Linux on x86_64 ((Ubuntu)) 也可以通过 ps 命令确认一下。
&gt; ps aux | grep mysql mysql 3357 0.2 9.8 1780000 391948 ? Ssl 22:46 0:04 /usr/sbin/mysqld 修改 MySQL 密码 安装 MySQL 的时候会生成一个默认密码。
&gt; sudo cat /etc/mysql/debian.cnf # Automatically generated for Debian scripts. DO NOT TOUCH! [client] host = localhost user = debian-sys-maint password = flP8kWluyyOyvs9Y socket = /var/run/mysqld/mysqld.sock [mysql_upgrade] host = localhost user = debian-sys-maint password = flP8kWluyyOyvs9Y socket = /var/run/mysqld/mysqld.sock 其中 user 和 password 就对应用户名和密码。
# 连接 MySQL &gt; mysql -udebian-sys-maint -pflP8kWluyyOyvs9Y # 修改密码 mysql&gt; use mysql; mysql&gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED WITH mysql_native_password BY &#39;root&#39;; 让 MySQL 可以远程访问 MySQL 配置文件 没有配置远程访问前，通过 netstat 命令查看 MySQL 的端口是这样的：
&gt; netstat -ano | grep 3306 tcp 0 0 127.0.0.1:33060 0.0.0.0:* LISTEN off (0.00/0/0) tcp 0 0 127.0.0.1:3306 0.0.0.0:* LISTEN off (0.00/0/0) 这里的 127.0.0.1:3306 表示 MySQL 只接收本地的连接。
打开 MySQL 配置文件：sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf。
... # Instead of skip-networking the default is now to listen only on # localhost which is more compatible and is not less secure. bind-address = 127.0.0.1 mysqlx-bind-address = 127.0.0.1 ... 找到 bind-address，原来是 127.0.0.1，改成 0.0.0.0。 然后重启 MySQL 服务：sudo service mysql restart。 配置远程访问后，通过 netstat 命令查看 MySQL 的端口是这样的：
&gt; netstat -ano | grep 3306 tcp 0 0 127.0.0.1:33060 0.0.0.0:* LISTEN off (0.00/0/0) tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN off (0.00/0/0) 这里的 0.0.0.0:3306 表示 MySQL 现在可以和外部建立连接。
MySQL 配置 登入 MySQL 实例，给 root 用户设置远程连接权限。
mysql&gt; use mysql; mysql&gt; select user,host from user; +------------------+-----------+ | user | host | +------------------+-----------+ | debian-sys-maint | localhost | | mysql.infoschema | localhost | | mysql.session | localhost | | mysql.sys | localhost | | root | localhost | +------------------+-----------+ 5 rows in set (0.00 sec) 没设置前 root 用户对应的 host 为 &ldquo;localhost&rdquo;。
mysql&gt; update user set host=&#39;%&#39; where user=&#39;root&#39; and host=&#39;localhost&#39;; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql&gt; select user,host from user; +------------------+-----------+ | user | host | +------------------+-----------+ | root | % | | debian-sys-maint | localhost | | mysql.infoschema | localhost | | mysql.session | localhost | | mysql.sys | localhost | +------------------+-----------+ 5 rows in set (0.00 sec) 将 root 用户对应的 host 设置为 &ldquo;%&rdquo; 表示可以进行远程连接。
mysql&gt; flush privileges; 别忘了，刷新数据库。
配置虚拟机防火墙 查看防火墙规则列表。
&gt; sudo iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 设置 3306 端口外部可以访问。
udo iptables -A INPUT -p tcp --dport 3306 -j ACCEPT 设置完会变成下面这样：
&gt; sudo iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT tcp -- anywhere anywhere tcp dpt:mysql Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 需要注意的是，用命令配置是即时生效的，重启以后规则会丢失。想要让配置永久有效，可以去修改 iptables 配置文件。命令 service iptables save 也可以让 iptables 设置长久有效，重启后不丢失。
虚拟机端口映射 选中需要修改的虚拟机 最上面的导航栏 &ndash;&gt; 点击 &ldquo;编辑&rdquo; &ndash;&gt; 点击 &ldquo;虚拟网络编辑器&rdquo; 打开命令行，使用 ifconfig 命令查看虚拟机在子网中的 IP。这里有可能会有很多个 IP，单看这里可能无法确定。
&gt; ifconfig ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.226.128 netmask 255.255.255.0 broadcast 192.168.226.255 inet6 fe80::7dd9:3248:6626:cde9 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:5c:43:29 txqueuelen 1000 (Ethernet) RX packets 607 bytes 57711 (57.7 KB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 283 bytes 28521 (28.5 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 1000 (Local Loopback) RX packets 266 bytes 22796 (22.7 KB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 266 bytes 22796 (22.7 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 虚拟网络编辑器 &ndash;&gt; 在最上面的列表里面找到 VMnet8（子网地址是 192.168.226.0 的那个）。从上面 ifconfig 命令的结果里面，找到在子网地址下的那个（这里就是 192.168.226.128） 在下面的 &ldquo;VMnet 信息&rdquo; 里面&ndash;&gt; 选择 &ldquo;NAT 模式&rdquo; &ndash;&gt; 点击右边的 &ldquo;NAT 设置&rdquo; 按钮。如果按钮不让点，就先点一下最下面的 &ldquo;更改设置&rdquo;。 端口转发 &ndash;&gt; 点击 &ldquo;添加&rdquo; &ndash;&gt; 添加一个主机端口和虚拟机端口的映射（这里把主机 3306 映射到虚拟机 3306），虚拟机 IP 地址就填上面的 192.168.226.128。 测试 搞完上面的步骤，如果没问题的话，理论上就可以从主机访问虚拟机的 MySQL 服务了。连接有点慢，应该和虚拟机环境有关系。
参考 Ubuntu安装mysql8, 修改mysql密码，配置远程连接虚拟机端口映射提供mysql远程服务如何在Ubuntu20.04上安装MySQL以及如何配置MySQL的远程连接Ubuntu 开启Mysql 3306端口远程访问]]></content></entry><entry><title>在 VMware 虚拟机中安装 Linux</title><url>/post/computer-science/application/vmware/linux/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>vmware</tag><tag>vmware-workstation</tag><tag>linux</tag><tag>ubuntu</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 VMware Workstation Pro 16 Ubuntu 22.04
安装 Ubuntu 22.04 下载页面在哪 官网的下载路径：
官网官网 &ndash;&gt; 最上面的导航栏 &ndash;&gt; 点击 &ldquo;Download&rdquo; &ndash;&gt; 选择 &ldquo;Ubuntu Desktop&rdquo; &ndash;&gt; 然后页面就会变成 &ldquo;Download Ubuntu Desktop&rdquo; 的页面，一般都是一个 LTS 版本，如果没有特别需求，直接点旁边的 &ldquo;Download&rdquo; 按钮就行了。 如果有特别的需求，在 &ldquo;Download&rdquo; 按钮的下面有一个 &ldquo;see our alternative downloads&rdquo; 链接，点击进入 Alternative downloads页面。 如果 &ldquo;Alternative downloads&rdquo; 页面还不能满足需求，在 &ldquo;Alternative downloads&rdquo; 页面的最下面，有一个 &ldquo;Past releases and other flavours&rdquo; 板块 &ndash;&gt; 板块里面有一个 Past releases，可以在里面找需要的版本。 中文官网的下载路径：
中文官网官网 &ndash;&gt; 最上面的导航栏 &ndash;&gt; 点击 &ldquo;下载&rdquo; &ndash;&gt; 选择 &ldquo;桌面&rdquo; &ndash;&gt; 然后页面就会变成 &ldquo;下载Ubuntu桌面系统&rdquo; 的页面，一般都是一个 LTS 版本，如果没有特别需求，直接点旁边的 &ldquo;下载&rdquo; 按钮就行了。 如果有特别的需求，在 &ldquo;下载&rdquo; 按钮的下面有一个 &ldquo;其他下载&rdquo; 链接，点击进入 其他下载页面。 如果 &ldquo;其他下载&rdquo; 页面还不能满足需求，在 &ldquo;其他下载&rdquo; 页面的最下面，有一个 &ldquo;历史版本和其他风味版&rdquo; 板块 &ndash;&gt; 板块里面有一个 查看历史版本，可以在里面找需要的版本。 下载和安装 在刚才的下载页面，下载 Ubuntu 22.04 LTS 的安装包。
新建虚拟机：
打开 VMware Workstation Pro。 最上面的导航栏 &ndash;&gt; 点击 &ldquo;文件&rdquo; &ndash;&gt; 点击 &ldquo;新建虚拟机&rdquo; &ndash;&gt; 一般一路下一步就行，中间需要选择上面下载的 Ubuntu 的安装包作为虚拟机的操作系统。 新建虚拟机完成后，启动虚拟机。 第一次进入操作系统，会弹出 Install（正常安装） 页面：
Install &ndash;&gt; 语言选择 English(US)（英语） &ndash;&gt; 点击 Continue。 Updates and other software &ndash;&gt; 选择 Normal installation（正常安装） &ndash;&gt; 其他的默认 &ndash;&gt; 点击 Continue。 Installation type &ndash;&gt; 选择 Erase disk and install Ubuntu（清除硬盘并安装） &ndash;&gt; 点击 Install Now &ndash;&gt; 点击 Continue。 Where are you? &ndash;&gt; 选择 Shanghai &ndash;&gt; 点击 Continue。 Who are you? &ndash;&gt; 填：计算机名称、用户名、密码 &ndash;&gt; 选择 Log in automatically（自动登录） &ndash;&gt; 点击 Continue。 其余直接点击下一步，然后等待安装完成。 共享文件夹 最上面的导航栏 &ndash;&gt; 点击 &ldquo;虚拟机&rdquo; &ndash;&gt; 点击 &ldquo;设置&rdquo;。 最上面的选项卡 &ndash;&gt; 点击 &ldquo;选项&rdquo; &ndash;&gt; 在下面的列表里找到 &ldquo;共享文件夹&rdquo; &ndash;&gt; 点击 &ldquo;共享文件夹&rdquo;。 右边的 &ldquo;文件夹共享&rdquo; 里选择 &ldquo;总是启用&rdquo; &ndash;&gt; 右边的 &ldquo;文件夹&rdquo; 里点击 &ldquo;添加&rdquo;。 点 &ldquo;下一步&rdquo; &ndash;&gt; 命名共享文件夹 &ndash;&gt; 主机路径就是本机的目录，名称就是映射到 Ubuntu 里的目录。 启动虚拟机，共享文件夹应该会被映射到 /mnt/hgfs/上面的名称对应的目录。如果没有 hgfs 目录就创建一个。如果看不到共享文件夹，就执行下面两条命令，然后再次进入 hgfs 目录就能看见了。
&gt; vmware-hgfsclient &gt; sudo vmhgfs-fuse .host:/ /mnt/hgfs -o allow_other 上面这样的操作是一次性的，下次开机又要重复操作。如果想让系统每次开机的时候自动挂载，需要编辑 /etc/fstab。这样系统启动时会自动将文件挂载到指定位置。
sudo vim /etc/fstab，使用管理员权限打开 /etc/fstab。在最后添加一行：.host:/ /mnt/hgfs fuse.vmhgfs-fuse allow_other 0 0。这样下次系统启动时就会自动挂载了。
常用软件 gcc # 这个命令将会安装一系列软件包，包括 gcc、g++、make # 一路 y 就行 &gt; sudo apt install build-essential # 可以通过输出 gcc 版本来检查是否安装成功 &gt; gcc --version gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0 git &gt; sudo apt-get update # 安装依赖 &gt; sudo apt-get install libcurl4-gnutls-dev libexpat1-dev gettext libz-dev libssl-dev # 安装 git &gt; apt-get install git # 可以通过输出 git 版本来检查是否安装成功 &gt; git --version netstat &gt; sudo apt-get install net-tools vim # 一路 y 就行 &gt; sudo apt-get install vim-gtk reference（参考） Download Ubuntu DesktopVMware虚拟机安装Ubuntu详解VMware虚拟机Ubuntu共享文件夹vmware ubuntu /mnt/hgfs 没有权限查看 找不到共享文件夹如何在 Ubuntu 20.04 上安装 GCC(build-essential)Ubuntu上 git的安装与使用]]></content></entry><entry><title>在 Windows 中安装 VMware 的产品</title><url>/post/computer-science/application/vmware/windows/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>windows</tag><tag>vmware</tag><tag>vmware-workstation</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 VMware Workstation Pro 16
安装 VMware Workstation 下载页面在哪 官网的下载路径：
官网官网 &ndash;&gt; 最上面的导航栏 &ndash;&gt; 点击 &ldquo;Resources&rdquo; &ndash;&gt; 在 &ldquo;Tools &amp; Training&rdquo; 下面 &ndash;&gt; 找到 &ldquo;Product Downloads&rdquo; &ndash;&gt; 点击后进入 下载页面最上面的标签页 -&gt; 选择 &ldquo;ByCategory&rdquo;，不选也行。 然后在下面找到 &ldquo;Desktop &amp; End-User Computing&rdquo;，然后在列表里找到 &ldquo;VMware Workstation Pro&rdquo; 那一行，在那一行最右边点击 &ldquo;Download Product&rdquo; 进入 &ldquo;Download VMware Workstation Pro&rdquo; 的下载页面。 中文官网的下载路径：
中文官网中文官网 &ndash;&gt; 最上面的导航栏 &ndash;&gt; 点击 &ldquo;资源&rdquo; &ndash;&gt; 在 &ldquo;工具和培训&rdquo; 下面 &ndash;&gt; 找到 &ldquo;产品下载&rdquo; &ndash;&gt; 点击后进入 下载页面最上面的标签页 -&gt; 选择 &ldquo;按类别&rdquo;，不选也行。 然后在下面找到 &ldquo;Desktop &amp; End-User Computing&rdquo;，然后在列表里找到 &ldquo;VMware Workstation Pro&rdquo; 那一行，在那一行最右边点击 &ldquo;Download Product&rdquo; 进入 &ldquo;Download VMware Workstation Pro&rdquo; 的下载页面。 下载和安装 在刚才的下载页面，切换 VMware Workstation Pro 的版本，选择 16.0 版本，然后下载 &ldquo;for Windows&rdquo; 的版本。
下载好之后执行安装，一般一路下一步就行。安装完成后，理论上应该购买正版然后激活。但是找个激活码也不是不行，不过建议经济允许的情况下，买一个正版，然后在心安理得的用激活码。
VMware Tools 这玩意应该是自动装好的，不需要手动安装。如果用不了，那再说。
]]></content></entry><entry><title>使用 Docker 部属 MySQL 8.0</title><url>/post/computer-science/application/docker/mysql8/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>docker</tag><tag>database(数据库)</tag><tag>mysql</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 Docker v20.10.17
拉取镜像 访问 Docker MySQL 镜像库拉取 MySQL 8.0 镜像。
&gt; docker pull mysql:8.0 8.0: Pulling from library/mysql ... Digest: sha256:147572c972192417add6f1cf65ea33edfd44086e461a3381601b53e1662f5d15 Status: Downloaded newer image for mysql:8.0 docker.io/library/mysql:8.0 拉好之后，可以在 image 列表看到。
&gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE mysql 8.0 40b83de8fb1a 4 days ago 535MB 启动容器 设置好参数，然后后台启动容器。
&gt; docker run -itd --name mysql-8-dev -p 127.0.0.1:13306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:8.0 45804f67e3bf4b79735c308a8073131525c5fbc6f714e8fca5efb4f628127532 docker run -itd：在后台运行容器，并且打印容器 id。 --name mysql-8-dev：设置容器的名字为 mysql-8-dev。 -p 127.0.0.1:13306:3306：将本机的 127.0.0.1:13306 端口和容器的 3306 端口进行映射。 -e MYSQL_ROOT_PASSWORD=123456：设置 mysql 密码为 123456，用户名默认为 root。 mysql:8.0：使用 mysql:8.0 镜像运行容器。 启动好容器之后，可以通过 docker ps 命令查看容器状态。
&gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 45804f67e3bf mysql:8.0 &#34;docker-entrypoint.s…&#34; 15 seconds ago Up 14 seconds 33060/tcp, 127.0.0.1:13306-&gt;3306/tcp mysql-8-dev 进入容器 使用命令行模式进入容器。mysql-8-dev 就是上面设置的容器的名字。也可以用 docker ps 命令中显示的容器的 id（CONTAINER ID）。
&gt; docker exec -it mysql-8-dev /bin/bash bash-4.4# 这里直接使用用户名和密码访问 mysql。
&gt; bash-4.4# mysql -uroot -p123456 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 10 Server version: 8.0.31 MySQL Community Server - GPL Copyright (c) 2000, 2022, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement. mysql&gt; 这样就表示成功进到 mysql 里面了。
]]></content></entry><entry><title>Linux memory（Linux 内存）</title><url>/post/computer-science/operating-system/memory/linux_memory/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>memory(内存)</tag></tags><content type="html">资料 linux_memory.drawio.html 页式管理 Linux 内存主要采用的是页式内存管理，但是由于 Intel 处理器的发展史，Linux 无法避免分段管理。
因为操作系统必须按照硬件结构设计，所以 Linux 的内核必须服从 CPU 的硬件结构。
虚拟地址空间 在 Linux 中，虚拟地址空间被分为内核空间和用户空间。
32 位系统，内核空间占用 1G，位于最高处，剩下的 3G 是用户空间。 （见图：linux_memory.drawio.html 2-2） 64 位系统，内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。 （见图：linux_memory.drawio.html 2-4） 进程在用户态时，只能访问用户空间内存。只有进入内核态后，才可以访问内核空间的内存。
虽然每个进程都各自有独立的虚拟内存，但是虚拟内存中的内核地址，关联的是相同的物理内存。
这样，进程切换到内核态后，就可以很方便地访问内核空间内存。
用户空间分布 32 位系统的用户空间分布的情况：
程序文件段（.text），包括二进制可执行代码。 已初始化数据段（.data），包括静态常量。 未初始化数据段（.bss），包括未初始化的静态变量。 堆段，包括动态分配的内存，从低地址开始向上增长。 文件映射段，包括动态库、共享内存等，从低地址开始向上增长。 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便自定义大小. （见图：linux_memory.drawio.html 2-6） 在这 6 个内存段中，堆和文件映射段的内存是动态分配的。
比如，使用 C 标准库的 malloc() 或者 mmap()，就可以分别在堆和文件映射段动态分配内存。
malloc malloc() 不是系统调用，而是 C 库里的函数，用于动态分配内存。
malloc 申请内存的时候，会有两种方式向操作系统申请堆内存:
通过 brk() 系统调用从堆分配内存，通过 brk 将堆顶指针向高地址移动，获得新的内存空间。 （见图：linux_memory.drawio.html 4-2） 通过 mmap() 系统调用在文件映射区域分配内存，也就是从文件映射区拿一块内存。 （见图：linux_memory.drawio.html 4-4） malloc 源码默认定义了一个阈值：如果用户分配的内存小于 128 KB，则使用 brk；如果用户分配的内存大于 128 KB，则使用 mmap。
分类内存采用两种方式的原因有两个：1、避免堆内存碎片；2、避免频繁的进行系统调用。
malloc 分配的是虚拟内存。如果分配后的虚拟内存没有被访问的话，是不会将虚拟内存不会映射到物理内存，这样就不会占用物理内存了。
只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断。然后操作系统会建立虚拟内存和物理内存之间的映射关系。
堆内存碎片 假设，先 malloc 2+2+2 K 的内存，然后 free 2+2 K。因为通过 brk 从堆空间分配的内存，并不会归还给操作系统。所以，这时 malloc 内存池就有 4K 的空闲。
如果这个时候 malloc 小于 4K ，就可以直接从内存池分配，如果 malloc 大于 4K，就必须再从堆上申请。
如果程序后来的 malloc 都大于 4K ，那么这个空闲的 4K 就变成了无法使用到的内存碎片。（见图：linux_memory.drawio.html 4-6）
生产环境的程序通常会长时间运行，所以这样的碎片有可能会越积越多，尤其是如果频繁的 malloc 和 free 小块内存。
malloc 在分配内存的时候，并不是按用户预期申请的字节数来分配内存空间大小，而是会预分配更大的空间作为内存池。具体会预分配多大的空间，跟 malloc 使用的内存管理器有关系。
内存池 brk 和 mmap 都是系统调用。执行系统调用是要进入内核态的，然后在回到用户态，运行态的切换会耗费不少时间。 如果都用 mmap 来分配内存，等于每次都要执行系统调用。
另外，因为 mmap 分配的内存每次释放的时候，都会归还给操作系统，于是每次 mmap 分配的虚拟地址都是缺页状态的，然后在第一次访问该虚拟地址的时候，就会触发缺页中断。
频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大。
为了改进这两个问题，malloc 通过 brk 系统调用在堆空间申请内存的时候，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放的时候，就缓存在内存池中。
等下次在申请内存的时候，就直接从内存池取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还存在，这样不仅减少了系统调用的次数，也减少了缺页中断的次数，这将大大降低 CPU 的消耗。
/proc/{pid}/maps 程序运行后可以通过 /proc/{pid}/maps 文件查看进程的内存分布情况。
02dc7000-02de8000 rw-p 00000000 00:00 0 [heap] 02de8000 - 02dc7000 = 21000，也就是在 heap（堆上）分配了 21000 字节。如果 malloc 是通过 mmap 分配的，右边显示 [heap] 的那个位置就啥都没有。
需要注意的是，程序中返回的地址应该是 02dc7010 而不是 02dc7000。前面的 16 字节（0x10）是内存块的头信息。内存块头信息在 《Linux\Unix 系统编程手册》 第 7 章里有提到。
图片：linux-memory.drawio/6-2、内存块头信息 free 如果 malloc 通过 brk 方式申请的内存，free 内存后，堆内存还存在。这是因为内存会被放入 malloc 的内存池里，当进程再次申请内存时就可以直接复用。当进程退出后，操作系统就会回收进程的所有资源。
如果 malloc 通过 mmap 方式申请的内存，free 释放内存后就会立刻归还给操作系统。也就是，如果是通过 brk 方式申请的内存，free 后，依然可以在 /proc/{pid}/maps 文件里看到，因为内存还没有被归还给操作系统。如果是通过 mmap 方式申请的内存，free 后，就看不到了。
free 函数使用的时候只传入一个内存地址，没有传入内存大小。内存大小被存在了这个指针指向的内存块的内存块的头信息里。
reference（参考） Crash Course Computer Science（计算机科学速成课） bilibili
CrashCourse 字幕组
Youtube 原视频
小林coding
图解系统
Linux 文档
malloc(3) - allocate and free dynamic memory
proc(5) - process information pseudo-filesystem
《Linux\Unix 系统编程手册》 第 7 章</content></entry><entry><title>使用 Jekyll 主题</title><url>/post/computer-science/application/jekyll/theme/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>Ruby</tag><tag>Jekyll</tag><tag>GitHub-Pages</tag></tags><content type="html">环境 CPU AMD64(x86_64) Windows 11 家庭版 Ruby 3.1.2 RubyGems 3.3.7 Jekyll 4.2.2
jekyll-TeXt-theme Github：
https://github.com/kitian616/jekyll-TeXt-theme
官方文档：
https://tianqi.name/jekyll-TeXt-theme/
第 1 步，从 Github 上把项目下载下来。
第 2 步，安装 Ruby 依赖包。
&amp;gt; bundle install --path vendor/bundle [DEPRECATED] The `--path` flag is deprecated because it relies on being remembered across bundler invocations, which bundler will no longer do in future versions. Instead please use `bundle config set --local path &amp;#39;vendor/bundle&amp;#39;`, and stop using this flag 一大堆输出。。。 Using jekyll-text-theme 2.2.6 from source at `.` Bundle complete! 3 Gemfile dependencies, 41 gems now installed. Bundled gems are installed into `./vendor/bundle` Post-install message from html-pipeline: ------------------------------------------------- Thank you for installing html-pipeline! You must bundle Filter gem dependencies. See html-pipeline README.md for more details. https://github.com/jch/html-pipeline#dependencies ------------------------------------------------- 安装完成后，可以使用 Jekyll 集成的那个开发用的服务器，然后使用浏览器在本地进行预览。
这里同样会遇到 webrick 无法加载的那个异常情况，解决方法是一样的。
jekyll-theme-chirpy Github：
https://github.com/cotes2020/jekyll-theme-chirpy
官方文档（同时也是个 Demo）：
https://chirpy.cotes.page/
个人感觉，这个主题比上面那个正在用的要好看不少。
但是无奈，按照官方文档走流程的时候，在发布流程的 Github Action 步骤卡住了。而且没有找到解决方案，遂遗憾放弃。</content></entry><entry><title>使用 Jekyll 和 GitHub Pages 搭建站点</title><url>/post/computer-science/application/jekyll/install_publish/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>Ruby</tag><tag>Jekyll</tag><tag>GitHub-Pages</tag></tags><content type="html"><![CDATA[环境 CPU AMD64(x86_64) Windows 11 家庭版 Ruby 3.1.2 RubyGems 3.3.7 Jekyll 4.2.2
安装 Jekyll 在官方文档中有详细的安装 Jekyll 的流程说明。
Jekyll 官方文档的中文版：http://jekyllcn.com/。
第 1 步，安装 Ruby。
Ruby 官方网站的中文版：http://www.ruby-lang.org/zh_cn/。
进入 Ruby 下载页面：http://www.ruby-lang.org/zh_cn/downloads/下载页面的文档指出，Windows 可以用 RubyInstaller：https://rubyinstaller.org/。
安装 Ruby 的方法
每个流行的平台都有多种工具可用于安装 Ruby：
Linux/UNIX 平台，可以使用第三方工具（如 rbenv 或 RVM）或使用系统中的包管理系统。 macOS 平台，可以使用第三方工具（如 rbenv 或 RVM）。 Windows 平台，可以使用 RubyInstaller。 进入 RubyInstaller 下载页面，页面右侧的说明会告诉你该下哪一个版本的。
Which version to download?
If you don’t know what version to install and you’re getting started with Ruby, we recommend that you use the Ruby+Devkit 3.1.X (x64) installer.
下载 Ruby+Devkit 3.1.2-1 (x64) 完成后，双击运行，启动 Ruby 安装向导，然后一路 next 即可。
记得勾选 Add Ruby executables to your PATH，把 Ruby 的运行目录添加到 Windows 的环境变量 PATH 里，要不然在命令行窗口（CMD）里不能直接用命令。
安装过程中，安装向导可能会卡住，等一会就行。RubyInstaller 会把 Ruby 和 RubyGems 一起装了。RubyGems 是一个 Ruby 程序，用来管理 Ruby 包的。
安装完成后，可以在命令行里使用命令输出一下版本信息，看看安装是否成功。
&gt; ruby -v ruby 3.1.2p20 (2022-04-12 revision 4491bb740a) [x64-mingw-ucrt] &gt; gem -v 3.3.7 第 2 步，安装 Jekyll。
使用 RubyGems 安装 Jekyll。
&gt; gem install jekyll 一大堆输出。。。 Done installing documentation for unicode-display_width, terminal-table, safe_yaml, rouge, forwardable-extended, pathutil, mercenary, liquid, kramdown, kramdown-parser-gfm, ffi, rb-inotify, rb-fsevent, listen, jekyll-watch, sassc, jekyll-sass-converter, concurrent-ruby, i18n, http_parser.rb, eventmachine, em-websocket, colorator, public_suffix, addressable, jekyll after 24 seconds 26 gems installed 安装过程需要几分钟，等它装完即可。如果长时间没有反应，可以在命令行按一下回车，不排除可能是 Windows 命令行卡住了没输出信息。
安装完成后，可以在命令行里使用命令输出一下版本信息，看看安装是否成功。
&gt; jekyll -v jekyll 4.2.2 生成模板 使用 jekyll 生成模板。
这里是在 D 盘的 workspace/github.io 目录里生成模板。
&gt; jekyll new github.io Running bundle install in D:/workspace/github.io... 一大堆输出。。。 New jekyll site installed in D:/workspace/github.io. Bundler 可以认为是一个针对项目的包管理程序。它通过项目目录下的 Gemfile 文件来管理项目依赖。Bundler 在安装依赖时，会使用 RubyGems。
开发服务器 Jekyll 集成了一个开发用的服务器，可以使用浏览器在本地进行预览。
&gt; jekyll serve Configuration file: D:/workspace/github.io/_config.yml Source: D:/workspace/github.io Destination: D:/workspace/github.io/_site Incremental build: disabled. Enable with --incremental Generating... Jekyll Feed: Generating feed for posts done in 0.808 seconds. Please add the following to your Gemfile to avoid polling for changes: gem &#39;wdm&#39;, &#39;&gt;= 0.1.0&#39; if Gem.win_platform? Auto-regeneration: enabled for &#39;D:/workspace/github.io&#39; Server address: http://127.0.0.1:4000/ Server running... press ctrl-c to stop. 正常情况应该是输出上面的内容，然后就用浏览器访问 http://localhost:4000/ 查看博客了。
异常情况 &gt; jekyll serve Configuration file: D:/workspace/github.io/_config.yml Source: D:/workspace/github.io Destination: D:/workspace/github.io/_site Incremental build: disabled. Enable with --incremental Generating... Jekyll Feed: Generating feed for posts done in 0.827 seconds. Please add the following to your Gemfile to avoid polling for changes: gem &#39;wdm&#39;, &#39;&gt;= 0.1.0&#39; if Gem.win_platform? Auto-regeneration: enabled for &#39;D:/workspace/github.io&#39; ------------------------------------------------ Jekyll 4.2.2 Please append `--trace` to the `serve` command for any additional information or backtrace. ------------------------------------------------ C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve/servlet.rb:3:in `require&#39;: cannot load such file -- webrick (LoadError) from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve/servlet.rb:3:in `&lt;top (required)&gt;&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:179:in `require_relative&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:179:in `setup&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb💯in `process&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `block in process_with_graceful_fail&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `each&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `process_with_graceful_fail&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:86:in `block (2 levels) in init_with_program&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `block in execute&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `each&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `execute&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/program.rb:44:in `go&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary.rb:21:in `program&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/exe/jekyll:15:in `&lt;top (required)&gt;&#39; from C:/Ruby31-x64/bin/jekyll:32:in `load&#39; from C:/Ruby31-x64/bin/jekyll:32:in `&lt;main&gt;&#39; 输出的信息提示使用 --trace 参数，看看执行过程中发生了什么。但是实际上下 1 行已经提示了，webrick 无法加载。
------------------------------------------------ Jekyll 4.2.2 Please append `--trace` to the `serve` command for any additional information or backtrace. ------------------------------------------------ C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve/servlet.rb:3:in `require&#39;: cannot load such file -- webrick (LoadError) 这里用一下 --trace 参数，输出没啥变化，依然提示 webrick 无法加载。
&gt; jekyll serve --trace Configuration file: D:/workspace/github.io/_config.yml Source: D:/workspace/github.io Destination: D:/workspace/github.io/_site Incremental build: disabled. Enable with --incremental Generating... Jekyll Feed: Generating feed for posts done in 0.747 seconds. Please add the following to your Gemfile to avoid polling for changes: gem &#39;wdm&#39;, &#39;&gt;= 0.1.0&#39; if Gem.win_platform? Auto-regeneration: enabled for &#39;D:/workspace/github.io&#39; C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve/servlet.rb:3:in `require&#39;: cannot load such file -- webrick (LoadError) from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve/servlet.rb:3:in `&lt;top (required)&gt;&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:179:in `require_relative&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:179:in `setup&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb💯in `process&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `block in process_with_graceful_fail&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `each&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `process_with_graceful_fail&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:86:in `block (2 levels) in init_with_program&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `block in execute&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `each&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `execute&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/program.rb:44:in `go&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary.rb:21:in `program&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/exe/jekyll:15:in `&lt;top (required)&gt;&#39; from C:/Ruby31-x64/bin/jekyll:32:in `load&#39; from C:/Ruby31-x64/bin/jekyll:32:in `&lt;main&gt;&#39; 这时可以回到上面使用 jekyll 生成模板的地方，从输出的信息中可以发现 Bundler 并没有安装 webrick。所以这里手动执行命令安装 webrick。
&gt; bundle add webrick Fetching gem metadata from https://rubygems.org/.......... Resolving dependencies... Fetching gem metadata from https://rubygems.org/.......... Resolving dependencies... 等待安装完成，应该就可以使用 jekyll serve 命令了。
推送项目到 GitHub Pages GitHub Pages 官方文档：https://pages.github.com/按照要求建一个名字叫 {username}.github.io 仓库，然后把项目推上去就行了。
然后就可以通过 https://{username}.github.io 访问了。
]]></content></entry><entry><title>BT 种子和磁力链接</title><url>/post/computer-science/protocol/bit-torrent/</url><categories><category>protocol(协议)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>protocol(协议)</tag></tags><content type="html">BT 种子 BT 种子，实际上指的是由 BitTorrent 协议所生成的一个包含资源信息的文件。
与传统的网络传输协议不同，BitTorrent 协议是一种以 P2P（peer-to-peer、用户对用户）模式为主的资源分享协议。采用的是一种去中心化的思想，不需要一个专门的文件发布者或者发布平台。
从理论上来说，一个 BT 种子只要发布了，种子所包含的资源就永远存在于互联网上。
平常所使用的 HTTP、FTP 等协议需要一个中心发布者在网络上发布文件，即一种点对多的模式。当然，如果中心发布者由于某种原因被封了或者发布者删除了资源，那么就无法下载资源了。
BitTorrent BitTorrent 协议的思想是将一个文件划分为大小相等的 n 块，每块大小必须为 2 的整数次方。
例如一个 100M 的文件，按照每块 1024kb 的大小被分为 100 个小块，每块中包含索引信息和 Hash 值，而我们的下载过程实际上就是块的交换过程。
BitTorrent 协议的资源发布者会根据要求，制作一个包含资源下载信息，例如 Tracker 服务器地址、文件大小、文件名、块文件大小等信息的 .torrent 文件，这个过程也就是平时说的做种。
如果要下载 BT 资源，首先要得到对应的 .torrent 文件，然后用专门的下载软件，例如 BitComet（比特彗星），下载过程大概为：
1、读取 .torrent 文件信息，载入内存。 2、得到文件内的 Tracker 地址，连接 Tracker 服务器。 3、Tracker 服务器回应下载请求，记录你的 IP 并告知其它下载者的 IP 地址。 4、你与其他在线的下载者连接，交换各自没有的块。 5、验证得到的块信息，若不同，则需要重新下载。 磁力链接 由上文可以看出，Tracker 是很重要的一个东西。一但 Tracker 服务器被封，就无法进行下载了。由此，Magnet URI scheme（磁力链接）诞生了。
磁力链接，是对等网络中进行信息检索和下载文档的电脑程序。和基于位置连接的统一资源定位符不同，磁力链接是基于 metadata（元数据）文件内容，属于统一资源名称。
也就是说，磁力链接不基于文档的IP地址或定位符，而是在分布式数据库中，通过散列函数值来识别、搜索来下载文档。
因为不依赖一个处于启动状态的主机来下载文档，所以特别适用没有中心服务器的对等网络。
磁力链接利用 DHT（distributed hash table、分布式哈希表）和 PEX（peer exchange、节点信息交换）实现了资源的随意传播，根本无法禁止。
磁力链接下载的本质是将每一个人都变为 Tracker 服务器，将资源与下载者对应起来，每位下载者保存部分信息。这样，在下载资源时，只需寻找拥有所需资源的下载者。
简单理解就是，A 认识 B，B 认识 C，C 认识 D 和 E。如果 A 想认识 E，就可以通过 B 和 C 的介绍来认识 D，不需要 A 一个个去寻找 E。
magnet:?xt=urn:btih:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 上面是一个常见的磁力链接。
magnet：为协议名。 xt：exact topic，资源定位点。 urn：Uniform Resource Name，资源名。 btih：BitTorrent info hash，表示种子散列函数。 最主要的就是 btih 后面唯一的一串 16 进制的数字。 图种 图种就是把包含 BT 种子的压缩文件隐藏在图片中。
下面的操作是在 windows 11 系统环境下操作的。
需要准备一张图片 1.jpg 和一个压缩文件 2.rar。然后新建一个 .bat 后缀的批处理文件，把下面的代码放进去。
copy /b 1.jpg+2.rar 3.jpg copy /b 是一个基础的 DOS 命令，作用是合并文件。
把图片、压缩文件、批处理文件放在同一个目录。然后执行批处理文件，执行完成后就会得到一张图片 3.jpg。
这个图片实际上同时文件含了图片和压缩文件。如果把图片 3.jpg 的后缀名改成 .rar，这个时候图片就变成了压缩文件。
这个压缩文件是可以解压的，压缩文件的内容就是 2.rar 的内容。</content></entry><entry><title>ELF 文件</title><url>/post/computer-science/operating-system/linux/elf/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>linux</tag><tag>linux-c</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 VMware Workstation Pro 16 Ubuntu 22.04 gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
前言 在看这篇之前，建议先看一下 什么是程序资料 {demo-c}/demo-in-linux/elf/ ELF 之前提到过，c 源码文件通过 gcc 编译得到可执行文件，这里的可执行文件就是 elf 文件的一种。关于 elf 具体的细节可以看 elf(5) - format of Executable and Linking Format (ELF) files。
elf 文件格式有四种：
normal executable files（普通可执行文件） relocatable object files（可重定位文件） core files（核心文件） shared objects（共享目标文件、共享库、动态库） objdump 这里观察一下 demo02 文件。命令具体的输出放在 {demo-c}/demo-in-linux/elf/objdump.md 里面。
readelf 通过 readelf 命令可以查看 elf 文件的具体信息。关于 readelf 命令具体怎么用可以看：readelf(1) - display information about ELF files。
这里会用到 -h、-l、-S、-s 几个参数。大概是：-h 输出 elf header （elf 文件头）、-l 输 program headers、-S 输出 section headers（段表）、-s 输出符号表。
这里观察一下 demo02 文件。命令具体的输出放在 {demo-c}/demo-in-linux/elf/readelf.md 里面。
-h 输出 elf header，这里截取了一些。
ELF Header: Data: 2&#39;s complement, little endian Type: DYN (Position-Independent Executable file) Machine: Advanced Micro Devices X86-64 Entry point address: 0x1060 Number of section headers: 31 Data：数据存储方式（这里是小端字节序）。 Type：elf 文件的类型。 Machine：机器架构。 Entry point address：程序的入口地址。 Number of section headers：elf 段表大小。 操作系统在加载完可执行文件后，会把控制权转移给该程序，然后找到入口地址（这里就是 0x1060）开始运行程序。
-S 输出 section headers（段表），这里截取了一些。
Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 1] .interp PROGBITS 0000000000000318 00000318 000000000000001c 0000000000000000 A 0 0 1 [12] .init PROGBITS 0000000000001000 00001000 000000000000001b 0000000000000000 AX 0 0 4 [16] .text PROGBITS 0000000000001060 00001060 0000000000000189 0000000000000000 AX 0 0 16 [18] .rodata PROGBITS 0000000000002000 00002000 0000000000000012 0000000000000000 A 0 0 4 [25] .data PROGBITS 0000000000004000 00003000 0000000000000018 0000000000000000 WA 0 0 8 [26] .bss NOBITS 0000000000004018 00003018 0000000000000010 0000000000000000 WA 0 0 4 [27] .comment PROGBITS 0000000000000000 00003018 000000000000002b 0000000000000001 MS 0 0 1 [28] .symtab SYMTAB 0000000000000000 00003048 00000000000003f0 0000000000000018 29 20 8 [29] .strtab STRTAB 0000000000000000 00003438 00000000000001fa 0000000000000000 0 0 1 .interp：程序解释器（elf 解释器）的路径。 .init：进程初始化的代码。 .text：程序指令&ndash;&gt;指令码&ndash;&gt;机器码&ndash;&gt;二进制指令&ndash;&gt;cpu 指令（芯片层级的指令）。 .rodata：只读数据（如：数字常量，字符串常量）。 .data：已经给值的全局变量、静态变量、局部变量。 .bss：未初始化的全局变量、静态变量、局部变量。 .symtab：符号表。和.strtab一起用。 .strtab：字符串符号表（变量名、函数名）。 .debug：调试信息。 其他的段的解释详见 linux 文档。 -s 输出符号表，这里截取了 demo02.c 代码里直接出现的几个。
Symbol table &#39;.symtab&#39; contains 42 entries: Num: Value Size Type Bind Vis Ndx Name 12: 0000000000004014 4 OBJECT LOCAL DEFAULT 25 si.1 13: 0000000000004020 4 OBJECT LOCAL DEFAULT 26 sj.0 20: 0000000000001149 54 FUNC GLOBAL DEFAULT 16 func1 25: 0000000000004010 4 OBJECT GLOBAL DEFAULT 25 ga 32: 000000000000117f 51 FUNC GLOBAL DEFAULT 16 func2 36: 00000000000011b2 55 FUNC GLOBAL DEFAULT 16 main 37: 000000000000401c 4 OBJECT GLOBAL DEFAULT 26 gb 下面一个一个看 数据存储方式 数据存储方式有两种：little endian（小端字节序）和 big endian（大端字节序）。小端字节序又叫主机字节序，大端字节序又叫网络字节序。上面 readelf -h demo02 命令的结果里面，在 Data 字段里可以看见 little endian，意思就是在 demo02 里面，数据的存储格式是小端字节序。下面来验证一下这个结论。
在 demo02 的源码里面，全局变量 ga 是一开始就明确的给了值的。在 readelf -s demo02 命令输出的符号表里，找到 ga 在的那一行，然后就可以知道到 ga 对应的内存地址是 0x4010。然后在 objdump -s demo02 命令输出的结果里面，找到 .data 段，然后找到地址 0x4010 对应的数据。
这里截取一下 .data 段全部的内容。
Contents of section .data: 4000 00000000 00000000 08400000 00000000 .........@...... 4010 2c010000 0a000000 ,....... 这里通过地址，就可以找到 0x4010 地址上对应的数据是什么。因为源码里面 ga 是 int 类型的，int 类型的长度是 4 个字节，所以 ga 的数据就对应从 0x4010 地址开始的 4 个字节的数据。也就是 2c010000 这一段。
源码里面 ga 初始化的时候是 300。10 进制的 300 用 16 进制表示就是 0x12c，补全 4 个字节就是 00 00 01 2c。但是，这里可以看到内存上的数据是 2c 01 00 00，是反的。这就是因为这里用的是小端字节序。
c 语言的 int 变量由 4 个字节组成，每个字节由 8 个 bit 位组成。把 10 进制的 300 转换成 2 进制就是 00000000 00000000 00000001 00101100，左边定义为高位，右边定义为低位。小端字节序的存储格式是把数据的低位放在内存低位上，而内存的排布是从低位到高位的，所以就变成了 00101100 00000001 00000000 00000000，转换成 16 进制就是 2c 01 00 00。
size 通过命令 size 可以查看文件中各段及其总和的大小，单位是字节。关于 size 命令具体怎么用可以看：size(1) - list section sizes and total size of binary files。
这里观察一下 demo02 文件。
&gt; size demo02 text	data	bss	dec	hex	filename 1588	608	16	2212	8a4	demo02 text，代码段通常是指用来存放程序执行代码的一块内存区域。 data，数据段通常是指用来存放程序中已初始化的全局变量的一块内存区域。数据段属于静态内存分配。 bss，bss 段通常是指用来存放程序中未初始化的全局变量的一块内存区域。bss 段属于静态内存分配。 默认情况下，段的大小是以十进制的方式来展示。 程序的入口地址 从 objdump -s demo02 命令输出的结果里可以知道 demo02 程序的入口地址是 0x1060。然后在 objdump -s demo02 命令输出的结果里面。找到 .text 段，然后找到地址 0x1060 对应的数据。命令输出的结果在文件 {demo-c}/demo-in-linux/elf/objdump.md 中。这里截取了 .text 段全部的内容。
Contents of section .text: 1060 f30f1efa 31ed4989 d15e4889 e24883e4 ....1.I..^H..H.. 1070 f0505445 31c031c9 488d3d33 010000ff .PTE1.1.H.=3.... 1080 15532f00 00f4662e 0f1f8400 00000000 .S/...f......... 1090 488d3d81 2f000048 8d057a2f 00004839 H.=./..H..z/..H9 10a0 f8741548 8b05362f 00004885 c07409ff .t.H..6/..H..t.. 10b0 e00f1f80 00000000 c30f1f80 00000000 ................ 10c0 488d3d51 2f000048 8d354a2f 00004829 H.=Q/..H.5J/..H) 10d0 fe4889f0 48c1ee3f 48c1f803 4801c648 .H..H..?H...H..H 10e0 d1fe7414 488b0505 2f000048 85c07408 ..t.H.../..H..t. 10f0 ffe0660f 1f440000 c30f1f80 00000000 ..f..D.......... 1100 f30f1efa 803d0d2f 00000075 2b554883 .....=./...u+UH. 1110 3de22e00 00004889 e5740c48 8b3de62e =.....H..t.H.=.. 1120 0000e819 ffffffe8 64ffffff c605e52e ........d....... 1130 0000015d c30f1f00 c30f1f80 00000000 ...]............ 1140 f30f1efa e977ffff fff30f1e fa554889 .....w.......UH. 1150 e58b05bd 2e000089 c6488d05 a40e0000 .........H...... 1160 4889c7b8 00000000 e8e3feff ff8b05a1 H............... 1170 2e000083 c0018905 982e0000 905dc3f3 .............].. 1180 0f1efa55 4889e548 83ec2089 7dec8b45 ...UH..H.. .}..E 1190 ec8945fc 8b45fc89 c6488d05 6b0e0000 ..E..E...H..k... 11a0 4889c7b8 00000000 e8a3feff ff8b45fc H.............E. 11b0 c9c3f30f 1efa5548 89e5b800 000000e8 ......UH........ 11c0 85ffffff b8000000 00e87bff ffffbf01 ..........{..... 11d0 000000e8 a7ffffff bf020000 00e89dff ................ 11e0 ffffb800 0000005d c3 .......]. 左边第 1 列是虚拟地址；中间的 4 列是指令码；最右边 1 列是 ASCII 码。 0x1060 是起始地址；f30f1efa 是起始指令； 指令是 16 进制的：0xf3 0x0f 0x1e 0xfa，大小为 4 个字节。 在命令 objdump -d demo02 的结果中，可以找到对应的汇编代码。命令输出的结果在文件 {demo-c}/demo-in-linux/elf/objdump.md 中。这里截取了程序的入口地址对应的部分。通过虚拟地址的值和指令的值可以对应起来。
Disassembly of section .text: 0000000000001060 &lt;_start&gt;: 1060:	f3 0f 1e fa endbr64 1064:	31 ed xor %ebp,%ebp 1066:	49 89 d1 mov %rdx,%r9 1069:	5e pop %rsi 106a:	48 89 e2 mov %rsp,%rdx 106d:	48 83 e4 f0 and $0xfffffffffffffff0,%rsp 1071:	50 push %rax 1072:	54 push %rsp 1073:	45 31 c0 xor %r8d,%r8d 1076:	31 c9 xor %ecx,%ecx 1078:	48 8d 3d 33 01 00 00 lea 0x133(%rip),%rdi # 11b2 &lt;main&gt; 107f:	ff 15 53 2f 00 00 call *0x2f53(%rip) # 3fd8 &lt;__libc_start_main@GLIBC_2.34&gt; 1085:	f4 hlt 1086:	66 2e 0f 1f 84 00 00 cs nopw 0x0(%rax,%rax,1) 108d:	00 00 00 _start 是函数名。因为 0x1060 是起始地址，所以 _start 函数，就是这个程序的入口函数。它在调用 main 函数之前，会做一些前期的准备工作。编程语言的 main 函数一般不是程序的入口函数，大部分入口函数都是类似 _start 函数这样的，而且不同的语言在初始化阶段会有各自的处理逻辑。
符号表 通过命令 readelf -s demo02 可以输出符号表。命令输出的结果在文件 {demo-c}/demo-in-linux/elf/readelf.md 中。这里截取了 _start 对应的数据和 demo02.c 代码里直接出现的几个。
Symbol table &#39;.symtab&#39; contains 42 entries: Num: Value Size Type Bind Vis Ndx Name 12: 0000000000004014 4 OBJECT LOCAL DEFAULT 25 si.1 13: 0000000000004020 4 OBJECT LOCAL DEFAULT 26 sj.0 20: 0000000000001149 54 FUNC GLOBAL DEFAULT 16 func1 25: 0000000000004010 4 OBJECT GLOBAL DEFAULT 25 ga 32: 000000000000117f 51 FUNC GLOBAL DEFAULT 16 func2 34: 0000000000001060 38 FUNC GLOBAL DEFAULT 16 _start 36: 00000000000011b2 55 FUNC GLOBAL DEFAULT 16 main 37: 000000000000401c 4 OBJECT GLOBAL DEFAULT 26 gb 这里用 ga 举例，ga 在源码中是个全局 int 变量，初始化为 300。
Name（符号名）：ga Ndx（段 id）：25，表示符号属于第 25 段。结合段表，第 25 段是 .data 段。 Type（类型）：OBJECT，表示是个对象。如果是 FUNC，就表示是个函数 Bind（绑定范围）：GLOBAL，表示全局。 Value（地址）：0x0000000000004010。 这里结合 .data 段的数据，ga 的数据保存在地址从 0x4010 开始往后的 4 个字节上，也就是上面的2c010000，值就是 300。
nm 命令 nm 也可以输出符号表。nm demo02 命令输出的内容在文件 {demo-c}/demo-in-linux/elf/nm.md 中。关于 gcc 命令具体怎么用可以看：nm(1) - list symbols from object files。
使用符号表的地址直接访问数据 在程序中可以直接使用符号表中的 Value 值去访问对应的内存数据。同样的源文件，每次编译得到的符号表的地址是一样的。如果只是修改了某个变量的值，没有大规模的修改代码的话，重新编译的时候，变量的地址一般也是不会变得。可以通过这种方式验证这个结论。
进程虚拟地址空间映射 在上面的输出中，与地址有关的数据，都不是程序跑起来的时候，在内存中真正的地址。程序在进程里跑起来的时候，操作系统会把真正的内存地址和 elf 文件中的虚拟地址做映射。
]]></content></entry><entry><title>Linux C 编程的注意点</title><url>/post/computer-science/operating-system/linux/notice/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>linux</tag><tag>linux-c</tag></tags><content type="html">其实就一个注意点，编程的时候，要注意代码运行的目标环境。同一段代码，在 Ubuntu 和 Centos 上运行的时候，整体的系统调用过程应该是差不多的，但是细节可能不一样。
举个例子，在 Ubuntu 22.04 和 Centos 7 上分别跑 helloworld。加载 libc.so.6 文件的这个步骤，在Ubuntu 22.04 上加载的是 /lib/x86_64-linux-gnu/libc.so.6，在 Centos 7 上加载的是 /lib64/libc.so.6。</content></entry><entry><title>Linux 文档</title><url>/post/computer-science/operating-system/linux/man-pages/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>linux</tag><tag>linux-c</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 VMware Workstation Pro 16 Ubuntu 22.04 gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
搞 linux c 编程，一定要学会看 linux 的文档，遇到问题，仔细看看文档，一般都能解决。
man 可以在 linux 系统中使用 man 命令或者使用在线文档（
man7.org
或者 Linux man pages online
）查看 linux 相关文档。
关于 man 命令具体怎么用可以看：
man(1) - an interface to the system reference manuals
。
在 centos 的 docker 容器中无法使用 man 命令 因为 centos 的 docker 的镜像，它将一些东西精简了，所以不能够使用一些常用的命令，比如 man 等等。
需要在 /etc/yum.conf 配置文件里面修改一下，注释掉：tsflags=nodocs，这个配置禁用了一些软件包。注释完成之后重新安装 man 即可使用。
yum -y install man yum -y install man-pages Linux man pages online 在线文档从 man7.org
或者 Linux man pages online
都能进的去。
man7.org 页面点击 Online manual pages 可以进到 Linux man pages online 页面。Linux man pages online 页面点击 by section 可以进到列表页面，在列表页面比较好找。</content></entry><entry><title>运行 ELF 文件</title><url>/post/computer-science/operating-system/linux/exec_elf/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>linux</tag><tag>linux-c</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 VMware Workstation Pro 16 Ubuntu 22.04 gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
前言 在看这篇之前，建议先看一下：
什么是程序什么是程序ELF 文件资料 {demo-c}/demo-in-linux/helloworld/ {demo-c}/demo-in-linux/process/ 进程是什么 简单的理解，程序启动起来就变成进程，直到程序运行结束。程序是静态的，进程是动态的。
怎么观察进程 strace 通过 strace 命令可以来跟踪进程执行时的系统调用和进程接收的信号。关于 strace 命令具体怎么用可以看：strace(1) - trace system calls and signals。这里会用到 -f、-i、-t、-T、-p、-s、-o 几个参数。
大概是：-f 跟踪子进程；-i 打印系统调用的地址；-t 每一行打印时间；-T 显示系统调用花费的时间；-p {pid} 指定跟踪的进程号；-s {length} 每一行的长度，默认 32，一般设置 65535；-o {file name} 输出到文件。
在 centos 的 docker 容器中使用 strace 命令报错 使用 strace -p 命令跟踪进程时报错：
attach: ptrace(PTRACE_SEIZE): Operation not permitted 参考官方文档：The solution for enabling of ptrace and PTRACE_ATTACH in Docker Containers。
启动容器的时候使用 –-privileged 参数，让容器内的 root 用户拥有真正的 root 权限。
docker run -it -p 127.0.0.1:9501:9501 -v {local path}:{docker path} --name={container name} --privileged centos:centos7 进入容器，然后使用命令：echo 0 &gt; /proc/sys/kernel/yama/ptrace_scope。将 /proc/sys/kernel/yama/ptrace_scope 文件中的值修改成0。然后就可以使用 strace -p 命令跟踪进程了。
观察一下执行 helloworld 的过程 可以直接用 strace -f -i -T -s 65535 ./helloworld 直接跟踪 ./helloworld 运行的过程，但是这样观察不到全部的细节。这里用另外一种观察方式，观察输入 ./helloworld 的那个终端对应的进程。
其实用户的输入，内也是有一个进程来处理的，这个进程会接收并分析用户输入的容，然后做出相应的动作。这里这个进程，会接收到用户输入的 ./helloworld，然后执行 helloworld 这个可执行文件。
假设有两个终端黑窗口（进程），进程 a 负责进行上面的操作。进程 b 负责观察进程 a。在进程 b 进行跟踪之前，需要现在进程 a 里面，使用 echo $$ 命令获取当前进程的 pid。然后进程 b 使用 strace -f -i -T -s 65535 -p {pid} -o strace.log 命令观察进程 a。
命令输出的结果：
strace: Process 5148 attached strace: Process 5333 attached ^Cstrace: Process 5148 detached 终端 a 运行输入 ./helloworld 执行程序，终端 b 在输出前两行之后，按 ctrl+c 终止监视，会输出第三行。追踪到的内容会输出到 strace.log 里面，下面看一下 strace.log 里面的内容。
最前面的重复出现的 read 和 write 这里截取了 strace.log 里面，最前面的一段。... 表示这里省略了代码，全部贴过来太长了。
5148 [00007ff14a0d98f4] pselect6(1, [0], NULL, NULL, NULL, {sigmask=[], sigsetsize=8}) = 1 (in [0]) &lt;2.905167&gt; 5148 [00007ff14a0d2992] read(0, &#34;.&#34;, 1) = 1 &lt;0.000010&gt; 5148 [00007ff14a0d974d] pselect6(1, [0], NULL, [0], {tv_sec=0, tv_nsec=0}, NULL) = 0 (Timeout) &lt;0.000009&gt; 5148 [00007ff14a0d2a37] write(2, &#34;.&#34;, 1) = 1 &lt;0.000014&gt; 5148 [00007ff14a0d98f4] pselect6(1, [0], NULL, NULL, NULL, {sigmask=[], sigsetsize=8}) = 1 (in [0]) &lt;0.104884&gt; 5148 [00007ff14a0d2992] read(0, &#34;/&#34;, 1) = 1 &lt;0.000011&gt; 5148 [00007ff14a0d974d] pselect6(1, [0], NULL, [0], {tv_sec=0, tv_nsec=0}, NULL) = 0 (Timeout) &lt;0.000009&gt; 5148 [00007ff14a0d2a37] write(2, &#34;/&#34;, 1) = 1 &lt;0.000022&gt; ... 这里用上面的第二行 5148 [00007ff14a0d2992] read(0, &quot;.&quot;, 1) = 1 &lt;0.000010&gt; 做一个说明：5148 是进程号；[00007ff14a0d2992] 是地址；read(0, &quot;.&quot;, 1) 是系统调用和调用的时候传入的参数；= 1 是前面那个系统调用的返回值；&lt;0.000010&gt; 是系统调用消耗的时间。
这段的意思就是，终端 a（进程 5148），是由 /bin/bash 程序启动来的（/bin/bash 程序就是输入命令的那个终端黑窗口）。这一大段 read 函数和 write 函数，跟踪到的就是用户在终端 a 里用键盘输入 ./helloworld 的过程。read 是读取用户的输入，write 是将用户的输入显示到屏幕上。
关于 read 函数和 write 函数具体怎么用可以看：read(2) - read from a file descriptor和 write(2) - write to a file descriptor。
clone 下一个关键的步骤是，调用 clone 函数。
... 5148 [00007ff14a0a8bc7] clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0x7ff149fbba10) = 5333 &lt;0.000117&gt; ... clone 函数的作用是创建一个进程，这里进程 5148 创建了进程 5333。关于 clone 函数具体怎么用可以看：clone(2) - create a child process。另外，fock 函数也可以创建一个进程，这个后面再说。
wait4 下一个关键的步骤是，是调用 wait4 函数。
... 5148 [00007ff14a0a845a] wait4(-1, &lt;unfinished ...&gt; ... 父进程调用 wait 函数会进入阻塞状态，直到有子进程退出。关于 wait4 函数具体怎么用可以看：wait4(2) - wait for process to change state, BSD style。
在这里就是进程 5148 调用 wait4 函数进入阻塞状态，然后操作系统切换到子进程 5333 继续运行。&lt;unfinished ...&gt; 出现这个就表示产生了进程切换。
execve 下一个关键的步骤是，是调用 execve 函数。
... 5333 [00007ff14a0a90fb] execve(&#34;./helloworld&#34;, [&#34;./helloworld&#34;], 0x564eeda28ec0 /* 55 vars */) = 0 &lt;0.001275&gt; ... 进程 5333 调用 execve 函数执行可执行文件 helloworld。关于 execve 函数具体怎么用可以看：execve(2) - execute program。
execve 函数会加载可执行文件的 .text （程序指令）和 .data （程序数据）到当前进程，并覆盖当前进程。[&quot;./helloworld&quot;] 是参数值。0x564eeda28ec0 /* 55 vars */ 是环境参数值。
在 linux 中，环境参数是供所有应用程序使用的公共数据。
libc.so.6 下一个关键的步骤是，加载 libc.so.6 文件。
... 5333 [00007f06cfe3cb38] openat(AT_FDCWD, &#34;/lib/x86_64-linux-gnu/libc.so.6&#34;, O_RDONLY|O_CLOEXEC) = 3 &lt;0.000078&gt; 5333 [00007f06cfe3cb88] read(3, &#34;\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0&gt;\0\1\0\0\0P\237\2\0\0\0\0\0@\0\0\0\0\0\0\0\360\300!\0\0\0\0\0\0\0\0\0@\08\0\16\0@\0B\0A\0\6\0\0\0\4\0\0\0@\0\0\0\0\0\0\0@\0\0\0\0\0\0\0@\0\0\0\0\0\0\0\20\3\0\0\0\0\0\0\20\3\0\0\0\0\0\0\10\0\0\0\0\0\0\0\3\0\0\0\4\0\0\0000&gt;\36\0\0\0\0\0000&gt;\36\0\0\0\0\0000&gt;\36\0\0\0\0\0\34\0\0\0\0\0\0\0\34\0\0\0\0\0\0\0\20\0\0\0\0\0\0\0\1\0\0\0\4\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\340\177\2\0\0\0\0\0\340\177\2\0\0\0\0\0\0\20\0\0\0\0\0\0\1\0\0\0\5\0\0\0\0\200\2\0\0\0\0\0\0\200\2\0\0\0\0\0\0\200\2\0\0\0\0\0\301D\31\0\0\0\0\0\301D\31\0\0\0\0\0\0\20\0\0\0\0\0\0\1\0\0\0\4\0\0\0\0\320\33\0\0\0\0\0\0\320\33\0\0\0\0\0\0\320\33\0\0\0\0\0\314x\5\0\0\0\0\0\314x\5\0\0\0\0\0\0\20\0\0\0\0\0\0\1\0\0\0\6\0\0\0\360H!\0\0\0\0\0\360X!\0\0\0\0\0\360X!\0\0\0\0\0\230O\0\0\0\0\0\0`%\1\0\0\0\0\0\0\20\0\0\0\0\0\0\2\0\0\0\6\0\0\0\300{!\0\0\0\0\0\300\213!\0\0\0\0\0\300\213!\0\0\0\0\0\320\1\0\0\0\0\0\0\320\1\0\0\0\0\0\0\10\0\0\0\0\0\0\0\4\0\0\0\4\0\0\0P\3\0\0\0\0\0\0P\3\0\0\0\0\0\0P\3\0\0\0\0\0\0000\0\0\0\0\0\0\0000\0\0\0\0\0\0\0\10\0\0\0\0\0\0\0\4\0\0\0\4\0\0\0\200\3\0\0\0\0\0\0\200\3\0\0\0\0\0\0\200\3\0\0\0\0\0\0D\0\0\0\0\0\0\0D\0\0\0\0\0\0\0\4\0\0\0\0\0\0\0\7\0\0\0\4\0\0\0\360H!\0\0\0\0\0\360X!\0\0\0\0\0\360X!\0\0\0\0\0\20\0\0\0\0\0\0\0\220\0\0\0\0\0\0\0\10\0\0\0\0\0\0\0S\345td\4\0\0\0P\3\0\0\0\0\0\0P\3\0\0\0\0\0\0P\3\0\0\0\0\0\0000\0\0\0\0\0\0\0000\0\0\0\0\0\0\0\10\0\0\0\0\0\0\0P\345td\4\0\0\0L&gt;\36\0\0\0\0\0L&gt;\36\0\0\0\0\0L&gt;\36\0\0\0\0\0\314p\0\0\0\0\0\0\314p\0\0\0\0\0\0\4\0\0\0\0\0\0\0Q\345td\6\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\20\0\0\0\0\0\0\0R\345td\4\0\0\0\360H!\0\0\0\0\0\360X!\0\0\0\0\0\360X!\0\0\0\0\0\0207\0\0\0\0\0\0&#34;, 832) = 832 &lt;0.000078&gt; ... 调用 openat 函数 和 read 函数加载 helloworld 程序所依赖的库文件 libc.so.6。
其中 openat 函数会打开 libc.so.6 文件。关于 openat 函数具体怎么用可以看：openat(2) - open and possibly create a file。
openat 函数的返回值 3 是个文件描述符。文件描述符是指当前进程在访问的文件，这个值一般大于等于 0。linux 进程默认情况下会有 3 个缺省打开的文件描述符，分别是标准输入=0， 标准输出=1， 标准错误=2。然后后面的 read 函数的第一个参数就是这个 3，表示从文件里读数据。
libc.so.6 是共享目标文件，也叫共享库、运行库、动态库。用户程序会调用运行库（CRT，C Runtime Library）。运行库封装了操作系统更底层的系统调用函数。Linux、Windows、Mac，这些系统它们的底层接口都是不一样的，并且比较原始且底层，直接使用比较复杂，所以要封装这些比较底层的系统调用。
write 下一个关键的步骤是，是调用 write 函数。
... 5333 [00007f06cfcf1a37] write(1, &#34;hello, world\n&#34;, 13) = 13 &lt;0.000096&gt; ... 调用 write 函数输出 hello, world\n 到屏幕上。返回值 13 表示 hello, world\n 有 13 个字节。
在源码里面，用的是 printf 函数。这个函数声明在 stdio.h 头文件里面。它的底层实现最终调用的就是 write 函数，而 write 函数的具体实现就在 libc.so.6 库里。write 函数就是暴露出来的最底层的函数了，再往下就是驱动和硬件相关了。
另外，系统调用函数是可以直接写在程序里的。
#include &lt;unistd.h&gt; int main() { write(1, &#34;hello, world\n&#34;, 13); return 0; } exit_group 下一个关键的步骤是，是调用 exit_group 函数。关于 exit_group 函数具体怎么用可以看：exit_group(2) - exit all threads in a process。
... 5333 [00007f06cfcc7ca1] exit_group(0) = ? 5333 [????????????????] +++ exited with 0 +++ ... 进程 5333 调用 exit_group(0) 函数退出进程，参数值 0 是进程退出状态码，就是程序里 return 的 0。
wait4 下一个关键的步骤是，是进程 5148 从 wait4 函数的阻塞状态中被唤醒。
... 5148 [00007ff14a0a845a] &lt;... wait4 resumed&gt;[{WIFEXITED(s) &amp;&amp; WEXITSTATUS(s) == 0}], WSTOPPED|WCONTINUED, NULL) = 5333 &lt;0.036896&gt; ... 父进程 5148 知道子进程 5333 退出了，前面调用的 wait4 函数会回收退出的子进程 5333，并回收子进程的内存资源。WIFEXITED(s) 和 WEXITSTATUS(s) 是宏函数，WEXITSTATUS(s) 可以拿到退出状态码。
至此整个 helloworld 程序执行结束。
]]></content></entry><entry><title>什么是程序</title><url>/post/computer-science/operating-system/linux/program/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>linux</tag><tag>linux-c</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 VMware Workstation Pro 16 Ubuntu 22.04 gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
资料 {demo-c}/demo-in-linux/helloworld/ 程序 存储在磁盘上的静态代码文件或者由静态代码文件编译出来的可执行文件都可以说是程序。
编译 通常说的编译指的是：c 源码文件通过 gcc 编译得到可执行文件（elf）。通常使用 gcc 命令 gcc xxx.c -o xxx 一步就完成了。但是，这一步里面其实有四个步骤：预处理、编译、汇编、链接。
关于 gcc 命令具体怎么用可以看：gcc(1) - GNU project C and C++ compiler。这里会用到 -E、-S、-c、-o 几个参数。
-E：预处理；-S：预处理、编译，得到汇编代码；-c：预处理、编译、汇编，得到可重定位文件；-o：指定目标名称；如果什么参数都不写，那就会预处理、编译、汇编、链接一步到位，得到可执行文件。
preprocessing（预处理）：gcc -E xxx.c -o xxx.i，预处理器会在源码的基础上增加一些代码。 compilation（编译）：gcc -S xxx.i -o xxx.s，编译器通过编译代码（词法分析、语法分析等）得到汇编代码。 assemble（汇编）：gcc -c xxx.s -o xxx.o，汇编器把汇编代码转化为机器指令，这一步得到的是可重定位文件。 link（链接）：gcc xxx.o -o xxx，连接器把各个模块链接起来，组织成为可执行文件。 在链接中，会把函数的名字和变量的名字都称为 symbol（符号）。源代码中的函数的名字和变量的名字，无论长度多少，最终都会转换为符号。
{demo-c}/demo-in-linux/helloworld/ 目录准备了：helloworld.c、helloworld.i、helloworld.s、helloworld.o、helloworld 五个文件。对应上面的源码文件，还有每个命令执行之后生成的文件。
看一下这几个文件 file 通过 file 命令可以查看文件的类型。关于 file 命令具体怎么用可以看：file(1) - determine file type。
&gt; file helloworld.c helloworld.c: C source, ASCII text, with CRLF line terminators &gt; file helloworld.i helloworld.i: C source, ASCII text &gt; file helloworld.s helloworld.s: assembler source, ASCII text &gt; file helloworld.o helloworld.o: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped &gt; file helloworld helloworld: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=79fbadd19d424598be050dd0fb91297abd895864, for GNU/Linux 3.2.0, not stripped 可以看到：helloworld.c 和 helloworld.i 都是 c 源码文件、helloworld.s 是汇编源码文件、helloworld.o 是可重定位文件、helloworld 是可执行文件。
objdump 通过 objdump 命令可以查看文件的具体内容。关于 objdump 命令具体怎么用可以看：objdump(1) - display information from object files。
这里会用到 -h、-s、-d 几个参数。大概是：-h 输出段表；-s 输出段表中每个段的详细内容；-d 输出 .text 段对应的汇编代码。
这里观察一下 helloworld.o 文件。命令具体的输出放在 {demo-c}/demo-in-linux/helloworld/objdump.md 里面。
命令输出的结果的第一行都是 helloworld.o: file format elf64-x86-64，这个是文件的类型。
-h 输出段表：
.text 是代码段，它用于存储程序指令（程序的代码） .data、.bss、.rodata 都是数据段，它们用于存储程序数据。 .bss 是未初始化数据段；.rodata 是只读数据段。 可执行文件 = 程序指令 + 程序数据 -s 输出段表中每个段的详细内容，这里截取了 .text 段：
Contents of section .text: 0000 f30f1efa 554889e5 488d0500 00000048 ....UH..H......H 0010 89c7e800 000000b8 00000000 5dc3 ............]. 每行的第一段是内存偏移量。从第二段开始的一段一段的，表示程序指令的内容（16 进制机器指令）。最后面的那串字符是程序指令的 ASICC 文本。
-d 输出 .text 段对应的汇编代码，这里截取了 .text 段的汇编代码：
Disassembly of section .text: 0000000000000000 &lt;main&gt;: 0:	f3 0f 1e fa endbr64 4:	55 push %rbp 5:	48 89 e5 mov %rsp,%rbp 8:	48 8d 05 00 00 00 00 lea 0x0(%rip),%rax # f &lt;main+0xf&gt; f:	48 89 c7 mov %rax,%rdi 12:	e8 00 00 00 00 call 17 &lt;main+0x17&gt; 17:	b8 00 00 00 00 mov $0x0,%eax 1c:	5d pop %rbp 1d:	c3 ret Disassembly of section .text，表示程序指令的内容，以及对应的汇编代码。这里和 -s 输出的结果对应。上面 -s 输出的结果里的 Contents of section .text 里的 f30f1efa。就对应 Disassembly of section .text 里的 0:	f3 0f 1e fa。
第二行的 4:	55 和后面的 push %rbp，就表示 55（0x55）反汇编后对应的汇编指令就是 push %rbp。
然后在观察一下 helloworld 文件。命令具体的输出也放在 {demo-c}/demo-in-linux/helloworld/objdump.md 里面。
这里可以看到，helloworld 的内容是比 helloworld.o 要多出不少的。而且通过 helloworld 的内容，我们可以发现 helloworld 的 .text 段的第一个函数不是 main 函数，而是 _start 函数。_start 函数会调用 __libc_start_main 函数进行一些必要的初始化操作，然后再调用 main 函数。
]]></content></entry><entry><title>在 Windows 环境安装和配置 Git</title><url>/post/computer-science/application/git/install_config/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>git</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 git 2.34.0
下载和安装 去 Git 官方网站下一个 Windows 环境的安装包。这里下载到的安装包是 Git-2.34.0-64-bit.exe。运行安装包，一路下一步即可。本体安装应该是自动配好的，可以输出版本检查一下有没有安装好。
&gt; git version git version 2.34.1.windows.1 全局配置用户名和邮箱 &gt; git config --global user.name &#34;xxx&#34; &gt; git config --global user.email &#34;xxx@xxx.com&#34; 执行命令后，会在目录 C:\Users\用户名\ 下创建一个 .gitconfig 文件用于保存配置。
记住密码 永久记住密码：
&gt; git config --global credential.helper store 临时记住密码：
&gt; git config –global credential.helper cache &gt; git config –global credential.helper &#39;cache –timeout=3600&#39; 这两条命令执行后，会在目录 C:\Users\用户名\ 下创建一个 .gitconfig 文件用于保存配置。第一次提交任然需要输入用户名和密码。提交成功后，同一个用户就不需要再输入了。提交成功后会在目录 C:\Users\用户名\ 下创建一个 .git-credentials 文件用于保存密码。
Github 配置 SSH 打开 Github 的账号设置页面，在左侧边栏里找到 Access-&gt;SSH and GPG keys。最后要把生成的 SSH 的公钥配置在这里。
第 1 步，在自己的终端上生成 SSH SSH 目录一般都在 ~/.ssh，对应到 win11 上就是 C:\Users\用户名\.ssh 目录。 进入 ~/ 目录，对应到 win11 上就是 C:\Users\用户名\ 目录。 这里建议用 Git 提供的那个 Git Bash 命令行窗口操作。它会自动的把 ~ 目录对应到 win11 的用户目录。 然后使用命令生成 SSH，一般一路回车即可。 &gt; ssh-keygen -t rsa -C &#34;xxx@xxx.com&#34; -f ~/.ssh/github_rsa Generating public/private rsa key pair. Enter passphrase (empty for no passphrase): 直接回车 Enter same passphrase again: 直接回车 Your identification has been saved in /c/Users/Administrator/.ssh/github_rsa Your public key has been saved in /c/Users/Administrator/.ssh/github_rsa.pub ... -t rsa：表示使用 rsa 算法。 -C &quot;xxx@xxx.com&quot;：指定 SSH 的名字，不一定非要是邮箱，但是一般用邮箱。 -f ~/.ssh/github_rsa：指定了生成出来的文件的目录和文件名。 如果不指定文件名，则会用默认的文件名，如果想要配置多个 SSH 就需要指定文件名。
第 2 步，获取和配置公钥 生成 SSH 的步骤完成后，用 cat 获取公钥。
&gt; cat ~/.ssh/github_rsa.pub ssh-rsa 一大串 xxx@xxx.com 然后把上面 cat 到的公钥内容贴到代码仓库配置 SSH 公钥的地方。
第 3 步，配置 SSH 如果第 1 步用的是默认的文件名，那第 3 步是不需要配置的，直接默认配置就生效了。 但是如果第 1 步指定了文件名，也就是需要配置多个 SSH 的时候，就需要进行下面的配置。 即使用 ssh-add 添加私钥。如果需要配置多个 SSH，那么每个 SSH 都要配置。
&gt; ssh-add ~/.ssh/github_rsa Identity added: /c/Users/Administrator/.ssh/github_rsa (xxx@xxx.com) 如果遇到报错：Could not open a connection to your authentication agent.。 就先执行 ssh-agent bash，这命令没有输出。然后再执行 ssh-add 命令。
ssh-add -l：查看私钥。 ssh-add -D：删除全部私钥。 私钥添加完成后，在 ~/.ssh/ 目录创建文件名为 config 的配置文件。 在 config 文件中添加以下配置内容，如果需要配置多个 SSH，那么每个 SSH 都要写一个。
# Github Host github.com HostName github.com IdentityFile ~/.ssh/github_rsa User xxx 符号 # 开头表示这行是注释。 Host：识别模式。和主机名一样就行。 HostName：主机名 Port：端口号。如果不是默认的 22 就需要指定。 IdentityFile：秘钥文件路径 User：用户名 第 4 步，测试 如果配置成功，则执行 ssh -T 命令后会，有下面提示成功的输出。
&gt; ssh -T git@github.com Hi xxx! You&#39;ve successfully authenticated, but GitHub does not provide shell access. 配置多个 SSH 这里给 Github 和 Gitee 两个代码仓库配置 SSH。
第 1 步、第 2 步是一样的。都是生成 SSH 然后到对应的仓库去配置。 第 3 步、第 4 步不一样。ssh-add 需要执行多次，把每个 SSH 都添加。config 文件的配置也需要配多个。
如果有第 3 个、第 4 个、或者更多的仓库，依葫芦画瓢即可。
Gitee 配置 SSH Gitee 的帮助中心有关于 配置 SSH 的文档打开 Gitee 的账号设置页面，在左侧边栏里找到 安全设置-&gt;SSH 公钥。最后要把生成的 SSH 的公钥配置在这里。
生成 SSH，这里除了用的是 ed25519 算法，其他的差不多。
&gt; ssh-keygen -t ed25519 -C &#34;xxx@xxx.com&#34; -f ~/.ssh/gitee_rsa Generating public/private ed25519 key pair. Enter passphrase (empty for no passphrase): 直接回车 Enter same passphrase again: 直接回车 Your identification has been saved in /c/Users/kelipute/.ssh/gitee_rsa Your public key has been saved in /c/Users/kelipute/.ssh/gitee_rsa.pub ... 生成 SSH 的步骤完成后，用 cat 获取公钥。
&gt; cat .ssh/gitee_rsa.pub ssh-ed25519 一大串 xxx@xxx.com 然后把上面 cat 到的公钥内容贴到代码仓库配置 SSH 的地方。
使用 ssh-add 添加私钥。
&gt; ssh-add ~/.ssh/gitee_rsa Identity added: /c/Users/Administrator/.ssh/gitee_rsa (xxx@xxx.com) 在 config 文件添加以下配置内容。
# Gitee Host gitee.com HostName gitee.com IdentityFile ~/.ssh/gitee_rsa User xxx 测试。
&gt; ssh -T git@gitee.com 阿里云云效配置 SSH 打开 云效的个人设置页面，在左侧边栏里找到 SSH 公钥。最后要把生成的 SSH 的公钥配置在这里。
生成 SSH，阿里云云效要求使用 ed25519 算法，其他的差不多。
&gt; ssh-keygen -t ed25519 -C &#34;xxx@xxx.com&#34; -f ~/.ssh/yun2xiao4_ed25519 Generating public/private ed25519 key pair. Enter passphrase (empty for no passphrase): 直接回车 Enter same passphrase again: 直接回车 Your identification has been saved in /c/Users/Administrator/.ssh/yun2xiao4_ed25519 Your public key has been saved in /c/Users/Administrator/.ssh/yun2xiao4_ed25519.pub ... 生成 SSH 的步骤完成后，用 cat 获取公钥。
&gt; cat ~/.ssh/yun2xiao4_ed25519.pub ssh-ed25519 一大串 xxx@xxx.com 然后把上面 cat 到的公钥内容贴到代码仓库配置 SSH 的地方。
使用 ssh-add 添加私钥。
&gt; ssh-add ~/.ssh/yun2xiao4_ed25519 Identity added: /c/Users/Administrator/.ssh/yun2xiao4_ed25519 (xxx@xxx.com) 在 config 文件添加以下配置内容。
# Gitee Host codeup.aliyun.com HostName codeup.aliyun.com IdentityFile ~/.ssh/yun2xiao4_ed25519 User xxx 腾讯云 Coding 配置 SSH Coding 的帮助中心有关于 配置 SSH 的文档打开 Coding 的个人账户页面，在左侧边栏里找到 SSH 公钥。最后要把生成的 SSH 的公钥配置在这里。
生成 SSH，腾讯云 Coding 的文档里给了命令，直接用就好了。
&gt; ssh-keygen -m PEM -t ed25519 -C &#34;huiyu.xue@ly.com&#34; -f ~/.ssh/coding_ed25519 Generating public/private ed25519 key pair. Enter passphrase (empty for no passphrase): 直接回车 Enter same passphrase again: 直接回车 Your identification has been saved in /c/Users/kelipute/.ssh/coding_ed25519 Your public key has been saved in /c/Users/kelipute/.ssh/coding_ed25519.pub ... 生成 SSH 的步骤完成后，用 cat 获取公钥。
&gt; cat ~/.ssh/coding_ed25519.pub ssh-ed25519 一大串 xxx@xxx.com 然后把上面 cat 到的公钥内容贴到代码仓库配置 SSH 的地方。
使用 ssh-add 添加私钥。
&gt; ssh-add ~/.ssh/coding_ed25519 Identity added: /c/Users/kelipute/.ssh/coding_ed25519 (xxx@xxx.com) 在 config 文件添加以下配置内容。
# Coding Host e.coding.net HostName e.coding.net IdentityFile ~/.ssh/coding_ed25519 User {xxx} 测试
&gt; ssh -T git@e.coding.net Are you sure you want to continue connecting (yes/no/[fingerprint])? 输入 yes，回车 CODING 提示: Hello xxx, You&#39;ve connected to coding.net via SSH. This is a Personal Key. ... ]]></content></entry><entry><title>Git 常用命令</title><url>/post/computer-science/application/git/common_command/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>git</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 git 2.34.0
创建 git init，初始化 git 仓库。
初始化之后就会在当前目录创建 .git/ 目录。
修改 git add .，添加所有文件到缓冲区。
git status，查看 git 库的状态。
当前在哪个分支，还有文件的变化情况，哪些文件被新增、修改、删除了。
git diff，用于文件修改了，但是还没有提交时，比较文件修改前后的差异。
git diff，默认比较全部的文件。
git diff {filename}，可以指定文件 filename 进行比较。
提交 git commit -m &amp;quot;message&amp;quot;，提交缓冲区的所有修改到本地仓库。
如果修改了但是没有 add 到缓冲区的，是不会被提交的。
git reset，回退版本。
git reset HEAD^，回退所有内容到上一个版本。
git reset {code}，回退所有内容到指定版本。
上面的 code 参数填的是 git log 输出的信息中，每个提交最前面的那一串。
--hard 参数，撤销工作区中所有未提交的修改内容，将暂存区与工作区都回退，并删除之前的所有的提交信息。
git reset --hard HEAD^，强行回退所有内容到上一个版本。
git reset --hard {code}，强行回退所有内容到指定版本。
git reset --hard origin/master，强行将本地分支回退到和远程 master 分支一样。
谨慎使用 --hard 参数。
日志 git log，查看历史记录，主要是提交信息。
--oneline 参数，查看历史记录的简洁的版本。
--graph 参数，查看历史记录中的分支和合并。
远程仓库 git remote，操作远程仓库
git remote -v，显示所有远程仓库。
git remote add {name} {url}，添加远程仓库 name 并设置地址为 url。
常用的：git remote add origin {url}，添加远程仓库 origin 并设置地址为 url。
git remote set-url origin {url}，修改远程仓库 origin 的地址为 url。如果未指定协议，则默认为 SSH。
git remote rm {name}，删除远程仓库 name 。
获取代码 git fetch，从远程仓库获取代码。
git fetch origin，从远程仓库 origin 获取代码。
获取代码并合并 git pull，从远程获取代码并合并。
git pull 其实是 git fetch 和 git merge FETCH_HEAD 的简写。
git pull {name} {remote branch}:{locol branch}，将远程仓库 name 的 remote branch 分支拉取过来，与本地的 locol branch 分支合并。
常用的：git pull origin master，将远程仓库 origin 的 master 分支拉取过来，与本地的当前分支合并。
上传代码并合并 git push,将本地的分支上传到远程并合并。
git push {name} {remote branch}:{locol branch}，将本地的 locol branch 分支推送到远程仓库 name 的 remote branch 分支。
如果本地的 locol branch 分支和远程仓库 name 的 remote branch 分支名字一样，可以简化成 git push {name} {branch}。
git push origin master:master，将本地的 master 分支推送到远程仓库 origin 的 master 分支。
常用的：git push origin master 是 git push origin master:master 的简写。
-u 参数，记录 push 到远端分支的默认值，下次想要继续 push 这个分支的时候，推送命令就可以简写成 git push。
执行 git push -u origin master 之后，下次在想推送 master 分支的时候，直接 git push 即可。
--force 参数，强制推送。
git push --force master，将本地的 master 分支强制推送到远程仓库 origin 的 master 分支并覆盖。
git push --force master 可以简写为 git push -f master。
谨慎使用 --force 参数。
git push origin -d {name}，删除远程仓库 origin 的 name 分支。
分支 git branch，列出本地分支。星号 * 标记当前在哪个分支下。
git branch -a，列出本地和远端的所有分支。星号 * 标记当前在哪个分支下。
git branch {name}，创建 name 分支。
git branch -d {name}，删除本地 name 分支。如果该分支有提交未进行合并，则会删除失败。
git branch -D {name}，强制删除本地 name 分支。如果该分支有提交未进行合并，也会删除成功。
git checkout {name}，切换到 name 分支。
git checkout -b {name}，创建 name 分支并切换到 name 分支。
git checkout .，把本地所有修改的，但是没有提交的，都回退到原来的状态。
合并 git merge {name}，合并 name 分支到当前分支。
如果合并时发生冲突，则会将有冲突的文件的文件名输出到命令行。
进入文件解决冲突后，需要执行 git add 命令通知 git 冲突已解决。
暂存 git stash，把所有没有提交的修改暂存。
git stash pop，恢复到 git stash 之前。
提交一个本地仓库到多个远程仓库 这里提交一个本地仓库到 Github 和 Gitee 两个远程仓库。
git remote add origin git@github.com:xxx/demo_project.git git push origin master git remote add gitee git@gitee.com:xxx/demo_project.git git push gitee master</content></entry><entry><title>使用 Git 时遇到的一些异常和解决方案</title><url>/post/computer-science/application/git/exception/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>git</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 git 2.34.0
无法拉取代码 使用 git pull 命令拉取代码时卡住，并输出如下信息：
&gt; git pull Auto packing the repository in background for optimum performance. See &#34;git help gc&#34; for manual housekeeping. fatal: failed to run repack 这是因为，git 本地仓库如果长时间不进行清理，会导致本地 dangling commit 太多，从而造成拉取代码失败。 可以使用 git fsck 命令查看本地的 dangling commit。
&gt; git fsck --lost-found Checking object directories: 100% (256/256), done. Checking objects: 100% (110393/110393), done. dangling commit 01039c0c1efcc232be342aacc928af72df82503b dangling blob 5b0bd062917d784486756ef941a7446b1aa5e340 dangling commit 4a1c18fa0803db6d64e9cffded496beb686aeaa7 dangling commit f528f06bd9739511bf962e32636697f807764cf8 dangling commit ea5fb0909b71b997c3feb5c436a150f745e40886 dangling commit c76448818640c1b0a3c00546abf16e5b4dff94e4 dangling commit d27fd8f73e071d3a629348f40d079888e821b10f dangling commit 9a84703a10972d28e784d26417d6f53193b7ef78 dangling blob e7841cedb8d8a5b2cb02814cd9a2af06c5f46e00 dangling commit 6e8cf4714bc2ebb4d866a0aa046766598a1bcaf6 dangling blob fa990caae09e8d23923aed1d303e56272f6c8587 dangling commit 269e6c37f2208841d904577cd6e70d36f8ab0283 dangling commit 1ca1f0e7aafa762a675076fbc25ff6ff7048e41b ... 使用 git gc 命令清理后，就可以正常拉取代码了。
&gt; git gc --prune=now Enumerating objects: 93146, done. Counting objects: 100% (93146/93146), done. Delta compression using up to 12 threads Compressing objects: 100% (28200/28200), done. Writing objects: 100% (93146/93146), done. Total 93146 (delta 67637), reused 88951 (delta 64013), pack-reused 0 Removing duplicate objects: 100% (256/256), done. ]]></content></entry><entry><title>Windows 10 环境使用 Docker</title><url>/post/computer-science/application/docker/windows/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>docker</tag></tags><content type="html"><![CDATA[安装 去官网下一个 win10 使用的 Docker Desktop（下文简称 desktop）安装包。因为 Docker Desktop For Windows 使用的是 hyper-v 虚拟机，所以安装之前需要启用 win10 系统中内置的 hyper-v 虚拟机服务。
安装之后，可以打开 win10 的 powershell，执命令行 docker run hello-world，检测是否安装成功。安装成功的话，输出应该是下面这样的。
&gt; docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &#34;hello-world&#34; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 镜像加速 国内从 DockerHub 拉取镜像有时会遇到困难，此时可以配置镜像加速器。
打开 desktop 的界面，点击右上角的设置按钮（齿轮图标）打开设置界面。然后在左侧选择 Docker Engine 标签，可以看见 json 格式的配置参数。
{ &#34;registry-mirrors&#34;: [ &#34;https://reg-mirror.qiniu.com&#34; ], &#34;insecure-registries&#34;: [], &#34;debug&#34;: false, &#34;experimental&#34;: false, &#34;features&#34;: { &#34;buildkit&#34;: true }, &#34;builder&#34;: { &#34;gc&#34;: { &#34;enabled&#34;: true, &#34;defaultKeepStorage&#34;: &#34;20GB&#34; } } } 在 registry-mirrors 参数中添加镜像加速的地址，这里用的是七牛云的加速器 https://reg-mirror.qiniu.com。
异常处理 Error response from daemon: status code not OK but 500 如果在使用目录映射时，遇到上述这样的错误，可能是因为没有给docker权限。
打开 desktop 的设置界面左侧 Resources 标签的 File Sharing 子标签。然后添加 docker 可以映射的目录。
查看容器 在 powershell 中，使用 docker ps 命令可以查看正在使用的容器。
-a 参数可以查看所有的包括未启动的容器。 &gt; docker ps -a 进入容器 在 powershell 中，使用 docker exec 命令可以使用命令行模式进入容器。
container id，容器 id。 &gt; docker exec -it {container id} /bin/bash 导出容器 在 powershell 中，使用 docker export 命令导出容器。建议用第二个命令，在 powershell 中第一个可能有 bug。
container id，容器 id。 file path，导出文件的路径和名字，比如 e:\xxx.tar。 &gt; 和 -o 表示导出到文件。 &gt; docker export {container id} &gt; {file path} &gt; docker export -o {file path} {container id} ]]></content></entry><entry><title>使用 Docker 部署 EasySwoole</title><url>/post/computer-science/application/docker/easyswoole/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>docker</tag><tag>php</tag><tag>EasySwoole</tag></tags><content type="html"><![CDATA[部署 Swoole Swoole 官方文档中提供了官方的 docker 镜像 https://hub.docker.com/r/phpswoole/swoole。
EasySwoole 官方文档中提到：&ldquo;如果没有特殊需求，请选择最新稳定版本开始下载(我这里是稳定版v4.4.23)&quot;。所以这里也使用 v4.4.23 版本的 Swoole。
DockerHub 页面右侧提供的命令 docker pull phpswoole/swoole 会默认拉取最新的镜像，这里我们需要指定版本的所以不能用上面的命令。
我们需要点击页面上的 Tags 标签，然后在下面找到 php7.4 版本 swoole 4.4.23 版本的 tag，tag 右侧提供了拉取镜像的命令 docker pull phpswoole/swoole:4.4.23-php7.4。打开 PowerShell 执命令行，拉取成功的话会是下面这样的输出。
&gt; docker pull phpswoole/swoole:4.4.23-php7.4 4.4.23-php7.4: Pulling from phpswoole/swoole 6ec7b7d162b2: Pull complete db606474d60c: Pull complete afb30f0cd8e0: Pull complete 3bb2e8051594: Pull complete e2b7fe41b468: Pull complete 9ab9906ce2f0: Pull complete 50fac8a5156f: Pull complete 1029765b1cd3: Pull complete e9a21d7557c6: Pull complete 517180811701: Pull complete b9c164c9c98f: Pull complete Digest: sha256:5bd895677cbc73a06ea33239459bc4a07486d15025c1d1c805438a61c839dd32 Status: Downloaded newer image for phpswoole/swoole:4.4.23-php7.4 docker.io/phpswoole/swoole:4.4.23-php7.4 同时使用命令 docker images 也能看到可以使用的镜像列表。
&gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE hello-world latest d1165f221234 3 months ago 13.3kB phpswoole/swoole 4.4.23-php7.4 fb33e322751b 5 months ago 480MB 启动容器 &gt; docker run -it -p 127.0.0.1:9503:9503 -v E:\code:/code phpswoole/swoole:4.4.23-php7.4 /bin/bash 这个命令，将本机 9503 端口映射到容器 9503 端口，将本机 E:\code 目录映射到容器 /code 目录。
php版本
&gt; php -v PHP 7.4.13 (cli) (built: Dec 18 2020 21:12:27) ( NTS ) Copyright (c) The PHP Group Zend Engine v3.4.0, Copyright (c) Zend Technologies composer版本
&gt; composer -V Composer version 1.10.19 2020-12-04 09:14:16 这个镜像安装了 pecl，可以用 pecl 安装需要的扩展
&gt; pecl help version PEAR Version: 1.10.12 PHP Version: 7.4.13 Zend Engine Version: 3.4.0 Running on: Linux 2bc0c5d254d5 5.10.25-linuxkit #1 SMP Tue Mar 23 09:27:39 UTC 2021 x86_64 异常处理 WARNING swManager_check_exit_status: worker#18[pid=642] abnormal exit, status=255, 遇到这样的报错是因为 swoole 和 xdebug 冲突了，需要关掉官方提供的 docker 镜像中的 xdbug 扩展。php7.4 版本 swoole 4.4.23 版本的镜像中的配置文件在 /usr/local/etc/php/conf.d/sdebug.ini-suggested。把里面都注释掉就行了。
]]></content></entry><entry><title>站点示例</title><url>/flinks.html</url><categories/><tags/><content type="html">如想交换本站友情链接，请在评论区留下你的站点信息，格式参考如下：
- name: Hugo-NexT desc: Hugo NexT 官方预览网站。 avatar: https://hugo-next.eu.org/imgs/hugo_next_avatar.png link: https://hugo-next.eu.org</content></entry></search>