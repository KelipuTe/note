<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>访客如何使用档案馆</title><url>/post/how_to_use/</url><categories/><tags/><content type="html">前言 帕里特档案馆（重建中，旧篇总计 283，迁移完成 8，新增 11），是个个人档案馆。
档案馆的内容主要是本人的学习笔记、对学到的东西的解释和思考、对实操过程的记录。
这些玩意本质上是当时的我给以后的我的留言。它们不是教程，更不是论文。
写它们的目的是，如果以后的我忘记了这块的内容，那么现在的我可以把以后的我教会。
本人能力有限，因此不能保证所有的内容的时效性和正确性。还请各位到访的访客务必小心。
本人能力有限，因此不能保证所有的内容的时效性和正确性。还请各位到访的访客务必小心。
本人能力有限，因此不能保证所有的内容的时效性和正确性。还请各位到访的访客务必小心。
另外，如果访客您觉得毫无干货或者内容非常水，那么非常抱歉。
如何使用档案馆 档案馆的内容分为三个部分：
文本 代码，借助 github 图，借助 draw.io 如果文本使用到了代码或者图，通常在文本的最前面会有一个标题为 资料 的部分。
如果是类似 {xxx}/aaa/bbb/ 这种格式的，就是 github 上的项目的代码，需要去 github 上查看。 其中 {demo-c}、{tcp-service-c} 是私有仓库，暂不对外开放。
关于项目的代码中的符号命名，详见 符号命名 这一篇。
实际开发中符号命名规则应该和团队的风格保持统一，这套符号命名规则是本人的个人喜好。
如果访客您非要说不符合哪里哪里的规范，怎么怎么有问题，那么访客您说的都对。
如果是类似 xxx.drawio.html 这种格式的，就是 draw.io 生成的 html，直接打开就可以预览。 参考到的外部资料通常在文本的最后面会有一个标题为 reference（参考） 的部分。</content></entry><entry><title>使用 Golang 实现 ORM 框架 -- 其他辅助工具</title><url>/post/computer-science/programming-language/framework/orm/golang/middleware/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>orm</tag><tag>middleware(中间件)</tag><tag>mysql</tag><tag>golang</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {orm-go}
/v20/ orm.drawio.html 注意：orm.drawio.html 里面的这个类图和流程图都是和 v20 版本的代码对应的最终形态。 中间件 ORM 框架的中间件和 web 框架的中间件的原理是一样的，这里就不重复了。这里需要考虑的是中间件注册在哪里，查询构造器上显然是不合适的，这里可以考虑和方言抽象一样，放到数据库抽象上去。在执行查询之前，先去数据库实例上把中间件拿出来，然后把执行查询的逻辑放在最里面。
另外，需要定义中间件入参和出参的数据格式。这里和 web 框架一样，要不然套不起来。但是这里比 web 框架会复杂一点，在 web 框架那里入参和出参是一样的，整条链路上都只需要处理 TCP 连接的输入流和输出流。ORM 框架这里，输入的参数有 4 种，即 4 种查询构造器。输出的参数有两种，即数据库执行 SQL 返回的两大类结果。
所以需要把 4 中查询构造器封装到中间件入参里面，入参包括查询构造器的类型和查询构造器的本体。把数据库执行 SQL 返回的两大类结果封装到中间件出参里面，出参包括数据库执行 SQL 返回的两大类结果以及异常。这里又有一个问题了，SQL 语句执行完了，怎么处理返回回来的被封装的两大类结果。
可以注意到，SELECT 和 INSERT、UPDATE、DELETE 是分别对应数据库执行 SQL 返回的两类结果的，而且前面执行 SQL 的时候也是分别使用 query() 和 exec() 的。所以在最外面，也就是进入中间件链条的位置，是可以知道执行的到底是哪类 SQL 语句的。所以对于数据库返回的结果，就可以在这里进行类型断言。</content></entry><entry><title>使用 Golang 实现 ORM 框架 -- INSERT、UPDATE、DELETE</title><url>/post/computer-science/programming-language/framework/orm/golang/insert_update_delete/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>orm</tag><tag>mysql</tag><tag>sqlite3</tag><tag>golang</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {orm-go}
/v20/ orm.drawio.html 注意：orm.drawio.html 里面的这个类图和流程图都是和 v20 版本的代码对应的最终形态。 前言 这篇是接着 SELECT 后面的。INSERT、UPDATE、DELETE 三个加起来都没有 SELECT 复杂。其中 INSERT 因为涉及到不同数据库的方言的处理，相对 UPDATE 和 DELETE 会更复杂一点。
本篇主要涉及：INSERT 语句的构造过程、不同数据库 INSERT 语句不一样的问题的处理方式、UPDATE 语句的构造过程、DELETE 语句的构造过程。
分析 INSERT 语句的使用场景 和 SELECT 的分析套路一样。
这里实现的是一个简单的 ORM，INSERT 的部分就先处理下面这几种。
INSERT INTO 表(列) VALUES(值) INSERT INTO 表(列) VALUES(值1),(值2) INSERT INTO 表(列) VALUES(值) ON DUPLICATE KEY UPDATE 列=VALUES(值) INSERT INTO 表(列) VALUES(值) ON DUPLICATE KEY UPDATE 列=值 从上面的 SELECT 语句结构可以看出，SELECT 语句大致可以分成几个部分。
INSERT INTO 表(列) VALUES(值) ON DUPLICATE KEY UPDATE (表达式) 然后再去看一下 MySQL 的官方文档中对 INSERT 语句的定义和说明。
MySQL INSERT Statement MySQL 8 官方文档中，关于 INSERT 语句的描述：
13.2.6 INSERT Statement
把文档给出的结构和上面的那几种比较一下，提取出文档中相关的描述部分，大概是下面这部分。
INSERT [INTO] tbl_name [(col_name [, col_name] ...)] { {VALUES | VALUE} (value_list) [, (value_list)] ... } [ON DUPLICATE KEY UPDATE assignment_list] assignment: col_name = value | [tbl_name.]col_name assignment_list: assignment [, assignment] ... 构造 INSERT 语句 从最简单的开始 先从最简单的 INSERT INTO 表(列) VALUES(值) 开始。
表和列很熟悉了，直接从元数据里搞。值也是一样的，构建元数据的时候，只通过反射获取了结构体属性的类型，值就是把结构体属性上的值也拿出来。然后按照把语句拼起来就可以了。INSERT 单个值的搞定了，多个值的循环单个值的步骤就行了。
提取查询构造器 在构造 INSERT 语句的时候会发现，在构造 SELECT 语句的时候使用到的一些构造的方法，在构造 INSERT 语句的时候也会用的到。所以这里可以提取一个抽象出来，就叫它 SQL 查询构造器好了。这样后面 UPDATE 和 DELETE 语句构造的时候也可以用的上，不用重复的去写。创建 SELECT 查询构造器或者 INSERT 查询构造器这些具体的构造器的时候，组合一个 SQL 查询构造器进去就行了。
处理 ON CONFLICT ON CONFLICT 在 MySQL 里面就是指的 ON DUPLICATE KEY UPDATE 也可以叫 UPSERT。这里单独拿出来说它是因为 ORM 框架一般不会只支持一种数据库。当需要支持多种数据库的时候，不同数据库的 SQL 语法之间冲突的部分就需要处理。这里用 MySQL 和 SQLite3 做演示。
在 MySQL 里面，语句是这样的：
INSERT INTO 表(列) VALUES(值) ON DUPLICATE KEY UPDATE 列=VALUES(列) INSERT INTO 表(列) VALUES(值) ON DUPLICATE KEY UPDATE 列=值 SQLite 官方文档中，关于 INSERT 语句和 ON CONFLICT 的描述：
INSERT
The ON CONFLICT Clause
在 SQLite3 里面，语句是这样的：
INSERT INTO 表(列) VALUES(值) ON CONFLICT (列) DO UPDATE SET 列=excluded.列; INSERT INTO 表(列) VALUES(值) ON CONFLICT (列) DO UPDATE SET 列=值; 这两个数据库的 ON CONFLICT 语法结构是不一样的，所以在构造 SQL 语句的之后需要分开处理。这里需要对两个数据库的 ON CONFLICT 进行抽象。然后通过观察每个数据库的 SQL 语句，也就是 ON CONFLICT 后面的两种赋值方式，也会得到一个抽象。同样的，MySql 官方文档里也已经告诉你了，这个抽象叫 assignment_list（这里叫赋值表达式）。这个东西 UPDATE 语句里面也会用到，后面再说。
处理的时候先处理完 INSERT 前面一样的部分，然后再处理 ON CONFLICT 的部分。这个地方处理的时候，会有一个从处理公共部分的 INSERT 查询构造器跳到处理不同部分的 ON CONFLICT 查询构造器的步骤。这里可以用在 INSERT 查询构造器里面定义一个抽象的方式，然后构造 INSERT 查询构造器的时候把 ON CONFLICT 查询构造器传进来。
另外一个思路是，INSERT 查询构造器处理完公共部分之后，把自己交给一个 ON CONFLICT 查询构造器。完了 ON CONFLICT 查询构造器处理完之后，在把他自己交给刚才的 INSERT 查询构造器，由 INSERT 查询构造器继续后面的执行 SQL 和处理结果集的步骤。
关于方言抽象的注入 从上面的过程可以发现，方言抽象是需要注入到 INSERT 查询构造器里面的。这就意味着每次创建新的 INSERT 查询构造器的时候，都需要根据到底是生成哪个数据库的 SQL 语句进而注入对应的方言抽象的实例。这显然是非常麻烦的，有一个更好的位置可以放这个方言抽象，这个位置就是数据库抽象。
仔细想一下，不管是哪种具体的查询构造器，构造出来的语句最终都是要靠数据库实例去执行的。而且方言本身也是因为需要使用不同的数据库从而产生的设计，所以把方言放到数据库抽象里面是最合适的。查询构造器在构造 SQL 的时候，就可以直接调用数据库实例里面的方言实例去处理不同数据库里面冲突的部分。
INSERT 语句就差不多了 UPDATE UPDATE 就比较简单了。同样的，把文档放在这里，然后把相关的描述部分提取出来。
13.2.15 UPDATE Statement
UPDATE table_reference SET assignment_list [WHERE where_condition] table_reference 和 where_condition 在 SELECT 那里处理过，assignment_list 在 INSERT 那里处理过。
注意这个 assignment（赋值语句） assignment 接口有两种实现。一个是列，对应 列=VALUES(列) 这种语句。另一种是常规的赋值语句，对应 列=值 这种的。这里注意一下 列=VALUES(列) 这种的，这种语句在 INSERT 的不同的数据库方言里和 UPDATE 语句里面，它的实现又是各不相同的。目前的实现是先把 assignment 接口断言成列，然后不同的数据库方言和 UPDATE 自己实现自己的逻辑。
DELETE DELETE 更简单。同样的，把文档放在这里，然后把相关的描述部分提取出来。
13.2.2 DELETE Statement
DELETE FROM tbl_name [WHERE where_condition] table_reference 在 SELECT 那里处理过，assignment_list 在 INSERT 那里处理过。
执行语句 这三个语句的执行和 SELECT 不一样，它们是没有处理结果集一说的，都是返回影响了多少行。顶多 INSERT 有一个返回插入的行的 id 的功能。所以这里需要再写一套和数据库交互的逻辑，因为返回值不一样。如果是在 Golang 里面，执行 SQL 调用的方法就是不一样的，SELECT 用的是 query() 这三个用的是 exec()。
全流程结束 到这里，生成 INSERT、UPDATE、DELETE 语句、执行语句、处理返回值，就都处理完了。同样的，设计上的东西，看类图、流程图会更加直观。细节上的实现，直接看代码，这个靠说是说不太清楚的。</content></entry><entry><title>使用 Golang 实现简单的 ORM 框架 -- SELECT</title><url>/post/computer-science/programming-language/framework/orm/golang/select/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>orm</tag><tag>mysql</tag><tag>golang</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {orm-go}/v20/ orm.drawio.html 注意：orm.drawio.html 里面的这个类图和流程图都是和 v20 版本的代码对应的最终形态。 前言 注意，这里实现的是一个简单的 ORM 框架，并不是一个完备的 ORM 框架，主要目的是研究原理和设计。
ORM 框架的核心功能主要有两个：1、把数据结构转换成 SQL 语句。2、处理 SQL 语句的执行结果。其他的功能，都是在这两个功能的基础上，再增加亿点点细节而已。
数据结构转换成 SQL 语句这没啥好说的，在这个简单的 ORM 框架里面就是把 Golang 的结构体转换成对应的 SQL 语句。处理 SQL 语句的执行结果主要指的是，简化手动操作，自动把 SELECT 语句执行的结果装到对应的结构体里去。
另外，这两个功能的实现过程都会用到反射操作和内存操作，需要先有这两个方面的知识。
本篇主要涉及：SELECT 语句的分析和抽象、SELECT 语句的构造过程、元数据的构造、结果集的处理。
分析 SELECT 语句的使用场景 这里实现的是一个简单的 ORM，SELECT 的部分就先处理下面这几种。
SELECT &hellip; FROM &hellip; SELECT &hellip; FROM &hellip; WHERE &hellip; SELECT &hellip; FROM &hellip; WHERE &hellip; GROUP BY &hellip; HAVING &hellip; SELECT &hellip; FROM &hellip; WHERE &hellip; ORDER BY &hellip; SELECT &hellip; FROM &hellip; WHERE &hellip; LIMIT &hellip; OFFSET &hellip; SELECT &hellip; AS &hellip; FROM &hellip; AS &hellip; WHERE &hellip; SELECT &hellip; FROM JOIN SELECT &hellip; FROM 子查询 SELECT &hellip; FROM &hellip; WHERE &hellip; IN &hellip; 从上面的 SELECT 语句结构可以看出，SELECT 语句大致可以分成几个部分。
SELECT {*|列|聚合函数} AS 别名 FROM {表|JOIN|子查询} AS 别名 WHERE 条件 GROUP BY 列 HAVING 条件 ORDER BY 列 LIMIT 数字 OFFSET 数字 这样大概的内容和处理流程就有了。就是构建 SELECT 语句需要哪些东西，构建的大概流程是什么样的。然后再去看一下 MySQL 的官方文档中对 SELECT 语句的定义和说明。
MySQL SELECT Statement MySQL 8 官方文档中，关于 SELECT 语句的描述：
13.2.10 SELECT Statement把文档给出的结构和上面的那几种比较一下，提取出文档中相关的描述部分，大概是下面这部分。
SELECT [DISTINCT] select_expr [, select_expr] ... [FROM table_references] [WHERE where_condition] [GROUP BY {col_name}, ...] [HAVING where_condition] [ORDER BY {col_name} [ASC | DESC], ...] [LIMIT {row_count | row_count OFFSET offset}] [FOR UPDATE] } 还需要关注以下关于别名的部分：
列的别名： A select_expr can be given an alias using AS alias_name.
表的别名： A table reference can be aliased using tbl_name AS alias_name or tbl_name alias_name. For each table specified, you can optionally specify an alias.
tbl_name [[AS] alias] 还需要关注一下 JOIN 的部分：
13.2.11.2 JOIN Clause主要是下面这部分，描述的是 JOIN 的结构。
table_reference: { table_factor | joined_table } table_factor: { tbl_name [[AS] alias] | table_subquery [AS] alias [(col_list)] | ( table_references ) } joined_table: { table_reference {JOIN} table_factor [join_specification] | table_reference {LEFT|RIGHT} JOIN table_reference join_specification | table_reference NATURAL [INNER | {LEFT|RIGHT} [OUTER]] JOIN table_factor } join_specification: { ON search_condition | USING (join_column_list) } 也就是说 JOIN 的结构大概可以描述成下面这几种，而且还可以嵌套。
表 JOIN 表 （表 JOIN 表） JOIN 表 表 JOIN 子查询 子查询 JOIN 子查询 还需要关注一下（Sub Query）子查询的部分：
13.2.13 Subqueries简单的理解，JOIN 和子查询都是构建了一个临时的表，和常规的表不同的是，这里的表名和表里的列都不是固定的，而是动态生成的。
到这里 SELECT 语句的构成分析的就差不多了，下面是对 SELECT 语句的构成进行合理的抽象。
分析和抽象 其实抽象的工作是比较容易的，官方文档中的描述已经把抽象给出来了。在这个简单的 ORM 框架里面，大概是下面这几个。
select_expr 对应列和聚合函数 table_references 对应表、JOIN、子查询 where_condition 对应查询条件 col_name 对应列 这里还需要再看一下关于表达式和聚合函数的部分：
9.5 Expressions12.20 Aggregate Functions到这里，在这个简单的 ORM 框架里需要实现的部分，就都差不多都了解了，下面就可以开始动手了。
构造语句 从最简单的开始 先从最简单的 SELECT 列 FROM 表 开始。首先需要构造一个处理 SELECT 语句的对象，封装相关的数据和方法，一般叫它查询构造器（这里叫 SELECT 查询构造器，为了和 INSERT、UPDATE、DELETE 区分开）。
这里上来就会遇到问题，语句里的列和表怎么来。在 ORM 框架中，这里的列和表，不是手动写入的，而是通过解析结构体得到的。既然是通过解析结构体，那么就需要有解析的规则。解析规则由 ORM 框架定义，是解析结构体的属性、还是解析结构体的属性的注释、还是解析 Golang 结构体的属性上的 tag、还是混合模式。
结构体需要按照 ORM 框架定义的解析规则去写，要不然 ORM 框架对着没有按规则来的结构体也是抓瞎的。虽然注释和 tag 可以自定义的随便写，但是结构体它至少会有属性，所以这里可以做一个兜底的策略。这个简单的 ORM 框架里的解析规则为：默认解析结构体的属性，如果结构体的属性上有 tag 就解析 tag。
解析出来的玩意，专业一点的叫法，叫 metadata（元数据），内容是结构体和数据库表的映射关系。包括结构体名和数据库表名的对应关系，结构体的属性名和数据库表的字段名的对应关系，里面还会有一些辅助的信息，这个后面再说。
元数据 在 Golang 里面，可以通过反射解析结构体。通过反射的一些列操作，可以得到结构体名、结构体的属性、还有挂在这些玩意上面的其他信息。这里通过转换结构体名得到数据库表名，拿到结构体名之后，直接驼峰命名转蛇形命名就行。
还可以通过解析注释或者定义接口的方式获取数据库表名。注释就不多说了，通过 AST 解析结构体的注释就行。定义接口，就是定义一个获取数据库表名的接口，然后具体对应数据库表的结构体去实现这个接口。
这样在 SQL 构建的过程中，通过类型断言可以确认结构体是否实现了这个接口，如果实现了这个接口就调用接口取获取自定义的数据库表名。
需要注意的是，元数据里关于结构体的属性名和数据库表的字段名的对应关系的数据，在两个方向上的都需要。因为元数据不止构造 SQL 语句的时候需要正向用，处理结果集的时候也需要用，只不过方向是反过来的，通过数据库字段名，找到对应的结构体属性名。
元数据这块的内容是独立的，可以和 SQL 语句构造的内容隔离开来，自己成为一个独立的模块，这里叫它元数据注册中心。
回到 SQL 语句的构造 解决完元数据的问题，那么语句里的列和表就都有了，这个语句就很好构造了。把传进来的结构体解析之后，把列和表捞出来塞到语句里就行。
对于列来说，后面还可以结合元数据，做一下列存不存在之类的校验。但是如果列写了别名或者是一个复杂查询啥的，校验起来会有点麻烦。
下面搞 WHERE 语句后面的 SELECT 列 FROM 表 WHERE 查询条件。
在动手设计之前，需要先观察一下查询条件的结构。这里列举几个常用的查询条件。
列{=|&gt;|&lt;|!=}值 列=值 AND 列=值 列=值 OR 列=值 列=值 AND (列=值 OR 列=值) 列 LIKE 值 列 IN (值) 这里可以观察到，查询条件的结构，大体上是嵌套起来的左中右的结构。中间是操作符，左边是列或者值，右边一般都是值。
这里看上去是一样的，但是实际上有两层抽象。第一层是：左=列，中间=操作符，右边=值；第二层是：左=第一层抽象 中间=操作符，右=第一层抽象。所以这里需要处理的对象不仅有第一层抽象的 column（列）和 value（值）。还有对第一层抽象的抽象，也就是 expression（表达式）。而且可以得出一个结论，列和值都是表达式的一种。由此可以推论，列和值可以是对象，但是表达式肯定是个接口。
这种左中右的结构，可以联想到树的结构，中间是一个根结点，左右是两个叶子结点。大概的形状见图：orm.drawio.html 2-0。常规的等于、大于、小于、不等于等数学运算和与、或两个逻辑运算可以直接通过这个结构表示。包括 LIKE 和 IN 也可以用这个结构。问题在于 NOT 逻辑运算和原生语句。NOT 只有一边，原生语句直接没有结构。其实这两个玩意，树形结构也是可以兼容的。
NOT 直接让他没有左边就可以了，处理的时候判断一下左边是不是空的就行。大概的形状见图：orm.drawio.html 2-2。
原生语句看上去是自定义的，不符合树的结构，但是可以换个思路，把语句拆开看，其实它已经包含了列和值，所以它就是一个完整的第一层抽象。只不过它只有左边，不需要中间和右边（语句放右边，不需要左边和中间也行）。大概的形状见图：orm.drawio.html 2-4。
代码中处理的时候用递归就行，先递归处理左边的非空叶子，然后处理中间的操作符，然后递归处理右边的非空叶子。每次递归的结果，两边加括号包起来，这样不容易出错。遇到空的位置，空格就不管了。括号和空格多了就多了，只要保证语法没问题就行。
基本的 WHERE 用这个结构就差不多了，需要注意 WHERE IN 那里不仅可以直接填数据，还可能涉及到子查询，这后面再说。
下面处理 GROUP BY SELECT 列 FROM 表 GROUP BY 列 HAVING 查询条件。
GROUP BY 其实很简单了，这玩意有两个部分。前面的列很简单了，没啥好说的。后面的 HAVING 和上面的 WHERE 是一样的。官方文档里面这两个位置都是 where_condition 把上面 WHERE 的逻辑直接拿过来复用就可以。
下面处理 ORDER BY SELECT 列 FROM 表 ORDER BY 列。
这玩意也没啥好说的，就是个列，加上升序或者降序的标志。
下面处理 LIMIT 和 OFFSET SELECT 列 FROM 表 LIMIT 20 OFFSET 100。
这两个也没啥好说的，就是两个数字。
处理 SELECT 后面的 SELECT 列 FROM 表。 SELECT 列 AS 新名字 FROM 表。 SELECT 聚合函数 FROM 表。 SELECT 聚合函数 AS 新名字 FROM 表。 SELECT 后面就两大类东西：列和聚合函数，还会涉及到别名。另外，这里还可以插入原生表达式。
从形态上看，列和聚合函数完全不一样，但是它们都可以放在 SELECT 后面，所以这里肯定有一个抽象。其实官方文档里也已经告诉你了，这个抽象叫 select_expr（这里叫查询表达式）。
这里分开处理这两个玩意。列很简单了，就是列。聚合函数需要一个单独的对象，对象里面放上聚合函数的名字还有聚合函数操作的那个列。别名就目前的场景而言其实很简单，就直接对象里给一个字符串设置一下就好了。加上表、JOIN、子查询的别名之后，这里的别名会变的复杂一点。原生表达式就更简单了，直接把表达式原封不动的放在这里就行了。
到这里，在单个表上的操作基本就都搞定了。下面开始搞 JOIN 和子查询。
JOIN SELECT 列 FROM JOIN。
实现简单的 JOIN 其实不怎么复杂，主要功能包括起别名、选择列、复杂一点的是 JOIN 可以嵌套。
常用的 JOIN 结构大概就是下面这几个：
表 A JOIN 表 B ON &hellip; 表 A AS 新名字 JOIN 表 B AS 新名字 ON &hellip; 表 A JOIN (表 B JOIN 表 C ON &hellip;) ON &hellip; 之前处理 FROM 后面那个位置的时候是直接用的数据库表名，但是那个位置其实可以放的玩意有表名、JOIN、子查询，这明摆了是要有一个抽象的，官方文档也告诉你了，叫 table_references（这里叫表表达式）。但是这三种对象的处理方式肯定是不一样的，语句形态差的都很远，基本没有共同点，所以铁定是分开各写各的。
观察一下上面的几个 JOIN 的样例，又是个左中右的结构，只不过这里的左右两边是一样的，都是 table_references。处理思路和上面的 WHERE 那里处理查询条件的思路是一样的，都是用递归，先处理递归左边的非空叶子，再递归处理右边的非空叶子。另外 JOIN 还有 ON 子句，官方文档里 ON 后面跟的是 search_condition。它和 WHERE 后面的 where_condition 是差不多的，这里不做复杂处理，所以直接拿过来复用。
这里可以换个思路理解，把带有 JOIN 的查询分成两块。JOIN 单独拿出来看，它最终其实就会变成个临时表。把别名当做表名，左右两个 table_references 的列就是临时表的列，这样问题就又回到了之前处理单个数据库表的问题。后面解决子查询的时候，思路也是这样的。
选择列和上面 SELECT 那里处理查询表达式的地方差不多。但是加入 JOIN 之后，列的处理会变得复杂一点，以前的列都是默认在同一个表里的，加入 JOIN 之后，表就不是一个了。所以列里面，必须把自己属于哪个表存着，这样构造列的时候，需要先构造前面的前缀，而且前缀这玩意可以有别名。也就是表和 JOIN 包括后面的子查询都要有别名，列从原来依托于元数据直接构造变成依托于 table_references 构造。
子查询 子查询看着很复杂，但是构成子查询的元素，上面都已经处理过了。前面说过，子查询就是一个临时表，把别名当做表名，左右两个 table_references 的列就是临时表的列，如果子查询设置了查询表达式，那么临时表的列就是查询表达式里面写的那些列。
整体思路和 JOIN 的思路是差不多的，区别的地方在于对列的处理方式不同。处理 JOIN 的时候，查询表达式里的列可能来自不同的表。但是在子查询这里，所有的列都来自子查询的临时表。
语句构建结束 在编码的时候使用 Builder 设计模式实现，基本思路就是将和 SELECT 语句有关的数据的填充和使用这些数据构造 SELECT 语句的部分隔离开。其最终形态就是常见的 ORM 框架的一堆用起来很流畅的链式调用，最后一个 First() 方法或者 Get() 方法，然后查询构造器构建 SQL、执行 SQL、处理结果集一气呵成之后返回结果集。
到这里简单的 SELECT 语句的构建思路就差不多了。下面就是执行语句和处理结果集了。
执行语句 执行语句分为两种，一种是直接执行，一种是事务执行。这两个的区别也很简单就是拿到数据库实例之后，要不要开事务。这个地方可以做两个抽象，一个是数据库的抽象，一个是事务的抽象。其中事务的抽象可以包括数据库的抽象，和装饰器有点像，事务对象可以理解成把数据库的抽象拿过来，用事务功能装饰一下。
这两个抽象其实可以再抽象出一个共同的部分，就是执行 SQL 的部分。无论是数据库的抽象还是事物的抽象，最后都会完成执行 SQL 的操作。这个部分可以再抽象一下，抽象成一个会话，一个会话就表示用户的一次数据库交互操作。
这样编码的时候可以使用依赖注入的方式，把数据库抽象或者事务抽象注入到 SELECT 查询构造器里面。SELECT 查询构造器在构造完 SQL 语句后，就可以继续使用链式调用的方式，调用会话抽象去执行语句。
处理结果集 结果集的处理也不难，前面构造的元数据里不是已经有反方向的映射关系了嘛。先通过数据库返回的结果集里面的结果的字段名，结合元数据，把所有的变量类型先确定好。然按照变量类型构造一个接收数据库返回的结构，接收的时候注意顺序。
成功接收到数据库的返回结果后，先通过元数据构造一个对应的空的结构体。然后通过数据库返回的字段名，结合元数据，反向去找结构体的属性。然后通过反射或者内存操作，把值塞到结构体对应的属性上去。
全流程结束 到这里，构造元数据、生成 SELECT 语句、执行语句、处理返回值，就都处理完了。设计上的东西，看类图、流程图会更加直观。细节上的实现，直接看代码，这个靠说是说不太清楚的。
]]></content></entry><entry><title>符号命名</title><url>/post/computer-science/programming-language/symbol_naming/</url><categories><category>programming-language(编程语言)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag></tags><content type="html">前言 实际开发中符号命名规则应该和团队的风格保持统一，这套符号命名规则是本人的个人喜好。
如果访客您非要说不符合哪里哪里的规范，怎么怎么有问题，那么访客您说的都对。
命名 本人的符号（变量名、方法名）命名方式和主流的命名方式比起来有一些奇怪。区别主要在于各种各样标记类型的前缀。
声明的变量名和方法名、定义的类型名，都会带前缀。加前缀的目的，主要是为一些特殊的类型作标记，编码过程中引起重视。
比如，一个 map，map 的内容是指向结构体的指针，前缀就是 m3p7s6（var m3p7s6user map[string]*User）。
基本类型就不管了。比如，一个切片，切片的内容是 int 类型，前缀就是 s5（var s5UserId []int）。
另外，如果是临时变量，t4 一定在最前面。
如果变量需要对外开放（声明为 public），则前缀全部为大写。
如果变量不需要对外开放（声明为 protected、private），则前缀全部为小写。
如果变量名是一个单词，则单词首字母用小写。（var name string）
如果变量名是两个或以上的单词，则第一个单词首字母用小写，后面的单词首字母用大写。（var s5UserId []int）
如果有前缀，则单词首字母可用小写也可用大写。（var s5name, s5Name []string）
Golang 命名目录时，多单词用中划线连接 import 引入时，多单词用下划线连接 目录里的 kn 后缀，用于回避关键字，比如：mapkn 符号命名全部都用驼峰（camel case） 数据库命名全部都用蛇形（snake case） 符号命名前缀：
t4，temp，临时变量 c5，const，常量 p7，pointer，指针 a5，array，数组 s5，slice，切片 m3，map，map c7，channel，管道 s6，struct，结构体 i9，interface，接口 f8，function，方法 版本号 版本号可能是 x.y 或者 x.y.z。大版本号从 2 开始，小版本号从 0 开始，以 2 为步长递增。
第 1 版：v2.0.0（v2.0） 第 1 版小改一次：v2.0.2（v2.2） 第 1 版小改一次：v2.0.4（v2.4） 第 1 版大改一次：v2.2.0（v2.6） 第 1 版小改一次：v2.2.2（v2.8） 第 2 版：v4.0.0（v4.0） 通常 x.y 用的多，本人的各种 demo 代码版本一般情况下达不到需要使用 x.y.z 这样的规模。
而且版本号一般不会超过 10，常见的是：v20、v22、v40、v200、v202、v220、v400。</content></entry><entry><title>使用 Golang 实现复杂的 Web 框架</title><url>/post/computer-science/programming-language/framework/web/golang/web_v40/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>web</tag><tag>http</tag><tag>router(路由)</tag><tag>middleware(中间件)</tag><tag>golang</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
前言 在看这篇之前，建议先看下面这几篇：
使用 Golang 开启 HTTP 服务 使用 Golang 实现简单的 Web 框架 &ndash; router(路由) 使用 Golang 实现简单的 Web 框架 &ndash; middleware(中间件) 路由树是 web 框架的核心。其他的功能，都是在路由树的基础上，再增加亿点点细节而已。
资料 {web-framework-go}/v40 实现功能 主要实现： 路由树（静态、通配符、路径参数、正则表达式）、路由组 全局中间件、可路由的中间件 次要实现： 内存池（请求上下文对象复用） 服务管理（管理多个子服务） 优雅退出、退出时的回调方法 计划实现： 用户认证（中间件实现） 文件操作（上传、下载） 单元测试、集成测试、性能测试 设计文档 路由树 首先是路由树结点的设计。结点的基础数据包括：结点类型、这个路由结点代表的那段路径、命中路由之后的的处理逻辑。
静态路由子结点使用 map 结构存储，查询时直接就可以通过路由段查询子结点。
通配符子结点、路径参数子结点、正则表达式子结点，这三个结点属于特殊结点，而且存在冲突关系，所以单独存储。
为了支持可路由的中间件，路由结点上还需要有存储中间件的地方，这样就可以为每个结点单独设置中间件。
另外，服务在运行的时候只要命中的是同一个路由，那么用到的中间件一定也是相同的，在服务启动的时候就可以把中间件遍历好，然后缓存下来。
// routingNode 路由结点 type routingNode struct { // nodeType 结点类型 nodeType int // part 这个路由结点代表的那段路径 part string // path 从根路由到这个路由结点的全路径 path string // f4handler 命中路由之后的处理逻辑 f4handler HTTPHandleFunc // m3routingTree 路由子树，子结点的 path =&gt; 子树根结点 m3routingTree map[string]*routingNode // p7paramChild 路径参数结点 p7paramChild *routingNode // paramName 路径参数路由和正则表达式路由，都会提取路由参数的名字 paramName string // p7regexpChild 正则表达式结点 p7regexpChild *routingNode // p7regexp 正则表达式 p7regexp *regexp.Regexp // p7anyChild 通配符结点 p7anyChild *routingNode // s5f4middleware 结点上注册的中间件 s5f4middleware []HTTPMiddleware // s5f4middlewareCache 服务启动后，命中结点时，需要用到的所有中间件 s5f4middlewareCache []HTTPMiddleware } 路由树的构造和遍历并不复杂，使用递归逻辑处理即可。不用担心递归带来的性能问题。
对于路由树的递归操作，都发生在服务启动时，这个时候会遍历路由树然后将结果缓存下来。
服务启动后，当请求访问过来时，就可以直接使用缓存里的结果，而不用每次都去遍历路由树。
路由组 路由组就是个语法糖。相当于路由组方法会在路由组内的每个成员注册的时候，附加路由组的路由前缀和路由组定义的中间件。
// Group 添加一组路由 func (p7this *HTTPHandler) Group(path string, s5f4mw []HTTPMiddleware, s5routeData []RouteData) { for _, rd := range s5routeData { t4path := path if &#34;/&#34; != rd.Path { t4path = path + rd.Path } p7this.addRoute(rd.Method, t4path, rd.F4handle, s5f4mw...) } } 中间件 全局中间件和可路由中间件是分开放的。全局中间件存储在核心处理逻辑上。可路由中间件存储在路由树结点上。
// HTTPHandlerInterface 核心处理逻辑的接口定义 type HTTPHandlerInterface interface { http.Handler ... } // HTTPHandler 核心处理逻辑 type HTTPHandler struct { ... // s5f4middleware 全局中间件 s5f4middleware []HTTPMiddleware ... } 当请求访问过来时，第一站到的是核心处理逻辑，核心处理逻辑会完成全局中间件的组装和执行。
func (p7this *HTTPHandler) ServeHTTP(i9w http.ResponseWriter, p7r *http.Request) { ... // 倒过来组装，先组装的在里层，里层的后执行 // 最里层应该是找路由然后执行业务代码 t4chain := p7this.doServeHTTP for i := len(p7this.s5f4middleware) - 1; i &gt;= 0; i-- { t4chain = p7this.s5f4middleware[i](t4chain) } // 写入响应数据这个中间件应该由框架开发者处理 // 它是最后一个环节，应该在最外层 t4m := FlashRespMiddleware() t4chain = t4m(t4chain) t4chain(p7ctx) } 在通过全局中间件之后，进入查询路由树的步骤。查询结果里会有路由树结点上的可路由中间件。
使用和全局中间件一样的套路，完成一遍可路由中间件的组装和执行。最后调用路由上的处理逻辑，开始真正的业务逻辑。
func (p7this *HTTPHandler) doServeHTTP(p7ctx *HTTPContext) { ... p7ri := p7this.findRoute(p7ctx.P7request.Method, p7ctx.P7request.URL.Path) ... // 这里用同样的套路，处理路由上的中间件，最后执行业务代码 t4chain := p7ri.p7node.f4handler for i := len(p7ri.p7node.s5f4middlewareCache) - 1; i &gt;= 0; i-- { t4chain = p7ri.p7node.s5f4middlewareCache[i](t4chain) } t4chain(p7ctx) } 优雅退出 想实现优雅退出，程序就不能阻塞在不可控的位置。这里可以直接把服务丢到协程里去。
然后在最外面，实现一个信号等待的逻辑，这样就可以通过信号控制程序的运行状态。
func (p7this *ServiceManager) Start() { // 启动服务 log.Println(&#34;服务启动中。。。&#34;) for _, p7s := range p7this.s5p7HTTPService { t4p7s := p7s go func() { if err := t4p7s.Start(); nil != err { if http.ErrServerClosed == err { log.Printf(&#34;子服务 %s 已关闭\n&#34;, t4p7s.name) } else { log.Printf(&#34;子服务 %s 异常退出，err:%s\r\n&#34;, t4p7s.name, err) } } }() } log.Println(&#34;服务启动完成。&#34;) // 监听 ctrl+c 信号 c4signal := make(chan os.Signal, 2) signal.Notify(c4signal, os.Interrupt) select { case &lt;-c4signal: ... } } 在可以主动介入程序运行之后，就可以设计主动拒绝新请求的逻辑了。这样可以实现服务不完全停止的情况下，拒绝对外服务。
因为服务停止不仅仅是不对外服务这么简单，在服务真正的停止之前，还有很多善后的工作需要做。
// HTTPHandler 核心处理逻辑 type HTTPHandler struct { ... // isRunning 服务是否正在运行 isRunning bool } func (p7this *HTTPHandler) doServeHTTP(p7ctx *HTTPContext) { // 如果服务已经关闭了就直接返回 if !p7this.isRunning { p7ctx.I9writer.WriteHeader(http.StatusInternalServerError) _, _ = p7ctx.I9writer.Write([]byte(&#34;服务已关闭&#34;)) return } ... } 虽然服务停止前有很多善后的工作需要做，但是理论上不会持续很久。
为了防止意外卡死的情况出现，可以再加一层超时强制停止的逻辑。必要的时候，也可以设计主动强制关闭的入口。
func (p7this *ServiceManager) Start() { ... // 监听 ctrl+c 信号 c4signal := make(chan os.Signal, 2) signal.Notify(c4signal, os.Interrupt) select { case &lt;-c4signal: log.Printf(&#34;接收到关闭信号，开始关闭服务，限制 %d 秒内完成。。。\r\n&#34;, p7this.shutdownTimeOut/time.Second) // 再次监听 ctrl+c 信号 go func() { select { case &lt;-c4signal: log.Println(&#34;再次接收到关闭信号，服务直接退出。&#34;) os.Exit(1) } }() time.AfterFunc(p7this.shutdownTimeOut, func() { log.Println(&#34;优雅关闭超时，服务直接退出。&#34;) os.Exit(1) }) p7this.Shutdown() } } 在拒绝新请求之后，由于有可能还有旧的请求没有处理完，所以是不能立刻就关闭服务的，需要等待一段时间。
func (p7this *ServiceManager) Shutdown() { ... log.Println(&#34;停止接收新请求。&#34;) for _, p7hs := range p7this.s5p7HTTPService { p7hs.Stop() } log.Printf(&#34;等待正在执行的请求结束，等待 %d 秒。。。&#34;, p7this.shutdownWaitTime/time.Second) time.Sleep(p7this.shutdownWaitTime) ... } 服务正式关闭服务之后，可能还有一些收尾的工作需要处理，然后才能彻底退出程序。
比如：系统里如果有缓存的话，可能需要把缓存进行持久化处理；系统关闭时，需要上报数据其他服务等。
这个可以通过回调实现，和中间件的用法类似。不过最后执行的时候，是所有的回调是并发执行的，而不是像中间件一样套起来，一次执行的。
func (p7this *ServiceManager) Shutdown() { ... log.Println(&#34;开始执行子服务的关闭回调。。。&#34;) for _, p7hs := range p7this.s5p7HTTPService { log.Printf(&#34;执行子服务 %s 的关闭回调，限制 %d 秒内完成。。。&#34;, p7hs.name, p7this.shutdownCallbackTimeOut/time.Second) for _, f4cb := range p7hs.s5f4shutdownCallback { t4f4cb := f4cb wg.Add(1) go func() { defer wg.Done() t4ctx, t4cancel := context.WithTimeout(context.Background(), p7this.shutdownCallbackTimeOut) defer t4cancel() t4f4cb(t4ctx) }() } } wg.Wait() ... } 到这里核心的部分就差不多了，细节上的实现可以看代码。
]]></content></entry><entry><title>使用 Hugo 和 GitHub Pages 搭建站点</title><url>/post/computer-science/application/hugo/hugo-start/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>Hugo</tag><tag>GitHub Pages</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 hugo 0.103.1
Hugo 文档 gohugoio/hugo英文文档中文文档安装 Hugo 在 Hugo Releases页面下载对应操作系统的版本。这里下载的是 hugo_0.103.1_windows-amd64.zip。
下载完成后，解压到想要的位置。这里使用的目录是 D:\hugo\bin。然后将这个目录添加到 系统变量 path 中（我的电脑 -&gt; 属性 -&gt; 高级系统设置 -&gt; 环境变量 -&gt; 系统变量 -&gt; path）。
搞定之后，可以打开控制台，输出一下版本信息，验证一下安装是否成功。或者试试 hugo help 命令，看看能不能输出帮助信息。
&gt; hugo version hugo v0.103.1-b665f1e8f16bf043b9d3c087a60866159d71b48d windows/amd64 BuildDate=2022-09-18T13:19:01Z VendorInfo=gohugoio 如果有需要的话，需要安装 extended 版本的。这里下载的是 hugo_extended_0.103.1_windows-amd64.zip。
&gt; hugo version hugo v0.103.1-b665f1e8f16bf043b9d3c087a60866159d71b48d+extended windows/amd64 BuildDate=2022-09-18T13:19:01Z VendorInfo=gohugoio 创建站点 使用命令创建一个站点，如果没问题的话，hugo 会在当前目录下创建一个名字是 project-name 的目录。
&gt; hugo new site {project-name} 新建的站点没有任何内容，可以使用命令创建一个内容页面。新创建的文件会在目录 content/ 里。创建内容页面的时候也可以带上目录。
&gt; hugo new helloworld.md &gt; hugo new posts/helloworld.md 安装主题 这里就是和别的站点工具不一样的地方了，比如 hexo 和 jekyll，如果没有安装主题的话，是会有一个默认的主题的。
但是 hugo 没有默认主题，需要去主题库下载一个，然后添加到站点里并配置好，这样才能启动站点。如果没有安装主题就启动的话，会报没有模板的错误。
可以去 官方的主题库找一个喜欢的。然后按照主题提供的文档配置一下。
Hugo NexT Hugo NexT这个主题是从 Hexo NexT 移植过来的。
GitHub 项目地址 hugo-next/hugo-theme-next。
按着 Hexo NexT 主题提供的的文档走，把主题配置到站点中。
别忘了先 git init，然后使用命令下载主题 git submodule add https://github.com/hugo-next/hugo-theme-next.git themes/hugo-theme-next。
如果需要升级主题的话，就进入 {path-to-project}/themes/github-style 目录，执行 git pull 命令，拉取最新的代码。
然后把 {path-to-project}themes/hugo-theme-next/exampleSite/ 目录下所有的文件复制到 {path-to-project}/ 目录下覆盖。
最后删除原来的配置文件 config.toml，然后就可以使用命令 hugo server 启动服务了。
另外需要注意的是，这个主题需要 hugo extended 版本，如果用的不是 extended 版本，启动的时候会报下面这样的错，提示去安装 extended 版本。
&gt; hugo server Start building sites … hugo v0.103.1-b665f1e8f16bf043b9d3c087a60866159d71b48d windows/amd64 BuildDate=2022-09-18T13:19:01Z VendorInfo=gohugoio WARN 2022/09/20 21:12:38 Hugo NexT 主题使用了 SCSS 框架，请到官方地址下载 Hugo Extended 版本：https://github.com/gohugoio/hugo/releases ERROR 2022/09/20 21:12:38 Because that use SCSS framework in Hugo NexT, Please download Hugo extended version on offical site: https://github.com/gohugoio/hugo/releases Error: Error building site: TOCSS: failed to transform &#34;main.scss&#34; (text/x-scss). Check your Hugo installation; you need the extended version to build SCSS/SASS.: this feature is not available in your current Hugo version, see https://goo.gl/YMrWcn for more information github-style（选看） github-style这个主题是 github 的页面风格。
GitHub 项目地址 MeiK2333/github-style。
按着 github-style 主题提供的的文档走，把主题配置到站点中。
别忘了先 git init，然后使用命令下载主题 git submodule add git@github.com:MeiK2333/github-style.git themes/github-style。
如果需要升级主题的话，就进入 {path-to-project}/themes/github-style 目录，执行 git pull 命令，拉取最新的代码。
在 content/ 里创建 post/ 目录，后面所有的内容页面都放到这个目录下面，要不然站点里不会展示。
最后在配置文件 config.toml 里设置主题 theme = &quot;github-style&quot;。然后就可以使用命令 hugo server 启动服务了。
站点是没有问题的，可以正常地跑起来。但是这个主题貌似没有实现标签分类，也可能是本人没有找到，所以就放弃继续使用了。
部署到 GitHub Pages 使用命令 hugo -t {theme-name} 来把发布用的目录编译出来。这里就是 hugo -t hugo-theme-next。
默认情况下会编译到 {path-to-project}/publish/ 目录。 可以通过编辑配置文件，在配置文件里添加 publishDir: docs，来修改这个目录。
push 到 github.io 的时候，如果使用的是 publish/ 目录。那么要 push publish/ 目录上去，然后设置 GitHub Pages 的 Branch 为 master 和 /(root)。
如果使用的是 docs/ 目录，那么就要 push 整个项目上去，然后设置 GitHub Pages 的 Branch 为 master 和 docs/。
文本头部信息 draft: true date: 2000-01-01 08:00:00 +0800 lastmod: 2002-01-01 08:00:00 +0800 title: &ldquo;title&rdquo; summary: &ldquo;summary&rdquo; toc: true
categories:
categories(分类) tags:
tags1(标签1) tags2(标签2) draft：是不是草稿，true=是；false=不是。启动的时候带 --buildDrafts 选项就可以看到草稿的内容。 date：创建时间 lastmod：最后修改时间 title：文本标题 summary：文本概述 toc：是不是显示文章目录，true=是；false=不是。 categories：文本分类，一般一个 tags：文本标签，可以多个 reference（参考） hugo个人博客搭建并部署到GitHub【 for Windows】]]></content></entry><entry><title>使用 Golang 实现简单的 Web 框架 -- middleware(中间件)</title><url>/post/computer-science/programming-language/framework/web/golang/middleware/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>web</tag><tag>http</tag><tag>middleware(中间件)</tag><tag>golang</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {demo-golang}
/demo/web/middleware/ web.drawio.html 中间件 web 框架的中间件可以理解成一种 AOP 方案的实现。可以借助各路教程中常见的洋葱模型来理解中间件的整体结构，这里我用的是同心圆模型。
中间件的同心圆模型结构示例见图：web.drawio.html 4-2。这玩意的核心思路就一个，一层一层的进去，一层一层的出来。另外，需要保证每层的数据格式都是一样的。定义数据格式可以保证，第一顺序可以换，第二可以加层或者减层。
定义中间件的时候需要关注两个重要的组成部分：路由对应的处理方法和中间件的处理方法。
路由对应的处理方法就是，中间件一层一层的进去之后，最里面那层和业务衔接的地方的定义。这里需要处理的是，把中间件的数据格式解包，交给业务逻辑去处理。拿到处理的结果后，在包装成中间件的数据格式，然后丢出去。
中间件的处理方法就是，中间件最外面一层的外面，进入中间件的地方的定义。因为进了第一层之后，每层都是一样的，所以这里只关注最外面一层。这里需要处理的是，把请求数据包装成中间件的数据格式，然后丢进去。拿到处理的结果后，把结果处理成请求想要的响应数据，然后响应回去。
这两个部分定义一起规定了中间件该怎么定义，中间件定义需要围绕这两个定义去实现，要不然调用链条串不起来。
// HTTPHandleFunc 路由对应的处理方法的定义 type HTTPHandleFunc func(p7ctx *HTTPContext) // HTTPMiddleware 中间件的处理方法的定义 type HTTPMiddleware func(next HTTPHandleFunc) HTTPHandleFunc 具体的中间件的实现方式，就像下面这样。
func DemoMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { // before DemoMiddleware next(p7ctx) // after DemoMiddleware } } } 这里假设定义两个中间件。
func AMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { // before AMiddleware next(p7ctx) // after AMiddleware } } } func BMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { // before BMiddleware next(p7ctx) // after BMiddleware } } } 然后这么链起来，B 在内层，A 在外层。
// serve 是最内层业务代码 chain := serve // 组装中间件 mb := BMiddleware() chain = mb(chain) ma := AMiddleware() chain = mb(chain) // 执行 chain(ctx) 最后的效果等价于下面这样的伪代码。
// before AMiddleware // before BMiddleware serve(p7ctx) // after BMiddleware // after AMiddleware 可路由的中间件 可路由的中间件就是在路由树的基础上，分别给每个路由树结点设置中间件。
这样在路由匹配到某个路由结点之后，不仅可以获取到路由的处理方法，还可以获取到路由上设置的中间件。
然后把这些中间件，按照定义好的顺序，套起来即可。</content></entry><entry><title>使用 Golang 实现简单的 Web 框架 -- router(路由)</title><url>/post/computer-science/programming-language/framework/web/golang/router/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>web</tag><tag>http</tag><tag>router(路由)</tag><tag>golang</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {demo-golang}/demo/web/router/ web.drawio.html 路由 在实现路由树之前，首先需要理解路由是干什么的。路由的作用简单地说就是，通过某个请求的请求路径找到对应的处理方法然后处理这个请求。
简单的路由可以使用 map 结构，就是单纯的字符串匹配。map 的 key 就是路由的路径，value 就是路由的处理方法。
像这样 &quot;user/num&quot; =&gt; func userNum()。如果路由命中了 user/num，就调用 func userNum() 去处理。
这个结构很简单了，接收到请求时，用请求的路径直接去 map 里找有没有对应的处理方法。能找到就处理，找不到就找不到，就 404。
简单的路由匹配可以解决，但是复杂一点的功能。比如：路径参数路由、正则匹配路由、通配符路由这样的需求，map 结构就没办法整。
比如 &quot;user/:id&quot; =&gt; func userId() 这样的，我 :id 的位置可以变，这 key 要怎么写，不好搞了嘛。
所以对于后面那些功能，就不能用 map 这种强一对一的结构。就需要换一个思路，观察一下 user/:id 和 user/num。
这两个的差别在于后面的部分，前面是一样的 user，这可以联想到分叉的结构。比如：一棵树的两个树杈、一根树枝上的两个叶子。
所以这里就可以考虑用树形结构来改造一下，把 key 拆了，公共的部分作为根结点，不同的部分作为叶子结点。
这样变成树结构之后，路由的解析步骤，就变成一层一层的了，就可以满足上面那些功能的要求，当一对一匹配不到的时候，就可以看看有没有别的路可以走。
也就是路由树的结点在存储静态子结点的同时，还可以额外设置特殊子结点。在找不到静态路由时，可以继续判断有没有特殊结点可以选择。
比如上面的 user/:id 和 user/num，当来一个 user/1 的时候，我直接打，命不重任何一个。
但是 :id 是一个特殊结点，它可以判断 1 是不是满足它的匹配条件，满足匹配条件的就放它过，也就是路由匹配上了。
路由树的结构示例见图：web.drawio.html 2-2。
路由树的设计没有强制的要求，不是非的像图里那样。按照实际场景的需求，只要设计出路由树的构建和查询规则合理即可。
路由组 路由组其实就是额外提供的方便使用的接口而已，相当于对路由的注册功能做了一层包装。
路由组的内部，会把定义到路由组上的路由路径前缀和中间件，附加到路由组内的每一个路由上去。
]]></content></entry><entry><title>关于帕里特档案馆和西柊慧音</title><url>/about/</url><categories/><tags/><content type="html">帕里特档案馆（重建中，旧篇总计 283，迁移完成 8，新增 11），是个个人档案馆。
档案馆的内容主要是本人的学习笔记、对学到的东西的解释和思考、对实操过程的记录。
这些玩意本质上是当时的我给以后的我的留言。它们不是教程，更不是论文。
写它们的目的是，如果以后的我忘记了这块的内容，那么现在的我可以把以后的我教会。
本人能力有限，因此不能保证所有的内容的时效性和正确性。还请各位到访的访客务必小心。
另外，如果访客您觉得毫无干货或者内容非常水，那么非常抱歉。
站点基于 hugo 0.103.1 extended 版本
搭建。使用的主题是 Hugo NexT
。
站点预计会部属在 github pages 和 gitee pages 上。
如果有问题，欢迎批评指正。同时也欢迎建设性意见。
和本人的交流方式，QQ：786907650；微信号：wxid_k3uqy9xeryn422。昵称和头像都是一样的。
有意交流者，请至少备注是谁和从哪来。</content></entry><entry><title>使用 Golang 开启 HTTP 服务</title><url>/post/computer-science/programming-language/golang/http/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag><tag>web</tag><tag>http</tag></tags><content type="html"> go version go1.19 windows/amd64
资料 {demo-golang}
/demo/web/http/ 开启 HTTP 服务 在 Go 中有多种方式，可以开启 HTTP 服务。但是总的来说基本就下面两大类思路（本质上其实是一类）。
使用官方提供的封装好的 net/http 包。 直接使用 net 包从 TCP 开始自行实现。 使用 net/http 包的时候，需要关注的最核心的部分，就是 Handler 接口 (src/net/http/server.go)。
type Handler interface { ServeHTTP(ResponseWriter, *Request) } 开启 HTTP 服务和 HTTP 请求被处理的流程大致如下：
直接或间接地创建 Server 结构体 (src/net/http/server.go) 的实例。 调用 Server 的 ListenAndServe() 方法。 ListenAndServe() 调用 net.Listen() (src/net/dial.go)，启动 TCP 服务。 net.Listen() 返回一个 net.Listener 接口 (src/net/dial.go) 的实例。 调用 net.Listener 的 Accept() 方法，就可以获取连接上来的 TCP 连接。 新开启一个协程，把这个 TCP 连接丢进去处理。自己则继续监听有没有别的 TCP 连接。 处理流程继续往下，会遇到这行代码：serverHandler{c.server}.ServeHTTP(w, w.req)。 这里调用的就是 Handler 的 ServeHTTP() 方法。再往下就进入框架或者业务处理流程了。</content></entry><entry><title>2-3-4 树</title><url>/post/computer-science/data-structure/2-3-4_tree/</url><categories><category>data-structure(数据结构)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>data-structure(数据结构)</tag><tag>b-tree</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 Cygwin gcc version 11.2.0
前言 在看 2-3-4 树之前，建议先看 2-3 树。相似的操作在 2-3-4 树不会重复详细的描述。
资料 2-3-4_tree.drawio.html 2-3-4 树 2-3-4 树就是 4 阶 B-树 2-3-4 树和红黑树是等价的： 2-3-4 树的结点个数 = 红黑树的黑色结点个数。 把 2-3-4 树的三结点和四结点拆开，就可以变成红黑树。 把红黑树的红结点移动到和父结点同层，就会变成 2-3-4 树。 2-3-4 树的性质 1、满足二叉查找树的基本性质。
2、结点可以存放一个元素、两个元素。
假设结点结构从左到右分别为：子树 1、元素 1、子树 2、元素 2、子树 3、元素 3、子树 4。 对于存放一个元素的结点。其形态为：子树 1、元素 1、子树 2。 子树 1 存放比 元素 1 小的元素； 子树 2 存放比 元素 1 大的元素。 对于存放两个元素的结点，其形态为：子树 1、元素 1、子树 2、元素 2、子树 3。 子树 1 存放比 元素 1 和 元素 2 都小的元素； 子树 2 存放在 元素 1 和 元素 2 之间的元素； 子树 3 存放比 元素 1 和 元素 2 都大的元素。 对于存放三个元素的结点，其形态为：子树 1、元素 1、子树 2、元素 2、子树 3、元素 3、子树 4。 子树 1 存放比 元素 1、元素 2、元素 3 都小的元素； 子树 2 存放在 元素 1 和 元素 2 之间的元素； 子树 3 存放在 元素 2 和 元素 3 之间的元素； 子树 4 存放比 元素 1、元素 2、元素 3 都大的元素。 3、2-3-4 树是绝对平衡的二叉查找树，所有叶子结点都在同一层上。从根结点到任意一个叶子结点所经过的结点数是相同的。
2-3-4 树的插入 下面列举的情况并不一定覆盖所有的场景，但是典型场景都有了，没有提到的场景可以根据典型场景推导。
只上溢不旋转的情况 1、空树。（类似 2-3 树的第 1 种情况）
2、二结点。（类似 2-3 树的第 2 种情况）
3、三结点。
添加结点 =&gt; 变四结点。（见图：2-3-4_tree.drawio.html 2-2-6）
4、没有父结点的四结点。
添加结点 =&gt; 变五结点 =&gt; 上溢（层数增加）。（见图：2-3-4_tree.drawio.html 2-4-2）
5、有父结点的四结点（父结点不是四结点）。
添加结点 =&gt; 变五结点 =&gt; 上溢（层数不增加）。（见图：2-3-4_tree.drawio.html 2-4-4）
这种情况，四结点是父结点哪个子结点，都是一样的处理逻辑，上溢一次。
这里，父结点可以是二结点也可以是三结点。
6、有父结点的四结点（父结点是四结点）。
添加结点 =&gt; 变五结点 =&gt; 上溢（父结点变五结点）=&gt; 父结点上溢（层数增加）。（见图：2-3-4_tree.drawio.html 2-6）
这种情况，四结点是父结点哪个子结点，都是一样的处理逻辑，上溢两次。
可以通过旋转抵消上溢的情况 1、有父结点的四结点（父结点是四结点、兄弟结点不是四结点）。
添加结点 =&gt; 变五结点 =&gt; 兄弟结点有空位 =&gt; 旋转结点到兄弟结点（抵消上溢，层数不增加）。
这种情况，如果只上溢的话，会上溢两次（自己上溢一次、父结点上溢一次），树的深度增加了，可能影响查询效率。
但是这个时候其实 2-3-4 树是不满的，兄弟结点是有空位的。这时候就可以通过旋转，重新平衡 2-3-4 树。
根据 2-3-4 树有空位的兄弟结点的位置，旋转的情况分为六种，处理方式是差不多的：
向右旋转一次（见图：2-3-4_tree.drawio.html 4-2-2） 向左旋转一次（见图：2-3-4_tree.drawio.html 4-2-4） 向右旋转两次（见图：2-3-4_tree.drawio.html 4-6） 向左旋转两次（无图，参考向右旋转两次的图）。 向右旋转三次（无图，参考向右旋转两次的图）。 向左旋转三次（无图，参考向右旋转两次的图）。 2、有父结点的四结点（父结点是四结点、兄弟结点是四结点、祖父结点是四结点、叔叔结点不是四结点）。
添加结点 =&gt; 变五结点 =&gt; 父结点和兄弟结点都没有空位，无法旋转，只能上溢（父结点变五结点） =&gt; 叔叔结点有空位 =&gt; 旋转结点到叔叔结点（抵消上溢，层数不增加）。
这种情况，如果只上溢的话，会上溢三次（自己上溢一次、父结点上溢一次、祖父结点上溢一次），树的深度增加了，可能影响查询效率。
但是这个时候其实 2-3-4 树是不满的，叔叔结点是有空位的。这时候就可以通过旋转，重新平衡 2-3-4 树。
这里第一次的上溢是避免不了的。上溢之后，重新以父结点为参照，这时就可以看做上面第一种情况。
根据 2-3-4 树有空位的叔叔结点的位置，旋转的情况分为六种，处理方式是差不多的：
（上溢一次后）向右旋转一次（无图，参考向右旋转三次的图）。 （上溢一次后）向左旋转一次（无图，参考向右旋转三次的图）。 （上溢一次后）向右旋转两次（无图，参考向右旋转三次的图）。 （上溢一次后）向左旋转两次（无图，参考向右旋转三次的图）。 （上溢一次后）向右旋转三次（见图：2-3-4_tree.drawio.html 4-8） （上溢一次后）向左旋转三次（无图，参考向右旋转三次的图）。 2-3-4 树的删除 下面列举的情况并不一定覆盖所有的场景，但是典型场景都有了，没有提到的场景可以根据典型场景推导。
删除叶子结点 1、删除三结点的结点。（类似 2-3 树的第 1 种情况）
2、删除四结点的结点。
直接删掉就好了，不会破坏 2-3-4 树的性质。（见图：2-3-4_tree.drawio.html 6-2-4）
3、删除二结点的结点（父结点是二结点、兄弟结点是二结点）。（类似 2-3 树的第 2 种情况）
4、删除二结点的结点（父结点是三结点、兄弟结点是二结点）。（类似 2-3 树的第 3 种情况）
5、删除二结点的结点（父结点是四结点，兄弟结点是二结点）。（类似第 3 种情况）
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（其中一个结点，层次不变） =&gt; 下溢结点和兄弟结点融合。（见图：2-3-4_tree.drawio.html 6-4-6）
6、删除二结点的结点（父结点是二结点、兄弟结点是三结点）。（类似 2-3 树的第 4 种情况）
7、删除二结点的结点（父结点是三结点、兄弟结点是三结点）。（类似 2-3 树的第 5 种情况）
8、删除二结点的结点（父结点是四结点、兄弟结点是三结点）。（类似第 6 种情况）
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3-4_tree.drawio.html 6-6-6）
另外，还有向左旋转三次的情况（见图：2-3-4_tree.drawio.html 6-10-4），向右旋转三次的处理方式是一样的。
9、删除二结点的结点（父结点是二结点、兄弟结点是四结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3-4_tree.drawio.html 6-8-2）
这种情况，删掉结点之后，自己这个位置就是空的了。也就是父结点变得少一个子树，这会破坏 2-3-4 树的性质。
和上面第 3 种情况不同的是，在第 3 种情况中，兄弟结点是二结点，借不出结点。而这里可以借一个结点过来，把这个子树补上，这样就不破坏 2-3-4 树的性质了。
图里的例子是向左旋转一次的情况，向右旋转一次的处理方式是一样的。
10、删除二结点的结点（父结点是三结点、兄弟结点是四结点）。（类似第 9 种情况）
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3-4_tree.drawio.html 6-8-4）
11、删除二结点的结点（父结点是四结点、兄弟结点是四结点）。（类似第 9 种情况）
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3-4_tree.drawio.html 6-8-6）
12、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是二结点、叔叔结点是二结点）。（类似 2-3 树的第 6 种情况）
13、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是三结点、叔叔结点是二结点）。（类似 2-3 树的第 7 种情况）
祖父结点是四结点的处理逻辑是一样的。
14、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是三结点、叔叔结点是三结点）。（类似 2-3 树的第 8 种情况）
叔叔结点是四结点的处理逻辑是一样的。
删除的不是叶子结点 这种情况需和平衡二叉树一样，找到中序遍历的前驱结点或者后继结点，把这两个结点互换位置，这个时候要删除的结点会被换到叶子结点的位置，然后再删除。
2-3-4 树转换成红黑树 1、三结点其中一个元素转化为红黑树的红结点，左右哪个元素都可以。四结点中两边的元素转化为红黑树的红结点。 2、拆分三结点和四结点，和父结点连接的一定是黑结点 （见图：2-3-4_tree.drawio.html 12-2） reference（参考） 掌握了2-3-4树也就掌握了红黑树，不信进来看看，建议收藏！ 理解2-3-4树bilibili&ndash;木子喵neko【neko】红黑树/插入【算法编程#11】【neko】红黑树/删除【算法编程#12】]]></content></entry><entry><title>2-3 树</title><url>/post/computer-science/data-structure/2-3_tree/</url><categories><category>data-structure(数据结构)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>data-structure(数据结构)</tag><tag>b-tree</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 Cygwin gcc version 11.2.0
资料 2-3_tree.drawio.html 2-3 树 2-3 树就是 3 阶 B-树。 把 2-3 树的三结点拆开，就可以变成红黑树。 2-3 树的性质 1、满足二叉查找树的基本性质。
2、结点可以存放一个元素、两个元素。
假设结点结构从左到右分别为：子树 1、元素 1、子树 2、元素 2、子树 3。 对于存放一个元素的结点，其形态为：子树 1、元素 1、子树 2。 子树 1 存放比 元素 1 小的元素； 子树 2 存放比 元素 1 大的元素。 对于存放两个元素的结点，其形态为：子树 1、元素 1、子树 2、元素 2、子树 3。 子树 1 存放比 元素 1 和 元素 2 都小的元素； 子树 2 存放在 元素 1 和 元素 2 之间的元素； 子树 3 存放比 元素 1 和 元素 2 都大的元素。 3、2-3 树是绝对平衡的二叉查找树，所有叶子结点都在同一层上。从根结点到任意一个叶子结点所经过的结点数是相同的。
2-3 树的插入 下面列举的情况并不一定覆盖所有的场景，但是典型场景都有了，没有提到的场景可以根据典型场景推导。
只上溢不旋转的情况 1、空树。
添加结点 =&gt; 变二结点。（见图：2-3_tree.drawio.html 2-2-2）
2、二结点。
添加结点 =&gt; 变三结点。（见图：2-3_tree.drawio.html 2-2-4）
3、没有父结点的三结点。
添加结点 =&gt; 变四结点 =&gt; 上溢（层数增加）。（见图：2-3_tree.drawio.html 2-4-2）
4、有父结点的三结点（父结点不是三结点）。
添加结点 =&gt; 变四结点 =&gt; 上溢（层数不增加）。（见图：2-3_tree.drawio.html 2-4-4）
这种情况，三结点是父结点哪个子结点，都是一样的处理逻辑，上溢一次。
5、有父结点的三结点（父结点是三结点）。
添加结点 =&gt; 变四结点 =&gt; 上溢（父结点变四结点）=&gt; 父结点上溢（层数增加）。（见图：2-3_tree.drawio.html 2-6）
这种情况，四结点是父结点哪个子结点，都是一样的处理逻辑，上溢两次。
可以通过旋转抵消上溢的情况 1、有父结点的三结点（父结点是三结点、兄弟结点不是三结点）。
添加结点 =&gt; 变四结点 =&gt; 兄弟结点有空位 =&gt; 旋转结点到兄弟结点（抵消上溢，层数不增加）。
这种情况，如果只上溢的话，会上溢两次（自己上溢一次、父结点上溢一次），树的深度增加了，可能影响查询效率。
但是这个时候其实 2-3 树是不满的，兄弟结点是有空位的。这时候就可以通过旋转，重新平衡 2-3 树。
根据 2-3 树有空位的兄弟结点的位置，旋转的情况分为四种，处理方式是差不多的：
向右旋转一次（见图：2-3_tree.drawio.html 4-2-2） 向左旋转一次（见图：2-3_tree.drawio.html 4-2-4） 向右旋转两次（见图：2-3_tree.drawio.html 4-4） 向左旋转两次（无图，参考向右旋转两次的图）。 2、有父结点的三结点（父结点是三结点、兄弟结点是三结点、祖父结点是三结点、叔叔结点不是三结点）。
添加结点 =&gt; 变四结点 =&gt; 父结点和兄弟结点都没有空位，无法旋转，只能上溢（父结点变四结点） =&gt; 叔叔结点有空位 =&gt; 旋转结点到叔叔结点（抵消上溢，层数不增加）。
这种情况，如果只上溢的话，会上溢三次（自己上溢一次、父结点上溢一次、祖父结点上溢一次），树的深度增加了，可能影响查询效率。
但是这个时候其实 2-3 树是不满的，叔叔结点是有空位的。这时候就可以通过旋转，重新平衡 2-3 树。
这里第一次的上溢是避免不了的。上溢之后，重新以父结点为参照，这时就可以看做上面第一种情况。
根据 2-3 树有空位的叔叔结点的位置，旋转的情况分为四种，处理方式是差不多的：
（上溢一次后）向右旋转一次（见图：2-3_tree.drawio.html 4-6-2） （上溢一次后）向左旋转一次（无图，参考向右旋转一次的图） （上溢一次后）向右旋转两次（见图：2-3_tree.drawio.html 4-6-4） （上溢一次后）向左旋转两次（无图，参考向右旋转两次的图）。 2-3 树的删除 下面列举的情况并不一定覆盖所有的场景，但是典型场景都有了，没有提到的场景可以根据典型场景推导。
删除叶子结点 1、删除三结点的结点。
直接删掉就好了，不会破坏 2-3 树的性质。（见图：2-3_tree.drawio.html 6-2）
2、删除二结点的结点（父结点是二结点、兄弟结点是二结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（唯一的结点，层次减少） =&gt; 父结点和兄弟结点融合。（见图：2-3_tree.drawio.html 6-4-2）
这种情况，删掉结点之后，自己这个位置就是空的了。也就是父结点变得少一个子树，这会破坏 2-3 树的性质。
处理方式是，就把父结点放到下面一层去，和兄弟结点融合成一个结点，这样就不会破坏 2-3 树的性质了。
图里的例子是父结点的子树 1 被删空了，子树 2 被删空的情况是一样的处理方式。
3、删除二结点的结点（父结点是三结点、兄弟结点都是二结点）。（类似第 2 种情况）
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（其中一个结点，层次不变） =&gt; 下溢结点和兄弟结点融合。（见图：2-3_tree.drawio.html 6-4-4）
4、删除二结点的结点（父结点是二结点、兄弟结点是三结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3_tree.drawio.html 6-6-2）
这种情况，删掉结点之后，自己这个位置就是空的了。也就是父结点变得少一个子树，这会破坏 2-3 树的性质。
和上面第 2 种情况不同的是，在第 2 种情况中，兄弟结点是二结点，借不出结点。而这里可以借一个结点过来，把这个子树补上，这样就不破坏 2-3 树的性质了。
图里的例子是向左旋转一次的情况，向右旋转一次的处理方式是一样的。
另外，还有向左旋转两次的情况（见图：2-3_tree.drawio.html 6-10-2），向右旋转两次的处理方式是一样的。
5、删除二结点的结点（父结点是三结点、兄弟结点是三结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3_tree.drawio.html 6-6-4）
图里的例子是向左旋转一次的情况，向右旋转一次的处理方式是一样的。
6、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是二结点、叔叔结点是二结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（父结点和兄弟结点融合） =&gt; 祖父结点少一个子树 =&gt; 祖父结点下溢（唯一的结点，层次减少） =&gt; 祖父结点和叔叔结点融合。（见图：2-3_tree.drawio.html 6-12-2）
这种情况，初始场景类似上面第 2 种情况，解决方案也是类似第 2 种情况的：下溢 + 融合。初始场景处理完之后，重新以父结点为参照，又是类似上面第 2 种情况，再来一遍就好了。
7、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是三结点、叔叔结点是二结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（父结点和兄弟结点融合） =&gt; 祖父结点少一个子树 =&gt; 祖父结点下溢（其中一个结点，层次不变） =&gt; 下溢结点和叔叔结点融合。（见图：2-3_tree.drawio.html 6-12-4）
这种情况，初始场景类似上面第 2 种情况，解决方案也是类似第 2 种情况的：下溢 + 融合。初始场景处理完之后，重新以父结点为参照，类似上面第 3 种情况，解决方案也是类似第 3 种情况的：下溢 + 融合。
8、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是三结点、叔叔结点是三结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（父结点和兄弟结点融合） =&gt; 祖父结点少一个子树 =&gt; 叔叔结点可以借一个结点 =&gt; 旋转结点到祖父结点的删除结点的位置。（见图：2-3_tree.drawio.html 6-14）
这种情况，初始场景类似上面第 2 种情况，解决方案也是类似第 2 种情况的：下溢 + 融合。初始场景处理完之后，重新以父结点为参照，类似上面第 4 种情况，解决方案也是类似第 4 种情况的：旋转。
删除的不是叶子结点 这种情况需和平衡二叉树一样，找到中序遍历的前驱结点或者后继结点，把这两个结点互换位置，这个时候要删除的结点会被换到叶子结点的位置，然后再删除。
2-3 树转换成红黑树 1、三结点其中一个元素转化为红黑树的红结点，左右哪个元素都可以。 2、拆分三结点，和父结点连接的一定是黑结点。 （见图：2-3_tree.drawio.html 10-2） reference（参考） 二三树、B树(多路平衡查找树)、B+树二叉树，红黑树，23树，B树，B+树2-3树的删除bilibili&ndash;天羽神奈2-3树的定义与搜索图解2-3树插入节点方法2-3树删除节点图解及示例]]></content></entry><entry><title>Virtual Memory（虚拟内存）</title><url>/post/computer-science/operating-system/memory/virtual_memory/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>memory(内存)</tag></tags><content type="html">资料 virtual_memory.drawio.html 虚拟内存涉及的知识点（笔记里不一定有） virtual memory（虚拟内存） memory protection（内存保护） dynamic memory allocation（动态分配内存） virtual memory address（虚拟内存地址） physical memory address（物理内存地址） memory management unit（MMU、内存管理单元） segmented memory management（段式管理） segment（段） segment table（段表） memory fragmentation（内存碎片） page memory management（页式管理） page（页） page table（页表） missing page interruption（缺页中断） multi-level page table（多级页表） Translation Lookaside Buffer（TLB、页表缓存） segmented paged memory management（段页式管理） 虚拟内存 单片机的 CPU 可以直接操作物理内存地址。但是，在这种情况下是无法同时运行多个程序的。
如果多个程序都操作了同一块物理内存，那么他们就可能会互相影响，最终可能导致程序崩溃。
操作系统使用虚拟内存将进程与物理内存进行隔离，为每个进程分配独立的一套虚拟内存地址，这样每个进程就互不干涉。
虚拟内存地址（virtual memory address）：程序使用的内存地址 物理内存地址（physical memory address）：硬件里面的内存地址 虚拟内存地址和物理内存地址的映射由操作系统为进程提供，进程不需要管数据到底存在哪块物理内存上。
进程使用的虚拟地址，会通过 CPU 芯片中的内存管理单元（Memory Management Unit、MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存。
另外，虚拟内存可以使得进程的运行内存超过物理内存大小。因为程序运行符合局部性原理，不是所有的内存都是同时在使用的。
操作系统主要有两种管理内存的方式：内存分段（Segmentation）和内存分页（Paging）。
段式管理 程序由若干个逻辑分段组成，如：代码分段、数据分段、栈段、堆段等。（见图：virtual_memory.drawio.html 2-2）
虚拟地址由段选择子和段内偏移量两部分组成。
段选择子保存在段寄存器。段选择子里的段号用作段表的索引。段表保存段基地址、段界限和特权等级等。（见图：virtual_memory.drawio.html 2-4）
虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。
段式管理的不足 段式管理的不足主要有两点：1、内存碎片；2、内存交换的效率低。
内存碎片有两种：
外部碎片：多个不连续的小物理内存，导致新的程序由于内存不够无法被装载。 内部碎片：程序所有的数据都被装载到了物理内存，但是这个程序有部分的数据可能并不是很常使用，这会导致内存的浪费。 内存交换可以解决外部碎片的问题。可以把程序占用的内存写到硬盘上，然后再从硬盘上读回到内存。在 Linux 中，内存交换空间（Swap 空间），这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。
对于多进程的系统来说，用分段的方式，很容易产生内存碎片。内存交换又受硬盘速度限制，效率低。
页式管理 整个虚拟内存空间和物理内存空间都被切成一个个固定尺寸大小的内存空间（内存页）。
分页可以让内存交换时，读写的数据少一点。在 Linux 中，每一页的大小为 4KB。
虚拟地址与物理地址之间通过页表来映射。（见图：virtual_memory.drawio.html 4-2）
页表存储在内存里，每个进程都有自己的页表。（见图：virtual_memory.drawio.html 4-4）
从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址，所以页表一定要覆盖全部虚拟地址空间。内存管理单元负责将虚拟内存地址转换成物理地址。
虚拟地址分为两部分：页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址。
页表里的页表项中除了物理地址之外，还有一些标记属性的数据，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。
对于一个内存地址转换，分三个步骤：
1、把虚拟内存地址，切分成页号和偏移量。 2、根据页号，从页表里面，查询对应的物理页号。 3、拿物理页号，加上前面的偏移量，就得到了物理内存地址。 当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常。然后进入系统内核空间，分配物理内存，更新进程页表，最后再返回用户空间，恢复进程的运行。
页式管理的优点 由于内存空间都是预先划分好的，所以释放的内存都是以页为单位释放的，不会产生无法给进程使用的小内存。
如果内存空间不够，操作系统会把其他正在运行的进程中的最近没被使用的内存页面给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。
一旦需要的时候，再加载进来，称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。
分页的方式使得在加载程序的时候，不需要一次性都把程序加载到物理内存中。只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。
简单分页的缺陷 简单分页有空间上的缺陷。
在 32 位的环境下，虚拟地址空间共有 4GB（2^32）。假设一个页的大小是 4KB（2^12），每个页表项 4 个字节。
那么 4GB 空间就需要 100 万（2^20）个页，大概 4MB 来存储页表。每个进程都有自己的虚拟地址空间（页表）。那么，100 个进程就需要 400MB 来存储页表。
多级页表（Multi-Level Page Table）可以解决简单分页的空间上的缺陷。
多级页表 多级页表把 100 多万个页表项再分页，用一个一级页表 4KB 表示全部的虚拟地址空间，一级页表一共有 1024 个页表项。每个一级页表项对应一个二级页表，每个二级页表也有 1024 个页表项。
（见图：virtual_memory.drawio.html 4-6）
二级页表可以在需要时进行创建。每个进程都有 4GB 的虚拟地址空间，而对于大多数程序来说，其使用到的空间远未达到 4GB，所以大多数的页表项都是空的。这样就可以节省下很多的空间。
多级页表解决了空间上的问题，但是转换工序带来了时间上的开销。
对于 64 位的系统，多级页表变成了四级目录，分别是：
PGD（page global directory、全局页目录项） PUD（page upper directory、上层页目录项） PMD（page middle directory、中间页目录项） PTE（page table entry、页表项）。 页表缓存 根据局部性原理，程序在一段时间内的执行会集中在整个程序的其中一个部分。相应地，执行所访问的存储空间也局限于某个内存区域。
利用这一特性，可以在 CPU 里放一块缓存，用来存放最常访问的页表项。这个缓存就是页表缓存（Translation Lookaside Buffer、TLB、快表、转址旁路缓存等）
段页式管理 内存分段和内存分页可以组合起来在同一个系统中使用。
先将程序划分为多个逻辑段，接着再把每个段划分为多个页。地址结构由段号、段内页号、页内位移三部分组成。
每个程序一张段表，每个段一张页表，段表中的地址是页表的起始地址，而页表中的地址则是物理页号。
（见图：virtual_memory.drawio.html 6-2）
段页式地址变换中要得到物理地址须经过三次内存访问：
访问段表，得到页表起始地址 访问页表，得到物理页号 将物理页号与页内位移组合，得到物理地址 可用软、硬件相结合的方法实现，虽然增加了硬件成本和系统开销，但提高了内存的利用率。
reference（参考） Crash Course Computer Science（计算机科学速成课） bilibili
CrashCourse 字幕组
Youtube 原视频
小林coding
图解系统</content></entry><entry><title>AVL-Tree（平衡二叉树）</title><url>/post/computer-science/data-structure/avl_tree/</url><categories><category>data-structure(数据结构)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>data-structure(数据结构)</tag><tag>binary-search-tree(二叉查找树)</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 Cygwin gcc version 11.2.0
资料 {demo-c}/data-structure/balanced_binary_tree.c balanced_binary_tree.drawio.html 平衡二叉树 AVL-Tree（balanced binary tree、平衡二叉树）是一种特殊的二叉排序树。
平衡二叉树的性质 1、满足二叉查找树的基本性质。 2、每个结点的左右子树的高度之差的绝对值（平衡因子）最多为 1。 平衡二叉树的插入 左旋和右旋 （见图：balanced_binary_tree.drawio.html 2-2）
4 种需要平衡的场景 1、LL 型
LL 型，直接右旋 x 结点。（见图：balanced_binary_tree.drawio.html 4-2）
2、LR 型
LR 型，直接右旋 x 结点，依然不平衡。（见图：balanced_binary_tree.drawio.html 4-4-2）
需要先左旋 y 结点，再右旋 x 结点。（见图：balanced_binary_tree.drawio.html 4-4-4）
3、RR 型
RR 型，直接左旋 x 结点。（见图：balanced_binary_tree.drawio.html 6-2）
4、RL 型
RL 型，直接左旋 x 结点，依然不平衡。（见图：balanced_binary_tree.drawio.html 6-4-2）
需要先右旋 y 结点，再左旋 x 结点。（见图：balanced_binary_tree.drawio.html 6-4-4）
平衡二叉树的删除 平衡二叉树的删除和二插叉查找树的删除步骤是差不多的。
区别在于，平衡二叉树删除结点之后，需要依次向上检查每一个结点是否平衡。
reference（参考） 平衡二叉树（AVL树）及C语言实现</content></entry><entry><title>使用 Docker 部属 MySQL 8.0</title><url>/post/computer-science/database/mysql/docker/</url><categories><category>mysql</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>database(数据库)</tag><tag>mysql</tag><tag>docker</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 Docker v20.10.17 docker images mysql 8.0
拉取镜像 访问 Docker MySQL 镜像库拉取 MySQL 8.0 镜像。
&gt; docker pull mysql:8.0 8.0: Pulling from library/mysql ... Digest: sha256:147572c972192417add6f1cf65ea33edfd44086e461a3381601b53e1662f5d15 Status: Downloaded newer image for mysql:8.0 docker.io/library/mysql:8.0 拉好之后，可以在 image 列表看到。
&gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE mysql 8.0 40b83de8fb1a 4 days ago 535MB 启动容器 设置好参数，然后后台启动容器。
&gt; docker run -itd --name mysql-8-dev -p 127.0.0.1:13306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:8.0 45804f67e3bf4b79735c308a8073131525c5fbc6f714e8fca5efb4f628127532 docker run -itd：在后台运行容器，并且打印容器 id。 --name mysql-8-dev：设置容器的名字为 mysql-8-dev。 -p 127.0.0.1:13306:3306：将本机的 127.0.0.1:13306 端口和容器的 3306 端口进行映射。 -e MYSQL_ROOT_PASSWORD=123456：设置 mysql 密码为 123456，用户名默认为 root。 mysql:8.0：使用 mysql:8.0 镜像运行容器。 启动好容器之后，可以通过 docker ps 命令查看容器状态。
&gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 45804f67e3bf mysql:8.0 &#34;docker-entrypoint.s…&#34; 15 seconds ago Up 14 seconds 33060/tcp, 127.0.0.1:13306-&gt;3306/tcp mysql-8-dev 进入容器 使用命令行模式进入容器。mysql-8-dev 就是上面设置的容器的名字。也可以用 docker ps 命令中显示的容器的 id（CONTAINER ID）。
&gt; docker exec -it mysql-8-dev /bin/bash bash-4.4# 这里直接使用用户名和密码访问 mysql。
bash-4.4# mysql -uroot -p123456 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 10 Server version: 8.0.31 MySQL Community Server - GPL Copyright (c) 2000, 2022, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement. mysql&gt; 这样就表示成功进到 mysql 里面了。
]]></content></entry><entry><title>Linux memory（Linux 内存）</title><url>/post/computer-science/operating-system/memory/linux_memory/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>memory(内存)</tag></tags><content type="html">资料 linux_memory.drawio.html 页式管理 Linux 内存主要采用的是页式内存管理，但是由于 Intel 处理器的发展史，Linux 无法避免分段管理。
因为操作系统必须按照硬件结构设计，所以 Linux 的内核必须服从 CPU 的硬件结构。
虚拟地址空间 在 Linux 中，虚拟地址空间被分为内核空间和用户空间。
32 位系统，内核空间占用 1G，位于最高处，剩下的 3G 是用户空间。 （见图：linux_memory.drawio.html 2-2） 64 位系统，内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。 （见图：linux_memory.drawio.html 2-4） 进程在用户态时，只能访问用户空间内存。只有进入内核态后，才可以访问内核空间的内存。
虽然每个进程都各自有独立的虚拟内存，但是虚拟内存中的内核地址，关联的是相同的物理内存。
这样，进程切换到内核态后，就可以很方便地访问内核空间内存。
用户空间分布 32 位系统的用户空间分布的情况：
程序文件段（.text），包括二进制可执行代码。 已初始化数据段（.data），包括静态常量。 未初始化数据段（.bss），包括未初始化的静态变量。 堆段，包括动态分配的内存，从低地址开始向上增长。 文件映射段，包括动态库、共享内存等，从低地址开始向上增长。 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便自定义大小. （见图：linux_memory.drawio.html 2-6） 在这 6 个内存段中，堆和文件映射段的内存是动态分配的。
比如，使用 C 标准库的 malloc() 或者 mmap()，就可以分别在堆和文件映射段动态分配内存。
malloc malloc() 不是系统调用，而是 C 库里的函数，用于动态分配内存。
malloc 申请内存的时候，会有两种方式向操作系统申请堆内存:
通过 brk() 系统调用从堆分配内存，通过 brk 将堆顶指针向高地址移动，获得新的内存空间。 （见图：linux_memory.drawio.html 4-2） 通过 mmap() 系统调用在文件映射区域分配内存，也就是从文件映射区拿一块内存。 （见图：linux_memory.drawio.html 4-4） malloc 源码默认定义了一个阈值：如果用户分配的内存小于 128 KB，则使用 brk；如果用户分配的内存大于 128 KB，则使用 mmap。
分类内存采用两种方式的原因有两个：1、避免堆内存碎片；2、避免频繁的进行系统调用。
malloc 分配的是虚拟内存。如果分配后的虚拟内存没有被访问的话，是不会将虚拟内存不会映射到物理内存，这样就不会占用物理内存了。
只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断。然后操作系统会建立虚拟内存和物理内存之间的映射关系。
堆内存碎片 假设，先 malloc 2+2+2 K 的内存，然后 free 2+2 K。因为通过 brk 从堆空间分配的内存，并不会归还给操作系统。所以，这时 malloc 内存池就有 4K 的空闲。
如果这个时候 malloc 小于 4K ，就可以直接从内存池分配，如果 malloc 大于 4K，就必须再从堆上申请。
如果程序后来的 malloc 都大于 4K ，那么这个空闲的 4K 就变成了无法使用到的内存碎片。（见图：linux_memory.drawio.html 4-6）
生产环境的程序通常会长时间运行，所以这样的碎片有可能会越积越多，尤其是如果频繁的 malloc 和 free 小块内存。
malloc 在分配内存的时候，并不是按用户预期申请的字节数来分配内存空间大小，而是会预分配更大的空间作为内存池。具体会预分配多大的空间，跟 malloc 使用的内存管理器有关系。
内存池 brk 和 mmap 都是系统调用。执行系统调用是要进入内核态的，然后在回到用户态，运行态的切换会耗费不少时间。 如果都用 mmap 来分配内存，等于每次都要执行系统调用。
另外，因为 mmap 分配的内存每次释放的时候，都会归还给操作系统，于是每次 mmap 分配的虚拟地址都是缺页状态的，然后在第一次访问该虚拟地址的时候，就会触发缺页中断。
频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大。
为了改进这两个问题，malloc 通过 brk 系统调用在堆空间申请内存的时候，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放的时候，就缓存在内存池中。
等下次在申请内存的时候，就直接从内存池取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还存在，这样不仅减少了系统调用的次数，也减少了缺页中断的次数，这将大大降低 CPU 的消耗。
/proc/{pid}/maps 程序运行后可以通过 /proc/{pid}/maps 文件查看进程的内存分布情况。
02dc7000-02de8000 rw-p 00000000 00:00 0 [heap] 02de8000 - 02dc7000 = 21000，也就是在 heap（堆上）分配了 21000 字节。如果 malloc 是通过 mmap 分配的，右边显示 [heap] 的那个位置就啥都没有。
需要注意的是，程序中返回的地址应该是 02dc7010 而不是 02dc7000。前面的 16 字节（0x10）是内存块的头信息。内存块头信息在 《Linux\Unix 系统编程手册》 第 7 章里有提到。
图片：linux-memory.drawio/6-2、内存块头信息 free 如果 malloc 通过 brk 方式申请的内存，free 内存后，堆内存还存在。这是因为内存会被放入 malloc 的内存池里，当进程再次申请内存时就可以直接复用。当进程退出后，操作系统就会回收进程的所有资源。
如果 malloc 通过 mmap 方式申请的内存，free 释放内存后就会立刻归还给操作系统。也就是，如果是通过 brk 方式申请的内存，free 后，依然可以在 /proc/{pid}/maps 文件里看到，因为内存还没有被归还给操作系统。如果是通过 mmap 方式申请的内存，free 后，就看不到了。
free 函数使用的时候只传入一个内存地址，没有传入内存大小。内存大小被存在了这个指针指向的内存块的内存块的头信息里。
reference（参考） Crash Course Computer Science（计算机科学速成课） bilibili
CrashCourse 字幕组
Youtube 原视频
小林coding
图解系统
Linux 文档
malloc(3) - allocate and free dynamic memory
proc(5) - process information pseudo-filesystem
《Linux\Unix 系统编程手册》 第 7 章</content></entry><entry><title>使用 Jekyll 主题</title><url>/post/computer-science/application/jekyll/jekyll-theme/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>Ruby</tag><tag>Jekyll</tag><tag>GitHub Pages</tag></tags><content type="html">环境 CPU AMD64(x86_64) Windows 11 家庭版 Ruby 3.1.2 RubyGems 3.3.7 Jekyll 4.2.2
jekyll-TeXt-theme Github：
https://github.com/kitian616/jekyll-TeXt-theme
官方文档：
https://tianqi.name/jekyll-TeXt-theme/
第 1 步，从 Github 上把项目下载下来。
第 2 步，安装 Ruby 依赖包。
&amp;gt; bundle install --path vendor/bundle [DEPRECATED] The `--path` flag is deprecated because it relies on being remembered across bundler invocations, which bundler will no longer do in future versions. Instead please use `bundle config set --local path &amp;#39;vendor/bundle&amp;#39;`, and stop using this flag 一大堆输出。。。 Using jekyll-text-theme 2.2.6 from source at `.` Bundle complete! 3 Gemfile dependencies, 41 gems now installed. Bundled gems are installed into `./vendor/bundle` Post-install message from html-pipeline: ------------------------------------------------- Thank you for installing html-pipeline! You must bundle Filter gem dependencies. See html-pipeline README.md for more details. https://github.com/jch/html-pipeline#dependencies ------------------------------------------------- 安装完成后，可以使用 Jekyll 集成的那个开发用的服务器，然后使用浏览器在本地进行预览。
这里同样会遇到 webrick 无法加载的那个异常情况，解决方法是一样的。
jekyll-theme-chirpy Github：
https://github.com/cotes2020/jekyll-theme-chirpy
官方文档（同时也是个 Demo）：
https://chirpy.cotes.page/
个人感觉，这个主题比上面那个正在用的要好看不少。
但是无奈，按照官方文档走流程的时候，在发布流程的 Github Action 步骤卡住了。而且没有找到解决方案，遂遗憾放弃。</content></entry><entry><title>使用 Jekyll 和 GitHub Pages 搭建站点</title><url>/post/computer-science/application/jekyll/jekyll-start/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>Ruby</tag><tag>Jekyll</tag><tag>GitHub Pages</tag></tags><content type="html"><![CDATA[环境 CPU AMD64(x86_64) Windows 11 家庭版 Ruby 3.1.2 RubyGems 3.3.7 Jekyll 4.2.2
安装 Jekyll 在官方文档中有详细的安装 Jekyll 的流程说明。
Jekyll 官方文档的中文版：http://jekyllcn.com/。
第 1 步，安装 Ruby。
Ruby 官方网站的中文版：http://www.ruby-lang.org/zh_cn/。
进入 Ruby 下载页面：http://www.ruby-lang.org/zh_cn/downloads/下载页面的文档指出，Windows 可以用 RubyInstaller：https://rubyinstaller.org/。
安装 Ruby 的方法
每个流行的平台都有多种工具可用于安装 Ruby：
Linux/UNIX 平台，可以使用第三方工具（如 rbenv 或 RVM）或使用系统中的包管理系统。 macOS 平台，可以使用第三方工具（如 rbenv 或 RVM）。 Windows 平台，可以使用 RubyInstaller。 进入 RubyInstaller 下载页面，页面右侧的说明会告诉你该下哪一个版本的。
Which version to download?
If you don’t know what version to install and you’re getting started with Ruby, we recommend that you use the Ruby+Devkit 3.1.X (x64) installer.
下载 Ruby+Devkit 3.1.2-1 (x64) 完成后，双击运行，启动 Ruby 安装向导，然后一路 next 即可。
记得勾选 Add Ruby executables to your PATH，把 Ruby 的运行目录添加到 Windows 的环境变量 PATH 里，要不然在命令行窗口（CMD）里不能直接用命令。
安装过程中，安装向导可能会卡住，等一会就行。RubyInstaller 会把 Ruby 和 RubyGems 一起装了。RubyGems 是一个 Ruby 程序，用来管理 Ruby 包的。
安装完成后，可以在命令行里使用命令输出一下版本信息，看看安装是否成功。
&gt; ruby -v ruby 3.1.2p20 (2022-04-12 revision 4491bb740a) [x64-mingw-ucrt] &gt; gem -v 3.3.7 第 2 步，安装 Jekyll。
使用 RubyGems 安装 Jekyll。
&gt; gem install jekyll 一大堆输出。。。 Done installing documentation for unicode-display_width, terminal-table, safe_yaml, rouge, forwardable-extended, pathutil, mercenary, liquid, kramdown, kramdown-parser-gfm, ffi, rb-inotify, rb-fsevent, listen, jekyll-watch, sassc, jekyll-sass-converter, concurrent-ruby, i18n, http_parser.rb, eventmachine, em-websocket, colorator, public_suffix, addressable, jekyll after 24 seconds 26 gems installed 安装过程需要几分钟，等它装完即可。如果长时间没有反应，可以在命令行按一下回车，不排除可能是 Windows 命令行卡住了没输出信息。
安装完成后，可以在命令行里使用命令输出一下版本信息，看看安装是否成功。
&gt; jekyll -v jekyll 4.2.2 生成模板 使用 jekyll 生成模板。
这里是在 D 盘的 workspace/github.io 目录里生成模板。
&gt; jekyll new github.io Running bundle install in D:/workspace/github.io... 一大堆输出。。。 New jekyll site installed in D:/workspace/github.io. Bundler 可以认为是一个针对项目的包管理程序。它通过项目目录下的 Gemfile 文件来管理项目依赖。Bundler 在安装依赖时，会使用 RubyGems。
开发服务器 Jekyll 集成了一个开发用的服务器，可以使用浏览器在本地进行预览。
&gt; jekyll serve Configuration file: D:/workspace/github.io/_config.yml Source: D:/workspace/github.io Destination: D:/workspace/github.io/_site Incremental build: disabled. Enable with --incremental Generating... Jekyll Feed: Generating feed for posts done in 0.808 seconds. Please add the following to your Gemfile to avoid polling for changes: gem &#39;wdm&#39;, &#39;&gt;= 0.1.0&#39; if Gem.win_platform? Auto-regeneration: enabled for &#39;D:/workspace/github.io&#39; Server address: http://127.0.0.1:4000/ Server running... press ctrl-c to stop. 正常情况应该是输出上面的内容，然后就用浏览器访问 http://localhost:4000/ 查看博客了。
异常情况 &gt; jekyll serve Configuration file: D:/workspace/github.io/_config.yml Source: D:/workspace/github.io Destination: D:/workspace/github.io/_site Incremental build: disabled. Enable with --incremental Generating... Jekyll Feed: Generating feed for posts done in 0.827 seconds. Please add the following to your Gemfile to avoid polling for changes: gem &#39;wdm&#39;, &#39;&gt;= 0.1.0&#39; if Gem.win_platform? Auto-regeneration: enabled for &#39;D:/workspace/github.io&#39; ------------------------------------------------ Jekyll 4.2.2 Please append `--trace` to the `serve` command for any additional information or backtrace. ------------------------------------------------ C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve/servlet.rb:3:in `require&#39;: cannot load such file -- webrick (LoadError) from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve/servlet.rb:3:in `&lt;top (required)&gt;&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:179:in `require_relative&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:179:in `setup&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb💯in `process&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `block in process_with_graceful_fail&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `each&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `process_with_graceful_fail&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:86:in `block (2 levels) in init_with_program&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `block in execute&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `each&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `execute&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/program.rb:44:in `go&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary.rb:21:in `program&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/exe/jekyll:15:in `&lt;top (required)&gt;&#39; from C:/Ruby31-x64/bin/jekyll:32:in `load&#39; from C:/Ruby31-x64/bin/jekyll:32:in `&lt;main&gt;&#39; 输出的信息提示使用 --trace 参数，看看执行过程中发生了什么。但是实际上下 1 行已经提示了，webrick 无法加载。
------------------------------------------------ Jekyll 4.2.2 Please append `--trace` to the `serve` command for any additional information or backtrace. ------------------------------------------------ C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve/servlet.rb:3:in `require&#39;: cannot load such file -- webrick (LoadError) 这里用一下 --trace 参数，输出没啥变化，依然提示 webrick 无法加载。
&gt; jekyll serve --trace Configuration file: D:/workspace/github.io/_config.yml Source: D:/workspace/github.io Destination: D:/workspace/github.io/_site Incremental build: disabled. Enable with --incremental Generating... Jekyll Feed: Generating feed for posts done in 0.747 seconds. Please add the following to your Gemfile to avoid polling for changes: gem &#39;wdm&#39;, &#39;&gt;= 0.1.0&#39; if Gem.win_platform? Auto-regeneration: enabled for &#39;D:/workspace/github.io&#39; C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve/servlet.rb:3:in `require&#39;: cannot load such file -- webrick (LoadError) from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve/servlet.rb:3:in `&lt;top (required)&gt;&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:179:in `require_relative&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:179:in `setup&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb💯in `process&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `block in process_with_graceful_fail&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `each&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `process_with_graceful_fail&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:86:in `block (2 levels) in init_with_program&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `block in execute&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `each&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `execute&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/program.rb:44:in `go&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary.rb:21:in `program&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/exe/jekyll:15:in `&lt;top (required)&gt;&#39; from C:/Ruby31-x64/bin/jekyll:32:in `load&#39; from C:/Ruby31-x64/bin/jekyll:32:in `&lt;main&gt;&#39; 这时可以回到上面使用 jekyll 生成模板的地方，从输出的信息中可以发现 Bundler 并没有安装 webrick。所以这里手动执行命令安装 webrick。
&gt; bundle add webrick Fetching gem metadata from https://rubygems.org/.......... Resolving dependencies... Fetching gem metadata from https://rubygems.org/.......... Resolving dependencies... 等待安装完成，应该就可以使用 jekyll serve 命令了。
推送项目到 GitHub Pages GitHub Pages 官方文档：https://pages.github.com/按照要求建一个名字叫 {username}.github.io 仓库，然后把项目推上去就行了。
然后就可以通过 https://{username}.github.io 访问了。
]]></content></entry><entry><title>BT 种子和磁力链接</title><url>/post/computer-science/protocol/bit-torrent/</url><categories><category>protocol(协议)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>protocol(协议)</tag></tags><content type="html">BT 种子 BT 种子，实际上指的是由 BitTorrent 协议所生成的一个包含资源信息的文件。
与传统的网络传输协议不同，BitTorrent 协议是一种以 P2P（peer-to-peer、用户对用户）模式为主的资源分享协议。采用的是一种去中心化的思想，不需要一个专门的文件发布者或者发布平台。
从理论上来说，一个 BT 种子只要发布了，种子所包含的资源就永远存在于互联网上。
平常所使用的 HTTP、FTP 等协议需要一个中心发布者在网络上发布文件，即一种点对多的模式。当然，如果中心发布者由于某种原因被封了或者发布者删除了资源，那么就无法下载资源了。
BitTorrent BitTorrent 协议的思想是将一个文件划分为大小相等的 n 块，每块大小必须为 2 的整数次方。
例如一个 100M 的文件，按照每块 1024kb 的大小被分为 100 个小块，每块中包含索引信息和 Hash 值，而我们的下载过程实际上就是块的交换过程。
BitTorrent 协议的资源发布者会根据要求，制作一个包含资源下载信息，例如 Tracker 服务器地址、文件大小、文件名、块文件大小等信息的 .torrent 文件，这个过程也就是平时说的做种。
如果要下载 BT 资源，首先要得到对应的 .torrent 文件，然后用专门的下载软件，例如 BitComet（比特彗星），下载过程大概为：
1、读取 .torrent 文件信息，载入内存。 2、得到文件内的 Tracker 地址，连接 Tracker 服务器。 3、Tracker 服务器回应下载请求，记录你的 IP 并告知其它下载者的 IP 地址。 4、你与其他在线的下载者连接，交换各自没有的块。 5、验证得到的块信息，若不同，则需要重新下载。 磁力链接 由上文可以看出，Tracker 是很重要的一个东西。一但 Tracker 服务器被封，就无法进行下载了。由此，Magnet URI scheme（磁力链接）诞生了。
磁力链接，是对等网络中进行信息检索和下载文档的电脑程序。和基于位置连接的统一资源定位符不同，磁力链接是基于 metadata（元数据）文件内容，属于统一资源名称。
也就是说，磁力链接不基于文档的IP地址或定位符，而是在分布式数据库中，通过散列函数值来识别、搜索来下载文档。
因为不依赖一个处于启动状态的主机来下载文档，所以特别适用没有中心服务器的对等网络。
磁力链接利用 DHT（distributed hash table、分布式哈希表）和 PEX（peer exchange、节点信息交换）实现了资源的随意传播，根本无法禁止。
磁力链接下载的本质是将每一个人都变为 Tracker 服务器，将资源与下载者对应起来，每位下载者保存部分信息。这样，在下载资源时，只需寻找拥有所需资源的下载者。
简单理解就是，A 认识 B，B 认识 C，C 认识 D 和 E。如果 A 想认识 E，就可以通过 B 和 C 的介绍来认识 D，不需要 A 一个个去寻找 E。
magnet:?xt=urn:btih:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 上面是一个常见的磁力链接。
magnet：为协议名。 xt：exact topic，资源定位点。 urn：Uniform Resource Name，资源名。 btih：BitTorrent info hash，表示种子散列函数。 最主要的就是 btih 后面唯一的一串 16 进制的数字。 图种 图种就是把包含 BT 种子的压缩文件隐藏在图片中。
下面的操作是在 windows 11 系统环境下操作的。
需要准备一张图片 1.jpg 和一个压缩文件 2.rar。然后新建一个 .bat 后缀的批处理文件，把下面的代码放进去。
copy /b 1.jpg+2.rar 3.jpg copy /b 是一个基础的 DOS 命令，作用是合并文件。
把图片、压缩文件、批处理文件放在同一个目录。然后执行批处理文件，之心完成后就会得到一张图片 3.jpg。
这个图片实际上同时文件含了图片和压缩文件。如果把图片 3.jpg 的后缀名改成 .rar，这个时候图片就变成了压缩文件。
这个压缩文件是可以解压的，压缩文件的内容就是 2.rar 的内容。</content></entry><entry><title>站点示例</title><url>/flinks.html</url><categories/><tags/><content type="html">如想交换本站友情链接，请在评论区留下你的站点信息，格式参考如下：
- name: Hugo-NexT desc: Hugo NexT 官方预览网站。 avatar: https://hugo-next.eu.org/imgs/hugo_next_avatar.png link: https://hugo-next.eu.org</content></entry></search>