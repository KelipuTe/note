<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>访客如何使用档案馆</title><url>/post/how_to_use/</url><categories/><tags/><content type="html"><![CDATA[关于访客如何使用档案馆 笔记内容分为三个部分：文本；程序代码（借助 github）；图（借助 draw.io）。
如果笔记涉及到具体的操作或者笔记是一个系列的，通常在文本的最前面会有一个标题为 前言 的部分。 如果涉及具体的操作，那前言会说明实践的环境。如果笔记是一个系列的，那前言会说明需要那些前置知识。
如果笔记里面涉及到了代码或者图，通常在文本的最前面会有一个标题为 资料 的部分。
如果是类似 &ldquo;{xxx}/xxx/xxx/&rdquo; 这种格式的，就是个人项目中的程序代码，需要去 github 上查看。 仓库地址我统一放在这里了，笔记里面只会写仓库名字，不会再写仓库地址。
KelipuTe{demo-c}{demo-assembly}{demo-golang}如果是类似 &ldquo;xxx.drawio.html&rdquo; 这种格式的，就是示意图，直接打开就可以预览。
关于我的个人项目中的符号命名，详见 符号命名这一篇。
如果参考了外部资料，通常在笔记的最后面会有一个标题为 参考 的部分。
]]></content></entry><entry><title>计算机科学相关笔记的导航</title><url>/post/computer-science/computer_science/</url><categories><category>computer-science(计算机科学)</category></categories><tags><tag>computer-science(计算机科学)</tag></tags><content type="html">正文 本篇是计算机科学相关笔记的导航。
硬件系统 这个部分，主要涉及硬件系统的几个基本的硬件单元。 主要是为了，了解 CPU 的基本原理，了解指令集是什么。
指令集是计算机的灵魂，整个计算机都是围绕指令集构建起来的。 它一方面指导硬件系统（比如 CPU）怎么设计，另一方面指导软件系统（比如 BIOS）怎么设计。 指令集就是一个抽象层，是连接硬件系统和软件系统的桥梁。
算术逻辑单元（Arithmetic and Logic Unit、ALU）
内存（Memory）
中央处理器（Central Processing Unit、CPU）
软件系统 这个部分，主要涉及操作系统、程序、在 linux 系统中使用 c 语言进行编程。 了解操作系统是什么、了解操作系统的系统调用、了解程序是什么、了解程序的基本运行过程。
基本输入输出系统（Basic Input/Output System、BIOS）
程序
在 Linux 中使用 C 语言进行编程的注意点
ELF 文件
运行 ELF 文件
系统调用
命令行参数和环境参数
动态链接和静态链接
进程的创建、进程的运行、进程的内存资源、进程的退出、进程的回收
终端和控制台
init 进程、进程间关系、作业、会话、守护进程
信号
线程
网络间进程间通信
I/O 模型
参考 频繁出现的外部引用不会每一篇笔记里都写，太烦了。 如果是某一篇或者某几篇笔记里引用的，就写在最后的参考里面。
ChatGPT
Bito
DeepL
{51CTO学堂}/{可用行师}/
Linux C核心技术
{51CTO学堂}/{可用行师}/
Golang核心高级
{51CTO学堂}/{可用行师}/
内存与数据精讲
{51CTO学堂}/{可用行师}/
内存与数据二</content></entry><entry><title>浮点数（笔记片段）</title><url>/post/computer-science/programming-language/assembly/%E6%B5%AE%E7%82%B9%E6%95%B0/</url><categories><category>assembly-language(汇编语言)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>assembly-language(汇编语言)</tag></tags><content type="html">前言 实践的环境：同 x86-64_架构
资料 示意图：
assembly.drawio.html 正文 x87 浮点数 基本架构手册第 8 章
这里主要看的是 x87 浮点数相关的内容。
基本架构手册 8.1.2 节
这里主要看的是 x87 浮点数的寄存器栈相关的内容。
移动数据 fld、fild 把数据压入 fpu 栈。浮点数用 fld，整数用 fild。
每次入栈后，st(0) 都会指向新入栈的元素。
示意图：assembly.drawio.html 4-2
fldz、fld1、fldpi 入栈 0.0；入栈 1.0；入栈 pi；
fst、fstp、fist、fistp 把 st(0) 中的数据移动到目标操作数上去。
浮点数用 fld、fstp，整数用 fist、fistp。
fstp、fistp 附带弹栈操作。
fcomvcc 测试 eflags 的标志位，如果为真，则将源操作数移至目标操作数 源操作数始终是 st(i) 之一，目标操作数始终是 st(0)
finit 将 fpu 的控制寄存器、状态寄存器、标记寄存器、指令指针寄存器、数据指针寄存器设置为默认状态。 fpu 控制寄存器设置为 037fh（四舍五入，屏蔽所有异常，64 位精度）。状态寄存器清零（未设置异常标志，top 设置为 0） 寄存器堆栈中的数据寄存器保持不变，但全部标记为空（11b）。指令指针寄存器和数据指针寄存器都被清空。
四则运算 fadd、faddp、fiadd 浮点数加法
无操作数形式：将 st(1) 加上 st(0)，结果放在 st(1)，然后弹栈。 单操作数形式：将 st(0) 加上源操作数，结果放在 st(0)。 双操作数形式：将 st(i) 加上 st(0)，结果放在 st(i)；或者将 st(0) 加上 st(i)，结果放在 st(0)。 浮点数用 fadd、faddp；整数用 fiadd。
faddp 附带弹栈操作；
fsub、fisub、fsubp 浮点数减法
无操作数形式：将 st(1) 减去 st(0)，结果放在 st(1)，然后弹栈。 单操作数形式：将 st(0) 减去源操作数，结果放在 st(0)。 双操作数形式：将 st(i) 减去 st(0)，结果放在 st(i)；或者将 st(0) 减去 st(i)，结果放在 st(0)。 浮点数用 fsub、fsubp；整数用 fisub。
fsubp 附带弹栈操作；
fimul、fimul、fmulp 浮点数乘法
无操作数形式：将 st(1) 乘上 st(0)，结果放在 st(1)，然后弹栈。 单操作数形式：将 st(1) 乘上源操作数，结果放在 st(0)。 双操作数形式：将 st(i) 乘上 st(0)，结果放在 st(i)；或者将 st(0) 乘上 st(i)，结果放在 st(0)。 浮点数用 fimul、fmulp；整数用 fimul。
fmulp 附带弹栈操作；
fdiv、fidiv、fdivp 浮点数除法
无操作数形式：将 st(1) 除以 st(0)，结果放在 st(1)，然后弹栈。 单操作数形式：将 st(1) 除以源操作数，结果放在 st(0)。 双操作数形式：将 st(i) 除以 st(0)，结果放在 st(i)；或者将 st(0) 除以 st(i)，结果放在 st(0)。 浮点数用 fdiv、fdivp；整数用 fidiv。
fdivp 附带弹栈操作；
浮点数比较 fcom、fcomp、fcomi、fcomip 比较两个操作数。
fcom、fcomp 指令有两种形式。
无操作数形式，将 st(0) 和 st(1) 进行比较。 单操作数形式，将源操作数和 st(0) 进行比较。 根据比较结果设置 fpu 中的 c0、c2、c3 标志位。一般和 fstsw、sahf 一起用。
fcomi、fcomip 进行比较之后，会根据比较结果设置 eflags 中的 zf、pf、cf 标志位
fcomp、fcomip 附带弹栈操作
fstsw、sahf fstsw，将 fpu 中的标志位存储到目标操作数。目标操作数一般是 ax。
sahf，用 ah 的值（ax 的高 8 位）设置 eflags 中的 sf、zf、af、pf、cf 标志位。
其他操作 frndint 根据当前的舍入模式，将 st(0) 舍入为最接近的整数值，结果存入 st(0)。
fabs、fchs fabs，对 st(0) 取绝对值。
fchs，把 st(0) 的符号反转。
fsqrt 计算 st(0) 的平方根，结果存入 st(0)。
fsin、fcos fsin，计算 st(0) 的正弦近似值，结果存入 st(0)。
fcos，计算 st(0) 的余弦近似值，结果存入 st(0)。
源操作数的单位必须是弧度，范围是 [-2^63, +2^63]。</content></entry><entry><title>函数和库（笔记片段）</title><url>/post/computer-science/programming-language/assembly/%E5%87%BD%E6%95%B0%E5%92%8C%E5%BA%93/</url><categories><category>assembly-language(汇编语言)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>assembly-language(汇编语言)</tag></tags><content type="html"><![CDATA[前言 实践的环境：同 x86-64_架构资料 笔记里的代码在：
{demo-assembly}/demo-in-linux/function/ {demo-assembly}/demo-in-linux/library/ 示例代码：
打印命令行参数和环境变量。 打印全局变量的数组。 打印全局变量的结构体。 示意图：
assembly.drawio.html 正文 函数 函数和代码块是不一样的。函数用的是 call 指令，而代码块用的是 jmp 指令。 使用 jmp 指令的时候，除了跳转不会有别的动作。使用 call 指令的时候，除了跳转，还有一些别的动作。
函数这里还有个堆栈的概念。堆栈是操作系统分配给进程或线程的一块连续的内存空间。 它的主要功能有两个，一个是用于函数内部临时存储数据，另一个是用于函数间传递参数。
和堆栈有关系的指令就两个 push（入栈） 和 pop（出栈）。 每 push 或者 pop 一次，rsp 寄存器的值就会变一次。在 64 位的系统上，一次移动 8 个字节。 push 的时候 rsp 的值变小（栈顶往上移动，反映在内存上就是内存地址变小），pop 就是 push 反过来。
当调用 call 进入一个函数的时候，会把 call 的下一行指令的地址 push 到堆栈。 然后，把 rip 修改成函数第一行指令的地址。下面执行的时候，就是函数的指令了。
当函数执行完毕，执行 ret 指令的时候。会从堆栈中把下一行指令的地址 pop 出来，然后，赋值给 rip。 这样 rip 就回到 call 的下一行指令上去了。就可以继续往下执行代码了。
示意图：assembly.drawio.html 8-2
函数的参数 函数的参数可以用寄存器、全局变量、堆栈进行传递。
用寄存器的问题在于，谁都能对寄存器上的数据进行修改。 用全局变量的问题在于，谁都能对全局变量进行修改。 这两个很类似，都用全局变量的概念来理解就好。
用堆栈也可以，但是，需要知道数据的大小和在内存上的具体位置。
函数的约定 X86_calling_conventions在页面里找到 System_V_AMD64_ABI 这一条，这个是 64 位 linux 系统的函数约定。
64 位整数用 rdi、rsi、rdx、rcx、r8、r9 传递，32 位的用 32 位对应的寄存器，以此类推。 浮点数用 xmm0 ~ xmm7 传递。如果参数很多，寄存器不够用的话，那就用堆栈传递。
64 位以下的整数返回值用 rad 传递，128 位以下的整数返回值用 rad 和 rdx 传递。 浮点数返回值用 xmm0 和 xmm1 传递。
linux 系统提供的系统函数的参数数量都是 6 个及以内的，寄存器是够用的。
示意图：assembly.drawio.html 8-4
一般函数代码的最前面会有这几条指令。
push %rbp mov %rsp, %rbp sub $xxx, %rsp 先用堆栈保存 rbp 的值，这个时候 rsp 会上移。然后，把 rsp 当前的值给 rbp。 然后，rsp 减去一个数值，这个操作相当于在内存上开辟了一块空间。这个位置一般用于存储函数的局部变量
进入函数之后，一般会申请一块堆栈空间，把寄存器里的参数都存下来，因为不知道后续的操作会不会影响寄存器。 申请的堆栈空间可以大一点，我发现有的时候申请正好够用的空间，调用 c 库函数的时候会 core dump，申请的大一点又不会 core dump。
一般函数代码的最后面会有这两条指令。
mov %rbp, %rsp pop %rbp 这两条指令适用于恢复栈指针的，也可以用 leave 指令代替。 leave 的作用：&ldquo;Set RSP to RBP, then pop RBP&rdquo;。
系统调用 调用 c 库的 printf 想调用 printf，那按照函数的约定传参数就好了。
这里需要注意的是，因为需要用到 c 库里的函数了，所以，链接的时候，需要加上动态库。
可以用 c 先写一个 hello world 看一下。
&gt; ldd hello_world.elf linux-vdso.so.1 (0x00007ffd309b0000) libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f177ea00000) /lib64/ld-linux-x86-64.so.2 (0x00007f177edd7000) libc.so.6 就是需要的 c 动态库，&quot;/lib64/ld-linux-x86-64.so.2&quot; 是链接器。
链接命令是这样写的：ld -lc -I /lib64/ld-linux-x86-64.so.2 xxx.o -o xxx.elf。 &ldquo;-lc&rdquo; 表示链接 c 动态库，&quot;-I /lib64/ld-linux-x86-64.so.2&quot; 指定动态链接器。
命令行参数和环境变量 示意图：assembly.drawio.html 8-6
多文件编译 如果一个汇编程序由多个文件组成，编译的时候分别编译，链接的时候一起链接。
as xxx.asm -o xxx.o -g as yyy.asm -o yyy.o -g ld xxx.o yyy.o -o xxxyyy.elf 还需要注意函数的作用域，如果要给别的文件用，那么定义的时候，需要加一个 &ldquo;.global&rdquo;。
.section .text .type functionName, @function .global functionName functionName: push %rbp mov %rsp, %rbp sub $16, %rsp leave ret 静态库和动态库 实例在这里：{demo-assembly}/demo-in-linux/library/
主要关注这几个文件 caller.asm、part1.asm、part2.asm。
静态库 静态库说白了就是将多个文件组合在一起。 主要的用处就是，编译或者链接的时候，可以少写一堆文件名。 比如，把 part1 和 part2 组合。
# ar r lib{名字}.a {xxx}.o ... ar r libpart.a part1.o part2.o 然后，编译或者链接的时候，写静态库就行，不用写那两个文件了。
ld caller.o libpart.a -o caller_ld.elf # gcc xxx.c lib{名字}.a -o xxx.elf 最终生成的 elf 里面，会包括静态库的所有代码。所以，静态库的缺点也就出来了。 如果多个应用程序都用了同一个静态库，那么磁盘里就会存在重复的代码。 如果修改了静态库，那么所有用到这个静态库的应用程序都需要重新编译。
动态库 动态库和静态库思路差不多，也是将多个文件组合在一起。
# gcc -shared -o lib{名字}.so {xxx}.o ... gcc -shared -o libpart.so part1.o part2.o 然后，编译或者链接的时候，写动态库就行。
# gcc xxx.c lib{名字}.so -o xxx.elf ld caller.o libpart.so -o caller_so.elf 和静态库不一样的地方，最终生成的 elf 里面，不会包括动态库的代码。 程序运行的时候，需要依靠动态库加载器（ld.so）加载动态库。
用 ldd 命令可以看到程序依赖的动态库的名字，还有动态库的地址。
&gt; ldd caller_so.elf linux-vdso.so.1 (0x00007ffc90745000) libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f6c97200000) /lib64/ld-linux-x86-64.so.2 (0x00007f6c975b2000) libpart.so =&gt; not found 如果显示 not found，就执行一下 export LD_LIBRARY_PATH=&quot;$LD_LIBRARY_PATH:.&quot; 然后再看看。
动态库可以解决静态库的两个问题。 如果多个应用程序都用了同一个动态库，那么磁盘里只需要存储一份代码。 如果修改了动态库，程序运行的时候，动态库加载器就会加载新的动态库。
]]></content></entry><entry><title>字符串（笔记片段）</title><url>/post/computer-science/programming-language/assembly/%E5%AD%97%E7%AC%A6%E4%B8%B2/</url><categories><category>assembly-language(汇编语言)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>assembly-language(汇编语言)</tag></tags><content type="html">前言 实践的环境：同 x86-64_架构
资料 笔记里的代码在 {demo-assembly}/demo-in-linux/string/
示例代码：
字符串大小写转换。 判断两个字符串是否相等。 计算字符串长度。 在字符串中寻找指定字符，并返回找到的第一个指定字符的下标。 正文 movs movs，用于传输字符串。
指令的源操作数和目标操作数都是内存操作数。 源操作数的地址从 rsi 寄存器读取。目的操作数地址从 rdi 寄存器读取。 指令执行之前，必须正确加载这两个寄存器。
每执行一次指令，就会按照指令设置的字节、字、双字、四字传输一次。 然后，rsi 和 rdi 上存储的地址都会自动增加或者减少对应的位数。
rsi 和 rdi 上存储的地址是增加或者减少，这个由 eflags 寄存器的 df 标志决定。 df = 0 的时候增加，可以通过 cld 指令设置；df = 1 的时候减少，可以通过 std 指令设置。默认 df = 0。 需要从头开始处理字符串的时候用 cld，需要从尾开始处理字符串的时候用 std。
想要传输完整的字符串，可以使用循环结构来处理，也可以用 rep 指令。 rep，按 rcx 寄存器中指定的次数重复字符串指令，或者重复到不再满足 eflags 的 zf 标志的指定条件。 rep 可以加载字符串指令前面作为前缀，像这样 rep movs。
和 rep 相似的有 5 个指令。rep、repe、repz、repne、repnz。 rep 的结束条件是 rcx 寄存器为 0。 repe、repz 的结束条件是 rcx 寄存器为 0 或者 zf 标志为 0。 repne、repnz 的结束条件是 rcx 寄存器为 0 或者 zf 标志为 1。
lods、stos lods，将一个字节、字、双字、四字从源操作数加载到 al、ax、eax、rax 寄存器。
源操作数是内存操作数，源操作数的地址从 rsi 寄存器读取。 指令执行之前，必须正确加载这个寄存器。
stos，将 al、ax、eax、rax 寄存器中的字节、字、双字、四字存储到目标操作数中。
目标操作数是内存操作数，目标操作数的地址从 rdi 寄存器读取 指令执行之前，必须正确加载这个寄存器。
数据传输完成后，rsi 和 rdi 上存储的地址都会自动增加或者减少对应的位数。
cmps cmps，用于比较字符。
源操作数和目标操作数是内存操作数。 源操作数的地址从 rsi 寄存器读取。目的操作数的地址从 rdi 寄存器读取。 指令执行之前，必须正确加载这两个寄存器。
指令将源操作数指定的字节、字、双字、四字与目标操作数指定的字节、字、双字、四字进行比较。 相等的话，就设置 eflags 的 zf 标志为 1。不相等的话，就设置 eflags 的 zf 标志为 0。
每执行一次指令，就会按照指令设置的字节、字、双字、四字比较一次，并设置结果。 然后，rsi 和 rdi 上存储的地址都会自动增加或者减少对应的位数。
使用循环结构或者 rep，就可以实现比较两个字符串是否相等。
scas scas，用于比较字符。该指令有 2 种形式，取决于操作数的数量。
无操作数形式，scas。内存操作数地址从 rdi 寄存器中读取。
单操作数形式，scas {内存操作数}。
指令将内存操作数指定的字节、字、双字、四字与 al、ax、eax、rax 中的值进行比较。 相等的话，就设置 eflags 的 zf 标志为 1。不相等的话，就设置 eflags 的 zf 标志为 0。
每执行一次指令，就会按照指令设置的字节、字、双字、四字比较一次，并设置结果。 然后，rdi 上存储的地址会自动增加或者减少对应的位数。
使用循环结构或者 rep，就可以实现从字符串里找某个字符。</content></entry><entry><title>整数的运算（笔记片段）</title><url>/post/computer-science/programming-language/assembly/%E6%95%B4%E6%95%B0/</url><categories><category>assembly-language(汇编语言)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>assembly-language(汇编语言)</tag></tags><content type="html">前言 实践的环境：同 x86-64_架构
资料 正文 四则运算 add add，实现整数的加法运算。
add 会自动分析操作数是有符号还是无符号。 有符号运算结果溢出（正数太大）时 of=1，无符号运算结果产生进位时 cf=1。
adc adc，实现整数的加法运算。用法和 add 一样。
adc 除了用目标操作数加源操作数，还会再额外加一个当前的 cf 标志位（1 或者 0）。
sub sub，实现整数的减法运算。用目标操作数减源操作数。
sub 会自动分析操作数是有符号还是无符号。 有符号运算结果溢出（负数太小）时 of=1，无符号运算结果产生借位时 cf=1。
sbb sbb，实现整数的减法运算。用法和 sub 一样。
sbb 除了用目标操作数减源操作数，还会再额外减一个当前的 cf 标志位（1 或者 0）。
mul mul，实现无符号整数的乘法运算。
目标操作数要先放到 rax、eax、ax、al 里面去。
如果运算结果过大，目标操作数寄存器放不下的话，会把运算结果拆成两部分。 如果是 64 位的运算结果过大，高 64 位放到 rdx，低 64 位放到 rax。
比如，无符号的 0xffff,ffff 已经把 eax 塞满了。这个时候再 x2，其结果 0x1,ffff,fffe 需要 33 位的空间。 eax 不够放了，这个时候就会把数据拆成两部分。高 32 位（0x1）放在 edx，低 32 位（0xffff,fffe）放在 eax。
imul imul，实现有符号整数的乘法运算。该指令有 3 种形式，取决于操作数的数量。
单操作数形式，imul {源操作数}。用法与 mul 指令相同。
双操作数形式，imul {目的操作数}, {源操作数}。 执行源操作数和目的操作数的有符号乘法运算。结果会被截断，并存储在目的操作数。
三操作数形式，imul {立即数}, {源操作数}, {目的操作数}。 执行立即数和源操作数的有符号乘法运算。结果会被截断，并存储在目的操作数。
div div 可以实现无符号整数的除法运算。
idiv idiv 可以实现有符号整数的除法运算。
自增自减 inc，在目标操作数上加 1，同时保留 cf 标志的状态。 dec，从目标操作数中减去 1，同时保留 cf 标志的状态。 这两条指令允许在不影响 cf 标志的情况下更新循环计数器。
逻辑运算 and，与运算。 or，或运算。 not，非运算。 xor，异或运算。 移位运算 左移 sal，算术左移。shl，逻辑左移。sal {计数操作数}, {目的操作数}。
它们执行相同的操作。将目标操作数中的位向左移动计数操作数中指定的位数。 移位后，超出目标操作数左边界的位，会先移入 cf 标志。
最低有效位（the least significant bit）被清零。
右移 sar，算术右移。shr，逻辑右移。sar {计数操作数}, {目的操作数}。
它们执行相同的操作。将目标操作数中的位向右移动计数操作数中指定的位数。 移位后，超出目的操作数右边界的位，会先移入 cf 标志。
最高有效位（the most significant bit）根据指令类型被置位或清零。
计数操作数 计数操作数可以是立即数或者 cl 寄存器。
计数操作数，在 32 位模式下，被屏蔽为 5 位，在 64 位模式下，被屏蔽为 6 位。 也就是说，计数的范围，在 32 位模式下，限制为 0 至 31，在 64 位模式下，限制为 0 至 63。</content></entry><entry><title>移动数据和流程控制（笔记片段）</title><url>/post/computer-science/programming-language/assembly/%E7%A7%BB%E5%8A%A8%E6%95%B0%E6%8D%AE%E5%92%8C%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/</url><categories><category>programming-language(编程语言)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>assembly-language(汇编语言)</tag></tags><content type="html"><![CDATA[前言 实践的环境：同 x86-64_架构资料 示意图：
assembly.drawio.html 正文 移动数据 bswap bswap，用于翻转寄存器上的数据的字节序。 主要用于小端字节序和大端字节序相互转换。
lea lea，用于获取内存地址。 主要用于把变量的内存地址传输到寄存器中。
mov mov，用于移动数据，把源操作数复制到目标操作数。 使用的时候需要注意，两个操作数的大小必须相同。
mov 变量名, 寄存器，表示移动变量上存储的值到寄存器。我的理解，这个时候是内存操作数的逻辑。 mov $变量名, 寄存器，表示移动变量的起始地址到寄存器。我的理解，这个时候是立即数的逻辑。
如果传输的数据是数组或者结构体这样的。那么就需要使用内存操作数，也就是间接寻址。 内存操作数的格式是 displacement(base, index, scale)。
displacement，常量或者内存操作数； base，地址寄存器（可选参数），内存操作数； index，索引寄存器（可选参数）。比如，数组下标； scale，缩放因子，可以是 1,2,4,8； 获取的数据的起始地址就位于 displacement + base + index * size。 常用的用法有两种，下面用数组举例。
.section .data array1: .int 1,2,3,4,5 第一种用法。
movl $2, %r8d movl array1(,%r8,4), %r10d displacement 是 array1，array1 对应的是一个内存操作数，也就是数组的起始地址。 base 不填；index 下标是 2；scale 缩放因子是 4，对应 int 的长度。 获取的数据的起始地址就位于 &ldquo;array1 + 2 * 4&rdquo;，数组的起始地址向后偏移 8，也就是下标为 2 的第 3 个元素。 写成 c 语言就相当于这样。
array1 int[5] = {1,2,3,4,5} r9d = *(array1+2) 第二种用法。
movq $array1, %r8 movl 4(%r8), %r10d displacement 是 4，常量。 base 地址是 array1，array1 对应的是一个内存操作数，也就是数组的起始地址。index 不填；scale 不填。 获取的数据的起始地址就位于 &ldquo;4 + array1 + 0 * 0&rdquo;，数组的起始地址向后偏移 4，也就是下标为 1 的第 2 个元素。 movsx movsx，带符号扩展数据。
8 位的 -1（1111,1111），带符号扩展到 16 位，依然是 -1（1111,1111,1111,1111）。
movzx movsx，扩展数据后填充 0。
8 位的 -1（1111,1111），扩展到 16 位后填充 0，就不是 -1 了，而是 255（0000,0000,1111,1111）。
xchg xchg，用于交换数据。
流程控制 jmp jmp，无条件跳转到另一处继续执行程序。和 c 语言里的 goto 一个意思。
jmp 指令的标签有两种写法，有名字的标签和纯数字标签。
有名字的标签。
_start: mov $1, %rax jmp jmpPoint mov $2, %rax jmpPoint: mov $3, %rax 看编译后的代码比较好理解，jmpPoint 标签就像变量一样，对应某个内存地址，jmp 就是跳到 jmpPoint 指向的地址上去了。
0000000000401000 &lt;_start&gt;: 401000:	48 c7 c0 01 00 00 00 mov $0x1,%rax 401007:	eb 07 jmp 401010 &lt;jmpPoint&gt; 401009:	48 c7 c0 02 00 00 00 mov $0x2,%rax 0000000000401010 &lt;jmpPoint&gt;: 401010:	48 c7 c0 03 00 00 00 mov $0x3,%rax 示意图：assembly.drawio.html 2-4
纯数字标签。
_start: mov $1, %rax jmp 1f 0: mov $2, %rax 1: mov $3, %rax jmp 0b 和有名字的标签一样，纯数字标签也对应某个内存地址。
纯数字标签和有名字的标签用法不太一样，用数字的时候需要指定方向。 比如，上面这段代码里的。1f 表示，往下找 1 标签，然后，跳过去。0b 表示，往上找 0 标签，然后，跳过去。
不写 f 和 b，在编译的时候不会报错，但是，运行的时候会报错。 因为，jmp 会认为是跳到内存地址 1 上去。然后，rip 寄存器的值就变成 1 了，这显然是不对的。
这两个结合起来用是可以实现循环结构的，上面的代码就是个死循环。
loop loop，用于实现循环结构。
先往 rcx、ecx、cx 寄存器（取决于系统是 64 位、32 位、16 位）中传输循环需要执行的次数。 然后，设置跳转的标签。每一次运行到 loop 指令处时。先检测计数寄存器的值。 如果计数寄存器大于 0，则跳转到标签处，计数寄存器自动减 1，然后，继续执行。
mov $5, %rcx loopPoint: mov %rcx, %rdx loop loopPoint 有条件的指令 cmp cmp，用于比较两个操作数，并根据结果设置 eflags 寄存器中的标志位。
标志位一般是给 jcc、loopcc、cmovcc、fcmovcc 这种带条件的指令用的。
带条件的指令，每条指令都有一个条件代码（cc），用于指示测试的条件。 测试的条件是 eflags 寄存器中的状态标志（cf、of、pf、sf、zf）。 如果处于指定状态，则执行相应的操作。如果不处于指定状态，则不执行操作。
cmovcc cmov，带条件的 mov。
cmp %rbx, %rcx cmovl $2, %rax cmovg（great），如果 rcx &gt; rbx 则执行 rax = 2。
jcc jcc，带条件的 jmp。
mov $1, %rax cmp %rbx, %rcx jg jmpPoint mov $2, %rax jmpPoint: mov $3, %rax jg（great），如果 rcx &gt; rbx 则跳转到 jmpPoint 继续执行。
]]></content></entry><entry><title>intel x86-64 架构（笔记片段）</title><url>/post/computer-science/programming-language/assembly/x86-64_%E6%9E%B6%E6%9E%84/</url><categories><category>assembly-language(汇编语言)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>assembly-language(汇编语言)</tag></tags><content type="html"><![CDATA[前言 实践的环境：
amd64（x86_64） windows 11 vmware workstation pro 16 ubuntu 22.04 linux version 5.19.0-41-generic gcc version 11.3.0 我是在虚拟机里跑的汇编程序，有的时候会遇到一些离谱的问题。 比如，同样一段汇编代码，重复执行的时候，结果不一样，有的时候成功，有的时候 core dump。 但是，gdb 调试的时候，寄存器和内存里的数据是对的，调用系统调用或者 c 库会 core dump。
笔记顺序：
x86-64 架构（本篇就是） 移动数据和流程控制整数浮点数字符串函数和库内联汇编（整理中） simd（整理中） 资料 示意图：
assembly.drawio.html 正文 intel cpu 架构文档 英特尔 64 和 32 架构软件开发人员手册在页面里找到 &ldquo;Intel® 64 and IA-32 Architectures Software Developer&rsquo;s Manual Volume 1: Basic Architecture&rdquo;。
这个手册下面简称为 &ldquo;基本架构手册&rdquo;，介绍了处理器的架构和编程环境。 这里主要看的是 64 位架构的寄存器、内存、指令相关的内容，写汇编程序最主要的就是这三个东西。
intel x86-64 架构 x86 泛指基于 intel 8086 并且向后兼容的 cpu 指令级架构。 最早的 intel 8086 是 16 位的微处理器（1978 年），后面还有 80816、80826、80836、80846 等。 现在，提到 x86，一般是指 32 位的架构（1985 年）。提到 x86-64（或者 x64），一般是指 64 位的架构（2003 年）。
基本架构手册 3.2.1 节这里主要看的是 64 位架构的内存地址空间、寄存器相关的内容。
基本架构手册 3.3.7 节这里主要看的是指令指针寄存器（rip）相关的内容。
指令指针寄存器（instruction pointer register），又叫程序计数器（program counter）。 指令指针寄存器上面存储的是下一条要执行的指令的地址。
示意图：assembly.drawio.html 2-2
注意指令指针寄存器和指令寄存器（instruction register）的区别。 指令寄存器上面存储的是正在被执行的指令。
分支（branch）指令，比如 jmp，就是通过修改 rip 的值，实现选择结构和循环结构的。
寄存器 基本架构手册 3.4.1.1 节这里主要看的是 64 位架构的通用寄存器相关的内容。
8 位：al、bl、cl、dl、dil、sil、bpl、spl、r8l ~ r15l 16 位：ax、bx、cx、dx、di、si、bp、sp、r8w ~ r15w 32 位：eax、ebx、ecx、edx、edi、esi、ebp、esp、r8d ~ r15d 64 位：rax、rbx、rcx、rdx、rdi、rsi、rbp、rsp、r8 ~ r15 还有 ah 寄存器，在 al 前面的 8 位上。bh、ch 以此类推。
示意图：assembly.drawio.html 2-6
rsp 就是栈指针，永远指向进程堆栈空间的栈顶。 函数的调用堆栈那里就需要用到 rbp、rsp 这两个寄存器。
基本架构手册 3.4.1.1 节这里主要看的是 64 位架构的通用寄存器相关的内容。
基本架构手册 3.4.3 节这里主要看的是 eflags 寄存器相关的内容。
cf，进位标志。最高位产生进位或者借位，则 cf=1，否则 cf=0。无符号整数运算结果溢出 cf=1。
zf，零标志。运算结果是 0，则 zf=1，否则 zf=0。
sf，符号标志位。就等于运算结果的最高位。有符号整数的符号位。
of，溢出标志。运算结果正数太大或者负数太小（不包括符号位），则 of=1,，否则 of=0。
基本架构手册 3.7.3.1 节这里主要看的是 64 位架构的内存操作数关的内容。
基本架构手册 8.1.2 节这里主要看的是浮点数（fpu）寄存器相关的内容。 fpu 寄存器是栈结构的，有 8 个 80 位的寄存器 st(0) ~ st(7)。 需要注意的是，入栈的时候，新数据始终在 st(0) 位置，老数据依次往上移动。
基本架构手册 10.2.2 节这里主要看的是 xxm 寄存器相关的内容。 有 8 个 128 位的寄存器 xmm0 ~ xmm7。
数据类型 基本架构手册 4 章，这里主要看的是数据类型。
&ldquo;.byte&rdquo;，定长 1 字节整型。 &ldquo;.short&rdquo;、&quot;.word&quot;，定长 2 字节整型。 &ldquo;.int&rdquo;、&quot;.long&quot;，定长 4 字节整型。 &ldquo;.quad&rdquo;，定长 8 字节整型。 &ldquo;.float&rdquo;，定长单精度浮点数，4 字节。 &ldquo;.double&rdquo;，定长双精度浮点数，8 字节。 &ldquo;.string&rdquo;，以 &ldquo;\0&rdquo; 结束的字符串。 声明经过初始化的变量。
.section .data {变量名1}: {数据类型} {数据} {变量名2}: {数据类型} {数据} 声明经过初始化的数组。
.section .data {变量名1}: {数据类型} {元素}, {元素}, {元素}... 声明经过初始化的结构体。
.section .data {变量名1}: {属性名1}: {数据类型} {数据} {属性名2}: {数据类型} {数据} 这里一定要空一行，要不然后面声明的变量，就会被当成结构体的属性 声明没有初始化的变量。
.section .bss .lcomm {变量名1}, {数据长度} .lcomm {变量名2}, {数据长度} 声明常量。
.equ {变量名1}, {值} .equ {变量名2}, {值} 原码、反码、补码 在计算机中，数据都是以补码的形式存储的。
对于有符号整数。 正整数的源码 = 反码 = 补码。 负整数的反码 = 除了源码的符号位，源码的其他位全部取反。 负整数的补码 = 负整数的反码 + 1。
这里的例子都是 1 字节的。 +000；源码 = 0000,0000；反码 = 0000,0000；补码 = 0000,0000； +001；源码 = 0000,0001；反码 = 0000,0001；补码 = 0000,0001； +127；源码 = 0111,1111；反码 = 0111,1111；补码 = 0111,1111； -001；源码 = 1000,0001；反码 = 1111,1110；补码 = 1111,1111； -002；源码 = 1000,0010；反码 = 1111,1101；补码 = 1111,1110； -126；源码 = 1111,1110；反码 = 1000,0001；补码 = 1000,0002； -127；源码 = 1111,1111；反码 = 1000,0000；补码 = 1000,0001； -128；补码 = 1000,0000； 10000000 应该是 -000 的位置，被用来存储 -128 了。
-127 + -001 = 1000,0001 + 11111111 = 1,1000,0000 +001 + -001 = 0000,0001 + 11111111 = 1,0000,0000 这两种情况，计算的时候，理论上都是溢出的。但是，如果把溢出的部分去掉，结果又是对的。
数据的范围 整数 1 字节，8 位，可以表示 2^8 = 256 个数字。
有符号整形，0xff ~ 0x7f，-128 ~ 127。
2 字节，16 位，可以表示 2^16 = 65,535 个数字。
有符号整形，0xffff ~ 0x7fff，-32,768 ~ 32,767。
4 字节，32 位，可以表示 2^32 = 4,294,967,295 个数字。
有符号整形，0xffff,ffff ~ 0x7fff,ffff，-2,147,483,648 ~ 2,147,483,647。
8 字节，64 位，可以表示 2^64= 18,446,744,073,709,551,616 个数字。
有符号整形，0xffff,ffff,ffff,ffff ~ 0x7fff,ffff,ffff,ffff，9,223,372,036,854,775,808 ~ 9,223,372,036,854,775,807。
浮点数 float，单精度，4 字节，1 位符号，8 位指数，23 位尾数。 1.175494351 E–38 ~ 3.402823466 E+38，6 ~ 7 个有效数字。
double，双精度，8 字节，1 位符号，11 位指数，52 位尾数。 2.2250738585072014 E–308 ~ 1.7976931348623158 E+308，15 ~ 16 个有效数字
数据扩展 整数 无符号整数和有符号正整数，在前面补 0。有符号负整数，在前面补 1。
1 字节的 -1 补码是 1111,1111，扩展到 2 字节，补码是 1111,1111,1111,1111。
至于为什么，看上面 原码、反码、补码那里 -1 和 -2 的补码就知道了。
指令 开发手册第 5 章，这里主要看的是指令相关的内容。
指令由操作码和操作数组成。 操作码，opcode，operation code，告诉 cpu 要做什么。 操作数，operand，有源操作数和目标（目的）操作数两种。 操作数的值有三种：立即数（写死的值）、寄存器、内存操作数。
也可以看这个页面 x86 and amd64 instruction reference这个网页里的指令是 intel 格式的，intel 格式的汇编和 att 格式的汇编，源操作数和目标操作数位置是反的。 imm{数字}，这种表示立即数；r 开头的表示寄存器；m 开头的表示内存操作数。还需要注意指令在 64 位操作系统上支不支持。
有的指令后面可以加后缀，后缀一般和操作的数据大小有关系。
b 对应 char，1 字节。 w（word，字）对应 short，2 字节。 l（double word，双字）对应 int、unsigned int，4 字节。 q（quad word，四字）对应 long、unsigned long、pointer，8 字节。 s 对应 float，4 字节。 d 对应 double，8 字节。 hello world 代码示例：{demo-assembly}/demo-in-linux/hello_world.asm
这个程序主要涉及汇编程序结构、移动数据、系统调用的内容，这里不展开说。
汇编代码的编译、链接、调试 编译生成可重定位文件。 as xxx.asm -o xxx.o -g。 &ldquo;-g&rdquo; 表示添加调试信息。
链接生成可执行文件。 ld xxx.o -o xxx.elf。
汇编程序可以使用 gdb 进行调试，方便观察寄存器和内存中的数据。 进入 gdb 调试后，使用命令 b *_start，在汇编程序入口打断点。 然后，使用命令 r，运行到断点处。然后，就是常规的 gdb 调试流程。
]]></content></entry><entry><title>GDB 调试工具</title><url>/post/computer-science/application/gdb_%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>gdb</tag></tags><content type="html"><![CDATA[正文 官方文档 官方手册：Debugging with GDB所有的命令：Command, Variable, and Function Indexgcc 编译 使用 gcc 编译源代码的时候，使用 -g 参数就可以让程序携带调试信息。
&gt; gcc -g hello.c -o hello.elf 进入和退出调试 进入调试的时候有两种情况，程序未运行和程序正在运行。
程序未运行的话，可以用这两种。
gdb {文件名} gdb &ndash;silent {文件名} 程序正在运行的话，可以用这两种。
gdb -p {pid} gdb &ndash;silent，先进 gdb，然后 attach {pid} 退出的话，如果是调试状态，直接在命令行里用 quit 就可以退出了。但是，如果是生产环境，这样是不行的。 生产环境退出的时候，先在命令行 detach，这样就不会影响被调试的进程，然后 quit。
gdb 也可以调试 go 程序和汇编程序，操作是一样的。
tab tab 键可以补全命令，如果有多个的话，会列出全部符合的。
help help {command}，输出 command 命令怎么用。
set、show set 用于设置参数或者配置，show 用于查看当前的参数或者配置。 这两个命令放到具体的场景中说，就不在这里细说了。
启动调试 有两个命令可以启动程序，start 和 run。这两个的区别在于： start 会执行到程序的第一行代码停住。比如，main() 的第一行代码。 run，简写 r，除非有断点，否则就会一直执行到程序结束。
start 还可以输入命令行参数。比如，start {args1} {args2}。 在 start 或者 run 之前，用 set args 也可以给程序输入命令行参数。比如，set args {args1} {args2}。
info info，简写 i，输出信息。info 后面可以跟很多东西。
info os，输出系统信息。 info proc，输出当前进程信息。 info proc {pid}，输出当前进程信息。 info proc mappings，输出进程内存信息。和 /proc/{pid}/maps 内容一样的。 info args，输出命令行参数。 list list，简写 l，输出代码，默认 10 行。输入一次后，继续按回车可以继续输出。 默认 10 行的这个值可以设置可以通过 set listsize {行数 n|unlimited} 修改为 {n|无限}。
list {行号 n}，输出从第 n 行开始的代码。 list {行号 n, 行号 m}，输出从第 n 行到第 m 行的代码。 list {函数名}，输出函数的代码。 info line，输出当前调试在第几行。
执行代码 有两个命令可以执行代码，next 和 step。这两个的区别在于： next，简写 n，逐行执行，会跳过函数。step，简写 s，逐行执行，会进入函数。
{next|step} {行数 n}，执行 n 行代码。
step 默认只会进入程序员编写的函数，不会进入 printf() 这样的底层函数。 因为 gcc -g 只会给程序员编写的代码添加调试信息，printf() 是不带调试信息的。 需要设置 set step-mode on 才可以进入 printf() 这样的底层函数。
调试函数 info functions，输出所有函数。
info functions {模糊函数名 str}，输出所有含有 str 的函数。
whatis {函数名}，打印函数的定义。
where，输出函数的调用栈。
backtrace，简写 bt，输出函数的调用栈。
输出顺序是从内到外，也就是从现在调试停住的位置，往上追溯一直到 main()。 输出的内容里包括，栈帧编号、内层是从哪个函数的哪一行代码进来的。
info frame，简写 i f，输出栈帧的信息。可以看到寄存器、上一层和下一层的栈帧、函数的参数。
frame {栈帧编号 n}，选择栈帧。 这个命令可以回到栈帧编号 n 对应的那个方法里面。然后，就可以看那个位置的相应的信息。 想回来的话 frame 0 就可以。
{up|down} {栈帧数量 n}，可以往上 n 层移动（往 main() 方向移动），或者往下 n 层移动（往调试停住的位置移动），默认一层。
call {函数名(变量)}，执行一下函数，打印结果。
print {函数名(变量)}，执行一下函数，打印结果。
finish，继续执行直到退出函数。
return {返回值}，不执行完，直接退出函数。可以设置返回值。
断点 break {行号 n}，简写 b，在第 n 行代码上打一个断点。 break {*(内存地址)}，在地址上打断点。 break {*(函数名)}，在函数名上打断点，函数名会指向内存地址。 tbreak {行号 n}，打一个临时断点。 info breakpoints，简写 info b 或者 i b，显示断点信息。
输出的内容里，最前面的 Num 是断点编号，Enb 表示断点是否启用，后面还有断点地址和在哪个方法里面。
continue，简写 c，运行到下一个断点。
ignore {断点编号} {次数 n}，忽略断点编号为 1 的断点 n 次。
catch {}，捕获断点。比如，catch syscall write，捕获系统调用 write。
condition {断点编号} {条件}，条件断点。比如 condition 1 x==5，x 等于 5 的时候停在断点编号为 1 的断点上。
condition {断点编号}，移除条件
{disable|enable} {断点编号}，{禁用|启用} 断点。
delete {断点编号}，删除断点。
watch {变量名}，添加观察断点，只要变量发生变化，就打印变化前后的值。
rwatch {变量名}，添加观察断点，只要对变量执行读操作就打印变量的数据。
awatch {变量名}，添加观察断点，只要对变量执行读写操作就打印变量的数据。
打印数据 print {expr}，简写 p，打印表达式的值，可以是变量，也可以是函数。
print {变量名}，打印变量。 print *(int *){内存地址}，把内存地址转换成 int * 类型，然后输出内存地址上的值。 print sizeof(变量)，打印变量的大小。 print {数组变量名}[{n}]@{m}，从数组下标 n 开始，打印 m 个元素。 ptype {变量名}，打印变量的类型。
set print address on/off，打不打印地址。 set print array on/off，打印数组的时候是不是竖着打。 set print array-indexes on/off，打印数组的时候带不带下标。 set print pretty on/off，打印结构体的时候有没有格式。 display {变量名}，打印变量。只要变量在当前运行的函数栈里面，每执行一条指令，就会打印一次所有在 display 里面的变量。
info display，查看所有在 display 里面的变量，会输出变量编号。
undisplay {变量编号}，取消打印变量。
输出内存地址上的数据 x/FMT address，格式化输出内存地址上的数据。
FTM 的格式可以理解成，{输出次数 n}{显示格式 f}{数据长度 s}。
输出次数，1 次输出 s 长度的数据，输出 n 次。
显示格式：x，16 进制；d，10 进制；t，2 进制；f，浮点数；a，地址；c，字符；s，字符串；
数据长度：b，字节；h(halfword)，半字，2 字节；w(word)，字，4 字节；g(giant)，双字，8 字节；
x/1xb 内存地址，从地址开始，以 16 进制打印 1 个字节。
x/1xb &amp;(变量名)，从变量的起始地址开始，以 16 进制打印 1 个字节。
x/s 字符串变量名，打印字符串。
FMT 的格式 print 和 display 也可以用。
汇编 disassemble，简写 disas，输出程序的汇编代码。 disassemble {函数名|内存地址}，也可以这么用。
&ldquo;-m&rdquo;，输出汇编和对应的源码
&ldquo;-r&rdquo;，输出汇编和对应的 16 进制机器码
{show|set} disassembly-flavor {风格}，{查看|设置}输出汇编代码的风格。风格有 att 和 intel。
{show|set} disassemble-next-line {on|off|auto}，反汇编下一行代码。
si，执行汇编一条指令。
info registers，简写 i r，查看寄存器的值，这里一般显示的是部分的。
info all-registers，查看所有寄存器的值。
info registers {寄存器名字}，输出寄存器的值
p {寄存器名字}，输出寄存器的值
layout {asm|regs|split|src}，显示汇编调试窗口，{汇编代码|寄存器+汇编代码|源码+汇编代码|源码}。
tui {reg all|float}，显示{所有的|浮点数}寄存器组。
============没整理
调试多进程 info inferiors 显示进程信息，还有编号，目前调试的进程，在编号前面会有个 * inferior 编号，切换进程
set follow-fork-mode parent/child 设置 fork 执行的时候跟踪父进程还是子进程，默认parent
这里需要注意的是，父子进程是同时执行的，调试父进程或者子进程的时候子进程或者父进程也在跑
set detach-on-fork on/off 调试一个进程的时候，其他的进程运不运行，默认是运行的
show/set schedule-multiple 这个也可以控制多进程是并发还是不并发
detach inferior 编号，分离进程 kill inferior 编号，kill 进程
多线程 info threads 显示线程信息，还有编号，目前调试的线程，在编号前面会有个 * thread 编号，切换线程
show/set schedule-locking on/off/step 调试一个线程的时候，其他的线程运不运行，默认是step暂停的，但是有特殊情况，这个可以看文档
thread apply all bt full 显示所有线程的局部变量
thread apply 线程编号 命令，可以让命令单独作用于某个线程
============
]]></content></entry><entry><title>关于</title><url>/about/</url><categories/><tags/><content type="html">帕里特档案馆（重建中），是个个人档案馆。
档案馆的内容主要是本人的学习笔记、对学到的东西的解释和思考、对实践过程的记录。 这些玩意本质上是当时的我给以后的我的留言。它们不是教程，更不是论文。
写它们的目的是，如果以后的我忘记了这块的内容，那么希望现在的我可以把以后的我教会。 如果访客您觉得毫无干货或者内容非常水，那么非常抱歉。
有一小部分笔记是整理过的可读性比较好的，一般是连贯完整的单独一篇或者连续几篇。 大部分笔记属于东一块西一块的，里面的内容有可能是断断续读的文本或者干脆就是关键词。
整理笔记很费事，为了说清楚内容，需要大量的时间梳理逻辑，梳理完之后还需要写文本。 如果某一块的内容需要的朋友比较多的话，我可能会抽时间整理出来。
本人能力有限，因此不能保证所有的内容的时效性和正确性。还请各位到访的访客务必小心。 本人能力有限，因此不能保证所有的内容的时效性和正确性。还请各位到访的访客务必小心。 本人能力有限，因此不能保证所有的内容的时效性和正确性。还请各位到访的访客务必小心。
站点基于 hugo 0.103.1 extended
搭建。 使用的主题是 Hugo NexT
。 部属在 github pages 上。
如果访客您发现我的内容有明显的问题或者错误，欢迎批评指正。同时也欢迎建设性意见。 我的交流方式，QQ：786907650；微信号：wxid_k3uqy9xeryn422。昵称和头像都是一样的，很好辨认。 有意交流者，请至少备注是谁和从哪来。</content></entry><entry><title>内存中的指令和数据</title><url>/post/computer-science/operating-system/memory/instruction_and_data/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>memory(内存)</tag></tags><content type="html"><![CDATA[前言 这篇笔记需要 elf、linux 进程的内存布局、gdb 调试相关的知识。
资料 笔记里的代码都在 {demo-c}/demo-in-linux/memory/ 目录下。
图在 memory.drawio.html 里面。
正文 内存地址 内存的存储单元会根据 CPU 的位宽以 16 进制从 0 开始顺序编号。 每个存储单元只对应一个编号，且只可以存储一个 byte 的数据。
32 位 CPU 最大的内存地址是 0xffffffff，容量为 2^32 字节 64 位 CPU 最大的内存地址是 0xffffffffffffffff，容量为 2^64 字节。
起始地址 起始地址（首地址、基地址、基址），指的是代码块（函数）或者数据（变量）所占内存空间的第一个存储单元的地址。
指令 这里的指令说的是代码块（函数）。函数的起始地址在编译时就已经确定了。
代码：instruction_in_memory.c
从 readelf -s 的结果里，找到代码块（methodA）的信息。 这里可以看到，代码块的起始地址是 0x1149，代码块的长度是 15。
Symbol table &#39;.symtab&#39; contains 37 entries: Num: Value Size Type Bind Vis Ndx Name 23: 0000000000001149 15 FUNC GLOBAL DEFAULT 16 methodA 然后，在 objdump -s 的结果里，找到起始地址的位置。 从起始地址开始的 15 个字节就是代码块对应的数据了。
Contents of section .text: 1140 ________ ________ __f30f1e fa554889 .....w.......UH. 1150 e5b80004 00005dc3 ________ ________ ......].....UH.. 起始地址也占了一个位置，所以计算结束地址的时候不是直接加代码块的大小。 起始地址为 0x1149，结束地址为 0x1157 = 起始地址（16） + (15-1)（10）
也就是 0x1149,0x114a,0x114b,0x114c,0x114d,0x114e,0x114f,0x1150,0x1151,0x1152,0x1153,0x1154,0x1155,0x1156,0x1157， 这 15 个地址上的数据。
可以再看一眼汇编代码，在 objdump -d 的结果里，找到起始地址的位置。 这里的数据和上面的 15 个字节的数据是一样的，这里详细的标注了每一个字节对应的汇编代码。
Disassembly of section .text: 0000000000001149 &lt;methodA&gt;: 1149:	f3 0f 1e fa endbr64 114d:	55 push %rbp 114e:	48 89 e5 mov %rsp,%rbp 1151:	b8 00 04 00 00 mov $0x400,%eax 1156:	5d pop %rbp 1157:	c3 ret gdb 调试 先打印一下代码块在程序中的起始地址，然后，打印从起始地址开始的 15 个地址上的数据。和上面一样的对吧。
(gdb) p methodA $1 = {int ()} 0x555555555149 &lt;methodA&gt; (gdb) x/15xb 0x555555555149 0x555555555149 &lt;methodA&gt;:	0xf3	0x0f	0x1e	0xfa	0x55	0x48	0x89	0xe5 0x555555555151 &lt;methodA+8&gt;:	0xb8	0x00	0x04	0x00	0x00	0x5d	0xc3 通过遍历也可以在程序里一个字节一个字节的打印代码块对应的内存地址上的内容。
&amp;methodA=0x56025d439149 [0x56025d439149]=fffffff3 [0x56025d43914a]=0f [0x56025d43914b]=1e [0x56025d43914c]=fffffffa [0x56025d43914d]=55 [0x56025d43914e]=48 [0x56025d43914f]=ffffff89 [0x56025d439150]=ffffffe5 [0x56025d439151]=ffffffb8 [0x56025d439152]=00 [0x56025d439153]=04 [0x56025d439154]=00 [0x56025d439155]=00 [0x56025d439156]=5d [0x56025d439157]=ffffffc3 这里打印 f3 出来 fffffff3 是因为符号扩展（sign extension），这里简单解释一下。 当 0xc3 被存储在 1 个字节的 char 变量中，被提升为 4 个字节的 int 或者被以十六进制打印时。 前面不是有三个字节的空位嘛，这个时候会扩展符号位以填充前面的空位，这样，就得到了 0xffffffc3。
数据 全局变量的起始地址在编译时就已经确定了。
代码：data_in_memory.c
从 readelf -s 的结果里，找到数据（globalI）的信息。 这里可以看到，数据的起始地址是 0x4010，数据的长度是 4。
Symbol table &#39;.symtab&#39; contains 37 entries: Num: Value Size Type Bind Vis Ndx Name 27: 0000000000004010 4 OBJECT GLOBAL DEFAULT 25 globalI 然后，在 objdump -s 的结果里，找到起始地址的位置。 从起始地址开始的 4 个字节就是代码块对应的数据了。
Contents of section .data: 4000 00000000 00000000 08400000 00000000 .........@...... 4010 00040000 起始地址为 0x4010，结束地址为 0x4013 = 起始地址（16） + 3（10）
也就是 0x4010,0x4011,0x4012,0x4013 这 4 个地址上的数据。
gdb 调试 这里和指令那里一样，先打印数据的起始地址，然后，打印地址上的数据。注意，数据在内存中是小端字节序。
(gdb) p &amp;globalI $3 = (int *) 0x555555558010 &lt;globalI&gt; (gdb) x/4xb 0x555555558010 0x555555558010 &lt;globalI&gt;:	0x00	0x04	0x00	0x00 和指令那里一样，也通过遍历也可以在程序里一个字节一个字节的打印数据对应的内存地址上的内容。
但是，要注意。对 int 类型进行取地址操作，拿到的是 int*。对 int* +1 会移动4个字节，这不是我们想要的。 如果想输出 int 类型的每个字节，首先需要将起始地址转换成 chat*，chat* +1 移动的就是 1 个字节了。
有意思的来了 如果在代码块里直接返回全局变量会怎么样呢。
代码：return_global.c
从 readelf -s 的结果里，找到代码块（methodA）和数据（globalI）的信息。
Symbol table &#39;.symtab&#39; contains 38 entries: Num: Value Size Type Bind Vis Ndx Name 23: 0000000000001149 16 FUNC GLOBAL DEFAULT 16 methodA 28: 0000000000004010 4 OBJECT GLOBAL DEFAULT 25 globalI 然后，我们看汇编代码，在 objdump -d 的结果里，找到代码块对应的汇编代码。
0000000000001149 &lt;methodA&gt;: 1149:	f3 0f 1e fa endbr64 114d:	55 push %rbp 114e:	48 89 e5 mov %rsp,%rbp 1151:	8b 05 b9 2e 00 00 mov 0x2eb9(%rip),%eax # 4010 &lt;globalI&gt; 1157:	5d pop %rbp 1158:	c3 ret globalI 是全局变量，methodA 的代码里直接返回了全局变量，这里的汇编代码，methodA 直接就用了 globalI 的地址。
栈 代码：stack.c
静态分配的内存在栈区，比如，函数里面的局部变量，每次执行的时候都不一样。
(gdb) p &amp;localI $1 = (int *) 0x7fffffffdeb4 (gdb) x/4xb 0x7fffffffdeb4 0x7fffffffdeb4:	0x00	0x04	0x00	0x00 7ffffffde000-7ffffffff000 rw-p 00000000 00:00 0 [stack] 可以和进程的内存信息比对一下。 0x7ffffffde000（栈堆首地址） &lt; 0x7fffffffdeb4（变量首地址） &lt; 0x7ffffffff000（栈堆尾地址）
堆 代码：heap.c
动态分配的内存在堆区，比如，给指针申请一块内存。
(gdb) p p7LocalJ $1 = (int *) 0x5555555596b0 (gdb) x/4xb 0x5555555596b0 0x5555555596b0:	0x00	0x08	0x00	0x00 555555559000-55555557a000 rw-p 00000000 00:00 0 [heap] 可以和进程的内存信息比对一下。 0x555555559000（堆首地址） &lt; 0x5555555596b0（变量地址） &lt; 0x55555557a000（堆尾地址）
指针 代码：pointer.c
首先定义一个变量，比如，定义一个 int 类型的。
(gdb) p &amp;localI $2 = (int *) 0x7fffffffdea4 (gdb) x/4xb 0x7fffffffdea4 0x7fffffffdea4:	0x00	0x04	0x00	0x00 二级指针
(gdb) p p7LocalI $4 = (int *) 0x7fffffffdea4 (gdb) p &amp;p7LocalI $3 = (int **) 0x7fffffffdea8 (gdb) x/8xb 0x7fffffffdea8 0x7fffffffdea8:	0xa4	0xde	0xff	0xff	0xff	0x7f	0x00	0x00 (gdb) p p7LocalII $5 = (int **) 0x7fffffffdea8 (gdb) p &amp;p7LocalII $6 = (int ***) 0x7fffffffdeb0 (gdb) x/8xb &amp;p7LocalII 0x7fffffffdeb0:	0xa8	0xde	0xff	0xff	0xff	0x7f	0x00	0x00 我画了个图，memory.drawio.html 2-2、代码的运行结果在内存里的结构，以及得到结果的过程
字符串 代码：string.c
&amp;strA=0x7fffffffdea0,strA=stringA &amp;strB=0x55555555601e,strB=stringB &amp;strB=0x555555556038,strB=stringBB &amp;strC=0x5555555596b0,strC=stringC 打印几个指针指向的地址，然后，结合 &ldquo;proc/{pid}/maps&rdquo; 看一下内存。
555555556000-555555557000 r--p 00002000 00:25 48 /mnt/hgfs/demo-c/demo-in-linux/memory/string.elf 555555559000-55555557a000 rw-p 00000000 00:00 0 [heap] 7ffffffde000-7ffffffff000 rw-p 00000000 00:00 0 [stack] strA 字符数组地址指向了栈，strB 指针两次都指向了 string.elf 文件，strC 字符数组地址指向了堆。
这里，因为是字符串，所以，可以直接在 objdump -s 命令输出的结果里面查找这几个字符串值。 这里直接说结论了，stringA 和 stringC 在 &ldquo;.text&rdquo; 段里面，stringB 和 stringBB 在 &ldquo;.rodata&rdquo; 段里面。 此外，在 &ldquo;.rodata&rdquo; 段里面，还可以看到很多写死在程序里的字符串。比如, 写在 printf() 里面的字符串。
stringA 和 stringC 这两个字符串只是初始化的时候长这样，底下真正对应的字符数组是可变的。
stringA 是一个字符数组的值，这个字符数组，存储在栈里面，编译的时候就知道有多大了。 存储在栈里面的字符数组是可变的，stringA 只用于初始化。
(gdb) p strA $1 = &#34;stringA\000\000\000\000\000\000\000\000&#34; (gdb) p &amp;strA $2 = (char (*)[16]) 0x7fffffffdea0 (gdb) x/16xb 0x7fffffffdea0 0x7fffffffdea0:	0x73	0x74	0x72	0x69	0x6e	0x67	0x41	0x00 0x7fffffffdea8:	0x00	0x00	0x00	0x00	0x00	0x00	0x00	0x00 同理 stringC 是一个字符数组的值，这个字符数组是程序运行的时候动态申请的内存，动态申请的内存在堆里面。 存储在堆里面的字符数组是可变的，stringC 只用于初始化。
stringB 和 stringBB 并没有开辟内存去存它们，程序运行起来之后，也没有办法去修改它们的值。所以，在编译的时候，就放到了只读数据段，也就是 &ldquo;.rodata&rdquo; 段。
Contents of section .rodata: 2000 01000200 7069643d 25640a00 26737472 ....pid=%d..&amp;str 2010 413d2570 2c737472 413d2573 0a007374 A=%p,strA=%s..st 2020 72696e67 42002673 7472423d 25702c73 ringB.&amp;strB=%p,s 2030 7472423d 25730a00 73747269 6e674242 trB=%s..stringBB 2040 00267374 72433d25 702c7374 72433d25 .&amp;strC=%p,strC=% 2050 730a006d 616c6c6f 635f7573 61626c65 s..malloc_usable 2060 5f73697a 65287374 7243293d 256c640a _size(strC)=%ld. 2070 00 malloc_usable_size(strC)=24 malloc_usable_size() 返回由 malloc() 或其他内存分配函数分配的内存块的大小。 由于内存对齐或者其他的因素，这个大小可能与传递给 malloc() 或其他内存分配函数的大小不同。
在示例代码 string.c 中使用 malloc() 分配了 8 个字节的内存来存储字符串 &ldquo;stringC&rdquo;。 但是，这里用 malloc_usable_size() 可以知道，malloc() 分配的内存块的实际大小是 24 字节。
这是因为，大多数内存分配函数是以内存块或内存页为单位进行分配的，通常比请求的大小大。 编译器也有可能会做一些优化，申请内存的时候多给的部分，在需要扩容的时候就可以直接用了。 不需要再通过系统调用去申请，可以减少系统调用的次数。
此外，一些内存分配函数可能会给内存块添加额外的元数据，以跟踪内存块的信息。 比如，调用 free() 函数的时候，只传了一个内存地址过去，它是怎么知道应该释放多大的内存的。
数组 代码：array.c
一维数组或者多维数组的变量都指向数组所占内存单元的起始地址。
555555559000-55555557a000 rw-p 00000000 00:00 0 [heap] 7ffffffde000-7ffffffff000 rw-p 00000000 00:00 0 [stack] 栈和堆就没啥好说的，直接声明的数组在栈里面，动态申请内存的数组是指针，指向堆。
(gdb) p &amp;a5I $2 = (int (*)[4]) 0x7fffffffde90 (gdb) x/16xb 0x7fffffffde90 0x7fffffffde90:	0x02	0x00	0x00	0x00	0x04	0x00	0x00	0x00 0x7fffffffde98:	0x08	0x00	0x00	0x00	0x10	0x00	0x00	0x00 (gdb) p &amp;a5J $3 = (int (*)[2][2]) 0x7fffffffdea0 (gdb) x/16xb 0x7fffffffdea0 0x7fffffffdea0:	0x20	0x00	0x00	0x00	0x40	0x00	0x00	0x00 0x7fffffffdea8:	0x80	0x00	0x00	0x00	0x00	0x01	0x00	0x00 通过观察内存可以发现，不管是 int[4] 还是 int[2][2]，在内存里都是连续的 16 个字节。
(gdb) p p7a5K $4 = (int (*)[4]) 0x5555555596b0 (gdb) x/16xb 0x5555555596b0 0x5555555596b0:	0x02	0x00	0x00	0x00	0x04	0x00	0x00	0x00 0x5555555596b8:	0x08	0x00	0x00	0x00	0x10	0x00	0x00	0x00 (gdb) p p7a5L $5 = (int (*)[2][2]) 0x5555555596d0 (gdb) x/16xb 0x5555555596d0 0x5555555596d0:	0x20	0x00	0x00	0x00	0x40	0x00	0x00	0x00 0x5555555596d8:	0x80	0x00	0x00	0x00	0x00	0x01	0x00	0x00 运行的时候动态分配的内存也是一样的，都是连续的 16 个字节。
(*p7a5L)[0]=0x56247f1946d0,p7l=0x56247f1946d0 (*p7a5L)[0][0]=32,&amp;(*p7a5L)[0][0]=0x56247f1946d0,p7ll+0=32,p7ll+0=0x56247f1946d0 (*p7a5L)[0][0]=64,&amp;(*p7a5L)[0][0]=0x56247f1946d4,p7ll+0=33,p7ll+0=0x56247f1946d4 (*p7a5L)[1]=0x56247f1946d8,p7l+1=0x56247f1946d8 (*p7a5L)[0][0]=128,&amp;(*p7a5L)[0][0]=0x56247f1946d8,p7ll+0=128,p7ll+0=0x56247f1946d8 (*p7a5L)[0][0]=128,&amp;(*p7a5L)[0][0]=0x56247f1946dc,p7ll+0=256,p7ll+0=0x56247f1946dc 指向数组的指针这里，需要关注的就不是内存了，而是指针移动的距离。 当指针声明为 (int(*)[2]) 的时候，指针 +1，移动的是 8 个字节，也就是一个 int[2] 的长度。 当指针声明为 (int *) 的时候，指针 +1，移动的是 4 个字节，也就是一个 int 的长度。
结构体 代码：struct.c
555555559000-55555557a000 rw-p 00000000 00:00 0 [heap] 7ffffffde000-7ffffffff000 rw-p 00000000 00:00 0 [stack] 栈和堆就没啥好说的，直接声明的结构体在栈里面，动态申请内存的结构体是指针，指向堆。 两个结构体里的 name 都是动态申请的内存，都指向堆。
sizeof(s6a)=16 &amp;s6a=0x7fffffffdeb0 &amp;s6a.name=0x7fffffffdeb0 s6a.name=0x5555555596b0 &amp;s6a.age=0x7fffffffdeb8 &amp;s6a.sex=0x7fffffffdebc 这里用 sizeof() 得出的结构体的大小是 16 个字节。但是，实际上加起来应该是 13 个字节。 声明的时候，结构体里面有三个字段，一个 &ldquo;char *&rdquo; 8 个字节，一个 int 4 个字节，一个 char 1 个字节。
这是因为编译器会使用填充和对齐来优化内存的使用和访问。 这会导致同一个 struct 在不同系统上的大小可能不同，这取决于不同系统上的数据类型的大小和对齐的规则。
在这里的情况是，struct 的大小是其最大字段的大小的倍数。 最大的字段是 &ldquo;char *&rdquo; 8 个字节，结构体一共需要 13 个字节。所以，分配给结构体的内存就是 16 个字节。
(gdb) x/16xb 0x7fffffffdeb0 0x7fffffffdeb0:	0xb0	0x96	0x55	0x55	0x55	0x55	0x00	0x00 0x7fffffffdeb8:	0x12	0x00	0x00	0x00	0x66	0x00	0x00	0x00 (gdb) x/16xb 0x5555555596b0 0x5555555596b0:	0x61	0x61	0x61	0x00	0x00	0x00	0x00	0x00 0x5555555596b8:	0x00	0x00	0x00	0x00	0x00	0x00	0x00	0x00 直接观察内存里从结构体首地址开始的 16 个字节。
最前面的 8 个字节，是小端字节序的，正过来就是 00 00 55 55 55 55 96 b0。 这就是 name 字段的地址 0x5555555596b0，前面的 0 被省略了。
然后是 4 个字节的 int。然后是 1 个字节的 char。最后 3 个字节填充的 0 用于对齐。
0x5555555596b0 上的 0x61 就是 a 的 ascii 码（10 进制是 97）。
sizeof(p7b)=8 p7b=0x5555555596d0 &amp;p7b-&gt;name=0x5555555596d0 p7b-&gt;name=0x5555555596f0 &amp;p7b-&gt;age=0x5555555596d8 &amp;p7b-&gt;sex=0x5555555596dc 这里因为是指针，所以 sizeof() 得出的大小是 8 个字节。
(gdb) x/16xb 0x5555555596d0 0x5555555596d0:	0xf0	0x96	0x55	0x55	0x55	0x55	0x00	0x00 0x5555555596d8:	0x12	0x00	0x00	0x00	0x66	0x00	0x00	0x00 (gdb) x/16xb 0x5555555596f0 0x5555555596f0:	0x62	0x62	0x62	0x00	0x00	0x00	0x00	0x00 0x5555555596f8:	0x00	0x00	0x00	0x00	0x00	0x00	0x00	0x00 和上面一样，直接观察内存里结构体指针指向的内存地址开始的 16 个字节。
最前面的 8 个字节，是小端字节序的，正过来就是 00 00 55 55 55 55 96 f0。 这就是 name 字段的地址 0x5555555596f0，前面的 0 被省略了。
然后是 4 个字节的 int。然后是 1 个字节的 char。最后 3 个字节填充的 0 用于对齐。
0x5555555596f0 上的 0x62 就是 b 的 ascii 码（10 进制是 98）。
]]></content></entry><entry><title>ELF</title><url>/post/computer-science/operating-system/linux/elf/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>elf</tag></tags><content type="html"><![CDATA[前言 前置笔记：程序实践的环境：同 程序资料 {demo-c}/demo-in-linux/elf/ 正文 elf 文件是什么文件 在 程序中提到过，c 源码文件通过 gcc 编译器编译可以得到可执行文件，这里的可执行文件就是 elf 文件的一种。 关于 elf 具体的细节可以看 &ldquo;elf(5) - format of Executable and Linking Format (ELF) files&rdquo;
elf(5) Amongst these files are normal executable files, relocatable object files, core files, and shared objects.
elf 文件格式有四种： 普通可执行文件（normal executable files）； 可重定位文件（relocatable object files）； 核心文件（core files）； 共享目标文件、共享库、动态库（shared objects）。
我在 {demo-c}/demo-in-linux/elf/ 目录下，准备了三个程序： symbol.c、0b_0_10_0x.c、address.c。分别用于讨论不同的问题。
elf 文件的内容 这里主要围绕 symbol.c 编译得到的 symbol.elf 文件。
先用 objdump 命令观察一下。 命令具体的输出放在 {demo-c}/demo-in-linux/elf/symbol_elf_objdump.md 里面。
然后，用 readelf 命令观察一下 symbol.elf。 关于 readelf 命令具体怎么用可以看 &ldquo;readelf(1) - display information about ELF files&rdquo;。
这里会用到 &ldquo;-h&rdquo;、&quot;-l&quot;、&quot;-S&quot;、&quot;-s&quot; 几个参数。 &ldquo;-h&rdquo; 表示输出 elf 文件头（elf header）；&quot;-l&quot; 表示输出 program headers； &ldquo;-S&rdquo; 表示输出段表（section headers）；&quot;-s&quot; 表示输出符号表。 命令具体的输出放在 {demo-c}/demo-in-linux/elf/symbol_elf_readelf.md 里面。
elf(5) The ELF header is always at offset zero of the file.
elf 文件头总是在文件的最前面，其他的数据都在后面。这很好理解，如果一个文件最前面不告我它是什么，我怎么知道它是什么。
分别解释一下。
&ldquo;-h&rdquo; 输出的 elf 文件头，这里截取了一些。
Data: 2&#39;s complement, little endian Type: DYN (Position-Independent Executable file) Machine: Advanced Micro Devices X86-64 Entry point address: 0x1060 Number of section headers: 31 Data：数据存储方式，这里是小端字节序（little endian）。 Type：elf 文件的类型，这里是可执行文件（Executable）。 Machine：机器架构，这里是 X86-64。 Entry point address：程序的入口地址。 操作系统在加载完可执行文件后，会把控制权转移给该程序，然后找到入口地址（这里就是 &ldquo;0x1060&rdquo;）开始运行程序。 Number of section headers：elf 段表的大小。 &ldquo;-S&rdquo; 输出 section headers（段表），这里截取了一些。
[Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 1] .interp PROGBITS 0000000000000318 00000318 000000000000001c 0000000000000000 A 0 0 1 [12] .init PROGBITS 0000000000001000 00001000 000000000000001b 0000000000000000 AX 0 0 4 [16] .text PROGBITS 0000000000001060 00001060 00000000000001d6 0000000000000000 AX 0 0 16 [18] .rodata PROGBITS 0000000000002000 00002000 0000000000000063 0000000000000000 A 0 0 8 [25] .data PROGBITS 0000000000004000 00003000 0000000000000018 0000000000000000 WA 0 0 8 [26] .bss NOBITS 0000000000004018 00003018 0000000000000010 0000000000000000 WA 0 0 4 [28] .symtab SYMTAB 0000000000000000 00003048 0000000000000408 0000000000000018 29 20 8 [29] .strtab STRTAB 0000000000000000 00003450 000000000000022c 0000000000000000 0 0 1 &ldquo;.interp&rdquo;：程序解释器（elf 解释器）的路径。 &ldquo;.init&rdquo;：进程初始化的代码。 &ldquo;.text&rdquo;：程序指令&ndash;&gt;指令码&ndash;&gt;机器码&ndash;&gt;二进制指令&ndash;&gt;cpu 指令（芯片层级的指令）。 &ldquo;.rodata&rdquo;：只读数据（如：数字常量，字符串常量）。 &ldquo;.data&rdquo;：已经给值的全局变量、静态变量、局部变量。 &ldquo;.bss&rdquo;：未初始化的全局变量、静态变量、局部变量。 &ldquo;.symtab&rdquo;：符号表。和 &ldquo;.strtab&rdquo; 段一起用。 &ldquo;.strtab&rdquo;：字符串符号表（变量名、函数名）。 &ldquo;.debug&rdquo;：调试信息，编译的时候带 &ldquo;-g&rdquo; 参数的时候就会有这一段。 其他的段的解释详见 linux 文档 elf(5)。 &ldquo;-s&rdquo; 输出的符号表，这里截取了 symbol.c 代码里直接出现的几个。
Num: Value Size Type Bind Vis Ndx Name 12: 0000000000004014 4 OBJECT LOCAL DEFAULT 25 staticIntB.1 13: 0000000000004020 4 OBJECT LOCAL DEFAULT 26 staticIntA.0 26: 000000000000401c 4 OBJECT GLOBAL DEFAULT 26 globalIntA 27: 0000000000001149 54 FUNC GLOBAL DEFAULT 16 functionA 28: 00000000000011b5 54 FUNC GLOBAL DEFAULT 16 functionC 36: 00000000000011eb 75 FUNC GLOBAL DEFAULT 16 main 38: 0000000000004010 4 OBJECT GLOBAL DEFAULT 25 globalIntB 40: 000000000000117f 54 FUNC GLOBAL DEFAULT 16 functionB 数据存储方式 数据存储方式有两种：小端字节序（little endian）和大端字节序（big endian）。 小端字节序又叫主机字节序，大端字节序又叫网络字节序。
上面 readelf -h 命令的结果里面，在 Data 字段里可以看见 &ldquo;little endian&rdquo;。 意思就是在 symbol.elf 里面，数据的存储格式是小端字节序。下面来验证一下这个结论。
在 symbol.c 的源码里面，全局变量 globalIntB 是一开始就明确的给了值的。 在 readelf -s 命令输出的符号表里，找到 globalIntB 在的那一行。 然后，就可以知道到 globalIntB 对应的内存地址是 0x4010。
在 objdump -s 命令输出的结果里面，找到内存地址 0x4010，地址上存储的就是全局变量 globalIntB 的数据。 内存地址 0x4010 在 &ldquo;.data&rdquo; 段里面，这里截取一下 &ldquo;.data&rdquo; 段的内容。
Contents of section .data: 4000 00000000 00000000 08400000 00000000 .........@...... 4010 2c010000 0a000000 ,....... 因为源码里面 globalIntB 是 int 类型的，int 类型的长度是 4 个字节。 所以，globalIntB 的数据就对应从 0x4010 地址开始的 4 个字节的数据。也就是 &ldquo;2c010000&rdquo; 这一段。
源码里面 globalIntB 初始化的时候是 300。 10 进制的 300 用 16 进制表示就是 0x12c，补全 4 个字节就是 &ldquo;00 00 01 2c&rdquo;。 但是，这里可以看到内存上的数据是 &ldquo;2c 01 00 00&rdquo;，是反的。这就是因为这里用的是小端字节序。
c 语言的 int 变量由 4 个字节组成，每个字节由 8 个 bit 位组成。 把 10 进制的 300 转换成 2 进制就是 &ldquo;00000000 00000000 00000001 00101100&rdquo;，左边定义为高位，右边定义为低位。 小端字节序的存储格式是把数据的低位放在内存低位上，而内存的排布是从低位到高位的。 所以，就变成了 &ldquo;00101100 00000001 00000000 00000000&rdquo;，转换成 16 进制就是 &ldquo;2c 01 00 00&rdquo;。
关于进制的问题，我放了一个示例代码，0b_0_10_0x.c。
通过 size 命令可以查看文件中各段及其总和的大小，单位是字节。 关于 size 命令具体怎么用可以看 &ldquo;size(1) - list section sizes and total size of binary files&rdquo;。
这里观察一下 symbol.elf 文件。
&gt; size demo02 text	data	bss	dec	hex	filename 1786	608	16	2410	96a	symbol.elf text，代码段，通常是指用来存放程序执行代码的一块内存区域。 data，数据段，通常是指用来存放程序中已初始化的全局变量的一块内存区域。数据段属于静态内存分配。 bss，通常是指用来存放程序中未初始化的全局变量的一块内存区域。bss 段属于静态内存分配。 默认情况下，段的大小是以十进制的方式来展示。 程序的入口地址 从 objdump -s 命令输出的结果里可以知道 symbol.elf 程序的入口地址是 0x1060。 然后在 objdump -s 命令输出的结果里面。找到 &ldquo;.text&rdquo; 段，然后找到地址 0x1060 对应的数据。 这里截取了 &ldquo;.text&rdquo; 段前三行的内容。
Contents of section .text: 1060 f30f1efa 31ed4989 d15e4889 e24883e4 ....1.I..^H..H.. 1070 f0505445 31c031c9 488d3d6c 010000ff .PTE1.1.H.=l.... 1080 15532f00 00f4662e 0f1f8400 00000000 .S/...f......... 左边第 1 列是虚拟地址；中间的 4 列是指令码；最右边 1 列是 ASCII 码。 &ldquo;0x1060&rdquo; 是起始地址；&ldquo;f30f1efa&rdquo; 是起始指令；指令是 16 进制的：&ldquo;0xf3 0x0f 0x1e 0xfa&rdquo;；大小为 4 个字节。 在 objdump -d 命令输出的结果中，可以找到对应的汇编代码。 这里截取了程序的入口地址对应的部分。通过虚拟地址的值和指令的值可以对应起来。
0000000000001060 &lt;_start&gt;: 1060:	f3 0f 1e fa endbr64 1064:	31 ed xor %ebp,%ebp 1066:	49 89 d1 mov %rdx,%r9 1069:	5e pop %rsi 106a:	48 89 e2 mov %rsp,%rdx 106d:	48 83 e4 f0 and $0xfffffffffffffff0,%rsp 1071:	50 push %rax 1072:	54 push %rsp 1073:	45 31 c0 xor %r8d,%r8d 1076:	31 c9 xor %ecx,%ecx 1078:	48 8d 3d 33 01 00 00 lea 0x133(%rip),%rdi # 11b2 &lt;main&gt; 107f:	ff 15 53 2f 00 00 call *0x2f53(%rip) # 3fd8 &lt;__libc_start_main@GLIBC_2.34&gt; 1085:	f4 hlt 1086:	66 2e 0f 1f 84 00 00 cs nopw 0x0(%rax,%rax,1) 108d:	00 00 00 &ldquo;_start&rdquo; 是函数名。因为 &ldquo;0x1060&rdquo; 是起始地址，所以 &ldquo;_start&rdquo; 函数，就是这个程序的入口函数。 它在调用 main 函数之前，会做一些前期的准备工作。编程语言的 main 函数一般不是程序的入口函数。 大部分入口函数都是类似 &ldquo;_start&rdquo; 函数这样的，而且不同的语言在初始化阶段会有各自的处理逻辑。
这里最右边的汇编代码是 ATT 格式的汇编语法，汇编语法有 intel 格式和 ATT 格式，ATT 格式主要用于 unix/linux 系统。 使用命令 objdump -d -M intel symbol.elf 就可以输出 intel 格式的汇编代码。
符号表 通过命令 readelf -s 可以输出符号表。 这里截取了 &ldquo;_start&rdquo; 对应的数据和 symbol.elf 代码里直接出现的几个。
Num: Value Size Type Bind Vis Ndx Name 12: 0000000000004014 4 OBJECT LOCAL DEFAULT 25 staticIntB.1 13: 0000000000004020 4 OBJECT LOCAL DEFAULT 26 staticIntA.0 26: 000000000000401c 4 OBJECT GLOBAL DEFAULT 26 globalIntA 27: 0000000000001149 54 FUNC GLOBAL DEFAULT 16 functionA 28: 00000000000011b5 54 FUNC GLOBAL DEFAULT 16 functionC 34: 0000000000001060 38 FUNC GLOBAL DEFAULT 16 _start 36: 00000000000011eb 75 FUNC GLOBAL DEFAULT 16 main 38: 0000000000004010 4 OBJECT GLOBAL DEFAULT 25 globalIntB 40: 000000000000117f 54 FUNC GLOBAL DEFAULT 16 functionB 这里用 globalIntB 举例，globalIntB 在源码中是个全局 int 变量，初始化为 300。
Name（符号名）：globalIntB Ndx（段 id）：25，表示符号属于第 25 段。结合段表，第 25 段是 &ldquo;.data&rdquo; 段。第 26 段是 &ldquo;.bss&rdquo; 段。 Type（类型）：OBJECT，表示是个对象。如果是 FUNC，就表示是个函数 Bind（绑定范围）：GLOBAL，表示全局。 Value（地址）：0x0000000000004010。 这里结合 &ldquo;.data&rdquo; 段的数据。 globalIntB 的数据保存在地址从 0x4010 开始往后的 4 个字节上，也就是上面的 &ldquo;2c010000&rdquo;，值就是 300。
命令 nm 也可以输出符号表。关于 gcc 命令具体怎么用可以看 &ldquo;nm(1) - list symbols from object files&rdquo;。 nm 命令输出的内容在文件 {demo-c}/demo-in-linux/elf/symbol_elf_nm.md 中。
使用符号表的地址直接访问数据 在程序中可以直接使用符号表中的 Value 值去访问对应的内存数据。 同样的源文件，每次编译得到的符号表的地址是一样的。 如果只是修改了某个变量的值，没有大规模的修改代码的话，重新编译的时候，变量的地址一般也是不会变得。 可以通过这种方式验证这个结论。
示例代码：address.c。不过，在 ubuntu 22.04 中，这种方式无效。
进程虚拟地址空间映射 需要注意的是，在上面的输出中，与地址有关的数据，都不是程序跑起来的时候，在内存中真正的地址。 程序在进程里跑起来的时候，操作系统会把真正的内存地址和 elf 文件中的虚拟地址做映射。
文件的权限 读写执行权限 在命令行中，使用 ls -l 命令，就可以看到文件的权限。
&gt; ls -l -rwxrwxrwx 1 root root 607 6月 10 19:16 symbol.c -rwxrwxrwx 1 root root 16216 6月 10 19:24 symbol.elf 第一列是文件的权限，第三列是文件的所有者，第四列是文件的所有群组。 这里以 &ldquo;-rwxrwxrwx&rdquo; 为例：第一位表示文件的类型；第 2~4 位分别表示 user 的读、写、执行权限； 第 5~7 位分别表示 group 的读、写、执行权限；第 8~10 位分别表示 other 的读、写、执行权限。
&ldquo;-rwxrwxrwx&rdquo; 表示：所有的用户都拥有这个文件的读、写、执行权限。 如果是 &ldquo;-rwxr-xr-x&rdquo;，则表示：user 有读、写、执行权限，而 group 和 other 只有读、执行权限，没有写权限。
特权权限 &ldquo;/etc/shadow&rdquo; 文件用于记录 linux 上所有用户的账号和密码。 只有超级管理员有读写权限，普通用户是没有读写权限的。
但是，没有写权限的普通用户却可以通过 passwd 命令修改自己的密码。 这是因为 passwd 命令对应的 &ldquo;/bin/passwd&rdquo; 文件的权限是 &ldquo;-rwsr-xr-x&rdquo;。
# /etc/shadow -rw-r----- 1 root shadow 1462 2月 6 12:38 shadow # /bin/passwd -rwsr-xr-x 1 root root 59976 11月 24 20:05 passwd 可以注意到 user 的执行权限位上是 s，这称为特权权限（Set User ID，SUID）。 如果 group 的执行权限位上是 s，就是（Set Group ID，SGID）。 文件所有者可以通过 chmod u+s 命令设置特权权限。有特权权限的文件通过 ls 命令看的时候是红色的。
在程序中，可以通过 getuid() 获取用户 id，通过 geteuid() 获取有效用户 id。 通过 setuid() 设置用户 id，通过 seteuid() 设置有效用户 id。
如果是文件的所有者，那么 getuid() 和 geteuid() 得到的结果是一样的。 如果不是文件的所有者，那么 geteuid() 就能拿到文件的所有者的 id。
如果文件所有者设置了特权权限，那么其他用户调用 seteuid() 并传入文件的所有者的 id 的时候，就可以拥有文件所有者的权限。 想要改回来，可以调用 seteuid() 并传入自己的有效用户 id，这样就没有文件所有者的权限了。
一般来说，程序主要是以普通用户运行的，以较低的权限执行程序，可以保证安全性。 但是，有时需要操作一些比较重要的数据，这个时候就需要提权。
提权后，可以短暂地拥有该可执行文件所有者的权限，然后就可以修改数据了。 特别需要注意的是，使用完之后一定要降权。
代码示例：{demo-c}/demo-in-linux/elf/setuid.c
]]></content></entry><entry><title>程序</title><url>/post/computer-science/operating-system/program/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag></tags><content type="html"><![CDATA[前言 实践的环境：
amd64（x86_64） windows 11 vmware workstation pro 16 ubuntu 22.04 linux version 5.19.0-41-generic gcc version 11.3.0 资料 {demo-c}/demo-in-linux/program/ 正文 什么是程序 程序是计算机可以执行的一条或者一组指令，不管怎样，程序最终要在计算机物理硬件上跑起来的。
程序有很多种形态：计算机可以直接执行，但是，不方便开发人员阅读和处理的二进制机器码是程序； 计算机不能直接执行，但是，方便开发人员阅读和处理的由各种编程语言编写的源代码也是程序。
程序还有一种特别的形态，即由各种编程语言编写的源代码编译出来的可执行文件。 比如：windows 系统中 exe 可执行文件；linux 系统中的 elf 可执行文件。
那么问题来了，程序有这么多种形态，它们之间是怎么能正确的相互转化的？ 答案是，通过抽象，而且是好多层的抽象。因为分类方式不同，会有不同的分层，所以下面说的，都是我的理解。
首先是，最上面的应用软件层和最下面的物理硬件层。 这两层比较好理解，应用软件层就是我们使用的各式各样的应用程序，物理硬件层就是这些应用程序最终运行时所依托的计算机物理硬件。
那么，中间有几层呢？这里不一定，我目前把中间分成 3 层。 操作系统肯定有一层，这个也好理解，我们使用计算机的时候都需要先安装一个操作系统。然后，在操作系统里面安装我们需要的应用程序。
一般来说，开发人员开发的应用程序是不能直接操作操作系统的，使用的是操作系统提供的系统接口。 开发人员通过操作系统提供的系统接口实现应用程序的功能。所以，这里有一层。
同理，开发人员开发的操作系统也是不能直接操作物理硬件的，使用的是物理硬件提供的固件接口。 固件是指嵌入硬件设备中的软件，开发人员通过固件接口开发操作系统。所以，这里也有一层。
从源代码到可执行文件 对于应用软件的开发人员来说，一般都是基于操作系统进行开发的。所以，我这里的讨论，到操作系统就为止了。 不是说下层就不重要了，而是由于抽象层的存在，我们可以规避掉下层茫茫多的细节，专心讨论上层的问题。
上面提到过，开发人员开发的应用程序，使用的是操作系统提供的系统接口。系统接口也叫系统调用（system call）。 这个玩意，现在就解释有点太早了，在 运行 ELF 文件这篇里面会详细的说。
实践的环境 这里，我借助 linux 系统和 c 语言来讨论这个问题。我这里实践的环境如下。 cpu 是 amd64（x86_64）架构，操作系统是 windows 11。这个可以通过 systeminfo 命令查看。
然后，在 windows 中，使用 vmware workstation pro 16，搭建 ubuntu 22.04 虚拟机。 ubuntu 22.04 的 linux 版本是 linux version 5.19.0-41-generic。这个可以通过 cat /proc/version 命令查看。
然后，在 linux 中安装 gcc 编译器，版本是 gcc version 11.3.0 (ubuntu 11.3.0-1ubuntu1~22.04)。
在 Linux 中使用 C 语言进行编程的注意点编译 可执行文件是操作系统提供的对于程序的抽象，内容包括程序指令和程序数据。 程序指令就是前面说过的指令集里面的指令，程序数据就是二进制的数据。 按照操作系统提供的对于程序的抽象编写出来的程序，操作系统才看得懂。
可执行文件就相当于一个操作手册，操作手册上记录了每一步要干什么。 手册上是用文字描述要干什么的，实际操作的时候，是一个个具体动作，指令集记录的就是文字描述和具体动作的对应关系。 操作系统拿着操作手册，再对照指令集，就可以知道需要在硬件系统上做什么具体动作。
想从源代码变成可执行文件，通常要进行编译。 在 linux 系统中就是，c 源码文件通过 gcc 编译器的编译得到 elf 可执行文件。 在 windows 系统中就是，c 源码文件通过 gcc 编译器的编译得到 exe 可执行文件。这里讨论的是在 linux 系统中的情况。
通常使用 gcc 命令 gcc xxx.c -o xxx 一步就完成了。但是，这一步里面其实有四个步骤：预处理、编译、汇编、链接。 关于 gcc 命令具体怎么用，可以看 &ldquo;gcc(1) - GNU project C and C++ compiler&rdquo;。
这里会用到 &ldquo;-E&rdquo;、&quot;-S&quot;、&quot;-c&quot;、&quot;-o&quot; 这几个参数。 &ldquo;-E&rdquo; 表示会进行预处理；&quot;-S&quot; 表示会进行预处理、编译，得到汇编代码； &ldquo;-c&rdquo; 表示会进行预处理、编译、汇编，得到可重定位文件；&quot;-o&quot; 表示指定目标名称； 如果什么参数都不写，那就会预处理、编译、汇编、链接一步到位，得到可执行文件。
预处理（preprocessing）：gcc -E xxx.c -o xxx.i，预处理器会在源码的基础上增加一些代码。 编译（compilation）：gcc -S xxx.i -o xxx.s，编译器通过编译代码（词法分析、语法分析等）得到汇编代码。 汇编（assemble）：gcc -c xxx.s -o xxx.o，汇编器把汇编代码转化为机器指令，这一步得到的是可重定位文件。 链接（link）：gcc xxx.o -o xxx.elf，连接器把各个模块链接起来，组织成为可执行文件。 在链接中，会把函数的名字和变量的名字都称为符号（symbol）。源代码中的函数的名字和变量的名字，无论长度多少，最终都会转换为符号。
我在 {demo-c}/demo-in-linux/program/ 目录准备了五个文件。 hello_world.c、hello_world.i、hello_world.s、hello_world.o、hello_world.elf。 分别对应上面的源码文件，还有每个命令执行之后生成的文件。
编译过程产生的几个文件 首先，我们使用 file 命令，依次看一下这 5 个文件的文件类型。 关于 file 命令具体怎么用，可以看 &ldquo;file(1) - determine file type&rdquo;。
&gt; file hello_world.c hello_world.c: C source, ASCII text, with CRLF line terminators &gt; file hello_world.i hello_world.i: C source, ASCII text &gt; file hello_world.s hello_world.s: assembler source, ASCII text &gt; file hello_world.o hello_world.o: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped &gt; file hello_world.elf hello_world.elf: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=6d49e18a785eb53d246ca89c5dbce54472ed1584, for GNU/Linux 3.2.0, not stripped 这里解释一下。 hello_world.c 和 hello_world.i 都是 c 源码文件（C source）； hello_world.s 是汇编源码文件（assembler source）； hello_world.o 是可重定位文件（relocatable）； hello_world.elf 是可执行文件（executable）。
特别注意一下 hello_world.elf，它的内容有点多的。 &ldquo;dynamically linked&rdquo; 表示它是动态链接的。 &ldquo;interpreter /lib64/ld-linux-x86-64.so.2&rdquo; 表示它有一个解释器，解释器的路径是 &ldquo;/lib64/ld-linux-x86-64.so.2&rdquo;。 这两个玩意，现在就解释有点太早了，在 运行 ELF 文件这篇里面会详细的说。
这里，再用 objdump 命令观察一下 hello_world.o 文件的具体内容。 关于 objdump 命令具体怎么用。可以看 &ldquo;objdump(1) - display information from object files&rdquo;
这里会用到 &ldquo;-h&rdquo;、&quot;-s&quot;、&quot;-d&quot; 这几个参数。 &ldquo;-h&rdquo; 表示输出段表；&quot;-s&quot; 表示输出段表中每个段的详细内容；&quot;-d&quot; 表示输出 &ldquo;.text&rdquo; 段对应的汇编代码。 命令的输出我放在 {demo-c}/demo-in-linux/program/ 目录的 hello_world_objdump.md 文件内。
分别解释一下。
命令输出的结果的第一行都是 hello_world.o: file format elf64-x86-64，这个是文件的类型。
&ldquo;-h&rdquo; 输出的段表。
&ldquo;.text&rdquo; 是代码段，它用于存储程序指令（程序的代码）； &ldquo;.data&rdquo;、&quot;.bss&quot;、&quot;.rodata&quot; 都是数据段，它们用于存储程序数据； &ldquo;.bss&rdquo; 是未初始化数据段；&quot;.rodata&quot; 是只读数据段； &ldquo;-s&rdquo; 输出的段表中每个段的详细内容。这里截取了 &ldquo;.text&rdquo; 段。
Contents of section .text: 0000 f30f1efa 554889e5 488d0500 00000048 ....UH..H......H 0010 89c7e800 000000b8 00000000 5dc3 ............]. 左边第 1 列是虚拟地址，表示内存偏移量。 中间的 4 列是指令码，表示程序指令的内容（16 进制机器指令）。 最右边 1 列是 ASCII 码，是程序指令的 ASCII 文本。 &ldquo;-d&rdquo; 输出的 &ldquo;.text&rdquo; 段对应的汇编代码。
Disassembly of section .text: 0000000000000000 &lt;main&gt;: 0:	f3 0f 1e fa endbr64 4:	55 push %rbp 5:	48 89 e5 mov %rsp,%rbp 8:	48 8d 05 00 00 00 00 lea 0x0(%rip),%rax # f &lt;main+0xf&gt; f:	48 89 c7 mov %rax,%rdi 12:	e8 00 00 00 00 call 17 &lt;main+0x17&gt; 17:	b8 00 00 00 00 mov $0x0,%eax 1c:	5d pop %rbp 1d:	c3 ret &ldquo;Disassembly of section .text&rdquo;，表示程序指令的内容，以及对应的汇编代码。这里和 &ldquo;-s&rdquo; 输出的结果对应。 上面 &ldquo;-s&rdquo; 输出的结果里的 &ldquo;Contents of section .text&rdquo; 里，第一行第二段的 &ldquo;f30f1efa&rdquo;，就对应这里的 &ldquo;0: f3 0f 1e fa&rdquo;。 下面一行的 &ldquo;4: 55&rdquo; 和后面的 &ldquo;push %rbp&rdquo;，就表示 &ldquo;55&rdquo;（0x55）反汇编后对应的汇编指令就是 &ldquo;push %rbp&rdquo;。
然后，再用 objdump 命令观察一下 hello_world.elf 文件。命令的输出也放在 hello_world_objdump.md 文件里面。 这里可以看到，hello_world.elf 的内容是比 hello_world.o 要多出不少的。
而且，通过 hello_world.elf 的内容，我们可以发现。
第一点：hello_world.elf 的 &ldquo;.text&rdquo; 段的第一个函数不是 main 函数，而是 &ldquo;_start&rdquo; 函数。 &ldquo;_start&rdquo; 函数会调用 &ldquo;__libc_start_main&rdquo; 函数进行一些必要的初始化操作，然后再调用 main 函数。 也就是说，main 函数并不是程序的入口。
第二点：一个简单的 hello world 程序没有看上去的那么简单。
可执行文件 关于 elf 可执行文件的详细的内容。我放到这篇里面去了。 ELF 文件程序的运行过程是怎样的 关于 elf 可执行文件的运行过程的详细的内容。我放到这篇里面去了。 运行 ELF 文件]]></content></entry><entry><title>动态链接和静态链接</title><url>/post/computer-science/operating-system/dynamically_statically_linked/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>linux</tag><tag>c-programming-language</tag></tags><content type="html"><![CDATA[前言 实践的环境：
amd64（x86_64） windows 11 vmware workstation pro 16 ubuntu 22.04 linux version 5.19.0-41-generic gcc version 11.3.0 前置笔记：运行 ELF 文件资料 {demo-c}/demo-in-linux/program/ {demo-c}/demo-in-linux/dynamically-statically-linked/ 正文 动态链接 &gt; file hello_world.elf hello_world.elf: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=6d49e18a785eb53d246ca89c5dbce54472ed1584, for GNU/Linux 3.2.0, not stripped 之前我们通过 file 命令查看 hello_world.elf 的文件类型时说过，它是 &ldquo;dynamically linked&rdquo; 的，也就是动态链接的。 如果一个 elf 可执行文件是动态链接的。那么，它必定有一个解释器，这个解释器就是 linux 动态链接器。 在这里就是 &ldquo;interpreter /lib64/ld-linux-x86-64.so.2&rdquo; 这一段。interpreter 就是解释器的意思，后面的是解释器的路径。
有的时候动态链接的信息可以从 file 命令的结果里可以直接看见。 如果没有的话，也可以通过 readelf 命令，从 elf 文件的 program headers 中找到。 这里截取了 readelf 命令的输出中关于解释器的那一部分。
Program Headers: Type Offset VirtAddr PhysAddr FileSiz MemSiz Flags Align INTERP 0x0000000000000318 0x0000000000000318 0x0000000000000318 0x000000000000001c 0x000000000000001c R 0x1 [Requesting program interpreter: /lib64/ld-linux-x86-64.so.2] 前面我们也提到过 &ldquo;.interp&rdquo; 段（上面的 INTERP）里面，存的就是程序解释器（elf 解释器）的路径。
这里的就是这个 &ldquo;interpreter: /lib64/ld-linux-x86-64.so.2&rdquo;，它就是 linux 动态链接器。 它的功能是，把 elf 程序所依赖的动态库（共享库）加载并初始化。
如果 elf 可执行程序的类型是动态链接的话，那么这个程序加载到内存运行时，操作系统会把控制权先交给动态链接器。 动态链接器加载完该程序所依赖的动态库并初始化相应的必要操作后，才会把控制权交给程序的入口地址。 如果这个程序没有 &ldquo;.interp&rdquo; 段，就会直接从程序的入口地址直接执行。
也就是说，linux 在使用 execve() 加载程序时。不管 elf 文件的具体类型是什么。 只要检测出含有 &ldquo;.interp&rdquo; 段，那么，linux 就会先运行动态链接器。 动态链接器运行完之后，才会将控制权交给 elf 程序的入口地址。
可以通过 ldd 命令查看文件依赖的动态库。 关于 ldd 命令具体怎么用，可以看 &ldquo;ldd(1) - print shared object dependencies&rdquo;。
&gt; ldd hello_world.elf linux-vdso.so.1 (0x00007fffafdd6000) libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f6d35e00000) /lib64/ld-linux-x86-64.so.2 (0x00007f6d3620c000) &ldquo;/lib64/ld-linux-x86-64.so.2&rdquo; 就是动态链接器。 通过 file /lib64/ld-linux-x86-64.so.2 命令，可以查看它的文件类型。
结果是：&quot;/lib64/ld-linux-x86-64.so.2: symbolic link to /lib/x86_64-linux-gnu/ld-linux-x86-64.so.2&quot; 其中 &ldquo;symbolic link to&rdquo; 表示它是个软链接。链接到的 &ldquo;ld-linux-x86-64.so.2&rdquo; 是个特殊的共享库文件，因为它可以执行。
&ldquo;/lib/x86_64-linux-gnu/libc.so.6&rdquo; 就是依赖的动态库。它是 c 的运行库，封装了很多操作系统的接口。 libc.so.6 是 GNU c 库（glibc）的一个重要组成部分，是大多数 linux 发行版使用的标准 c 库。
linux 系统中，c 库的命名规则通常遵循 libc.so.&lt;版本&gt; 的模式，libc.so.6 就表示它是 c 库的第 6 版。
动态库允许多个程序在内存中共享同一实例，减少内存消耗，并使动态库的更新变得容易，而不需要重新编译所有依赖它的程序。 这样程序就可以以模块的形式独立开发，并且方便后续的维护和升级。
动态库的查找路径：&quot;/usr/lib&quot;、&quot;/usr/lib64&quot; 存储的是操作系统的共享库； &ldquo;/usr/local/lib&rdquo;、&quot;/usr/local/lib64&quot;存储的是第三方的共享库。
&ldquo;linux-vdso.so.1&rdquo;，它是比较特殊的一个共享库，它不在文件系统中，而是在内核中。 详细的可以看：&ldquo;vdso(7) - overview of the virtual ELF dynamic shared object&rdquo;。
编写和使用动态库 我在 &ldquo;{demo-c}/demo-in-linux/dynamically-statically-linked/&rdquo; 目录下准备了样例代码。
dynamically_library.c 是动态库本体。里面准备了一个 print_hello_world()。 编码完成后使用 gcc -fPIC -shared dynamically_library.c -o dynamically_library.so 命令，编译成动态库。
动态库一般有两种使用方式：编译时链接动态库（写代码的时候引入头文件，头文件里面是声明和定义）；程序中显示调用动态库。
首先是编译时使用动态库，我们在 use_when_gcc.c 里面直接声明然后调用 print_hello_world()。 这个时候直接使用 gcc 编译肯定是不行的，因为标准库里面没有 print_hello_world()。
需要使用 gcc use_when_gcc.c ./dynamically_library.so -o use_when_gcc.elf 命令，在编译时连接动态库。
在程序中显示调用动态库比较麻烦，需要借助几个系统调用：dlopen()、dlsym()。代码在 use_in_code.c 里面。 这个编译的时候这样写 gcc use_in_code.c -ldl -o use_in_code.elf，不需要连接动态库。
静态链接 如果通过 file 命令查看静态链接的 elf 可执行文件的话，结果中会有 &ldquo;statically linked&rdquo;。 静态链接的程序，会直接从程序的入口地址开始执行。
我这里准备了 2 个文件，statically_library.c、statically_use.c
// statically_library.c int returnVal (int v){ return v; } // statically_use.c #include &lt;stdio.h&gt; int main() { returnVal(1); return 0; } 使用 gcc 先将两个文件编译成可重定位文件。 gcc -c statically_library.c -o statically_library.o。 gcc -c statically_use.c -o statically_use.o。
编译 statically_use.c 的时候会报错，这个忽略就好，这玩意肯定是有问题的。
statically_use.c: In function ‘main’: statically_use.c:4:3: warning: implicit declaration of function ‘returnVal’ [-Wimplicit-function-declaration] 4 | returnVal(1); | ^~~~~~~~~ 这个时候我们使用 objdump 命令分别看一下 statically_library.o 和 statically_use.o。 这里截取了 &ldquo;.text&rdquo; 段的内容，要和下面 statically_call.elf 的对比着看的。
&gt; objdump -s statically_library.o Contents of section .text: 0000 f30f1efa 554889e5 897dfc8b 45fc5dc3 ....UH...}..E.]. &gt; objdump -s statically_use.o Contents of section .text: 0000 f30f1efa 554889e5 bf010000 00b80000 ....UH.......... 0010 0000e800 000000b8 00000000 5dc3 ............]. 然后，这里用的不是 gcc 了，用的是静态链接器 ld，用 gcc 的时候，它会自动调用 ld。 链接 statically_library.o 和 statically_use.o 并设置程序入口为 main。 ld statically_library.o statically_use.o -e main -o statically_call.elf。
这个时候就得到了一个 elf 可执行文件。这玩意跑不起来，因为除了这两段代码别的啥都没有。 用 file 命令看一下，可以看到输出的结果里面有 &ldquo;statically linked&rdquo;。
&gt; file statically_call.elf statically_call.elf: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, not stripped 再使用 objdump 命令看一下 statically_call.elf。可以发现 &ldquo;.text&rdquo; 段的内容，就是上面两个文件拼起来的。
&gt; objdump -s statically_call.elf Contents of section .text: 401000 f30f1efa 554889e5 897dfc8b 45fc5dc3 ....UH...}..E.]. 401010 f30f1efa 554889e5 bf010000 00b80000 ....UH.......... 401020 0000e8d9 ffffffb8 00000000 5dc3 ............]. 静态链接器会将输入的目标文件进行合并，把 &ldquo;.text&rdquo; 段、&quot;.data&quot; 段等进行合并，合并后会重新计算段的大小、偏移位置。 同时静态链接器还要完成符号解析（确保所有的符号被正确地连接）、重新定位（调整内存地址和引用）等操作。
]]></content></entry><entry><title>运行 ELF 文件</title><url>/post/computer-science/operating-system/linux/exec_elf/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>elf</tag></tags><content type="html"><![CDATA[前言 前置笔记：ELF 文件实践的环境：同 程序资料 {demo-c}/demo-in-linux/program/ 正文 进程是什么 可执行文件只是程序而已，程序自己是跑不起来的，需要把程序交给操作系统去执行。
当一个程序被交给操作系统执行时，操作系统首先会创建一个进程。 与此同时，一个线程也会被立刻启动起来去执行程序中的 main 函数。 这个线程就叫主线程，后续创建的线程都是这个主线程的子线程。
线程被称作轻量级进程，它是操作系统调度的最小单元，通常一个进程可以拥有多个线程。
进程不仅局限于程序（那段可执行代码），还包含其他资源。例如，文件、内存、线程、信号等。 进程拥有独立的资源空间，进程中的线程共享进程的资源空间。
简单的理解，程序是静态的，进程是动态的，程序需要变成进程，才能够真正的运行起来，程序启动起来就变成进程，直到程序运行结束。
怎么观察进程 可以通过 strace 命令可以跟踪进程执行时的系统调用和进程接收的信号。 关于 strace 命令具体怎么用，可以看 &ldquo;strace(1) - trace system calls and signals&rdquo;。
这里会用到 &ldquo;-f&rdquo;、&quot;-i&quot;、&quot;-t&quot;、&quot;-T&quot;、&quot;-p&quot;、&quot;-s&quot;、&quot;-o&quot; 这几个参数。 &ldquo;-f&rdquo; 跟踪子进程；&quot;-i&quot; 打印系统调用的地址；&quot;-t&quot; 每一行打印时间； &ldquo;-T&rdquo; 显示系统调用花费的时间；&quot;-p {pid}&ldquo;指定跟踪的进程号； &ldquo;-s {length}&rdquo; 每一行的长度，默认 32，一般设置 65535；&quot;-o {file name}&rdquo; 输出到文件。
关于系统调用的详细的内容。我放到这篇里面去了。 系统调用这里观察一下 hello_world.elf 可执行文件运行的过程。 命令的输出我放在 {demo-c}/demo-in-linux/program/ 目录的 hello_world_objdump.md 文件内。
在 centos 的 docker 容器中使用 strace 命令报错 使用 strace -p 命令跟踪进程时报错：
attach: ptrace(PTRACE_SEIZE): Operation not permitted 参考官方文档： The solution for enabling of ptrace and PTRACE_ATTACH in Docker Containers。
启动容器的时候使用 &ldquo;–-privileged&rdquo; 参数，让容器内的 root 用户拥有真正的 root 权限。
docker run -it -p 127.0.0.1:9501:9501 -v {local path}:{docker path} --name={container name} --privileged centos:centos7 进入容器，然后使用命令：echo 0 &gt; /proc/sys/kernel/yama/ptrace_scope。 将 &ldquo;/proc/sys/kernel/yama/ptrace_scope&rdquo; 文件中的值修改成 0。然后就可以使用 strace -p 命令跟踪进程了。
观察一下 hello world 程序运行的过程 可以直接用 strace -f -i -T -s 65535 ./hello_world.elf 命令直接跟踪 ./hello_world.elf 命令运行的过程。 但是，这样观察不到全部的细节。这里用另外一种观察方式，观察输入 ./hello_world.elf 并运行程序的那个终端对应的进程。
其实用户的输入，也是有一个进程来处理的，这个进程会接收并分析用户输入的容，然后做出相应的动作。 这里这个进程，会先接收到用户输入的 ./hello_world.elf 还有回车符。 通过分析，得到这条命令的意思是这是要执行 hello_world.elf 这个可执行文件。然后，就去执行相应的操作。
假设有两个终端黑窗口（进程），进程 a 负责进行上面的操作。进程 b 负责观察进程 a。 在进程 b 进行跟踪之前，需要现在进程 a 里面，使用 echo $$ 命令获取当前进程的 pid。 然后进程 b 使用 strace -f -i -T -s 65535 -p {pid} -o hello_world_elf_strace.log 命令观察进程 a。
strace 命令输出的结果：
strace: Process 5148 attached strace: Process 5333 attached ^Cstrace: Process 5148 detached 终端 a 运行输入 ./hello_world.elf 执行程序，终端 b 在输出前两行之后，按 ctrl+c 终止监视，会输出第三行。 追踪到的内容会输出到 hello_world_elf_strace.log 里面，下面看一下 log 里面的内容。
最前面的重复出现的 read 和 write 这里截取了 strace.log 里面，最前面的一段。... 表示这里省略了代码，全部贴过来太长了。
2222 [00007f060c91b8f4] pselect6(1, [0], NULL, NULL, NULL, {sigmask=[], sigsetsize=8}) = 1 (in [0]) &lt;4.219516&gt; 2222 [00007f060c914992] read(0, &#34;.&#34;, 1) = 1 &lt;0.000107&gt; 2222 [00007f060c91b74d] pselect6(1, [0], NULL, [0], {tv_sec=0, tv_nsec=0}, NULL) = 0 (Timeout) &lt;0.000100&gt; 2222 [00007f060c914a37] write(2, &#34;.&#34;, 1) = 1 &lt;0.000098&gt; 2222 [00007f060c91b8f4] pselect6(1, [0], NULL, NULL, NULL, {sigmask=[], sigsetsize=8}) = 1 (in [0]) &lt;0.269215&gt; 2222 [00007f060c914992] read(0, &#34;/&#34;, 1) = 1 &lt;0.000736&gt; 2222 [00007f060c91b74d] pselect6(1, [0], NULL, [0], {tv_sec=0, tv_nsec=0}, NULL) = 0 (Timeout) &lt;0.000152&gt; 2222 [00007f060c914a37] write(2, &#34;/&#34;, 1) = 1 &lt;0.000115&gt; ... 这里用上面的第二行 &ldquo;2222 [00007f060c914992] read(0, &ldquo;.&rdquo;, 1) = 1 &lt;0.000107&gt;&rdquo; 做一个说明： &ldquo;2222&rdquo; 是进程号；&rsquo;[00007f060c914992]&rsquo; 是地址；&lsquo;read(0, &ldquo;.&rdquo;, 1)&rsquo; 是系统调用和调用的时候传入的参数； &ldquo;= 1&rdquo; 这里的 1 是前面那个系统调用的返回值；&quot;&lt;0.000107&gt;&quot; 是系统调用消耗的时间。
终端 a（进程 2222），是由 &ldquo;/bin/bash&rdquo; 程序启动来的（&quot;/bin/bash&quot; 程序就是输入命令的那个终端黑窗口）。 这一大段 read 函数和 write 函数，跟踪到的就是用户在终端 a 里用键盘输入 ./helloworld 的过程。 read 是读取用户的输入，write 是将用户的输入显示到屏幕上。
关于 read 函数和 write 函数具体怎么用可以看 &ldquo;read(2) - read from a file descriptor&rdquo; 和 &ldquo;write(2) - write to a file descriptor&rdquo;
clone 下一个关键的步骤是，调用 clone()。
... 2222 [00007f060c8eabc7] clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD &lt;unfinished ...&gt; 3579 [00007f060c8eac02] set_robust_list(0x7f060cb82a20, 24 &lt;unfinished ...&gt; 2222 [00007f060c8eabc7] &lt;... clone resumed&gt;, child_tidptr=0x7f060cb82a10) = 3579 &lt;0.000430&gt; ... clone() 的作用是创建子进程，这里父进程 2222 创建了子进程 3579。 关于 clone() 具体怎么用可以看 &ldquo;clone(2) - create a child process&rdquo;。 另外，fock() 也可以创建子进程，这个后面再说。
wait4 下一个关键的步骤是，是父进程调用 wait4()。
... 2222 [00007f060c8ea45a] wait4(-1, &lt;unfinished ...&gt; ... 父进程调用 wait4() 会进入阻塞状态，直到有子进程退出。 关于 wait4() 具体怎么用可以看 &ldquo;wait4(2) - wait for process to change state, BSD style&rdquo;。
在这里就是，父进程调用 wait4() 进入阻塞状态，然后操作系统切换到子进程继续运行。 出现 &ldquo;&lt;unfinished &hellip;&gt;&rdquo; 这个就表示产生了进程切换。
execve 下一个关键的步骤是，是子进程调用 execve()。
... 3579 [00007f060c8eb0fb] execve(&#34;./hello_world.elf&#34;, [&#34;./hello_world.elf&#34;], 0x5595c15c1ed0 /* 55 vars */) = 0 &lt;0.009663&gt; ... 子进程调用 execve() 执行可执行文件 hello_world.elf。 关于 execve() 具体怎么用可以看 &ldquo;execve(2) - execute program&rdquo;。
execve() 会加载可执行文件的 &ldquo;.text&rdquo; （程序指令）和 &ldquo;.data&rdquo; （程序数据）到当前进程，并覆盖当前进程。 &lsquo;[&quot;./helloworld&quot;]&rsquo; 是命令行参数。&ldquo;0x564eeda28ec0 /* 55 vars */&rdquo; 是环境参数。环境参数是供所有应用程序使用的公共数据。
关于命令行参数和环境参数的详细的内容。我放到这篇里面去了。 命令行参数和环境参数libc.so.6 下一个关键的步骤是，加载 libc.so.6 文件。
... 3579 [00007f02afc17b38] openat(AT_FDCWD, &#34;/lib/x86_64-linux-gnu/libc.so.6&#34;, O_RDONLY|O_CLOEXEC) = 3 &lt;0.000014&gt; 3579 [00007f02afc17b88] read(3, &#34;\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0&gt;\0\1\0\0\0P\237\2\0\0\0\0\0@\0\0\0\0\0\0\0\360\300!\0\0\0\0\0\0\0\0\0@\08\0\16\0@\0B\0A\0\6\0\0\0\4\0\0\0@\0\0\0\0\0\0\0@\0\0\0\0\0\0\0@\0\0\0\0\0\0\0\20\3\0\0\0\0\0\0\20\3\0\0\0\0\0\0\10\0\0\0\0\0\0\0\3\0\0\0\4\0\0\0000&gt;\36\0\0\0\0\0000&gt;\36\0\0\0\0\0000&gt;\36\0\0\0\0\0\34\0\0\0\0\0\0\0\34\0\0\0\0\0\0\0\20\0\0\0\0\0\0\0\1\0\0\0\4\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\340\177\2\0\0\0\0\0\340\177\2\0\0\0\0\0\0\20\0\0\0\0\0\0\1\0\0\0\5\0\0\0\0\200\2\0\0\0\0\0\0\200\2\0\0\0\0\0\0\200\2\0\0\0\0\0\301D\31\0\0\0\0\0\301D\31\0\0\0\0\0\0\20\0\0\0\0\0\0\1\0\0\0\4\0\0\0\0\320\33\0\0\0\0\0\0\320\33\0\0\0\0\0\0\320\33\0\0\0\0\0\314x\5\0\0\0\0\0\314x\5\0\0\0\0\0\0\20\0\0\0\0\0\0\1\0\0\0\6\0\0\0\360H!\0\0\0\0\0\360X!\0\0\0\0\0\360X!\0\0\0\0\0\230O\0\0\0\0\0\0`%\1\0\0\0\0\0\0\20\0\0\0\0\0\0\2\0\0\0\6\0\0\0\300{!\0\0\0\0\0\300\213!\0\0\0\0\0\300\213!\0\0\0\0\0\320\1\0\0\0\0\0\0\320\1\0\0\0\0\0\0\10\0\0\0\0\0\0\0\4\0\0\0\4\0\0\0P\3\0\0\0\0\0\0P\3\0\0\0\0\0\0P\3\0\0\0\0\0\0000\0\0\0\0\0\0\0000\0\0\0\0\0\0\0\10\0\0\0\0\0\0\0\4\0\0\0\4\0\0\0\200\3\0\0\0\0\0\0\200\3\0\0\0\0\0\0\200\3\0\0\0\0\0\0D\0\0\0\0\0\0\0D\0\0\0\0\0\0\0\4\0\0\0\0\0\0\0\7\0\0\0\4\0\0\0\360H!\0\0\0\0\0\360X!\0\0\0\0\0\360X!\0\0\0\0\0\20\0\0\0\0\0\0\0\220\0\0\0\0\0\0\0\10\0\0\0\0\0\0\0S\345td\4\0\0\0P\3\0\0\0\0\0\0P\3\0\0\0\0\0\0P\3\0\0\0\0\0\0000\0\0\0\0\0\0\0000\0\0\0\0\0\0\0\10\0\0\0\0\0\0\0P\345td\4\0\0\0L&gt;\36\0\0\0\0\0L&gt;\36\0\0\0\0\0L&gt;\36\0\0\0\0\0\314p\0\0\0\0\0\0\314p\0\0\0\0\0\0\4\0\0\0\0\0\0\0Q\345td\6\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\20\0\0\0\0\0\0\0R\345td\4\0\0\0\360H!\0\0\0\0\0\360X!\0\0\0\0\0\360X!\0\0\0\0\0\0207\0\0\0\0\0\0&#34;, 832) = 832 &lt;0.000015&gt; ... 子进程调用 openat() 和 read() 加载 hello_world.elf 程序所依赖的库文件 libc.so.6。
其中 openat() 会打开 libc.so.6 文件。 关于 openat() 具体怎么用可以看 &ldquo;openat(2) - open and possibly create a file&rdquo;。
openat() 的返回值 3 是个文件描述符。文件描述符是指当前进程在访问的文件，这个值一般大于等于 0。 linux 进程默认情况下会有 3 个缺省打开的文件描述符，分别是：标准输入 0、标准输出 1、标准错误 2。 然后，后面的 read 函数的第一个参数就是这个 3，表示从文件里读数据。
libc.so.6 是共享目标文件，也叫共享库、运行库、动态库。用户程序会调用运行库（C Runtime Library、CRT）。 运行库封装了操作系统更底层的系统调用函数。Linux、Windows、Mac，不同的操作系统，底层接口都是不一样的。 并且这些底层接口都比较 &ldquo;原始&rdquo;，如果想直接使用，那是比较复杂的，所以，要封装这些比较底层的系统调用。
关于静态链接和动态链接的详细的内容。我放到这篇里面去了。 动态链接和静态链接write 下一个关键的步骤是，是调用 write()。
... 3579 [00007f02af914a37] write(1, &#34;hello, world\n&#34;, 13) = 13 &lt;0.000117&gt; ... 调用 write() 输出 &ldquo;hello, world\n&rdquo; 到屏幕上。返回值 13 表示 &ldquo;hello, world\n&rdquo; 有 13 个字节。
在源码里面，用的是 printf()。这个函数声明在 stdio.h 头文件里面。 它的底层实现最终调用的就是 write()，而 write() 的具体实现就在 libc.so.6 库里。 write() 就是操作系统暴露出来的最底层的函数了，再往下就要和驱动、硬件等相关了。
另外，程序是可以直接调用系统调用函数的。 也就是说，直接在程序里写 write(1, &quot;hello, world\n&quot;, 13) 也是可以的。 但是，这个时候，头文件就不是 stdio.h 了，而是 unistd.h。就像下面这样。
#include &lt;unistd.h&gt; int main() { write(1, &#34;hello, world\n&#34;, 13); return 0; } exit_group 下一个关键的步骤是，是调用 exit_group()。 关于 exit_group() 具体怎么用可以看 &ldquo;exit_group(2) - exit all threads in a process&rdquo;。
... 3579 [00007f02af8eaca1] exit_group(0) = ? 3579 [????????????????] +++ exited with 0 +++ ... 子进程调用 exit_group(0) 退出进程，参数值 0 是进程退出状态码，也就是程序里 return 的 0。
wait4 下一个关键的步骤是，是父进程从 wait4() 的阻塞状态中被唤醒。但是，父进程怎么被唤醒的呢。
Topic 2 Multiprocessing (4) A SIGCHLD is sent automatically by the kernel to a process, telling the process that one of its child process terminates or stops.
子进程退出的时候，操作系统先知道。然后，操作系统会给父进程发一个 SIGCHLD 信号。 然后，父进程知道子进程退出了，前面调用的 wait4() 会回收退出的子进程，并回收子进程的内存资源。
... 2222 [00007f060c8ea45a] &lt;... wait4 resumed&gt;[{WIFEXITED(s) &amp;&amp; WEXITSTATUS(s) == 0}], WSTOPPED|WCONTINUED, NULL) = 3579 &lt;0.035522&gt; ... 2222 [00007f060c89bc9b] --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=3579, si_uid=1000, si_status=0, si_utime=0, si_stime=0} --- 2222 [00007f060c8ea45a] wait4(-1, 0x7ffdb295ab90, WNOHANG|WSTOPPED|WCONTINUED, NULL) = -1 ECHILD (No child processes) &lt;0.000005&gt; ... &ldquo;WIFEXITED(s)&rdquo; 和 &ldquo;WEXITSTATUS(s)&rdquo; 是宏函数，&ldquo;WEXITSTATUS(s)&rdquo; 可以拿到退出状态码。
至此整个 hello world 程序执行结束。 进程 上面 hello world 程序执行的过程，就是一个非常典型的进程的生命周期。 主要包括进程的创建、进程的运行、进程的内存资源、进程的退出、进程的回收。
关于这块的详细的内容。我放到这篇里面去了。 进程的创建、进程的运行、进程的内存资源、进程的退出、进程的回收参考 百度百科-主线程Topic 2 Multiprocessing (4)]]></content></entry><entry><title>Golang 反射的基本使用方式</title><url>/post/computer-science/programming-language/golang/reflect/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag><tag>reflect(反射)</tag></tags><content type="html"><![CDATA[前言 CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64 资料 {demo-golang}/demo/reflectkn/ reflect.drawio.html 正文 注意，笔记里的代码是伪代码，方便说明和区分用的。
实例 在 Golang 中，一个实例（叫变量也行），它由类型信息和值信息组成。
比如：var int a = 8。a 就是一个实例，它的类型信息就是 int，值信息就是 8。
当然实际上没有这么简单，这里就是方便理解。
反射 和反射相关的 API 都在 reflect 包里面。其中最核心的 API 有两个：reflect.Type() 和 reflect.Value()。
reflect 包有一个很强的假设，使用者知道他在干什么。比如，使用者知道他在操作的变量是什么类型的。
所以，在调用 API 之前一定要先读注释，确认什么样的情况下可以调用。如果调用的不对就会 panic。
reflect.Type() 可以用来操作类型信息，类型信息只能读取。比如，代码里定义了一个 int 实例，编译的时候这个实例肯定也是 int 的。
reflect.Value() 可以用来操作值信息，部分值信息可以修改。比如，私有变量就应该不能改，能改的话，就破坏私有变量的定义了。
另外，通过 reflect.Value() 可以获取 reflect.Type()，反过来则不行。
在计算机中数据都是存储在内存上的 0 和 1，既然 reflect.Value() 可以操作值信息，那么它就必须知道，数据在哪里，有多长。
如果没有类型信息，它就不知道要从内存上拿多长的数据。反过来则不行，只知道类型，不代表知道数据在哪。
基本类型 基本类型比较简单了。比如，int 类型。
reflect.TypeOf(int).Kind() 直接就能拿到 reflect.Int 类型。
reflect.ValueOf(int).Interface() 直接就能拿到 interface{} 类型的值。再做一次类型断言，就可以得到 int 类型的值了。
代码示例：{demo-golang}/demo/reflectkn/int_test.c
array、slice、string 这几个类型不能直接用 reflect.ValueOf(array).Interface()。
要先通过 reflect.ValueOf(array).Len() 拿到长度。然后，通过 reflect.ValueOf(array).Index(i) 拿到每一个元素。
拿到每一个元素之后，就可以通过 Index(i).Interface() 拿到具体的值了。
如果是多维数组的话，Index(i).Interface() 会拿到多维数组的元素。比如，二维数组，这里拿到的就是一维数组。
代码示例：
{demo-golang}/demo/reflectkn/array_test.c {demo-golang}/demo/reflectkn/slice_test.c {demo-golang}/demo/reflectkn/string_test.c map map 类型是单独一类的处理方法，可以使用 reflect.ValueOf(map).Len() 拿到长度。但是，不能用下标进行遍历。遍历方式有两种。
第一种是先通过 reflect.ValueOf(map).MapKeys() 拿到所有的键，通过遍历所有的键，去一个一个找值。
MapKeys() 会返回一个值信息的切片，可以配合 Len() 拿到的长度，就可以通过下标访问每一个键。
把拿到的键传给 reflect.ValueOf(map).MapIndex(键)，就可以拿到键对应的值的值信息。
这样 reflect.ValueOf(map).MapIndex(键).Interface() 就可以拿到具体的值了。
第二种是通过 reflect.ValueOf(map).MapRange() 拿到一个有点像单链表的可以遍历的结构。
然后，一个一个处理就好了。通过 t4MapRange.Next() 判断元素有没有遍历到头，有的话会返回 true。
然后，用 t4MapRange.Key().Interface() 可以拿到键，用 t4MapRange.Value().Interface() 可以拿到值。
这就处理完一个键值对了，然后，再调用 t4MapRange.Next() 判断元素有没有遍历到头，有的话继续。
代码示例：{demo-golang}/demo/reflectkn/map_test.c
指针类型 指针类型会麻烦一点，有两种情况，第一种是一级指针，第二种是多级指针。比如，*int 类型和 **int 类型。
指针类型的 reflect.Type() 和 reflect.Value() 都可以使用 Elem()，分别拿到各自解引用后的结果。
代码示例：{demo-golang}/demo/reflectkn/int_test.c
一级指针 比如，*int 类型。
reflect.TypeOf(*int).Kind() 拿到的类型是 reflect.Pointer。
reflect.TypeOf(*int).Elem().Kind() 拿到的类型才是 reflect.Int。
reflect.ValueOf(*int).Elem().Interface() 直接就能拿到 interface{} 类型的值。
因为，Elem() 已经相当于解引用了，所以，这里直接就能拿到具体的值。
多级指针 比如，**int 类型。需要连续进行 Elem()，直到拿到具体的类型。
reflect.TypeOf(**int).Elem().Kind() 拿到的类型是 reflect.Pointer。
也就是说，对 **int 的类型信息进行 Elem()，拿到的是 *int 的类型，还是个 reflect.Pointer。
要再来一次 Elem()，也就是 reflect.TypeOf(**int).Elem().Elem().Kind() 拿到的类型才是 reflect.Int。
多级指针的这个过程可以用循环去处理。最后和一级指针一样，通过 Interface() 就能拿到 interface{} 类型的值。
实例和指针的关系 见图：reflect.drawio.html 2-2
方法 方法本身是可以匿名进行调用的，就像下面这样。
testFunc := func() { fmt.Println(&#34;testFunc&#34;) } testFunc() 这种方式处理有入参和出参的方法是很麻烦的，在调用的时候，必须知道变量里存的到底是什么类型的方法。如果方法的类型在不一样，那就基本没办法处理了。
这个时候，就需要用到反射了。通过反射，可以知道一个方法的入参和出参分别有几个，分别是什么类型的。
知道了这些，就可以根据方法的入参，构造对应的参数传入，也可以根据方法的出参，构造对应的参数来接收。
比如，糙一点的用法。可以通过 reflect.TypeOf(func).NumIn() 知道方法有几个入参。
然后，构造一个入参切片 inputSlice := make([]reflect.Value, num)，把所有的参数用 reflect.ValueOf(参数) 转换成反射的值类型，放进去。
再构造一个出参切片 outputSlice := make([]reflect.Value, 0)。然后，就可以调用方法了 outputSlice = reflect.ValueOf(func).Call(inputSlice)。
代码示例：
{demo-golang}/demo/reflectkn/func.c {demo-golang}/demo/reflectkn/func_test.c 结构体 关于结构体的反射有两个部分，一部分是和结构体实例有关系的，一部分是和结构体本身有关系的（属性和方法）。
代码示例：
{demo-golang}/demo/reflectkn/struct.c {demo-golang}/demo/reflectkn/struct_test.c 结构体实例 结构体实例有两种情况，第一种直接就是结构体、第二种是结构体指针。
如果直接就是结构体的话，reflect.TypeOf(struct).Kind() 得到的是 reflect.Struct 类型。
如果直接就是结构体指针的话，处理方式和上面指针类型那里是一样的。
结构体属性 通过 reflect.TypeOf() 和 reflect.ValueOf() 先拿到结构体的类型信息和值信息。
然后，通过 reflect.TypeOf(struct).NumField() 可以拿到结构体属性的数量。
知道数量之后，就可以通过 reflect.TypeOf(struct).Field(i) 和 reflect.ValueOf(struct).Field(i)，分别获取每一个属性的类型信息和值信息。
需要注意的是，私有属性是拿不到值信息的，只能拿到类型信息。通过 reflect.TypeOf(struct).Field(i).IsExported() 可以判断是不是私有属性。
reflect.TypeOf(struct).Field(i).Name 可以获取属性的名称，reflect.Zero(reflect.TypeOf(struct).Field(i).Type).Interface() 可以用类型信息构造零值。
反射还可以用来修改属性的值。很多框架都需要用到，通过属性名称找到并修改属性值，这样的操作。
reflect.TypeOf(struct).FieldByName(属性名称) 这样就可以通过属性名称，找到对应的属性的值信息。注意，这里通过结构体的类型信息，找到的是属性的值信息。
然后，用 reflect.TypeOf(struct).FieldByName(属性名称).CanSet() 可以用来判断属性能不能进行赋值操作。
如果可以的话，可以通过 reflect.TypeOf(struct).FieldByName(属性名称).Set(reflect.ValueOf(属性值)) 把值放进去。
其中 reflect.ValueOf(属性值) 这个部分，就是把具体的数据类型转换成反射使用的数据类型。
结构体属性的 Tag 通过 reflect.TypeOf(struct).Field(i).Tag 就可以拿到结构体某个属性上的 Tag，这里拿到的是 reflect.StructTag。
然后，在通过 reflect.StructTag 的 Get() 方法，就可以拿到整个 Tag 里面某个具体的 Tag 的内容了。
type User struct { Id int `orm:&#34;column_name=user_id&#34;` } 比如，对于 User 的 Id 属性来说，Field(i).Tag.Get(orm) 就会拿到字符串 &ldquo;column_name=user_id&rdquo;。
结构体方法 结构体方法的处理方式，是结构体属性的处理方式和方法的处理方式相结合。
先通过 reflect.TypeOf(struct).NumMethod() 知道结构体有几个方法。
然后，就可以通过下标进行遍历了。reflect.TypeOf(struct).Method(i) 这样就能拿到方法的类型信息。
Method(i).NumIn() 和 Method(i).NumOut() 分别可以拿到方法的入参数量和出参数量。
Method(i).Type.In(i) 和 Method(i).Type.Out(i) 分别可以拿到方法每个入参的参数类型和每个出参的参数类型。
调用结构体方法和调用方法那里有点区别 outSlice = Method(i).Func.Call(inputSlice)。
参考（reference） {极客时间}/Go 实战训练营反射部分 ]]></content></entry><entry><title>Golang 实现简单的自定义 RPC 协议</title><url>/post/computer-science/programming-language/golang/rpc/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag><tag>reflect(反射)</tag><tag>protocol(协议)</tag><tag>rpc(远程过程调用)</tag></tags><content type="html">前言 CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64 前置笔记：
关于 RPC 的基本认知
Golang 反射的基本使用方式
在动手实现自定义 RPC 之前，先搞清楚 RPC 是什么，以及 RPC 的原理。
资料 {micro-service-go}
/v20/ rpc.drawio.html 正文 先来看看有几块东西 RPC 的意思是远程过程调用。既然是调用，那么这玩意肯定有一个调用方，一个被调用方，也就是说会有客户端和服务端。
然后，又是远程调用，那客户端和服务端应该不在同一个服务里，那么它们之间要用就需要用到网络，那么他们之间就必须要商量一个通信的方式，也就是需要一个通信协议。
差不多就这三个玩意：客户端、服务端、协议。
理论上，可以基于 TCP 协议构造一个 RPC 协议，也可以基于 HTTP 协议构造一个 RPC 协议，这个其实没有严格的规定。
进行协议设计的时候需要注意的是。如果是基于 HTTP 协议设计，那么里面会包含 HTTP 和 TCP 两个协议，会多一层转换的开销。
如果是直接基于 TCP 协议设计，虽然少一层转换的开销，但是编码难度上去了。在实际应用中，需要做好协议性能和开发难度的权衡。
这几块东西是怎么工作的 RPC 有一个核心的描述：它想像使用本地服务一样使用远端服务。
也就是说，如果在 a 服务上有另一个类 B，在远端服务 b 上有一个类 A，这个类 B 想直接 new 一个类 A 出来，然后调用方法。
通常情况下这么干肯定是不行的，因为 a 服务上并没有类 A 的代码。但是如果把类 A 的代码在 a 服务上再写一份，那就没意义了。
RPC 这里想要的是 a 服务上有一个类 A 的壳子，这个类 A 的壳子可以直接 new 出来，然后调用壳子上的方法。
调用壳子上的方法的时候，这个壳子上的方法做的事情是，把调用者传进来的参数收集起来，然后交给远端服务 b 上真正的类 A 去处理，拿到处理结果后，返回给调用者。
调用者只是感觉上和使用本地服务没什么区别。
为了保证 a 服务和远端服务 b 上的类 A 是一样的，这里需要引入一个公共的抽象。
a 服务基于这个公共的抽象实现一个壳子，远端服务 b 基于这个公共的抽象实现真正的功能。
这里的两方是可以使用不同的语言的，a 服务上收集到的调用参数可以进行序列化处理然后再传到远端服务 b，只要远端服务 b 能根据序列化的数据还原出调用参数就行。
来总结一下这几块东西是怎么工作的：
客户端需要实现一个壳子。 壳子需要收集调用参数，把调用参数序列化，然后传给远端服务 b。 远端服务 b 在接到数据之后，需要用序列化后的数据还原出调用参数，处理完成后把结果返回回去。 壳子收到远端服务 b 的处理结果后，把处理结果返回给调用者。 这里面还有几处细节：
双方的通信的方式，也就是协议还没有约定。 远端服务 b 在接到数据之后，需要知道调用哪个类的哪个方法，这个是壳子需要告诉远端服务 b 的。 远端服务 b 处理出错了怎么办，也就是异常还没有处理。 RPC 调用的大概过程 用流程图（见图：rpc.drawio.html 4-2）来描述 RPC 调用的大概过程比较合适。
大概的实现 几个抽象 服务：就是壳子和真正的功能的抽象，两端需要基于这个抽象传递方法的入参和出参。 序列化：序列化可以用任意的算法，比如 JSON 或 protobuf。抽象是为了方便后续扩展新的序列化算法，上层不需要知道参数是怎么序列化的。 协议：协议可以用任意的协议，比如自定义 JSON 协议或自定义 RPC 协议。抽象是为了方便后续扩展新的协议，上层不需要知道数据是怎么发出去的。 网络请求：网络请求可以使用任意的形式，比如 TCP 或 HTTP，比如每次都新建连接或使用连接池。 对网络请求层进行抽象是为了可以替换不同的实现，上层不需要知道网络请求是怎么实现的。 请求参数和响应参数：对这两个东西进行抽象是为了方便对 RPC 流程进行抽象。要不然请求的那个地方会是任意类型的，不方便添加中间件之类的结构。 协议 协议设计见图：rpc.drawio.html 6-2
最前面的定长的部分，这几个字段属于非常常见的字段了，很多协议里都可以看到这种设计。
请求（响应）头长度用于标记请求（响应）头的长度，这里的请求头包括前面定长的部分。 请求（响应）体长度用于标记请求（响应）体的长度。 这两个玩意合起来用于从 TCP 里读取一个完整的报文。也就是从 TCP 里读取的时候，先读前面 8 个字节，然后解析出这两个长度，这样就可以知道这一个报文的长度了。 版本号、序列换算法、压缩算法这三个属于标记位，用于提示客户端或者服务端，协议的内容怎么解析。
请求头里用 \r\n 分隔每一条数据。最前面两个固定为：service name 和 method name，后面则是剩下的元数据。
比如，链路追踪 id 和超时时间之类的。service name 和 method name 单独拿出来放最前面是考虑到：
1、这两个属于必须字段；2、如果有网关的存在，网关直接解析最前面这两个字段就可以进行转发，不用解析整个请求头。
响应头里只有一个放异常的位置。因为返回响应的时候一般都是原路返回的，所以 service name 和 method name 是不必要的。
然后，元数据，本来就是上游传过去的，没必要传回来，而且一般也不会有穿别的元数据回来的需要。所以请求头里的玩意，在响应头里都可以去掉。
壳子 客户端这边最重要的就是壳子了。如果客户端里需要大量使用 RPC 的话，那么每个方法都要作 RPC 改造。
但是，每个方法要做的事情都是一样的：收集调用信息，发起 RPC 调用，得到结果，返回给调用者。所以，这里应该要进行封装。
问题来了，各个方法它是不一样的，这东西怎么封装呢。这里就需要使用约定加反射的技巧。这里使用的是 Golang，别的语言依葫芦画瓢就行了。
首先约定 RPC 方法的入参只有两个：上下文和一个结构体指针。结构体里面装着方法需要的所有的参数。
方法的出参也是两个：一个结构体指针和异常。结构体里面装着方法返回的所有的结果。这样子反射就好操作了。
对于入参，通过反射获取入参的上下文参数，然后进行格式化，作为协议里的元数据。通过反射获取入参的结构体，然后进行序列化，作为协议请求报文里的请求体。
对于出参，通过反射获取出参的结构体，然后进行序列化，作为协议响应报文里的响应体。通过反射获取异常，然后进行格式化，作为协议里的元数据。
异常 上面提到，异常是放到元数据那里的。为什么异常要放到元数据的位置呢。这是因为不管是 TCP 协议还是 HTTP 协议，它们都属于字节流协议。
请求过来的时候，不会被分隔成独立的协议数据报文，这个也就是经常问的那个 TCP 粘包的问题。
协议内部也是一样的，如果把出参的结构体和异常都放到响应体里面，那就需要有分隔它们的手段。要不然这两玩意粘在一起，直接序列化是要报错的。
大概就差不多了 具体的直接看代码就好了。
参考（reference） {极客时间}/
Go 实战训练营
反射部分、RPC 框架部分</content></entry><entry><title>关于 RPC 的基本认知</title><url>/post/computer-science/protocol/rpc/</url><categories><category>protocol(协议)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>protocol(协议)</tag><tag>rpc(远程过程调用)</tag></tags><content type="html">前言 资料 rpc.drawio.html 正文 RPC 是什么 RPC 是 Remote Procedure Call 的简写，翻译成中文叫远程过程调用。用这玩意的目的，简单的理解就是，想像使用本地服务一样使用远端服务。
这个怎么理解呢？这里先假定有一个类 A 在 a 服务上，这个类 A 实现了一个方法。
如果现在在 a 服务上有另一个类 B 要调用这个方法，那么通常是直接 new 一个类 A 出来，然后调用方法就行了。
现在如果这个类 A 在远端服务 b 上，怎么办呢？通常情况是 a 服务通过网络，请求 b 服务来达到目的。
比如，可以通过发起一次 TCP 进行访问，可以通过短连接的 HTTP 进行访问，当然长链接的 Socket 的也行。
这些请求方式各不相同，原因是它们对于两个服务之间的沟通方式有着不同约定，这些约定也就是协议。
那么 RPC 协议是啥样的呢？RPC 协议希望，即使类 A 在远端服务 b 上，a 服务上的类 B 依然可以使用 new 一个类 A 出来，然后调用接口的方式达到目的。
这里在 a 服务上的类 A 的使用方式看上去本地调用一样，但是背地里它是通过网络请求，请求了 b 服务，调用了 b 服务上真正的类 A 的接口拿到结果，然后返回给调用者的。
RPC 的原理 RPC 首先需要定义一个协议，也就是约定两个服务之间的沟通方式。这个协议主要是为了把本地服务的接口调用的信息传递给远端服务。
也就是 a 服务上的类 A 假装自己就是 b 服务上的类 A，这样上游调用的时候，类 A 就可以拿到调用的信息（调了哪个接口，传了哪些参数）。
然后，把这些调用信息传递给 b 服务上真正的类 A 去执行。
这个过程大概可以简单的分成下面几个步骤：
a 服务上的类 A 需要把自己伪装成 b 服务上的类 A，从外面看上去是一样的。 a 服务上的类 A 在被调用的时候需要把调用的信息收集起来，然后通过网络传给 b 服务。 b 服务接收到请求之后需要通过传过来的调用的信息，分析出这个请求调的是类 A，传了哪些参数。 b 服务 new 一个类 A 出来，使用传过来的参数调用接口拿到结果。 b 服务拿到结果之后，给 a 服务传回去。a 服务上的类 A 拿到结果之后，对上游做出响应。</content></entry><entry><title>线程</title><url>/post/computer-science/operating-system/linux/thread/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>thread(线程)</tag></tags><content type="html"><![CDATA[前言 实践的环境：
amd64（x86_64） windows 11 vmware workstation pro 16 ubuntu 22.04 linux version 5.19.0-41-generic gcc version 11.3.0 前置笔记： 进程的创建、进程的运行、进程的内存资源、进程的退出、进程的回收资料 {demo-c}/demo-in-linux/thread/ 正文 主线程 当一个进程启动时，默认会创建一个主线程。主线程会从 main() 开始执行代码。 main() 就是主线程的入口函数。每个线程都会有一个入口函数。 主线程一旦退出，整个进程就会退出，子线程无论有没有退出，都会被强制干掉。
并发和并行 当线程数量小于等于 CPU 核心数时，所有的线程并行执行。CPU 的核心够所有线程同时跑，不存在等待的情况。
当线程数量大于 CPU 核心数时，所有的线程并发执行。 CPU 的核心不够所有的线程同时跑，所以，每个线程执行一个时间片，然后，切换到其它线程执行。
多线程 多线程程序在执行的时候有两种情况。一种是子线程并入主线程，一种是主线程与子线程分离。
子线程并入主线程的情况，主线程调用 pthread_join() 后，会一直阻塞到子线程结束退出为止，当子线程结束退出后，主线程会继续往后执行。 主线程与子线程分离线的情况，主程调用 pthread_detach() 后，主线程与子线程分离，当子线程结束退出后，资源会被自动回收。
编写多线程程序的时候需要注意，如果主线程里面没有 sleep()、pthread_join()、pthread_detach() 这些相当于等待的代码结构。 那么，主线程执行完 pthread_create() 后就会结束，子线程没有来得急执行，就会被强制退出了。
代码示例：
{demo-c}/demo-in-linux/thread/thread_join.c {demo-c}/demo-in-linux/thread/thread_detach.c 编译的时候，如果代码是多线程程序，gcc 命令需要加上 &ldquo;-lpthread&rdquo; 选项。例如：gcc xxx.c -lpthread -o xxx.elf
线程可以通过调用 pthread_exit() 结束并退出，同时可以返回返回值。 比如，想返回个 3，这么写 &ldquo;pthread_exit((void *)3)&rdquo; 就行了。 或者直接用 return 也是可以的。同样的，想返回个 3，这么写 &ldquo;return (void *)3&rdquo; 就行了。
这样，pthread_join() 的第二个参数就能拿到返回值。注意，这个参数是个二级指针，一般传 **int 进去。
互斥锁 下面这段程序，本意是想将 x 中的数据取出来，对其 +100，然后再放回去。 如果跑两次的话，期望是依次输出 y=200，y=300。但是，在并发场景下，会输出 2 次 y=200。
因为，两个线程都会读到 100；然后，阻塞；然后，对其 +100；然后，赋值回去。
int x = 100; void *mythread() { int y = x; sleep(1); y = y + 100; x = y; printf(&#34;[info]:child pthread, y=%d\n&#34;, x); } 这里就需要用互斥锁对全局变量 x 进行保护，确保同一时刻只有一个线程有权利对 x 进行读写操作。
互斥锁常用于保护临界区的数据。有互斥锁的保护，在并发场景下，两个线程就会顺序执行，依次输出 y=200，y=300。
代码示例：{demo-c}/demo-in-linux/thread/mutex_lock.c
可以使用 pthread_mutex_init() 初始化互斥锁，也可以使用常量 PTHREAD_MUTEX_INITIALIZER 初始化互斥锁。
pthread_mutex_lock() 加不上锁的时候就会阻塞。对同一个锁重复执行加锁动作会死锁。
条件变量 程序在运行的时候会有，如果不满足某个条件就等待，直到条件满足再继续执行的场景。
假设，有一个线程 a 执行的时候，发现条件不满足，自己不能继续执行了，但是，自己前面加锁锁了临界资源 1。 再假设，有另一个线程 b，它手上有线程 a 需要的临界资源 2，但是，线程 b 需要线程 a 锁住的临界资源 1 才能继续执行。
这个时候，如果线程 a 不把所锁放掉，就陷入等待了，那么自己锁定的临界资源 1 就不会被释放。 这时，临界资源 1 是闲置的，但是，线程 b 就会拿不到，最终造成相互等待的死锁的情况。
这种情况就需要使用条件变量了。条件变量和需要结合互斥锁使用，互斥锁的存在是为了保护条件变量。 可以使用 pthread_cond_init() 初始化条件变量，也可以使用常量 PTHREAD_COND_INITIALIZER 初始化条件变量。
当线程 a 发现条件不满足时，就可以调用 pthread_cond_wait()。 调用 pthread_cond_wait() 会阻塞当前线程，并且会释放互斥锁。当 pthread_cond_wait() 被激活之后会再自动加锁。
另外的线程在释放掉临界资源后，可以使用 pthread_cond_signal() 唤醒一条阻塞的线程。 或者使用 pthread_cond_broadcast() 唤醒全部阻塞的线程。
代码示例：{demo-c}/demo-in-linux/thread/cond_wait.c
惊群问题 惊群问题（Thundering herd、cache stampede、cache-rashing），是多线程（多进程）程序中可能会发生的性能问题。
当多个线程（进程）竞争同一个共享资源，而该资源一次只能由一个对象访问时，就会出现惊群问题。
当资源可用时，所有的对象会同时醒来，并开始竞争同一个共享资源。这种突发的情况会导致资源使用量激增，进而导致系统性能下降。
惊群问题，可以使用互斥锁、信号量、或者其他同步原语，来调节对共享资源的访问。
缓存可以用来减少对共享资源的访问需求，提高系统的整体性能。负载均衡可以将共享资源分散出去，避免单点争夺。
]]></content></entry><entry><title>进程池</title><url>/post/computer-science/operating-system/linux/process_pool/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>process(进程)</tag></tags><content type="html">前言 前置笔记：
进程的创建、进程的运行、进程的内存资源、进程的退出、进程的回收
信号
进程间通信（IPC）
实践的环境：同 程序
资料 {demo-c}
/demo-in-linux/process-pool/ 正文 进程池 进程的创建和销毁是有代价的。每次需要的时候，新创建一个子进程，使用完了在销毁掉，这种方式非常的浪费资源。
进程池就是预先创建好一组用于处理某种问题的子进程，等遇到这个问题的时候直接就可以丢给其中一个子进程去处理。
使用完了并不会销毁掉子进程，而是把数据都初始化回去之后，重新放回进程池中。这样就可以避免频繁的创建和销毁子进程。
实现进程池的时候需要注意几点。
父进程怎么给子进程传递数据。 父进程怎么选择用哪个子进程。 子进程用完了之后要重新初始化。 子进程怎么退出，防止变成孤儿进程。 父进程怎么接收外部数据。 代码示例：
{demo-c}/demo-in-linux/process-pool/pool.c {demo-c}/demo-in-linux/process-pool/write.c 示例中：
父进程通过匿名管道传递数据给子进程。 子进程的工作是接收父进程的数据并打印。 父进程使用轮询算法选择用哪个子进程。 子进程用完了之后会重新初始化接收缓冲区。 子进程通过父进程发送的信号退出。 父进程通过命名管道从外部接收数据。 父进程通过信号和特殊的输入 &amp;ldquo;exit&amp;rdquo; 退出。</content></entry><entry><title>在 Linux 中使用 C 语言进行编程的注意点</title><url>/post/computer-science/operating-system/linux/notice/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag></tags><content type="html"><![CDATA[正文 学会看 linux 文档 想在 linux 系统中使用 c 语言进行编程，一定要学会看 linux 的文档。
在线文档 在线文档可以从 man7.org进去。 在 man7.org 页面，点击 &ldquo;Online manual pages&rdquo;，可以进到 Linux man pages online页面。
在 &ldquo;Linux man pages online&rdquo; 页面，点击 &ldquo;by section&rdquo; 链接，可以进到一个列表页面。在这个列表页面，有所有的条目。 虽然，东西多，但是，可以用浏览器进行全文搜索，找起来比较容易，不需要知道要找的条目到底在哪个 page。
man 命令 在 linux 操作系统中，可以使用 man 命令查看 linux 文档。但是，用 man 命令的时候，需要知道要找的条目到底在哪个 page。
比如：在线文档 by section 页面上的 &ldquo;execve(2) - execute program&rdquo;，用 man 命令就是 man 2 execve； 在线文档 by section 页面上的 &ldquo;exec(3) - execute a file&rdquo; 用 man 命令就是 man 3 exec。
在 docker 的 centos 容器中无法使用 man 命令 因为，docker 的 centos 容器，它把一些东西精简了，所以，有一些命令不能使用。
需要修改 &ldquo;/etc/yum.conf&rdquo; 配置文件。注释掉 tsflags=nodocs 这一行。这个配置禁用了一些软件包。 修改配置文件后，使用 yum -y install man 和 yum -y install man-pages 命令，重新安装 man 命令，即可使用。
注意代码运行的目标环境 编程的时候，要注意代码运行的目标环境。 同一段代码，在 ubuntu 和 centos 上运行的时候，整体的系统调用过程应该是差不多的，但是细节可能不一样。
举个例子，在 ubuntu 22.04 和 centos 7 上分别跑 hello world 程序。加载 libc.so.6 文件的这个步骤。 在 ubuntu 22.04 上加载的是 &ldquo;/lib/x86_64-linux-gnu/libc.so.6&rdquo;；而在 centos 7 上加载的是 &ldquo;/lib64/libc.so.6&rdquo;。
笔记中出现的文档 笔记中出现的 linux 文档，都会统一写在这里。直接在在线文档 by section 页面搜就可以。每一篇笔记都贴链接，太麻烦了。
笔记中出现的是从文档中节选的关键的部分，或者和实践过程有关的部分。有可能是整段的，有可能是节选的，看的时候稍微注意一点。
进程 标题 描述 进程的标识 &mdash; getuid(2) - get user identity &mdash; geteuid(2) - get user identity &mdash; getpid(2) - get process identification &mdash; getppid(2) - get process identification &mdash; getpgid(2) - set/get process group &mdash; 进程的创建 &mdash; fork(2) - create a child process 创建子进程 vfork(2) - create a child process and block parent 创建子进程 clone(2) - create a child process 创建子进程 进程的运行 &mdash; execve(2) - execute program 执行程序 exec(3) - execute a file &mdash; 进程的退出 &mdash; exit(2) - terminate the calling process &mdash; _Exit(2) - terminate the calling process &mdash; _exit(2) - terminate the calling process &mdash; exit(3) - cause normal process termination &mdash; exit_group(2) - exit all threads in a process 退出进程中所有的线程 进程的回收 &mdash; wait(2) - wait for process to change state &mdash; waitpid(2) - wait for process to change state &mdash; wait4(2) - wait for process to change state, BSD style 等待回收进程 进程的运行顺序 &mdash; nice(1) - run a program with modified scheduling priority &mdash; nice(2) - change process priority &mdash; renice(1) - alter priority of running processes &mdash; getpriority(2) - get/set program scheduling priority &mdash; setpriority(2) - get/set program scheduling priority &mdash; 进程的内存资源 &mdash; proc(5) - process information pseudo-filesystem &mdash; getrlimit(2) - get/set resource limits &mdash; setrlimit(2) - get/set resource limits &mdash; ptrace(2) - process trace 跟踪和控制另一个进程 信号 标题 描述 signal(7) - overview of signals &mdash; sigaction(2) - examine and change a signal action &mdash; sigprocmask(2) - examine and change blocked signals &mdash; sigpending(2) - examine pending signals &mdash; sigsetops(3) - POSIX signal set operations &mdash; alarm(2) - set an alarm clock for delivery of a signal &mdash; kill(2) - send signal to a process 发送信号给一个过程 &mdash; &mdash; 进程间通信 标题 描述 管道 &mdash; pipe(7) - overview of pipes and FIFOs &mdash; pipe(2) - create pipe &mdash; mkfifo(3) - make a FIFO special file (a named pipe) &mdash; System V IPC &mdash; ipc(2) - System V IPC system calls &mdash; System V 消息队列 &mdash; msgget(2) - get a System V message queue identifier &mdash; msgsnd(2) - System V message queue operations &mdash; msgrcv(2) - System V message queue operations &mdash; msgctl(2) - System V message control operations &mdash; System V 信号量 &mdash; semget(2) - get a System V semaphore set identifier &mdash; semctl(2) - System V semaphore control operations &mdash; semop(2) - System V semaphore operations &mdash; System V 共享内存 &mdash; shmget(2) - allocates a System V shared memory segment &mdash; shmat(2) - System V shared memory operations &mdash; shmdt(2) - System V shared memory operations &mdash; POSIX IPC &mdash; mq_overview(7) - overview of POSIX message queues &mdash; sem_overview(7) - overview of POSIX semaphores &mdash; shm_overview(7) - overview of POSIX shared memory &mdash; &mdash; &mdash; 网络间进程间通信 标题 描述 socket(7) - Linux socket interface socket 概述 socket(2) - create an endpoint for communication 创建 socket ip(7) - Linux IPv4 protocol implementation 设置 ipv4 的 tcp、udp 等 tcp(7) - TCP protocol TPC 概述 udp(7) - User Datagram Protocol for IPv4 UDP 概述 unix(7) - sockets for local interprocess communication UNIX Socket bind(2) - bind a name to a socket 绑定地址和端口 listen(2) - listen for connections on a socket 监听 socket accept(2) - accept a connection on a socket 接受连接 connect(2) - initiate a connection on a socket 发起连接 recv(2) - receive a message from a socket 从 socket 读取数据 recvfrom(2) - receive a message from a socket 从 socket 读取数据 send(2) - send a message on a socket 向 socket 发送数据 sendto(2) - send a message on a socket 向 socket 发送数据 &mdash; &mdash; 线程 标题 描述 线程 &mdash; pthreads(7) - POSIX threads 线程概述 pthread_create(3) - create a new thread 创建线程 pthread_join(3) - join with a terminated thread 子线程合入主线程 pthread_detach(3) - detach a thread 主线程与子线程分离 pthread_exit(3) - terminate calling thread 线程退出 互斥锁 &mdash; pthread_mutex_init(3p) - destroy and initialize a mutex 互斥锁初始化 pthread_mutex_lock(3p) - lock and unlock a mutex 互斥锁加锁 pthread_mutex_unlock(3p) - lock and unlock a mutex 互斥锁释放 条件变量 &mdash; pthread_cond_init(3p) - destroy and initialize condition variables 条件变量初始化 pthread_cond_wait(3p) - wait on a condition 等待条件变量 pthread_cond_signal(3p) - signal a condition 唤醒一条被条件变量阻塞的线程 pthread_cond_broadcast(3p) - broadcast or signal a condition 唤醒全部被条件变量阻塞的线程 &mdash; &mdash; IO 多路复用 标题 描述 epoll(7) - I/O event notification facility epoll 概述 epoll_create(2) - open an epoll file descriptor 创建 epoll 文件描述符 epoll_ctl(2) - control interface for an epoll file descriptor 添加、修改、删除 epoll 关联的 linux 内核事件 epoll_wait(2) - wait for an I/O event on an epoll file descriptor &mdash; &mdash; &mdash; 文件 标题 描述 access(2) - check user&rsquo;s permissions for a file &mdash; open(2) - open and possibly create a file &mdash; read(2) - read from a file descriptor 从文件描述符读取数据 write(2) - write to a file descriptor 向文件描述符写入数据 fcntl(2) - manipulate file descriptor 操作文件描述符 elf(5) - format of Executable and Linking Format (ELF) files elf 相关 openat(2) - open and possibly create a file 打开或者创建一个文件 &mdash; &mdash; 终端 标题 描述 tty(1) - print the file name of the terminal connected to standard input &mdash; tty(4) - controlling terminal &mdash; pty(7) - pseudoterminal interfaces &mdash; pts(4) - pseudoterminal master and slave &mdash; ptmx(4) - pseudoterminal master and slave &mdash; posix_openpt(3) - open a pseudoterminal device &mdash; &mdash; &mdash; linux 命令 标题 描述 man(1) - an interface to the system reference manuals 查看文档 gcc(1) - GNU project C and C++ compiler 用于编译 file(1) - determine file type 查文件类型 objdump(1) - display information from object files 查看文件信息 strace(1) - trace system calls and signals 跟踪系统调用 readelf(1) - display information about ELF files 查看 elf 文件内容 size(1) - list section sizes and total size of binary files 查看段大小 nm(1) - list symbols from object files 查看符号表 ldd(1) - print shared object dependencies 查看文件依赖的动态库 &mdash; &mdash; 其他 标题 描述 errno(3) - number of last error errno 怎么用 htons(3) - convert values between host and network byte order 主机字节序和网络字节序的转换 inet_addr(3) - Internet address manipulation routines 点分十进制和二进制网络字节顺序的转换 strncasecmp(3) - compare two strings ignoring case 比较两个字符串，忽略大小写 vdso(7) - overview of the virtual ELF dynamic shared object &mdash; sscanf(3) - input string format conversion &mdash; strstr(3) - locate a substring &mdash; isalpha(3) - character classification functions &mdash; readdir(3) - read a directory &mdash; &mdash; &mdash; ]]></content></entry><entry><title>Windows 10 环境使用 Docker</title><url>/post/computer-science/application/docker/windows/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>docker</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 Docker v20.10.17 正文 安装 去 Docker 官网下一个 Windows 11 使用的 Docker Desktop For Windows（下面简称 docker） 安装包。
因为，Docker Desktop For Windows 使用的是 hyper-v 虚拟机。所以，安装之前，需要安装并启用 Windows 11 的 hyper-v 虚拟机服务。
安装之后，可以打开 Windows PowerShell（下面简称 powershell），执命令行 docker run hello-world，检测是否安装成功。成功的话，输出应该是下面这样的。
&gt; docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &#34;hello-world&#34; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 输出版本信息 也可以通过，在 powershell 中，使用 &ldquo;docker version&rdquo; 命令，输出 docker 的版本信息，检测是否安装成功。这里截取了部分输出。
&gt; docker version Client: Version: 20.10.17 Go version: go1.17.11 OS/Arch: windows/amd64 镜像加速 国内从 DockerHub拉取镜像有时会遇到困难，此时可以配置镜像加速器。
打开 docker 的界面；点击右上角的 &ldquo;设置按钮&rdquo;（图标是个齿轮），打开 &ldquo;设置界面&rdquo;；点击左侧的 &ldquo;Docker Engine 标签&rdquo;，就可以看见 json 格式的配置参数。
在 registry-mirrors 参数中添加镜像加速的地址，这里用的是七牛云的加速器 &ldquo;https://reg-mirror.qiniu.com&rdquo;。如果没有 registry-mirrors 参数的话，就加一个。
修改好之后，点击右下角的 &ldquo;Apply &amp; Restart 按钮&rdquo;，等 docker 转完圈应该就可以了。如果不行的话，重启 docker 试试。
{ &#34;registry-mirrors&#34;: [ &#34;https://reg-mirror.qiniu.com&#34; ] } 输出 docker 的信息 在 powershell 中，使用 &ldquo;docker info&rdquo; 命令，输出 docker 的信息。
如果操作了上面的镜像加速的部分，这里在输出理就可以看到刚才设置的加速器的地址。
&gt; docker info Registry Mirrors: https://reg-mirror.qiniu.com/ 异常处理 Error response from daemon: status code not OK but 500 如果在使用目录映射时，遇到上面这样的报错，那可能是因为没有给 docker 权限。
打开设置界面；点击左侧的 &ldquo;Resources 标签&rdquo;；点击 &ldquo;File Sharing 子标签&rdquo;。然后添加 docker 可以映射的目录。
&gt; docker ps -a 拉取镜像和启动容器 mysqldocker composerabbitmqeasyswoole查看容器 在 powershell 中，使用 &ldquo;docker ps&rdquo; 命令，可以查看正在使用的容器。
&ldquo;-a&rdquo; 参数，可以查看所有的包括未启动的容器。 进入容器 容器启动之后，在 powershell 中，使用 &ldquo;docker exec&rdquo; 命令，可以使用命令行模式进入容器。
&gt; docker exec -it {container} /bin/bash {container}，可以填容器的名字或者容器的 ID（&ldquo;docker ps&rdquo; 命令中输出的 CONTAINER ID）。 导出容器 在 powershell 中，使用 &ldquo;docker export&rdquo; 命令，可以导出容器。
&gt; docker export {container} &gt; {file path} &gt; docker export -o {file path} {container} {container}，可以填容器 id。 {file path}，导出文件的路径和名字。比如，e:\xxx.tar。 &ldquo;&gt;&rdquo; 操作符和 &ldquo;-o&rdquo; 参数，都表示导出到文件。 建议用第二个命令，在 powershell 中第一个可能有 bug。
]]></content></entry><entry><title>使用 gomock 工具进行单元测试</title><url>/post/computer-science/programming-language/golang/mockgen/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag><tag>test</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64 github.com/golang/mock v1.6.0 正文 gomock 是测试框架；mockgen 是代码生成工具，可以根据接口的规范自动生成代码。
安装 mockgen (https://github.com/golang/mock)，github 上的 README 就是文档。
go 版本大于 1.16 的，使用 go install github.com/golang/mock/mockgen@v1.6.0 命令安装。装完就可以用了，直接命令行窗口输入 &ldquo;mockgen&rdquo; 命令，会得到下面的输出。
&gt; mockgen mockgen has two modes of operation: source and reflect. Source mode generates mock interfaces from a source file. It is enabled by using the -source flag. Other flags that may be useful in this mode are -imports and -aux_files. Example: mockgen -source=foo.go [other options] Reflect mode generates mock interfaces by building a program that uses reflection to understand interfaces. It is enabled by passing two non-flag arguments: an import path, and a comma-separated list of symbols. Example: mockgen database/sql/driver Conn,Driver -aux_files string (source mode) Comma-separated pkg=path pairs of auxiliary Go source files. -build_flags string (reflect mode) Additional flags for go build. -copyright_file string Copyright file used to add copyright header -debug_parser Print out parser results only. -destination string Output file; defaults to stdout. -exec_only string (reflect mode) If set, execute this reflection program. -imports string (source mode) Comma-separated name=path pairs of explicit imports to use. -mock_names string Comma-separated interfaceName=mockName pairs of explicit mock names to use. Mock names default to &#39;Mock&#39;+ interfaceName suffix. -package string Package of the generated code; defaults to the package of the input with a &#39;mock_&#39; prefix. -prog_only (reflect mode) Only generate the reflection program; write it to stdout and exit. -self_package string The full package import path for the generated code. The purpose of this flag is to prevent import cycles in the generated code by trying to include its own package. This can happen if the mock&#39;s package is set to one of its inputs (usually the main one) and the output is stdio so mockgen cannot detect the final output package. Setting this flag will then tell mockgen which import to exclude. -source string (source mode) Input Go source file; enables source mode. -version Print version. -write_package_comment Writes package documentation comment (godoc) if true. (default true) 2022/12/12 10:00:27 Expected exactly two arguments 生成 mock 文件 参数很多但是一般就用两个：&quot;-package&quot; 指定生成的 go 文件的包名；&quot;-destination&quot; 指定生成的 go 文件的位置和文件名。 比如，给 go-redis 的 Cmdable 接口生成 mock，就可以在项目的根目录输入下面的命令。
mockgen -package=mock -destination=&quot;mock/redis_cmdable.mock.go&quot; github.com/redis/go-redis/v9 Cmdable。
这个命令就表示给 go-redis 的 Cmdable 接口生成 mock。生成的 go 文件的包名为 &ldquo;package mock&rdquo;。生成的文件在 &ldquo;./mock/&rdquo; 目录，文件名为 redis_cmdable.mock.go。 有的时候，运行命令之后，文件不是立刻生成的，需要等一会。另外，生成的过程会创建临时目录和临时文件，它们会被自动删掉的，不用管。
如果上面的命令没有生成文件，就先试试不加参数的能不能执行：mockgen github.com/go-redis/redis/v9 Cmdable。这个命令会使用默认配置生成 mock 文件。
如果碰到下面这种报错：
prog.go:12:2: no required module provides package github.com/golang/mock/mockgen/model; to add it: go get github.com/golang/mock/mockgen/model prog.go:12:2: no required module provides package github.com/golang/mock/mockgen/model; to add it: go get github.com/golang/mock/mockgen/model prog.go:14:2: no required module provides package github.com/go-redis/redis/v9: go.mod file not found in current directory or any parent directory; see &#39;go help modules&#39; prog.go:12:2: no required module provides package github.com/golang/mock/mockgen/model: go.mod file not found in current directory or any parent directory; see &#39;go help modules&#39; 2022/12/10 16:40:01 Loading input failed: exit status 1 报错信息里面已经提示了，就执行一下 go get github.com/golang/mock/mockgen/model 命令就行了。
在单元测试里使用 func TestXXX(t *testing.T) { // 开头这里 NewController 和 Finish 是固定要调用一下的 ctrl := gomock.NewController(t) defer ctrl.Finish() // 这个方法是 mockgen 生成的，在 mock/redis_cmdable.mock.go 里面 cmdable := mock.NewMockCmdable(ctrl) // 定义 redis 语句执行的结果 cmd := redis.NewCmd(context.Background(), nil) cmd.SetVal(&#34;OK&#34;) // 把上面定义的执行结果，指定给一个语句 cmdable.EXPECT().Eval(gomock.Any(), {redis 语句}, 语句需要的参数 1, 语句需要的参数 2, ..., gomock.Any()).Return(cmd) } 这么就定义好了，调用 redis 执行指定的 redis 语句的 mock 数据。注意，测试的时候调用的语句和语句需要的参数必须是一样的。而且，上面这种定义方式这里只能调用一次。
cmdable := mock.NewMockCmdable(p7ctrl) cmd := redis.NewCmd(context.Background(), nil) cmd.SetErr(context.DeadlineExceeded) cmdable.EXPECT().Eval(gomock.Any(), {redis 语句 1}, 语句需要的参数 1, 语句需要的参数 2, ..., gomock.Any()).Times(2).Return(cmd) cmd2 := redis.NewCmd(context.Background(), nil) cmd2.SetVal(&#34;OK&#34;) cmdable.EXPECT().Eval(gomock.Any(), {redis 语句 2}, 语句需要的参数 1, 语句需要的参数 2, ..., gomock.Any()).Return(cmd2) 可以用 Times() 方法指定语句的调用次数，如果无限次的话就用 AnyTimes()。如果需要设置多种语句执行的结果，那就像上面那样，挨个定义，挨个设置就行。
用 Times() 的时候，不知道需不需要控制调用次数。这里用的时候发现，如果设置的调用次数没用完测试就结束了，那单元测试会报错。调整一下调用次数和被测试的程序保持一致就行。
controller.go:269: missing call(s) to 中间一大堆，应该就是调用次数没用完那个 redis 语句 controller.go:269: aborting test due to missing call(s) 如果设置了，但是没有调用的话，就会报下面这样的错：
controller.go:269: missing call(s) to 一大堆，会具体说哪个接口没调用 controller.go:269: aborting test due to missing call(s) ]]></content></entry><entry><title>基本输入输出系统（Basic Input/Output System、BIOS）</title><url>/post/computer-science/operating-system/bios/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>bios</tag></tags><content type="html">前言 前置笔记： 中央处理器（Central Processing Unit、CPU）
资料 正文 基本输入输出系统 之前的笔记，大概描述了一下 CPU 的基本运行原理。这里面有一个问题没有讨论，那段程序怎么装到内存里去。
最简单的方法是，直接把程序烧录进内存。如果这么做的话，内存里的数据就是固定的，每次读都一样。 那么这块内存，就不能装载不同的程序，进而达到执行不同的任务的目的。换句话说就是，没有通用性。
现在的计算机里的内存，每次启动的时候都是空的，可以根据需要装载不同的程序到内存中而不用替换内存的。 所以，这里肯定不是直接把程序烧录进内存的。但是，想要让计算机能够装载不同的程序到内存中，这本身又是需要程序去处理的。
就是说，计算机启动之后，需要有一个程序去实现装载不同的程序的功能，但是，这个程序又不能直接烧录进内存。 那么怎么办呢？分开喽。用一块内存专门存储这个程序，然后，用另外一块内存来装载不同的程序。
现在我们都知道了，内存可以分为只读内存（read-only memory，ROM）和随机存取内存（Random Access Memory，RAM）。 那个实现装载不同的程序到内存中的程序，是基本输入输出系统（Basic Input/Output System、BIOS）。
BIOS 是烧录在主板上的 ROM 里面的，一般在计算机主板的非易失性存储芯片上。 它属于固件，负责提供低级别的软件，控制计算机的硬件组件，使其能够启动和运行操作系统。 计算机启动的时候，干的第一件事情，就是运行 BIOS 程序。有了 BIOS 才能干后面的事情。
硬件自检 BIOS 程序干的第一件事情是进行检查，检查计算机硬件能不能满足基本的运行条件。 这个过程叫硬件自检（power-on self-test，POST）。 硬件自检的时候还会识别连接到计算机的设备，比如：显示器、硬盘、键盘、鼠标、等。
如果硬件有问题，主板就会发出蜂鸣。比如，内存条没插好的话，一般会 &amp;ldquo;滴~&amp;rdquo; 一下。 如果硬件没有问题，显示器就会显示硬件的信息。硬件自检完成之后，BIOS 会搜索引导程序，然后，把计算机的控制权转交它。
引导程序 启动顺序 引导程序负责将操作系统加载到内存中。引导程序通常位于外部存储器上，比如： 硬盘（系统盘）的第一个扇区；可启动的 USB 驱动器（装机盘）；CD-ROM（装机光碟）。
计算机的外部存储器可以有好几个，在 BIOS 的操作界面可以设置这些外部存储器的优先级。指定 BIOS 应该先去那个设备上寻找引导程序。 如果在第一块硬盘的第一个扇区没有找到引导程序，BIOS 将按照启动设备的优先级在其他设备上寻找它，比如，第二块硬盘。
启动设备的优先级叫作启动顺序（boot sequence），存储在 CMOS（互补金属氧化物半导体）存储器中， 它是一种非易失性存储器，用于存储 BIOS 设置和配置。CMOS 存储器数量很少，它由主板上的电池供电。
主引导记录 这里用硬盘的第一个扇区为例。扇区是磁盘操作的最小可寻址单位，通常每个扇区有 512 个字节的存储容量。 如果硬盘的第一个扇区的最后两个字节是 0x55 和 0xAA，那么表示这个设备可以用于启动。
这最前面的 512 个字节，就叫做主引导记录（Master boot record、MBR）。主引导记录只有 512 个字节，放不了太多东西。 它的主要作用是，告诉计算机到硬盘的哪一个位置去找操作系统。
主引导记录由三个部分组成。第 1-446 字节：调用操作系统的机器码。 第 447-510 字节：分区表（Partition table）。第 511-512 字节：主引导记录签名（0x55 和 0xAA）。
分区表 分区表的作用是将硬盘分成若干个区，每个区可以安装不同的操作系统。因此，主引导记录必须知道将控制权转交给哪个区。
分区表的长度有 64 个字节，里面又分成四项，每项 16 个字节。也就是说，一个硬盘最多只能分四个主分区（一级分区）。 每个主分区的 16 个字节，由 6 个部分组成。
第 1 个字节：如果为 0x80，就表示该主分区是激活分区，控制权要转交给这个分区。 四个主分区里面只能有一个是激活的。第 2-4 个字节：主分区第一个扇区的物理位置（柱面、磁头、扇区号等等）。
第 5 个字节：主分区类型。第 6-8 个字节：主分区最后一个扇区的物理位置。 第 9-12 字节：该主分区第一个扇区的逻辑地址。第 13-16 字节：主分区的扇区总数。
随着硬盘越来越大，四个主分区已经不够了，需要更多的分区。 但是，分区表只有四项，因此规定有且仅有一个区可以被定义成扩展分区（Extended partition）。 扩展分区里面又分成多个区，叫做逻辑分区（logical partition）。
扩展分区中的每个逻辑驱动器的分区信息都存在一个类似于 MBR 的扩展引导记录（Extended boot record、EBR）中。 它里面也包含一张 64 字节的分区表，但是最多只有两项（也就是两个逻辑分区）。
第一项描述一个逻辑分区，第二项描述下一个扩展分区。如果不存在下一个扩展分区，第二项就不需要使用。 扩展分区的整个结构就像个链表，理论上可以包含无数个逻辑分区。
找到操作系统 找操作系统分为三种情况：
从主分区启动：如果分区表的四个主分区里面只有一个是激活的，计算机会读取激活分区的第一个扇区，叫做卷引导记录（volume boot record、VBR）。 卷引导记录的主要作用是，告诉计算机，操作系统在这个分区里的位置。然后，计算机就会加载操作系统了。
从扩展分区启动：一般不这么干，如果操作系统确实安装在扩展分区，那么一般会用启动管理器（引导装载程序）。
启动管理器（boot loader）：计算机读取主引导记录前面 446 个字节之后，不再把控制权转交给某一个分区， 而是运行事先安装的启动管理器，由用户选择启动哪一个操作系统。比如，Linux 的 Grub，Windows 7 的 Bootmgr。
操作系统 控制权转交给操作系统后，操作系统的内核首先被载入内存。
以 Linux 系统为例，先载入 /boot 目录下面的 kernel。内核加载成功后，第一个运行的是 /sbin/init 程序。 init 进程是 Linux 启动后的第一个进程，pid 进程编号为 1，其他进程都是它的后代。 然后，init 进程加载操作系统的各个模块，进而启动整个 Linux 系统。
如果是 Windows 7 的话，先载入 windows\system32\winload.exe。 然后，winload.exe 去加载 Windows 7 内核和操作系统的各个模块，进而启动整个 Windows 7 系统。
参考 {CSDN}/{JerkWisdom}/
操作系统引导过程
{阮一峰的网络日志}/
计算机是如何启动的？
{百度百科}/[bios、扩展引导记录] ChatGPT
+ DeepL</content></entry><entry><title>Stable Diffusion</title><url>/post/computer-science/application/stable-diffusion/stable_diffusion/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>artificial-intelligence(人工智能)</tag><tag>stable-diffusion</tag></tags><content type="html"><![CDATA[正文 Stable Diffusion + Stable Diffusion web UI + 启动器 {bilibili}/{Aniraiden}/【AI制图教程】5分钟从零极速教会你用AI出图，职业美术实际使用经验技巧{bilibili}/{秋葉aaaki}/【AI绘画】Stable Diffusion 最终版 无需额外下载安装！可更新✓ 训练✓ 汉化✓ 提供7G模型 NovelAI{bilibili}/{秋葉aaaki}/【AI绘画】启动器正式发布！一键启动/修复/更新/模型下载管理全支持！大佬提供了整合包和启动器。整合包只有一个压缩包。启动器有两个文件，一个是启动器的压缩包，一个是启动器运行依赖。先安装启动器运行依赖。
整合包的压缩包和启动器的压缩包直接解压即可。这里假设，整合包解压之后的目录路径是 {Stable Diffusion}，方便下面的说明。
解压完成后，把启动器目录下的所有文件移动到 {Stable Diffusion} 目录覆盖。然后，就可以使用 {Stable Diffusion} 目录下的 A启动器.exe 启动了。
如果没有什么特别的需要，打开启动器后，直接点击右下角的一键启动即可。点击一键启动后，会弹出一个控制台，这个就是程序的本体，不要关掉了。
等待程序启动，看见控制台里输出 Running on local URL: http://127.0.0.1:7860 的时候，就表示启动成功了。
这个时候，应该会自动在浏览器里打开 http://127.0.0.1:7860。如果没有打开的话，可以手动打开浏览器，然后访问 http://127.0.0.1:7860。这里假设，这个界面叫 {web UI}，方便下面的说明。
模型 模型，一般去 civitai下载。常用的一般是 CheckPoint 大模型和 LoRA 小模型。
CheckPoint 把下载下来的模型放到 {Stable Diffusion}\models\Stable-diffusion\ 目录。
{web UI} 界面左上角，Stable Diffusion 模型(ckpt)，在下拉列表里选择需要启用的模型。
LoRA {bilibili}/{秋葉aaaki}/【AI绘画】全新的微调模型！LoRA模型使用教程 插件安装 NovelAI把下载下来的模型 {Stable Diffusion}\extensions\sd-webui-additional-networks\models\lora\ 目录。
正常的写 Tag。然后，设置 &ldquo;可选附加网络(LoRA 插件)&rdquo; 选项。勾选 &ldquo;启用&rdquo;，然后，选择需要的附加网络类型，设置权重。
Tag 语法 &lsquo;,&rsquo;：用于分隔不同的关键词。比如：white hair,red eyes。 &lsquo;|&rsquo;：用于等比例混合。在 web UI 才可以用。比如：white|black hair。 &ldquo;(tag:权重数值)&quot;：用于设置 tag 的权重。权重数值 0.1~100。 &ldquo;(tag)&quot;、&rdquo;((tag))&quot;：用于增加权重。一层小括号，权重增加 1.1 倍。 &ldquo;[tag]&quot;、&rdquo;[[tag]]&quot;：用于减少权重。一层中括号，权重减少 1.1 倍。 &ldquo;[tag1:tag2:数字]&quot;：用于渐变。数字大于 1 表示，第{数字}步之前 tag 1，第{数字}步之后 tag 2。数字小于 1 表示，总步数百分之{数字}之前 tag 1，总步数百分之{数字}之后 tag 2。比如：[white hair:black hair:5]。 &ldquo;[tag1|tag2]&quot;：用于交替。比如：[white hair|black hair]。 Prompt（提示词） Tag 不是越多越好，控制在 100 个以内。只写最关键的 Tag，别的 Tag 有需要的时候在加。注意 Tag 之间的冲突，比如：全身+上半身、长腿+短腿、等。
注意 Tag 的顺序，基本按照画面从上到下的顺序。同类的 Tag 里面，越关键的 Tag，越往前放。但是，有的时候，需要越级调整；有的时候，LoRA 模型有 Tag 要求。
Negative prompt（反向提示词） 反向提示词就是不想出现在画面里的 Tag。这个也不是越多越好，画面有问题的时候在加。
常用 Negative prompt EasyNegative, (worst quality, low quality:1.4), (poorly drawn face:1.4), (extra limbs:1.35), (malformed hands:1.4),(poorly drawn hands:1.4),(mutated fingers:1.4),
异常 报错 1 NansException: A tensor with all NaNs was produced in VAE. This could be because there&#39;s not enough precision to represent the picture. Try adding --no-half-vae commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check. 打开启动器，在左侧菜单栏找到高级选项，在高级选项界面，勾选 &ldquo;不使用半精度 VAE(&ndash;no-half-vae)&rdquo; 和 &ldquo;关闭数值溢出检查(&ndash;disable-nan-check)&quot;。
ControlNet 安装 {bilibili}/{秋葉aaaki}/【AI绘画】完美控制画面！告别抽卡时代 人物动作控制/景深/线稿上色 Controlnet安装使用教程大佬提供了整合包。这里假设，整合包解压之后的目录路径是 {controlnet}，方便下面的说明。
{web UI} --&gt; 扩展 --&gt; 从网址安装。在 &ldquo;扩展的 git 仓库网址&rdquo; 里，输入 https://jihulab.com/hunter0725/sd-webui-controlnet，然后点击下面的安装按钮。
等待安装，安装成功后，会在安装按钮的下面输出 Installed into D:\stable-diffusion\extensions\sd-webui-controlnet. Use Installed tab to restart.
把 {controlnet}\安装\openpose\ 目录下面的文件，放到 {Stable Diffusion}\extensions\sd-webui-controlnet\annotator\openpose\ 目录。
把 {controlnet}\安装\midas\ 目录下面的文件，放到 {Stable Diffusion}\extensions\sd-webui-controlnet\annotator\midas\ 目录。
把 {controlnet}\模型\ 目录下面的文件，放到 {Stable Diffusion}\extensions\sd-webui-controlnet\models\ 目录。
这些都搞定之后，{web UI} --&gt; 扩展 --&gt; 已安装。点击应用并重启用户界面按钮。重启完成后，应该就可以在文生图（别的也行）左下方的设置区域的最下面，看见 ControlNet 的选项。
使用 正常的写 Tag。然后，设置 &ldquo;扩散控制网络(ControlNet)&rdquo; 选项。勾选 &ldquo;启用&rdquo;，如果显存低于 8G，还需要勾选 &ldquo;低显存优化&rdquo;。然后，选择预处理器和模型，这两个要匹配着选。
预处理器选 &ldquo;canny&rdquo;，模型选 &ldquo;control_canny&rdquo;，实现边缘检测，达到上色的效果。 预处理器选 &ldquo;depth&rdquo;，模型选 &ldquo;control_depth&rdquo;，实现深度图，达到指定的画面结构。 预处理器选 &ldquo;hed&rdquo;，模型选 &ldquo;control_hed&rdquo;，实现 hed 边缘检测，没有 canny 那么精准的控制，AI 可以自由发挥。 预处理器选 &ldquo;openpose&rdquo;，模型选 &ldquo;control_openpose&rdquo;，实现人体动作控制。可以用其他软件做出骨骼图。 还有很多其他的。 比如，预处理器选 &ldquo;openpose 姿态及手部检测&rdquo;，模型选 &ldquo;control_openpost&rdquo;。然后，给 ControlNet 一张图片（最好是真人的）。然后，就可以开始生成图片了。
预处理器会参考给的图片生成对应的生成条件图，ControlNet 会用生成条件图去指导 AI 生成图片。这里是可以自己造生成条件图，然后，直接给 ControlNet 的。
个人比较喜欢的模型 CheckPoint 模型 名字 平台 id 链接 描述 AbyssOrangeMix2 - Hardcore civitai 4451 https://civitai.com/models/4451/abyssorangemix2-hardcore二次元、涩涩 Counterfeit-V2.5 civitai 4468 https://civitai.com/models/4468/counterfeit-v25二次元 AnyHentai civitai 5706 https://civitai.com/models/5706/anyhentai二次元、涩涩 ChilloutMix civitai 6424 https://civitai.com/models/6424/chilloutmix写实、涩涩 Cetus-Mix civitai 6755 https://civitai.com/models/6755/cetus-mix二次元 MeinaMix civitai 7240 https://civitai.com/models/7240/meinamix二次元、涩涩 AbyssOrangeMix3 (AOM3) civitai 9942 https://civitai.com/models/9942/abyssorangemix3-aom3二次元、涩涩 MeinaHentai civitai 12606 https://civitai.com/models/12606/meinahentai二次元、涩涩 AOAOKO [PVC Style Model] civitai 15509 https://civitai.com/models/15509/aoaoko-pvc-style-model二次元、PVC 模型 LoRA 模型 名字 平台 id 链接 描述 额外说明 X-Ray Hentai 2.5 civitai 3938 https://civitai.com/models/3938/x-ray-hentai-25二次元、x-射线透视 Tag：x-ray、x-ray view、cross-section。采样方法：Euler、Euler A。 Eye - LoRa civitai 5529 https://civitai.com/models/5529/eye-lora二次元、眼睛 Tag：loraeyes。 明日方舟-年 Arknights-Nian civitai 8185 https://civitai.com/models/8185/arknights-nian明日方舟-年 Tag：origen(普通年)、china dress(旗袍年)。 POV Doggystyle LoRA [1 MB] civitai 8723 https://civitai.com/models/8723/pov-doggystyle-lora-1-mb二次元、后背位 Tag：&lt;lora:POVDoggy:0.9&gt;。权重 0.9~1.0。Tag penis，如果有一般是浅入，如果没有一般是深入。 breastInClass: Better Bodies civitai 9025 https://civitai.com/models/9025/breastinclass-better-bodies写实、身体 Tag：&lt;lora:breastinclassbetter_v141:0.5&gt; Innies: Better vulva civitai 10364 https://civitai.com/models/10364/innies-better-vulva写实、阴部 Tag：&lt;lora:inniesbettervaginas_v11:1.0&gt; [NSFW]Tentacles LoRA | 触手 civitai 11886 https://civitai.com/models/11886/nsfwtentacles-lora-or二次元、触手 Tag：tentacles。 H&amp;K HK416 LoRA civitai 12519 https://civitai.com/models/12519/handk-hk416-loraHK416 Tag：gun、weapons、holding weapon、assault rifle。 站立后背位/立ちバック/standing doggystyle civitai 12682 https://civitai.com/models/12682/standing-doggystyle二次元、后背位 权重 0.5~0.7。共通的 tag 为 1girl,1boy,sex。配合 from normal 可以生成后背的视角、配合 from front 可以生成正对的视角、配合 from side 可以生成侧面的视角、配合 from behind,pov 可以生成后背的 pov 视角。 Doggystyle from side view civitai 12961 https://civitai.com/models/12961/doggystyle-from-side-view二次元、后背位、侧面的视角 采样方法：DPM SDE Karras。 Corruption/悪堕ち/恶堕 civitai 17610 https://civitai.com/models/17610/corruption二次元、恶堕 Tag：corruption、empty eyes、half-closed eyes、evil smile、no pupils、crazy smile。权重 0.3~0.7。 Incoming hug/kiss civitai 21388 https://civitai.com/models/21388/incoming-hugkiss二次元、抱过来、亲过来 Tag：incoming hug(抱过来)、incoming kiss(亲过来)。Nagative：EasyNegative、bad-hands-5。 Murky&rsquo;s After Sex Lying LoRA civitai 18194 https://civitai.com/models/18194/murkys-after-sex-lying-lora二次元、事后 Tag：after sex。 程序本体 {github}/CompVis/stable-diffusion{github}/AUTOMATIC1111/stable-diffusion-webui{github}/Mikubill/sd-webui-controlnet]]></content></entry><entry><title>submodule</title><url>/post/computer-science/application/git/submodule/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>git</tag></tags><content type="html">正文 删除 submodule 目录后，重新执行命令添加的时候报错怎么办 在使用 hugo 的时候，会使用 submodule 来添加主题。误删 submodule 的目录，重新执行命令添加的时候报如下的错误。
&amp;gt; git submodule add https://github.com/hugo-next/hugo-theme-next.git themes/hugo-theme-next fatal: &amp;#39;themes/hugo-theme-next&amp;#39; already exists in the index 解决方法是：
删掉 submodule 的目录。（这里已经被删掉了） 打开 {项目根目录}/.gitmodules，找到对应的 submodule 条目，删掉。 打开 {项目根目录}/.git/config，找到对应的 submodule 条目，删掉。 删掉 {项目根目录}/.git/modules/{对应的目录}。 然后就可以重新执行命令添加了。
参考（reference） git submodule删除后重新添加问题</content></entry><entry><title>本人关于学习的总结</title><url>/post/philosophy/about_study/</url><categories><category>philosophy(哲学)</category></categories><tags><tag>philosophy(哲学)</tag></tags><content type="html"><![CDATA[前言 本篇是本人关于学习的总结。本文中出现的经历包括：本人对于本人的学习过程的时间以及出现的问题做出的总结和反思；另外 3 个朋友对本人的学习过程的实践以及出现的问题做出的总结、反思、交流。样本容量只有 4。所以，可以预见，特例和错误的情况是一定存在的。还请各位到访的访客务必小心。
由于本人能力有限，找不到合适的语言去描述这些关于学习的问题。因为，这些问题本身在本人看来是 &ldquo;不可名状&rdquo; 的。所以，本篇的内容大多数都是借用别的学科的概念或者使用比喻。需要读者自行去理解和把握本人到底在说什么。还请各位到访的访客见谅。
被代码框框起来的文本是和大佬们交流后新增的部分，作为对现有学习思路的补充和更正。 资料 about_study.drawio.html computer_system.drawio.html 正文 本人学习的基本思路 本人的学习思路是在 费曼技巧的基础上增加了自己的东西（主要是理解和把握知识的思路）。然后，以毛主席的《实践论》作为指导思想，进行实践。
学习最终要达到的目的 本人的观点，学习最终要达到的目的并不是只有学到了知识，还有在学到知识的过程中得到的智慧。从某种意义上说，智慧其实是更重要的，但是智慧这东西有点虚，有点 &ldquo;不可名状&rdquo;。
这里引用两段话对这个观点做一下补充解释，但是需要各位访客自行去尝试理解和把握。
他掂量着石头的重量，发现他抬得起这颗石头，也抬的动其他石头。他可以将它们排在一起，建成一个地基、一项工程、一座城堡。
这段话引用自游戏《Braid》。
令人敬畏的事物不需要隐藏，令人敬畏的事物既富有又出手大方。宝藏就在那里。
这段话引用自《诗篇46的秘密》。
本人的这套学习思路。特点是，稳。只要知识能够成功并入体系，那就会是印象深刻的，即使忘了也能很快捡起来。而且，因为是以理解和把握为主，所以重塑性很强。缺点是，慢。因为，需要从多个方向和多个角度对知识进行理解和把握。
本人和几个参与交流实践的朋友，目前用起来没有什么太大的问题。但是，肯定是存在幸存者偏差的。如果各位到访的访客想尝试的话，还请务必小心。
可能让访客觉得奇怪的是，本人通篇没有说明实操的时候具体应该怎么做。这里不是不想说明，原因是不知道哪里入手。
因为本身的实践过程会包含大量的比喻、借喻、暗喻的手法，到具体实施的时候就因人而异了。本人喜欢比喻和借喻，有的朋友喜欢比喻和暗喻，有的朋友本身天赋异禀，有的朋友喜欢等待灵光乍现。
题外话 比记忆力，人是比不过 AI 的。AI 已经在学习如何思考了，但是很多人却还在死记硬背。
学习的过程是怎样的 借助毛主席的《实践论》 如果对如何学习没有什么想法的话，可以把学习泛化成一种实践，然后就可以借助毛主席的《实践论》来进行指导了。
本人的学习思路有两种：一种是有现成的理论可以学的情况（见图：about_study.drawio.html 40-2），另一种是没有现成的理论可以学的情况（见图：about_study.drawio.html 40-4）。
不管是哪种情况，理论和实践经验都需要相互结合。脱离实践的理论是纸上谈兵。实践是认识的根本，不能脱离于实践去学习。但是，脱离理论的实践容易盲目，这个情况也要小心。
作为软件工程师，首先代码肯定是要勤写的，但是不能盲目的堆砌代码。记得留点时间，停下来，对前面写代码的时候的思考过程进行总结和反思。
最基本的学习思路有了之后，还需要有一个打持久战的心理预期。学习是由浅入深的，由片面到深刻的，无限向前发展的过程。知识一般都不会单独出现，要出现就是成群结队的。学习的时候，理论上应该是先一个一个学，然后尝试在它们之间建立联系，最后从整体上理解和把握。
从整体上理解和把握了这块的知识后，其实还没完，这里还只是建立了这块的知识内部之间的联系。还需要把这块的知识放到整个体系中去，再次从体系上理解和把握。让这块的知识和体系中别的知识建立联系。最终要能够理解（这里不强求把握）这块的知识在体系中的来龙去脉。
这里借用桃树来解释一下为什么要这样做。假设，假设有一棵正在开花的桃树，现在要从零开始学习它。花很漂亮，所以，就从花开始。一开始的学习会聚焦于花。花研究完了，发现花是连在树干上的，所以，下一步的学习会聚焦于树干。
树干研究完了。向上，发现树干上除了有花，还有叶子。向下，发现除了地面上的花、树干、叶子，还有地面下的根系。叶子和根系看上去和花没有直接关系，还需要继续研究。发现，叶子可以进行光合作用产生营养，根系会从土壤中吸收营养，树干除了支撑还会输送养分，根系还提供了支撑防止倾倒，它们一起为树的生长提供了条件。
到这里，花、树干、叶子、根系之间的联系已经处理的差不多了。但是，完没完呢？没完。还要把当下的这棵树放到体系中去。现在的这棵树，是从一颗种子开始的。种子发芽后，破土而出，长成小树苗，再一步一步成长到现在。现在这棵树已经开花了，继续发展，后面还会结果，结果之后还会产生新的桃树。
到这里，桃树内部的知识联系的差不多了。但是，完没完呢？依然没完。桃树作为整体还和土地、水源、空气等等有联系。重不重要？重要，这些都是桃树能够存在的前提。但是，需不需要深入研究？其实是不需要的。知道有这么一层的联系就好了。
同样的道理，回到软件工程师。不要局限于某个语言的生态，而是要将语言的生态放到整个软件体系中去，全面的看。到这里，还没有完。软件最终是要跑在计算机硬件上的，它无法脱离计算机体系，但是计算机硬件的知识理解即可，不需要掌握。
由此可见，想学习知识，要关注的内容是很多的。这中间一定是存在反复的过程的。面对失败，不要心生胆怯，回顾一下学习的过程，反思一下哪里有问题，把这些东西总结下来。然后再下一个循环里进行验证。只要能吃一堑长一智，失败便能够成为成功之母。
前面提到的 &#34;学习是由浅入深的，由片面到深刻的，无限向前发展的过程&#34;。不要理解为线性的由浅入深的。 由浅入深后，随着体系的变化，位置可能从相对原来的深变成了相对现在的浅。这是个循环往复，螺旋前进的过程。 这里再借用桃树的生长过程来解释一下。桃树生长的时候，树根的大小、树干的粗细、树冠的大小是匹配的。 小树苗不会先长树根，再长树干；或者先长树干，再长树冠。也不会先长树冠，再长树干；或者先长树干，再长树根。 树根、树干、树冠是一起长的。 不要急于求成。一辈子的饭，要平均到每一天去吃，用一年是吃不完的，如果硬塞进去，那人也没了，这是比较普世而且跨学科跨领域的规律。太快太猛往往会适得其反。对于学习来说，怕的从来都不是慢，怕的是停。
题外话：大有大的难处 桃树是不能无限长大的。这个观点需要各位访客自行理解和把握。 如果按比例把桃树放大 10 倍会发生什么？这可不是简单的树冠变大，树干变粗，根系变大的问题。 这里需要带入参数才能体现。这里意思一下，把桃树抽象成一个均质立方体。 假设，桃树的长、宽、高都是 l，质量是 m，树干的宽度是 r。 那么，整棵树的压力压在树干上，从树干横截面的角度，就是 m/2π(r^2)。 按比例把桃树放大 10 倍后会发生什么？树的长、宽、高都变成 10l，树干的宽度变成 10r，这两个应该没有疑问。 但是，质量呢？是 10m 嘛？不是，是 (10^3)m。 因为，长、宽、高每个方向上都变成 10 倍了，体积从原来的 l^3 变成了 (10l)^3。 又因为是均质的，所以质量就变成 (10^3)m 了。 这个时候，整棵树的压力压在树干上，从树干横截面的角度，就是 1000m/2π((10r)^2) = 10m/2π(r^2)。 按比例放大的时候，桃树是三维放大，但是承载压力的树干的截面是二维放大。 如果组成树干的材料没有变化（如果桃树进化了那另说），那么当压力变大的时候，树干的结构有可能会撑不住的。 把这种情况推演到极端的无限，在这种情况下最合理的造型就是沙堆的形状（金字塔的形状）。 大家经常讨论从 0 到 1 和 从 1 到 n 的区别。但是，从 1 到 n 内部，也是需要分情况讨论的。 从 1 到 2；从 2 到 3；从 3 到 10；从 10 到 10000；它们是不一样的。 从 0 到 1 是从无到有的难；从 1 到 2 是从对一到对多的难；从 2 到 3 和从 3 到 10 相对简单； 从 10 到 10000 是从量变到质变的难。大有大的难处。 题外话：跨学科交流 种果树的时候有两种神奇的操作，嫁接和杂交。让新的果实同时获得两种旧的果实的特点。放到学习里，可以看做是跨学科交流，或者复杂科学。
节选片段 下面是从《实践论》中节选出的本人认为对于学习来说最核心的片段。有时间的话可以通过文末的链接去看一下《实践论》整篇的内容。
&hellip;曾经有一部分教条主义的同志长期拒绝中国革命的经验，否认“马克思主义不是教条而是行动的指南”这个真理，而只生吞活剥马克思主义书籍中的只言片语，去吓唬人们。还有另一部分经验主义的同志长期拘守于自身的片断经验，不了解理论对于革命实践的重要性，看不见革命的全局，虽然也是辛苦地——但却是盲目地在工作。
&hellip;人类社会的生产活动，是一步又一步地由低级向高级发展，因此，人们的认识，不论对于自然界方面，对于社会方面，也都是一步又一步地由低级向高级发展，即由浅入深，由片面到更多的方面。在很长的历史时期内，大家对于社会的历史只能限于片面的了解，这一方面是由于剥削阶级的偏见经常歪曲社会的历史，另方面，则由于生产规模的狭小，限制了人们的眼界。
&hellip;只有人们的社会实践，才是人们对于外界认识的真理性的标准。&hellip;人们要想得到工作的胜利即得到预想的结果，一定要使自己的思想合于客观外界的规律性，如果不合，就会在实践中失败。人们经过失败之后，也就从失败取得教训，改正自己的思想使之适合于外界的规律性，人们就能变失败为胜利，所谓“失败者成功之母”，“吃一堑长一智”，就是这个道理。辩证唯物论的认识论把实践提到第一的地位，认为人的认识一点也不能离开实践，排斥一切否认实践重要性、使认识离开实践的错误理论。
辩证唯物论的认识论把实践提到第一的地位，认为人的认识一点也不能离开实践，排斥一切否认实践重要性、使认识离开实践的错误理论。&hellip;判定认识或理论之是否真理，不是依主观上觉得如何而定，而是依客观上社会实践的结果如何而定。真理的标准只能是社会的实践。&hellip;
原来人在实践过程中，开始只是看到过程中各个事物的现象方面，看到各个事物的片面，看到各个事物之间的外部联系。&hellip;这叫做认识的感性阶段，就是感觉和印象的阶段。&hellip;在这个阶段中，人们还不能造成深刻的概念，作出合乎论理（即合乎逻辑）的结论。
社会实践的继续，使人们在实践中引起感觉和印象的东西反复了多次，于是在人们的脑子里生起了一个认识过程中的突变（即飞跃），产生了概念。概念这种东西已经不是事物的现象，不是事物的各个片面，不是它们的外部联系，而是抓着了事物的本质，事物的全体，事物的内部联系了。概念同感觉，不但是数量上的差别，而且有了性质上的差别。循此继进，使用判断和推理的方法，就可产生出合乎论理的结论来。&hellip;这是认识的第二个阶段。&hellip;认识的真正任务在于经过感觉而到达于思维，到达于逐步了解客观事物的内部矛盾，了解它的规律性，了解这一过程和那一过程间的内部联系，即到达于论理的认识。重复地说，论理的认识所以和感性的认识不同，是因为感性的认识是属于事物之片面的、现象的、外部联系的东西，论理的认识则推进了一大步，到达了事物的全体的、本质的、内部联系的东西，到达了暴露周围世界的内在的矛盾，因而能在周围世界的总体上，在周围世界一切方面的内部联系上去把握周围世界的发展。
认识过程中两个阶段的特性，在低级阶段，认识表现为感性的，在高级阶段，认识表现为论理的，但任何阶段，都是统一的认识过程中的阶段。感性和理性二者的性质不同，但又不是互相分离的，它们在实践的基础上统一起来了。我们的实践证明：感觉到了的东西，我们不能立刻理解它，只有理解了的东西才更深刻地感觉它。感觉只解决现象问题，理论才解决本质问题。这些问题的解决，一点也不能离开实践。无论何人要认识什么事物，除了同那个事物接触，即生活于（实践于）那个事物的环境中，是没有法子解决的。
理性认识依赖于感性认识，感性认识有待于发展到理性认识，这就是辩证唯物论的认识论。哲学上的“唯理论”和“经验论”都不懂得认识的历史性或辩证性，虽然各有片面的真理（对于唯物的唯理论和经验论而言，非指唯心的唯理论和经验论），但在认识论的全体上则都是错误的。由感性到理性之辩证唯物论的认识运动，对于一个小的认识过程（例如对于一个事物或一件工作的认识）是如此，对于一个大的认识过程（例如对于一个社会或一个革命的认识）也是如此。
在马克思主义看来，理论是重要的，它的重要性充分地表现在列宁说过的一句话：“没有革命的理论，就不会有革命的运动。”然而马克思主义看重理论，正是，也仅仅是，因为它能够指导行动。如果有了正确的理论，只是把它空谈一阵，束之高阁，并不实行，那末，这种理论再好也是没有意义的。认识从实践始，经过实践得到了理论的认识，还须再回到实践去。
社会实践中的发生、发展和消灭的过程是无穷的，人的认识的发生、发展和消灭的过程也是无穷的。根据于一定的思想、理论、计划、方案以从事于变革客观现实的实践，一次又一次地向前，人们对于客观现实的认识也就一次又一次地深化。客观现实世界的变化运动永远没有完结，人们在实践中对于真理的认识也就永远没有完结。
借助牛顿第一运动定律 如果上面的说明不好理解的话，这里再借助牛顿第一运动定律做一下解释。
牛顿第一运动定律：任何物体都要保持匀速直线运动或静止状态，直到外力迫使它改变运动状态为止。牛顿第一运动定律又称惯性定律。惯性是物体固有属性之一，物体对其运动状态变化的一种阻抗。
先来看两组示意图。见图：about_study.drawio.html 60-2、60-4。两组图简要描述了物体在不同外力下的运动轨迹。
本人认为，人的思维也可以用惯性定律来解释，惯性思维不一定非要用心理学来解释。人一开始的时候，思维中什么都没有，就相当于处于静止状态。然后，在后面几十年的时间跨度中，不停地接受信息。这些信息就相当于图中的这个外力，信息的正确性和有效性就决定了外力的大小。
在遇到思路上的问题的时候，思维并不是最初的静止状态，而是已经有了方向和速度的。这个时候如果什么都不做，那思路只会沿着原来的方向前进。
这里就分两种情况了。第一种是思路问题不大，目标在当前前进方向的侧前方。这个时候只需要提供合适的外力，略微修正前进的方向即可。持续不断地提供小外力，或者直接一剂猛药提供短时间的大外力。都可以达到目的。
第二种情况是思路偏的有点厉害，目标在当前前进方向的侧后方。这个情况问题就没有第一种情况那么简单了。因为目标在后面，无论是持续不断地提供小外力，或者直接一剂猛药提供短时间的大外力。都改变不了目前依然再向前前进的现状。
这个时候第一要务是让思维停下来。毕竟方向错了，那就是越走越远。所以，当务之急是停下来。这里就会出现一个非常奇诡的场景，明明在努力学习，但是收获却不是很多。很多朋友就会在这个结点产生放弃的思想。
但是，其实并非是没有收获，努力学习在这里产生的效果要分为两个阶段去看。第一个阶段看上去没有收获的原因是，大部分输出都用于 &ldquo;拉住错误思维，让它在错误的方向上停下来&rdquo;，这个过程没有正面的效果，所以看上去像没有收获。
其实这个时候，能停下来，从往错误的方向前进变成原地踏步，就是最理想的结果。在此之后，进入第二个阶段。在第二个阶段中，已经开始朝着反方向慢慢的加速了。这个时候继续持续提供输出，就会朝着反方向越来越快，越来与越接近目标。到这个时候，所谓的收获才会慢慢浮现出来。
另外，不建议使用大力砖飞的提供短时间的大外力的操作，毕竟火箭的加速度，一般人承受不住。
学习学的是什么东西 这里需要借助黑格尔辩证法和天文学中的一些概念。比如，本质是表象的表象、宇宙空间（space）、黑洞（black hole）、光（light）、天体运动轨道。
借助黑格尔辩证法 首先需要来解释一下 &ldquo;本质是表象的表象&rdquo; 是什么意思。
这里借用计算机体系中的缓存的概念来举例子。缓存这个概念在计算机体系中有很多的具象化体现。比如，web 系统的 redis，web 系统的本地缓存组件、mysql 数据库的 buffer pool、cpu 的 cpu cache。
它们看上去形态各异，使用的场景也不一样。但其实，它们都是同一种东西，解决的都是同一种场景。这个例子的关键不在于缓存这个概念最终是什么样的具象化体现，而是在于缓存这个概念是怎么从上面这些具体的场景中提取出来的。
这里画个图来辅助理解一下本人的观点。见图：about_study.drawio.html 20-2-2。如果假设一个 &ldquo;东西&rdquo; 它有表象和本质，那么一般会画成图里那样。外面一层是表象（web 系统的 redis），包着最里面的本质（缓存的概念）。
然后，通常意义上的透过现象看本质就会是图 about_study.drawio.html 20-2-4 描绘的这样。先在外面，仔细地从各个角度研究这个表象，然后在一系列观察、总结、推导之后，发现了被表象包裹着的本质。
到这里，图还是比较好理解的。下面把圆形换成方形，意思是一样的，只不过方便后续画图。见图：about_study.drawio.html 20-4-4。
这个图是什么意思呢？它的意思是，刚才在表象里面发现的本质，其实和表象是一体的，它是从表象的最外面凹陷进去的。只不过形成的这个孔洞非常的小，小到在外面仔细观察都不一定看的见。
也就是说，刚才经过一系列观察、总结、推导之后，发现的所谓的本质，其实还是表象的一部分。因为，没有发现那个微小的孔洞结构，所以，认为这两个不是一个东西。也就是认为表象包裹着本质。
&ldquo;本质是表象的表象&rdquo; 的意思就是，这个本质是其实是假的本质，是表象故意呈现出来误导观察者的。真正的本质和那个孔洞结构有关，这个图形因为这个孔洞的存在，才呈现出现在这个样子。那么，图形原来是什么样子？为什么扭曲成现在这个样子？这个过程才是真正的本质所在（缓存这个概念是怎么被提取出来的）。见图：about_study.drawio.html 20-8。
&#34;本质是表象的表象&#34; 这个概念描述的是站在不同的观察角度的问题。反过来，&#34;表象是本质之本质&#34; 也是成立的。 借助天文学 下面，本人借助天文学从另外一个角度解释，所谓的概念，到底是什么。这里还是用缓存举例。
单个概念 假设有一个概念空间的存在，那么真正的缓存的概念对应的那个位置应该是黑洞（这里直接贴上百科的链接，不了解的可以先看一下：黑洞），没办法直接观察。
在和别人交流缓存这个概念的时候，其实是在不停地朝黑洞发射光线（进行描述）。通过发出的光线的轨迹，去限制那个黑洞的边界。见图：about_study.drawio.html 2-2。
如果光线绕了一圈回来了（逻辑前后是连贯的），那就说明描述是有效的。光线的轨迹圈住了一个范围，概念就在这个范围里面。这里把图形抽象一下，画一个椭圆表示这个有效的描述，就像图 about_study.drawio.html 2-4 里那样。
如果描述的不明所以，或者假大空，那就像图 about_study.drawio.html 4-2 一样。光线都环绕不起来，也就是说黑洞可能的位置有很大一块地方，不知道到底在哪。
如果是泛泛而谈，大概知道个什么东西，那就像图 about_study.drawio.html 4-4 一样。光线环绕是环绕起来了，但是内部的位置有很大一块地方，知道一定在这个范围内，但是到底在哪还是很还不确定的。
如果认知进一步理解了，那反映到图上就是光线环绕起来的范围被缩小了。就像图 about_study.drawio.html 4-6-4 一样。这种情况还存在理解有偏差的情况，虽然进一步理解了，但是还是有点歪（范围不是全方位收缩的，有一个或几个方向没有收缩）。就像图 about_study.drawio.html 4-6-2 一样。
最后经过不断的学习，深入理解了。那就像图 about_study.drawio.html 4-8 一样。可以发射出一条相对精准的光线（比较深刻的描述），用相对较小的范围把黑洞框住（解释缓存的概念）。
上文的这种想法反映到日常场景中，就会和图 about_study.drawio.html 6-2 一样。整体结构如果用形象一点的比喻，就和黑洞一样，中间一个 &ldquo;概念虚空&rdquo;（概念本体），周围一大堆描述光线（大量的人做出的大量的描述）环绕着这个 &ldquo;概念虚空&rdquo;。
外部观察者，不能直接看到那个黑洞（光线都被吸进去了，从外面看上去，就是什么都没有）。但是，周围大量的光线环绕黑洞所形成的明亮的吸积盘，向外界说明着这里有个黑洞。
学习的过程就是，通过 6-2 这个图，从而知道中间有个黑洞（和图 about_study.drawio.html 6-4 一样，但是这个黑洞应该是看不见的）。当自己可以发射新的光线环绕这个黑洞的时候，就意味着掌握了这个概念了（在概念空间知道这个概念到底在哪，而且可以通过发射光线标记它的位置给别人看）。
两个有前后依赖关系概念 如果是两个有前后依赖关系概念的话怎么办？这里借助天体运动轨道来解释。（这里直接贴上百科的链接，不了解的可以先看一下：天体运动）
选择的是日地模型（地月模型也行），只不过这里需要把太阳和地球都替换成黑洞。见图：about_study.drawio.html 6-2。中间的&quot;概念 1&quot;是太阳，也就是前置概念。旁边的&quot;概念 2&quot;是地球，也就是依赖前置概念的概念。
这个应该比较好理解，地球绕太阳运行的原因是 &ldquo;太阳+地球+万有引力&rdquo;，三者缺一不可。虽然，严格意义上说，力的作用是相互的，这里应该不分前后。但是理论上，行星是被恒星塑造出来的，然后才有后面的事情。所以，这里用这个结构来进行比喻。
这里还想上面那样做一个说明。如果对这个整体的概念结构，只描述了概念 1；或者只描述了概念 2（见图：about_study.drawio.html 10-4-2）；或者描述了 概念 1 和概念 2，但是没有描述行星轨道（见图：about_study.drawio.html 10-4-4）；那都是只理解了其中一部分。对整体的概念结构的把握是有残缺的。
所以，必须要对整体的概念结构进行描述。这里又有两种方式，第一种是泛泛的描述（见图：about_study.drawio.html 10-2），大概知道里面有什么，但是不清楚细节。
另一种是深入进去仔细地了解了所有的部分（见图：about_study.drawio.html 10-6-2）。这种其实已经理解的差不多了，但是还缺一点，为什么整体的概念结构长这样？
这得通过不断地观察和实践，最终才能得出结论。见图：about_study.drawio.html 10-8-2。这个理解就是很深刻的，不仅理解这两个概念，还通过不同角度呈现的不同的状态，得出那个隐藏在后面的东西（轨道和万有引力，这两玩意直观上是看不见的）。
到这里就可以得出，对于这种场景，什么样的描述才是深刻的。这个描述应该先描述概念 1，再描述概念 2，然后还要描述这两个概念的关系，最后描述一下整体概念结构。见图：about_study.drawio.html 10-8-4。
这个图其实不完全对，它只描述了一个瞬间。正确的图，应该是无数多个瞬间叠起来的。但是这玩意画不出来，这里就用文字描述一下。就是环绕概念 2 的光线形成的光圈，应该是绕着概念 1 绕圈的。概念 1 应该是被无数个光圈环绕，而不是像现在这样只有一个。
放到行星绕恒星运行的轨道模型上，那就应该先描述恒星（它施加影响），在描述行星（它被影响），然后描述行星在围绕恒星运行（呈现什么现象），最后描述一下是万有引力在对整个结构起作用（隐藏在后面的东西）。
还用上面的光线和黑洞来抽象一下，见图：about_study.drawio.html 12-2、12-4。这两个图不完全对，上面说过了。和上面一样，能通过图 about_study.drawio.html 12-2 推导出黑洞的存在，而且能在每个时刻（注意是每个时刻，这里和上面不一样了）都能发射光线完成上述的环绕，就意味着掌握了这个概念了。
两个互相有依赖关系概念 这种场景就不细说了，见图：about_study.drawio.html 14-2。说起来很复杂，而且场景数量理论上也是无限的，而且复杂度也是无限的，放在这里就是举个例子。希望通过对上面两个例子的说明，访客们对其他的场景也能举一反三。
学习需要学多少东西 借助计算机体系 计算机系统是一个完整的体系，可分为硬件系统和软件系统。软件系统里面还可以分为下层的操作系统和上层的应用程序。
应用程序里面还可以分：最下面的各种编程语言；中间层的各种中间件和支持服务；最上层的业务程序。这里画个简单的示意图。见图：computer_system.drawio.html 2-2。
计算机体系，有一个重要的概念就是抽象。正是因为抽象的存在，让上层下层可以各自独立变化，让工程师们可以更好地分工，可以无心智负担的使用下层提供的接口。
但是这不意味着，下层就不存在了。为了提高对上层的把握，是需要知道上层调用下层的接口的时候，下层到底是怎么提供的服务。
大多数程序员的日常工作其实是局限于软件系统上层的应用程序的最上层的业务程序的部分。这个部分的特点是内容很多，各种眼花缭乱的有意思的新技术层出不穷。
但是再多内容，再新的技术也是需要下层提供支持的。因为最终的程序是要跑在计算机硬件上的，它无法脱离计算机体系。
这里不是说应用层就不重要了，应用层除了有计算机体系内部的知识，还有大量的别的学科的知识。 应用层有大量的通过跨学科交流而诞生的产物，比如（狭义一点，不一定对，但是就那个意思）， 人工智能是和数学交叉，游戏是和图形学交叉，大数据是和统计学交叉。 本人的观点是，向下深入底层，这是计算机体系学习的方向。向上拓宽应用层，这是跨学科交流的学习方向。 两者其实都是复杂科学的学习方向，复杂的方向不一样而已。 要避免一个误区。开始上层的工作，不需要完全掌握下层。因为，下层还有下层，下层的下层还有下层，是学不完的。想做一盘菜，需要掌握切菜、炒菜的技能。怎么造菜刀、怎么造锅、怎么种菜，其实是不需掌握的。
实际上，上层的工作，往往是边做边学习的过程。遇到不会的点，就针对性的去学那个点还有一下相关的点就好了，只需要掌握必要的知识和技能就行，不需要把那个点所在的整块都学会。
这里也不是说，光会调包就可以成为某个方面的专家。而是说有，一些过于深入并且已经完全成熟或者是完全可靠的技术和知识是不需要去掌握的。知道怎么用就行了。
人的精力有限。&ldquo;吾生也有涯，而知也无涯。以有涯随无涯，殆已！已而为知者，殆而已矣！&quot;。虽然不能掌握全部的细节，但是大概了解每个部分在干什么，还是可以的。
参考（reference） 费曼技巧 实践论{bilibili}/YJango学习观系列视频 一款硬核解密游戏，一个“疯子”的第九艺术朝圣之路诗篇46的秘密【重译版】{北风计算机编程}/为什么要学习底层{bilibili}/渤海小吏缓慢进化的人性系列视频、楚汉双雄系列视频 ]]></content></entry><entry><title>计算机网络（computer network）</title><url>/post/computer-science/network/network/</url><categories><category>network(网络)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>network(网络)</tag></tags><content type="html"><![CDATA[资料 network.drawio.html 正文 计算机网络 计算机一开始的时候和网络并不是密切相关的。网络这种结构很早以前就出现了。比如，古代的驿站体系、近代的情报系统等，都是靠人、牲畜、载具搭建起来的。
计算机一开始出现的时候，都是独立存在的大型机器。后来，随着计算机的发展，在计算机之间分享数据和资源渐渐变得有用起来。随即，计算机网络出现了。
局域网 计算机网络刚开始的时候，是几台距离很近的计算机，通过电缆连起来之后，一起分享物理资源（比如，存储器和打印机）。见图：network.drawio.html 2-2。要不然，的把存储器（纸卡、磁带）搬来搬去，很麻烦。
这种由计算机近距离构成的小型网络就是局域网（local area network、LAN）了。局域网可以是小到同一个房间里的两台机器，或者大到一个区域内的成百上千台机器。
以太网 局域网里如果只有两台机器那还好说，一对一通信没有歧义。但是如果是两台以上的机器，它们之间通过电缆连起来之后，怎么进行通信呢？电缆上的电信号是没有指向的，只要有计算机将数据发送到电缆上，那么所有的计算机都能收到电信号。
MAC 假设，现在一个局域网里有 4 台计算机（a、b、c、d）。见图：network.drawio.html 4-2。a 想将数据发送给 d。这个时候，a 向电缆上发送了数据，那么 b、c、d 都能识别到电信号，也就是都能接收到一样的数据。问题来了，b 和 c 怎么知道数据不是给自己的，d 怎么知道数据是给自己的。
这里就需要用到以太网（ethernet）了。为了解决这个问题，以太网规定，每台计算机都有唯一的媒体访问控制地址（media access control address、MAC address）。把这个地址放在要传输的数据的最前面，这样网络中的每一台计算机接收到数据后，就可以知道这个数据是不是发给自己的。
类似这种多台计算机共享同一个传输媒介的方法叫载波侦听多路访问（carrier sense multiple access、CSMA）载体（carrier）指的是运输数据的媒介，以太网用的是电缆，WiFi 用的是空气。多个计算机同时在检测载体中的信号，所以叫多路访问和侦听。
冲突 用共享载体有一个很大的弊端，整个网络上同一时间只能有一台计算机发送信息。如果有多个计算机同时发送信息，电信号就要打起来了，这叫冲突。随着网络中计算机变多，这种情况出现的概率也会变高。
为了防止出现冲突，计算机可以先检测网络中是不是有数据，如果有那就停止传输，等待网络空闲下来，然后再次尝试。问题在于，别的计算机也会这么做，冲突依然不可避免。
以太网解决这个问题的方式是，如果检测到冲突，就会在再次尝试之前等待一段时间。等待时间由一个设置好的时间间隔和一个随机时间组成。如果时间到了再次尝试依然检测到冲突，那么意味着网络处于拥塞状态。
这个时候，等待时间的时间间隔会翻倍。如果时间到了再次尝试依然检测到冲突，那么等待时间的时间间隔会继续翻倍，直到成功传输。这种以指数增长的等待方式叫指数退避（exponential backoff）。
交换机 尽管以太网可以一定程度上解决冲突的问题，但是如果所有的计算机都连接在同一个载体上，那冲突问题依然还是很严重的。为了减少冲突，提升效率，就需要减少同一载体中设备的数量。
冲突域 载体和连接在载体上的设备构成一个冲突域（collision domain）。上文的 4 台计算机（a、b、c、d）和连接它们的载体构成了一个冲突域。为了减少冲突，可以使用交换机（switch）把它拆成两个冲突域。见图：network.drawio.html 4-4。交换机位于两个网络之间，只有在必要时才在两个网络间传递数据。
假设，a 和 b 一个冲突域，c 和 d 一个冲突域。a 将数据发送给 b 的时候，交换机不会把数据发送给 c 和 d 所在的网络。也就是说，这个时候 c 和 d 所在的网络依然是空闲的。这样，c 就可以在同一时间将数据发送给 d。
如果是 a 将数据发送给 d 的场景。这个时候，交换机就会把数据发送给 c 和 d 所在的网络，这个时候两个网络都处于被占用的状态。就和上文 a、b、c、d 在一个冲突域中是等价的。
路由 电路交换 想连接两台相隔遥远的计算机或者网络，最简单的办法是分配一条专用的通信线路。早期的电话系统就是这样运作的，这种方式叫电路交换（circuit switching），是直接用电路把两者连接起来。
这种方式用到是能用，但是，对于普通的通信需求来说。为每一对计算机或者网络都铺设专门的线路，价格过于昂贵。而且总有线路处于空闲状态，太浪费。除非真的有需要铺设专线进行通信的需求。
报文交换 另一种传输数据的方式是报文交换（message switching）。它的运行方式有点像邮政系统。两个设备之间的线路上会有多个类似站点的东西，每个站点都知道数据的下一站需要发到哪里。见图：network.drawio.html 6-2。
计算机连成网络之后，两个点之间通常会有不止一条路线，这些不同的路线就叫路由（routing）。报文交换的好处是，有多个不同的路由可以使用，这样相比较专线而言，可靠程度更高。
消息沿着路由跳转的次数叫跳数（hop count）。跳数可以记录到消息里面，用于判断路由有没有出现问题。因为在网状的结构中，有可能出现环形结构或者消息在两个路由器之间来回传递。如果某条消息的跳数很高，那么路由肯定哪里出问题了。
报文交换的站点一次只能传递一个消息，如果消息很大，那就有可能堵塞网络。后面的消息，要么等待前面的大消息传完，要么选择另一条效率稍低的路由。
分组交换 分组交换（packet switching）可以解决报文交换的网络被大消息堵塞的问题。
分组交换将整个消息分成很多的小块，叫数据包（packet），每个数据包都需要包含目标地址（目标的位置）。这种消息的格式由网际互连协议（IP、internet protocol）定义。IP 协议规定，每台计算机都需要一个 IP 地址。这样，路由器（站点）就可以知道需要将数据包发到哪里去。
路由器还会平衡与其他路由器之间的负载，如果有一个大消息，可能会造成单挑路由阻塞，那就可以通过多个路由进行发送。见图：network.drawio.html 8-2-2、8-2-4。这也叫拥塞控制（congestion control），可以保证网络传输的可靠性和速率。
去中心化 报文交换和分组交换这样的网状结构就是去中心化（decentralization）的结构，网络中的两个点之间存在多条路由。如果一条路由因为某些原因失效了，也可以使用别的路由继续进行消息的传输。
互联网 想接入互联网，首先需要和互联网服务商（internet service provider、ISP）打交道。比如，去中国电信办理一个宽带服务。然后工作人员会上门安装一个光猫，通过光猫就可以接入互联网了。如果家里有多台设备需要上网的话，还需要安装一个路由器。这个路由器连接的家里的所有的设备构成了一个局域网。
然后，路由器通过光猫再连接到广域网（wide area network、WAN）。广域网也有路由器，它们一般属于互联网服务商。在广域网里，会先连接到一个区域性路由器，这个路由器可能覆盖一个小区或者一个街道。然后，再连接到一个更大的广域网，可能覆盖一个城市。
可能再跳几次，最终到达互联网主干。互联网主干由一群超大型、超高带宽的路由器组成。在 Linux 或者 Windows 操作系统中可以使用 traceroute 命令来看网络跳了几次。
比如，在 Windows 的 Power Shell 里面用 tracert 命令，跟踪一下 www.baidu.com的访问过程。
&gt; tracert www.baidu.com 通过最多 30 个跃点跟踪 到 www.a.shifen.com [180.101.50.242] 的路由: 1 1 ms &lt;1 毫秒 &lt;1 毫秒 XiaoQiang [192.168.31.1] 2 3 ms 1 ms 1 ms 192.168.1.1 3 9 ms 7 ms 11 ms 100.65.0.1 4 4 ms 7 ms 7 ms 61.152.5.173 5 * * * 请求超时。 6 * * 9 ms 202.97.72.206 7 10 ms 88 ms 9 ms 58.213.95.26 8 * * * 请求超时。 9 11 ms 10 ms 10 ms 58.213.96.66 10 * * * 请求超时。 11 * * * 请求超时。 12 * * * 请求超时。 13 11 ms 9 ms 9 ms 180.101.50.242 跟踪完成。 数据包是如何传输的 上文提到，数据包里有 IP 地址。IP 协议负责把数据包送到正确的计算机。但是，计算机上同时在运行的程序一般不止一个。计算机收到数据包后，应该交给那个程序呢？
因此，需要在 IP 协议之上，开发更高级的协议。比如，传输控制协议（transmission control protocol、TCP） 和用户数据报协议（user datagram protocol、UDP）。TCP 和 UDP 规定，数据包里还需要有端口号。
每个想访问网络的程序都需要向操作系统申请一个端口号。这样，操作系统在接收到数据包之后，就可以根据端口号，把数据包送到正确的程序。
域名系统 数据包是通过 IP 地址和端口号进行传输的。但是，在使用浏览器时，输入的并不是 IP 地址，而是网址（域名）。这个功能由域名系统（domain name system、DNS）提供，它负责把域名和 IP 地址一一对应。
当在浏览器里输入一个网址的时候，会先去 DNS 服务器找这个网址对应的 IP 地址。DNS 服务器一般由互联网服务商提供。如果网址有效，则会返回 IP 地址。如果网址无效，则会返回 DNS 解析错误。
域名的数量是非常多的，用一个超长的列表存储全部的域名和对应的 IP 地址是不合适的，DNS 用的是树状结构。最上面是顶级域名，顶级域名下面是二级域名，二级域名下面是子域名。这样，数据就可以散布在很多的 DNS 服务器上，不同的服务器负责树的不同部分。
网络分层模型 这里主要讨论 4 层的 TCP/IP 网络模型，它是常见的网络分层模型的一种。TCP/IP 网络模型的 4 层 &ldquo;从上到下&rdquo; 分别是，应用层、传输层、网络层、数据链路层（网络接口层）。应用层上面，面向的是各种用户，数据链路层下面，面向的是物理结构。
应用层，各种用户使用的各种应用软件都是在应用层实现的。当两个设备上的应用需要进行通信的时候，应用就会把需要传递的数据交给传输层，由传输层完成数据的传输工作，应用层不需要关心数据是如何传输的。
这就类似于，位于两地的人（比如，人 a 和 人 b）需要进行交流的时候，只需要写封信，然后，交给邮递员，由邮政系统完成信的邮递工作，写信的人是不需要关心信是怎么被邮递过去的。应用层常见的协议有 HTTP、FTP、DNS。
TCP 位于传输层。位于传输层的还有 UDP。IP 位于网络层。
ICMP（internet control message protocol、internet 控制报文协议） BGP（border gateway protocol、边界网关协议） 万维网 万维网（world wide web、WWW）可以用浏览器来访问，它运行在互联网之上，和互联网是不同的东西。在计算机组成的网络中，互联网是传输数据的工具，二万维网是其中传输数据最多的程序。
万维网的最基本的单位是单个页面。页面上有内容，也有其他页面的链接，这些链接也叫超链接（hyperlink）。这些超链接形成巨大的互联网络，这也是万维网名字的由来。
没有超链接的时候，想要访问某个文件，需要准确地知道这个文件在计算机的哪个目录下面。有了超链接之后，为了使网页能互相连接，每个网页需要一个唯一的地址，这地址就是统一资源定位器（uniform resource locator、URL）。
如果网页的数据只有纯文本，那么是无法表明什么是链接什么不是链接的，所以需要定义一套规则来进行标记，这就是超文本标记语言（hypertext mark-up language、HTML）。随之一起的，还有基于 TCP 协议开发的超文本传输协议（hyper text transfer protocol、HTTP）
参考（reference） Crash Course Computer Science（计算机科学速成课） bilibiliCrashCourse 字幕组Youtube 原视频28、计算机网络-Computer Networks 29、互联网-The Internet 30、万维网-The World Wide Web ]]></content></entry><entry><title>【实验性质，带图片】Golang 实现简单的 Web 框架 -- middleware(中间件)</title><url>/post/computer-science/programming-language/framework/web/golang/middleware_v4/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>web</tag><tag>http</tag><tag>middleware(中间件)</tag><tag>golang</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64 资料 {demo-golang}/demo/web/middleware/ web.drawio.html 前置笔记：【实验性质，带图片】Golang 实现简单的 Web 框架 &ndash; router(路由)正文 前置（后置）工作成对出现 承接上一篇的问题，在前一篇里讨论前置（后置）工作的时候，都是以 &ldquo;前置（后置）工作是可以独立执行的整体&rdquo; 为前提讨论的。如果它们之间有合作关系，也就是需要相互传递数据，那么怎么办呢？这里可以使用封装的思路，设计一个全链路通用的数据结构。然后所有的前置（后置）工作和最终的处理方法都接收这个数据结构作为参数。
在最外层 ServeHTTP 方法最开始的地方创建一个这样的数据结构，先封装 ServeHTTP 方法的两个参数，然后在后面调用到的所有方法那里一层一层传下去。如果后面的工作需要前面的工作的数据，就可以借助这个数据结构进行传递。
type 全链路通用的数据结构 struct { // ServeHTTP 方法的两个参数 http.ResponseWriter *http.Request // 其他参数 } 这里沿用上一篇中，访问 &ldquo;/user/id&rdquo; 的时候的结果。结合上面说的全链路通用的数据结构，最终地执行逻辑可以总结成下面这样。注意一定是引用传递，值传递进去的是一个副本，方法里面修改副本是不会影响外面的这个本体的。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 构造一个全链路通用的数据结构，封装 ServeHTTP 方法的两个参数 // 前置工作 user (引用传递全链路通用的数据结构) // 前置工作 user-id (引用传递全链路通用的数据结构) // /user/id 的处理逻辑 (引用传递全链路通用的数据结构) // 后置工作 user (引用传递全链路通用的数据结构) } 这里画个代码块的示意图，见图：web.drawio.html 6-6-2，下面要用。
这个结构可以解决需要互相传递数据的问题。比如，如果 &ldquo;后置工作 user&rdquo; 需要使用 &ldquo;前置工作 user&rdquo; 生成的数据，那就可以借助全链路通用的数据结构，&ldquo;前置工作 user&rdquo; 在执行的时候往里面塞点东西，这样后面的流程就可以用了。看上去没有什么大的漏洞。
处理异常 前面所有的流程里面，都是以代码正常执行为前提进行设计的，尚且没有考虑异常处理，因为异常处理本身确实就比较烦。
有 try-catch 结构的语言，直接一个大的 try-catch 包起来。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 构造一个全链路通用的数据结构，封装 ServeHTTP 方法的两个参数 try { // 前置工作 user (引用传递全链路通用的数据结构) // 前置工作 user-id (引用传递全链路通用的数据结构) // /user/id 的处理逻辑 (引用传递全链路通用的数据结构) // 后置工作 user (引用传递全链路通用的数据结构) } catch () { } } 没有 try-catch 结构的语言，只能在最后接收参数的地方判断一下返回值的内容，根据返回值的内容进行相应的处理。Golang 在最前面还可以加个 recover 恢复块。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 构造一个全链路通用的数据结构，封装 ServeHTTP 方法的两个参数 defer func(){ recover() } // 前置工作 user (引用传递全链路通用的数据结构) // 前置工作 user-id (引用传递全链路通用的数据结构) // /user/id 的处理逻辑 (引用传递全链路通用的数据结构) // 后置工作 user (引用传递全链路通用的数据结构) if x == 全链路通用的数据结构里的标记位 { // 标记位等于 x 就怎么怎么样 } else if y == 全链路通用的数据结构里的标记位 { // 标记位等于 y 就怎么怎么样 } } 屏蔽复杂度 前面的设计已经解决了绝大部分的问题。但是还有一点缺陷，全链路通用的数据结构里面会杂糅大量的数据。这些数据对于后面的整个流程来说是必须的，但是对于其中某一些流程来说，不是必须的。
比如，&ldquo;前置工作 user&rdquo; 和 &ldquo;后置工作 user&rdquo; 想要进行沟通，所以在全链路通用的数据结构里面放了一个值。但是，这个值对于 &ldquo;前置工作 user-id&rdquo; 和 &ldquo;/user/id&rdquo; 的处理逻辑来说就是没用的。
那么这里怎么优化呢？&ldquo;前置工作 user&rdquo; 和 &ldquo;后置工作 user&rdquo; 不是想要进行沟通嘛，那么能不能直接把这两个部分直接连起来呢？可以的，把中间的 &ldquo;前置工作 user-id&rdquo; 和 &lsquo;&quot;/user/id&quot; 的处理逻辑&rsquo; 看作一个整体的代码块。
那么这里需要的，就是以一整个方法作为参数的结构。代码（伪代码）就会变成类似下面这样的结构。这样的话，前面需要放到全链路通用的数据结构里的值是不是就不要了。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 构造一个全链路通用的数据结构，封装 ServeHTTP 方法的两个参数 func 前置工作 user + 后置工作 user (引用传递全链路通用的数据结构) { // 前置工作 user 的处理逻辑 func 剩下的 (引用传递全链路通用的数据结构) { // 前置工作 user-id (引用传递全链路通用的数据结构) // /user/id 的处理逻辑 (引用传递全链路通用的数据结构) } // 后置工作 user 的处理逻辑 } } 上面那个代码块示意图会变成这样，见图：web.drawio.html 6-6-4。
这个结构怎么实现呢？首先需要注意到，这里需要传进去的已经不是那个全链路通用的数据结构了。需要传进去的是上面的伪代码中，中间的那个 &ldquo;func 剩下的&rdquo; 部分，也就是下面这部分。它是一个整体的代码块，或者说是一个完整的方法。
func 剩下的 (引用传递全链路通用的数据结构) { // 前置工作 user-id (引用传递全链路通用的数据结构) // /user/id 的处理逻辑 (引用传递全链路通用的数据结构) } 这个部分还有一个问题，&ldquo;func 剩下的&rdquo; 里面的 &ldquo;前置工作 user-id&rdquo; 不是处理逻辑的一部分。换句话说，上面这个操作只是个 &ldquo;前置工作 user&rdquo; 和 &ldquo;后置工作 user&rdquo; 恰好成对出现的特例，无法推广出一个通用的操作技巧。那么怎么办呢？
这里的 &ldquo;前置工作 user-id&rdquo; 如果能和 &ldquo;前置工作 user&rdquo; 一样，有一个 &ldquo;后置工作 user-id&rdquo; 和它配对是不是就行了。所以，补一个 &ldquo;后置工作 user-id&rdquo; 给 &ldquo;前置工作 user-id&rdquo;，这个 &ldquo;后置工作 user-id&rdquo; 什么都不做，单纯就是占个位置。
同样的如果只有后置工作，也可以补一个什么都不做的前置工作。这样就变得和上面 &ldquo;前置工作 user&rdquo; 和 &ldquo;后置工作 user&rdquo; 一样了。
func 剩下的 (引用传递全链路通用的数据结构) { // 前置工作 user-id (引用传递全链路通用的数据结构) // /user/id 的处理逻辑 (引用传递全链路通用的数据结构) // （补一个）后置工作 user-id (引用传递全链路通用的数据结构) } 然后，整个代码就可以变成这样了，一个类似套娃的结构。上面那个代码块示意图会变成这样，见图：web.drawio.html 6-6-6。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 构造一个全链路通用的数据结构，封装 ServeHTTP 方法的两个参数 func 前置工作 user + 后置工作 user (引用传递全链路通用的数据结构) { // 前置工作 user 的处理逻辑 func 前置工作 user-id + 空的后置工作 user-id (引用传递全链路通用的数据结构) { // 前置工作 user-id // /user/id 的处理逻辑 (引用传递全链路通用的数据结构) // （补一个）后置工作 user-id } // 后置工作 user 的处理逻辑 } } 这样，除了最里面的处理逻辑，外面的前置（后置）工作的部分，就都可以抽象成同一个结构了，是可以随意组合或者调整顺序的。
中间件 上面这玩意就是所谓的中间件（Middleware）的概念了，见图：web.drawio.html 6-2-2。也就是常听到的洋葱模型，见图：web.drawio.html 6-2-4。或者同心圆模型，见图：web.drawio.html 6-2-6。
本人更喜欢同心圆模型。前面两个模型的示意图，都没有明显的把嵌套的关系展现出来，更多的展示的是层层递进的关系。而同心圆模型，精准地反映了嵌套的关系，一层一层的进去之后，不管怎么走，都要再一层一层的原路出来。
中间件的设计（Golang） 代码结构设计 上面有两个部分需要定义：前置（后置）工作和处理逻辑。全链路通用的数据结构，上面已经定义过了，这里直接用。
// HTTPHandleFunc 处理逻辑 type HTTPHandleFunc func(ctx *HTTPContext) // HTTPMiddleware 前置（后置）工作 type HTTPMiddleware func(next HTTPHandleFunc) HTTPHandleFunc 处理逻辑没什么好说的，接收全链路通用的数据结构就行了。重点在于前置（后置）工作，它需要一个处理逻辑作为输入，然后再返回一个新的处理逻辑。
新的处理逻辑内部需要调用传入的那个处理逻辑，形成一个套娃的结构。具体的前置（后置）工作的实现方式，就像下面这样。
func DemoMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(ctx *HTTPContext) { // before DemoMiddleware next(ctx) // after DemoMiddleware } } } 这里假设定义两个前置（后置）工作。
func AMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { // before AMiddleware next(p7ctx) // after AMiddleware } } } func BMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { // before BMiddleware next(p7ctx) // after BMiddleware } } } 假设，具体的处理逻辑，定义成下面这样。
func UserId (p7ctx *HTTPContext) { // get user by id } 然后这么链起来，B 在内层，A 在外层。
// 最内层的处理逻辑 chain := func UserId() // 套第一层 mb := BMiddleware() chain = mb(chain) // 套第二层 ma := AMiddleware() chain = ma(chain) // 执行 chain(ctx) 怎么装起来的见图：web.drawio.html 6-4。最后的效果等价于下面这样的伪代码。
// before AMiddleware // before BMiddleware serve(p7ctx) // after BMiddleware // after AMiddleware 测试用例设计 这种结构没办法直接进行测试，可以使用一些间接方法。比如，让每个中间件都输出一个全局唯一的而且没有前缀冲突的字符串到全链路通用的数据结构里面。整个链路运行之后，从全链路通用的数据结构里面取出字符串，和测试用例相比较。下面举个例子。
func UserId (p7ctx *HTTPContext) { p7ctx.TestString = append(p7ctx.TestString, &#34;UserId;&#34;) } func AMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { p7ctx.TestString = append(p7ctx.TestString, &#34;beforeA;&#34;) next(p7ctx) p7ctx.TestString = append(p7ctx.TestString, &#34;afterA;&#34;) } } } func BMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { p7ctx.TestString = append(p7ctx.TestString, &#34;beforeB;&#34;) next(p7ctx) p7ctx.TestString = append(p7ctx.TestString, &#34;afterB;&#34;) } } } 测试用例 2 chain := func UserId() mb := BMiddleware() chain = mb(chain) ma := AMiddleware() chain = ma(chain) chain(ctx) 结果：&ldquo;beforeA;beforeB;UserId;afterB;afterA;&rdquo;
测试用例 4 chain := func UserId() ma := AMiddleware() chain = ma(chain) mb := BMiddleware() chain = mb(chain) chain(ctx) 结果：&ldquo;beforeB;beforeA;UserId;afterA;afterB;&rdquo;
可路由的中间件 上面实现的那个就是可路由的中间件。它就是在路由树的基础上，分别给每个路由树结点设置中间件。这样在匹配过程中，如果结点上设置了中间件，那么就把这些中间件记录下来。在路由匹配到某个路由结点获取到路由的处理方法之后，把最终的处理方法和这些中间件按照定义好的顺序套起来即可。
参考（reference） {极客时间}/Go 实战训练营Web 框架部分 ]]></content></entry><entry><title>【实验性质，带图片】Golang 实现简单的 Web 框架 -- router(路由)</title><url>/post/computer-science/programming-language/framework/web/golang/router_v4/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>web</tag><tag>http</tag><tag>router(路由)</tag><tag>golang</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64 资料 {demo-golang}/demo/web/router/ web.drawio.html 前置笔记：Golang 开启 HTTP 服务正文 Web 框架是什么 概念解释 简单的理解，Web 框架就是工程师们在反复开发 WEB 系统的后端服务时，对于 &ldquo;如何处理重复的代码&rdquo; 这个问题，想出的一种解决方案。Web 框架的核心目标主要有：减少重复的代码，提高代码的可维护性；提供常用的组件，提高编程的效率。
重复的代码分为两种。一种是，在一个工程中，多处都需要使用的代码。另一种是，在多个工程中，都需要使用的代码。Web 框架内部的设计是为了解决在一个工程中的重复的代码，Web 框架本体的设计是为了解决在在多个工程中的重复的代码。
在一个工程中的重复的代码是指，在一个工程中，有多处的逻辑是相同的，但是编码实现的时候，没有对逻辑进行封装，而是暴力的把代码复制粘贴。这么做会导致，如果这块逻辑有变化，那么所有复制粘贴的地方都需要修改。
在多个工程中都需要使用的代码是指，在多个项目中，可能都需要路由、中间件、参数校验、日志等常用的组件。这个时候就可以把这些常用的组件打包到一起，下次在需要构建类似的工程的时候，就可以直接拿过来用。
比喻解释 用比喻来理解，Web 框架就相当于毛坯房外加一堆事先准备好的建材。毛坯房是指，房屋的框架结构有了但是里面没有装修。事先准备好的建材是指，在房子外面事先准备好了砖头、水泥、石灰这类最基础的材料。毛坯房本体直接就可以用，如果使用者有别的需要，也对房屋进行不同的装修，添加不同的内饰。
比如，烘焙店和服装店内部装修肯定是不一样的。在进行装修的时候，可以直接使用事先准备好的建材。如果觉得事先准备好的建材不能满足需求，那就需要自行准备新的建材。比如，烘焙店和服装店如果想加一面墙，那可以直接用事先准备好的砖头、水泥。但是如果烘焙店想铺木地板或者服装店想贴墙纸，那就需要自行准备了。
这套逻辑套到 Web 框架上来是一样的，毛坯房对应的就是框架的核心组件，事先准备好的建材对应的就是常用的组件。对于 Web 系统来说，主要任务都是处理网络请求（毛坯房本体）。但是具体到不同的业务系统，它们内部处理的具体的业务逻辑肯定是不同的（不同的装修、不同的内饰）。比如，商城系统主要是处理商品和订单的，成绩管理系统主要是处理成绩的。但是有可能会使用相同的组件（事先准备好的建材）。比如，都需要登录、都需要记日志。
本人想到的最合理的解释 如果通过前面的概念和比喻还是不怎么好理解什么是 WEB 框架，那么还有一个更简单的理解，工程师们想偷懒，他们通过创造并使用 Web 框架这个工具，来达到偷懒的目的。
Web 框架是怎么被创造出来的 现在是知道有 Web 框架这么个工具了，但是这个工具是怎么被创造出来的呢？想要解释这个问题，就必须回到 Web 框架这个概念还没有出现的 &ldquo;蛮荒时代&rdquo; 去。下面将结合代码来说明这个问题，代码将会使用 Golang 处理 HTTP 1.1 的请求。
从 TCP 开始 别看见 TCP 就紧张，这里不要求深入了解 TCP 的细节，只需要知道 TCP 是一个字节流协议就可以了。字节流协议，它的意思就是说，传输数据的时候，它是以字节为单位的，传输的过程像流水一样，一个字节接着一个字节的。见图：web.drawio.html 2-2。
HTTP 1.1 是基于 TCP 协议实现的，所以 HTTP 1.1 也可以说是一种字节流协议。这里为什么要说这个呢？主要是想强调一下，在计算机的 &ldquo;眼里&rdquo;，HTTP 报文它不是一个整体，而是一个一个字符。HTTP 1.1 报文大概的格式见图：web.drawio.html 2-4-2、2-4-4。
既然发出去的 HTTP 报文就是一串字符，那么如果不说明这串字符怎么解读，那这串字符就毫无意义。所以客户端和服务端会通过约定请求行的 method 和 url 来区分不同的报文，method 和 url 的组合就是路由。
可以区分不同的报文之后，后面的请求头部和请求体才有意义。分析 HTTP 报文是什么类型，然后根据类型提取报文中的数据的过程就是解析 HTTP 报文的过程。
Golang 的 &ldquo;net&rdquo; 包和 &ldquo;net/http&rdquo; 包 在 net 包里，提供了对 TCP 的支持。而 &ldquo;net/http&rdquo; 包就是基于 net 包，实现了对 HTTP 协议的解析。这里就不费劲的从 TCP 开始搞了，怎么使用 TCP 和解析 HTTP 报文对理解 Web 框架其实没啥帮助。所以直接从 &ldquo;net/http&rdquo; 包开始。
再继续之前，建议先看一下 前置笔记：Golang 开启 HTTP 服务。下面会直接从 &ldquo;net/http&quot;包 的 Handler 接口的 ServeHTTP 方法切入。在 ServeHTTP 方法的第二个参数 &ldquo;*Request&rdquo; 里面，就可以拿到已经解析好的 HTTP 请求。
type Handler interface { ServeHTTP(ResponseWriter, *Request) } 从最简单的场景开始 假设，所有接口的处理逻辑都是一个完整的整体。
如果啥都不考虑，那大可以直接用 if-else 的结构去判断 method 和 url，然后在 if-else 分支里面写各自的处理逻辑。如果把处理逻辑封装到方法面去，那这样的代码的逻辑其实是非常清晰的。
func ServeHTTP(http.ResponseWriter, *http.Request) { if Request.Method == &#34;GET&#34; { if Request.URL == &#34;/user/id&#34; { // /user/id 的处理逻辑 } else if Request.URL == &#34;/user/name&#34; { // /user/name 的处理逻辑 } } else if Request.Method == &#34;POST&#34; { if Request.URL == &#34;/order/create&#34; { // /order/create 的处理逻辑 } else if Request.URL == &#34;/order/delete&#34; { // /order/delete 的处理逻辑 } } } 即使后面报文的类型越来越多，无非也就是 if-else 的分支多了一点。可以再对 url 的处理做一次封装，代码就可以拆开来了。
func ServeHTTP(http.ResponseWriter, *http.Request) { if Request.Method == &#34;GET&#34; { handleGet() } else if Request.Method == &#34;POST&#34; { handlePost() } } func handleGet(){ if Request.URL == &#34;/user/id&#34; { // /user/id 的处理逻辑 } else if Request.URL == &#34;/user/name&#34; { // /user/name 的处理逻辑 } else if xxx { } else if xxx { } } func handlePost(){ if Request.URL == &#34;/order/create&#34; { // /order/create 的处理逻辑 } else if Request.URL == &#34;/order/delete&#34; { // /order/delete 的处理逻辑 } else if xxx { } else if xxx { } } 就目前来看这种给 method 和 url 都写一个 if-else 的分支的写法，似乎并没有什么非常明显的弊端。这种结构也可以使用 map 结构代替。可以是一层的：map[method+url]处理方法，或者嵌套的：map[method]{map[url]处理方法}。
处理逻辑需要一些前置（后置）工作 但是实际上并不是 &ldquo;所有接口的处理逻辑都是一个完整的整体&rdquo;。比如，商城系统的下订单和取消订单的接口。下订单的接口的处理逻辑假设为，校验用户+下订单。取消订单的接口的处理逻辑假设为，校验用户+取消订单。
这里可以换一个角度，把下订单的接口的处理逻辑分成：前置工作 &ldquo;校验用户&rdquo; 和处理逻辑 &ldquo;下订单&rdquo;。把取消订单的接口的处理逻辑分成：前置工作 &ldquo;校验用户&rdquo; 和处理逻辑 &ldquo;取消订单&rdquo;。
这里讨论的是前置（后置）工作相同的情况。如果每个处理逻辑需要执行的前置（后置）工作不同，那就退回到 &ldquo;所有接口的处理逻辑都是一个完整的整体&rdquo; 那种情况去了。前置（后置）工作相同的情况有几种：所有的处理逻辑都需要，部分处理逻辑需要。
所有的处理逻辑都需要 这种场景非常好处理，直接在最外面写就好了。哪怕前置（后置）工作有多个或者它们之间有顺序要求的场景。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 前置工作 a // 前置工作 b if Request.Method == &#34;GET&#34; { handleGet() } else if Request.Method == &#34;POST&#34; { handlePost() } // 后置工作 c } 部分处理逻辑需要 这种场景乍一看可以沿用 &ldquo;所有的处理逻辑都需要&rdquo; 的方案，把前置（后置）工作下放到每个 if-else 的分支里面去就好了。但是这么做是有问题的。
假设 &ldquo;/user/id&rdquo; 和 &ldquo;/user/name&rdquo; 都需要 &ldquo;前置工作 user&rdquo;，&quot;/user/id&rdquo; 自己还需要 &ldquo;前置工作 user-id&rdquo;，&quot;/user/name&quot; 自己还需要 &ldquo;后置工作 user-name&rdquo;。如果按照上面的写法，代码会写成下面这样子。
func handleGet(){ if Request.URL == &#34;/user/id&#34; { // 前置工作 user // 前置工作 user-id // /user/id 的处理逻辑 } else if Request.URL == &#34;/user/name&#34; { // 前置工作 user // /user/name 的处理逻辑 // 后置工作 user-name } } 乍一看问题不大，但是如果后面有 &ldquo;/user/a&rdquo;、&quot;/user/b&quot; 一直到 &ldquo;/user/z&rdquo; 呢？如果要求每个 &ldquo;/user/&rdquo; 开头的，都需要 &ldquo;前置工作 user&rdquo; 呢？这时候上面这种写法，&ldquo;前置工作 user&rdquo; 就要写 n 次，很麻烦。如果后面要求变了，要求每个 &ldquo;/user/&rdquo; 开头的都需要 &ldquo;前置工作 user2&rdquo;，或者这里就需要改 n 个地方，更麻烦。
所以要想办法，把这个公共的模块提取出去。比如，变成下面这样（这里写了个伪代码，用的是 SQL 的 LIKE 语法），把有这种要求的 url 前缀单独拿到一个 if-else 的分支里去。
func handleGet(){ if Request.URL like &#34;/user/%&#34; { // 前置工作 user if Request.URL == &#34;/user/id&#34; { // 前置工作 user-id // /user/id 的处理逻辑 } else if Request.URL == &#34;/user/name&#34; { // /user/name 的处理逻辑 // 后置工作 user-name } // 后置工作 user } else { if Request.URL == &#34;/order/id&#34; { // /order/id 的处理逻辑 } } } 乍一看问题不大，如果要求每个 &ldquo;/user/&rdquo; 开头的从都需要 &ldquo;前置工作 user&rdquo; 变成都需要 &ldquo;前置工作 user2&rdquo;，那么只需要改一处。但是如果前缀的层级很多呢？比如，加一个 &ldquo;/user/info/a&rdquo;，同时要求每个 &ldquo;/user/info/&rdquo; 开头的从都需要 &ldquo;前置工作 user-info&rdquo;。那上面这种写法就要变成。
func handleGet(){ if Request.URL like &#34;/user/%&#34; { // 前置工作 user if Request.URL like &#34;/user/info/%&#34; { // 前置工作 user-info if Request.URL == &#34;/user/info/a&#34; { // /user/info/a 的处理逻辑 } } else { if Request.URL == &#34;/user/id&#34; { // 前置工作 user-id // /user/id 的处理逻辑 } else if Request.URL == &#34;/user/name&#34; { // /user/name 的处理逻辑 // 后置工作 user-name } } // 后置工作 user } else { if Request.URL == &#34;/order/id&#34; { // /order/id 的处理逻辑 } } } 这样下去 if-else 的层级就会变得越来越深了。if-else 的层级太深，不利于代码的可读性和可维护性。更重要的是，这样的代码改的时候，找起来非常的麻烦，还要担心层级会不会改错了。所以这个问题是需要规避的。那么怎么规避呢？可以使用有层次的结构。
设想一个场景，图书馆里有大量的书需要分类管理。那么可以先按书内容的类别，分到不同的楼层去。然后再按书的作者，分到不同的书架上去。如果想处理某一类的书，可以只在某个楼层内操作，不会影响到别的楼层。如果想处理某一类的某个作者的书，可以只在某个楼层的某个书架上操作，不会影响到这个楼层的别的书架，更不会影响到别的楼层。
这里把这种结构画出来就很直观了。见图：web.drawio.html 4-2。
这种结构在数据结构里对应的就是树形结构。把上面的 method、url、前置（后置）工作对应进去再画一张图。见图：web.drawio.html 4-4。
路由树 基本概念 到这里，所谓的路由树的概念就呼之欲出了。上面的那棵树的结点中记录了全路径，但是这其实是不需要的。当命中 &rsquo;like &ldquo;/user/%&rdquo;&rsquo; 分支往下走的时候，后面的 url 最前面的那段就肯定是 &ldquo;/user/&quot;。所以这里就可以借助前缀的思路，用 &ldquo;/&rdquo; 作为分隔标志，将上面的那棵树转化成前缀树。见图：web.drawio.html 4-6-2。注意有个根结点（&rdquo;/&quot; 结点）。
这样当一个 HTTP 请求过来的时候，先通过 method 判断应该到哪一棵路由树里去找。然后用 &ldquo;/&rdquo; 将 url 分开，依次去路由树里匹配，如果结点上有前置（后置）工作就需要记录下来。最后找到目标结点时，按照前置工作、处理逻辑、后置工作的顺序依次执行。
比如，在 web.drawio.html 4-6-2 这颗树里，访问 &ldquo;/user/id&rdquo; 的时候。依次会访问：&quot;/&quot; 结点；&ldquo;user&rdquo; 结点，记录下 &ldquo;前置工作 user&rdquo; 和 &ldquo;后置工作 user&rdquo;；id 结点，记录下 &ldquo;前置工作 user-id&rdquo; 和 &ldquo;/user/id&rdquo; 的处理逻辑。见图：web.drawio.html 4-6-4。
执行的时候，从逻辑上考虑的话，应该是前面的结点的前置任务应该在前面，前面的结点的后置任务应该在后面。所以上面就应该按照 &ldquo;前置工作 user&rdquo;、&ldquo;前置工作 user-id&rdquo;、&quot;/user/id&quot; 的处理逻辑、&ldquo;后置工作 user&rdquo; 的顺序依次执行。
路由树的设计（Golang） 代码结构设计 路由树，从名字里就可以知道，它首先是一个是树结构，所以，设计工作应该从树结点开始。这里用 web.drawio.html 4-6-2 里的那个路由树为例。
一条完整的路由会被拆成有父子关系的一系列结点。那么，树结点里面一定有一个数据用于标记它是路由中的哪一个部分。然后，还需要知道父子关系，所以，结点需要存储其子结点的信息。这里一般没有回溯的需求，如果需要支持路由的回溯匹配，那么结点就需要记录父结点的信息。
一条路由最后会对应一个处理方法，这个显然是需要记录的。另外，还有前置工作和后置工作，这部分属于中间件，放到后面说，这里先不搞。所以，代码结构目前应该差不多像下面这样。
// routingNode 路由结点 type routingNode struct { // part 这个路由结点代表的那段路径 part string // handler 命中路由之后的处理逻辑 handler HTTPHandleFunc // routingTree 路由子树，子结点的 path =&gt; 子树根结点 routingTree map[string]*routingNode } 测试用例设计 对于最基本的路由树结构，测试用例设计是非常简单的。
用例编号 测试用例 测试目标 2 /user 根结点（空结点） -&gt; 根结点有 1 个子结点（user） 4 /user + /user/info user 结点（空结点） -&gt; user 结点有 1 个子结点（info） 6 /user + /order 根结点有 1 个结点（user） -&gt; 根结点有 2 个结点（user、order） 这样最基本的几种情况就都测到了。
路径参数路由、正则匹配路由、通配符路由 静态的路由匹配可以用上面的 if-else 分支或者路由树解决。但是一些高级玩法，比如：路径参数路由、正则匹配路由、通配符路由，这样的就没办法整。
路径参数路由，一般长这样 &ldquo;user/:id&rdquo;，能把路由里的某一段提取出来，放到事先定义好的变量里面。
正则匹配路由一般长这样 &ldquo;user/:id(/\d/)&quot;，它和路径参数路由很像，区别在于，正则匹配路由在提取出路由里的某一段之后，还需要对数据的格式进行校验。
通配符路由一般长这样 &ldquo;/user/*&quot;，它就很暴力了，只要路由前面是 &ldquo;/user/&rdquo; 开头的，后面是什么都可以匹配上。
这里以路径参数路由为例。比如，定义 &ldquo;user/:id&rdquo; 这样一个路径参数路由，在对应的处理方法里，事先定义好了一个变量 id 用于接收 &ldquo;:id&rdquo; 这个位置对应的字符串。
最终达到的效果是：如果访问的是 &ldquo;user/1&rdquo;，那么变量 id 的值就是字符串 &ldquo;1&rdquo;；如果访问的是 &ldquo;user/2&rdquo;，那么变量 id 的值就是字符串 &ldquo;2&rdquo;；如果访问的是 &ldquo;user/a&rdquo;，那么变量 id 的值就是字符串 &ldquo;a&rdquo;。
对于这种 &ldquo;:id&rdquo; 的位置可以变的路由。if-else 分支或者 map 是无解的。因为，&quot;:id&rdquo; 对应的位置可变，意味着这里会对应无穷多个 if-else 分支。路由树有没有解呢？路由树可以解决，路由树只需要在 user 结点上增加一个特殊的 &ldquo;:id&rdquo; 结点，专门用于处理路径参数路由即可。见图：web.drawio.html 4-8-2。
访问 &ldquo;/user/1&rdquo; 的时候。依次会访问：&rdquo;/&quot; 结点；&ldquo;user&rdquo; 结点。到了 &ldquo;user&rdquo; 结点之后，按照默认逻辑下面要找的是 1 结点，但是 &ldquo;user&rdquo; 结点下面只有 &ldquo;info&rdquo; 结点、&ldquo;id&rdquo; 结点，无法匹配。这个时候就可以尝试匹配 &ldquo;:id&rdquo; 结点，看看 1 符不符合 &ldquo;:id&rdquo; 结点的要求。
这里 &ldquo;:id&rdquo; 的位置可以是任意的字符串，所以 1 是符合要求的，所以 &ldquo;/user/1&rdquo; 最终调用的就应该是 &ldquo;:id&rdquo; 结点的处理逻辑。见图：web.drawio.html 4-8-4。
但是需要注意的是，这三个玩意匹配的时候可能都能匹配上，所以需要人为的定义这三个特殊的路由，哪个优先匹配，哪个最后匹配。
最后，写代码的时候，路由注册和路由查询的逻辑建议分开。因为路由注册和路由查询的逻辑看似都是找结点，但是细节上还是有点区别的。路由注册的时候，是严格按照路由层级注册的，而路由查询的时候，需要考虑特殊结点。
路径参数路由、正则匹配路由、通配符路由的设计（Golang） 代码结构设计 路径参数路由、正则匹配路由、通配符路由的匹配逻辑和普通结点是不同的，需要能识别出它们。在树结构里，可以通过给结点打上标记来区分不同的结点。
在上面的设计中，把所有的结点都放到了一个 map 里面管理，这个操作在这里是行不通的。这三种特殊的结点没有实际上的 url，也就提取不出 map 的 key。所以，这三种特殊的结点需要专门的地方来存储。
而且这三种特殊结点理论上都是唯一的。比如，一个结点上不可能同时有两个路径参数路由。假设，同时存在 &ldquo;/user/:id&rdquo; 和 &ldquo;/user/:name&rdquo;，那么 &ldquo;/user/a&rdquo; 应该命中哪一个呢。另外，通配符结点的后面不应该有子结点，因为，全部都会被通配符结点截胡。
普通结点里用于标记它是路由中的哪一个部分的那个参数，在这三种结点里面是没啥用的。路径参数路由和正则匹配路由需要一个额外的参数存储参数的名字，正则匹配路由还需要一个参数存储正则表达式。
所以，上面的代码结构需要增加点东西，目前应该差不多像下面这样。
// routingNode 路由结点 type routingNode struct { // nodeType 结点类型 nodeType int // part 这个路由结点代表的那段路径 part string // path 从根路由到这个路由结点的全路径 path string // handler 命中路由之后的处理逻辑 handler HTTPHandleFunc // routingTree 路由子树，子结点的 path =&gt; 子树根结点 routingTree map[string]*routingNode // paramChild 路径参数结点 paramChild *routingNode // paramName 路径参数路由和正则表达式路由，都会提取路由参数的名字 paramName string // regexpChild 正则表达式结点 regexpChild *routingNode // regexp 正则表达式 regexp *regexp.Regexp // anyChild 通配符结点 anyChild *routingNode } 测试用例设计 三种特殊结点的测试用例设计就稍微复杂一点了。而且因为结点类型变多了，还需要考虑注册结点的时候的顺序的问题。三种特殊结点有可能会干扰注册普通结点时的结点查询逻辑。
用例编号 测试用例 测试目标 - 普通结点 + 参数路由结点 - 2 /user + /user/:id user 结点（空结点） -&gt; user 结点有 1 个参数路由子结点（:id） 4 /user + /user/info + /user/:id user 结点有 1 个子结点（info） -&gt; user 结点有 1 个子结点（info）和 1 个参数路由子结点（:id） 6 /user + /user/:id + /user/info user 结点有 1 个参数路由子结点（:id） -&gt; user 结点有 1 个子结点（info）和 1 个参数路由子结点（:id） 8 /user + /user/:id + /user/:id/info 参数路由结点（:id）（空结点） -&gt; 参数路由结点（:id） 有 1 个子结点（info）注意用例 8 和用例 6 的区别。 10 /user + /user/:id + /user/:name user 结点有两个参数路由子结点，报错 12 /user + /user/:id + /user/:id/:name 参数路由结点（:id）（空结点） -&gt; 参数路由结点（:id）有 1 个参数路由子结点（:name） - 普通结点 + 正则表达式结点 - 42 /user + /user/:id(/\d/) user 结点（空结点） -&gt; user 结点有 1 个正则表达式子结点（:id） 44 /user + /user/info + /user/:id(/\d/) user 结点有 1 个子结点（info） -&gt; user 结点有 1 个子结点（info）和 1 个正则表达式子结点（:id） 46 /user + /user/:id(/\d/) + /user/info user 结点有 1 个正则表达式子结点（:id） -&gt; user 结点有 1 个子结点（info）和 1 个正则表达式子结点（:id） 48 /user + /user/:id(/\d/) + /user/:id(/\d/)/info 正则表达式结点（:id）（空结点） -&gt; 正则表达式结点（:id） 有 1 个子结点（info）注意用例 48 和用例 46 的区别。 50 /user + /user/:id(/\d/) + /user/:name(/^[A-Za-z0-9]+$/) user 结点有两个正则表达式子结点，报错 52 /user + /user/:id(/\d/) + /user/:id(/\d/)/:name(/^[A-Za-z0-9]+$/) 正则表达式结点（:id）（空结点） -&gt; 正则表达式结点（:id）有 1 个正则表达式子结点（:name） - 普通结点 + 通配符结点 - 82 /user + /user/* user 结点（空结点） -&gt; user 结点有 1 个通配符子结点 84 /user + /user/info + /user/* user 结点有 1 个子结点（info） -&gt; user 结点有 1 个子结点（info）和 1 个通配符子结点 86 /user + /user/* + /user/info user 结点有 1 个通配符子结点 -&gt; user 结点有 1 个子结点（info）和 1 个通配符结点子结点 88 /user + /user/* + /user/*/info 通配符结点后面不能有子结点，报错 - 4 种结点混合，这里就不一个一个写了，场景太多了 - 前置（后置）工作成对出现 上面讨论前置（后置）工作的时候，都是以 &ldquo;前置（后置）工作是可以独立执行的整体&rdquo; 为前提讨论的。如果它们之间有合作关系，也就是需要相互传递数据，那么怎么办呢？这个放到下一篇里说：【实验性质，带图片】Golang 实现简单的 Web 框架 &ndash; middleware(中间件)参考（reference） {极客时间}/Go 实战训练营Web 框架部分 ]]></content></entry><entry><title>init 进程、进程间关系、作业、会话、守护进程</title><url>/post/computer-science/operating-system/linux/process02/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>process(进程)</tag></tags><content type="html"><![CDATA[前言 前置笔记： 进程的创建、进程的运行、进程的内存资源、进程的退出、进程的回收交叉笔记：终端和控制台实践的环境：同 程序资料 {demo-c}/demo-in-linux/process02/ 正文 init 进程 init 程序是 Linux 操作系统中不可缺少的程序之一，它是一个由内核启动的用户级进程。 内核会在过去曾使用过 init 程序的几个地方查找它，它的正确位置（对 Linux 系统来说）是 &ldquo;/sbin/init&rdquo;。 如果内核找不到 init，它就会试着运行 &ldquo;/bin/sh&rdquo;。如果这两个都运行失败了，操作系统的启动也会失败。
Linux 操作系统的启动首先从 BIOS 开始，接下来进入 boot loader，由 boot loader 载入内核，进行内核初始化。 内核启动之后（被载入内存，开始运行，初始化所有的设备驱动程序和数据结构之后），就会通过启动一个用户级程序 init 的方式，完成引导进程。
内核初始化的最后一步就是启动 init 进程，这个进程是系统的第一个进程，它负责产生其他所有的用户进程。 所以，init 进程始终是第一个进程，其进程编号始终为 1。 其他所有的用户进程每个进程都有父进程，一直上溯的话，所有的进程会形成一个以 init 进程为根结点的树状结构。
进程树 这里简单的验证一下。先打开一个终端，使用 &ldquo;echo $$&rdquo; 命令，打印当前进程的 pid。 再打开一个终端，使用 &ldquo;echo $$&rdquo; 命令，打印当前进程的 pid。然后使用 &ldquo;pstree -p&rdquo; 命令，观察一下进程树。
&gt; echo $$ 1963 &gt; echo $$ 2166 &gt; pstree -p systemd(1)─┬... ├─systemd(1074)─┬─... │ ├─gnome-terminal-(1945)─┬─bash(1963) │ │ ├─bash(2166)───pstree(2173) 这里从进程树里截取了有关的片段。 可以看到，打开的两个终端，bash(1963) 和 bash(2166) 的父进程都是 gnome-terminal-(1945)。 终端 bash(2166) 执行 pstree 命令的时候，又创建了一个子进程 pstree(2173)。
进程组 进程组（process group）是一个或者多个进程的集合。 每个进程必须而且只能属于一个进程组。集合里的这些进程并不是孤立的，它们之间会存在父子或者兄弟的关系。 进程有自己的唯一标识，称为进程 id（process id、pid），进程组也有自己的唯一标识，称为进程组 id（process group id、pgid）。
每个进程组都有一个组长进程，组长进程的 pid 与其 pgid 相同。组长进程可以创建一个进程组，一般是进程变成组长进程的时候。
进程组的生命周期从被创建开始，直到进程组内所有进程终止或离开该组。 无论组长进程是否终止，只要进程组中存在未终止的进程，这个进程组就不会消失。 组长进程终止后，进程组中便不存在组长进程，剩下的进程也不会自动推选新的组长进程。
进程组的作用是为了方便对进程进行管理。 假设有一个任务需要好多进程一起协作完成，现在出于某种原因需要终止这个任务。 如果没有进程组，就需要用 pid 一个一个杀掉这些进程，而且还要考虑顺序，先杀子进程再杀父进程。 如果有进程组的话，就可以搞一个杀进程组的操作。
通过 getpgid() 或者 getpgrp() 可以获取进程所属的进程组 id。通过 setpgid() 可以设置进程的进程组 id。 进程通过 setpgid() 只能设置它自己和它的子进程的 ppid。 如果它的子进程调用了 exec 家族的函数，那么它也无法更改这个子进程的 ppid 了。
创建出来的子进程一开始是和父进程是一组的，会继承父进程的 pgid。 可以通过把子进程的 pgid 设置成子进程的 pid，来创建以子进程为组长进程的新进程组。
作业 Linux 是一个多用户多任务的分时操作系统。 多用户是指多个用户可以在同一时间使用计算机系统。 多任务是指 Linux 可以同时执行多个任务，可以在一个任务还未执行完的同时执行另一项任务。 多个用户和多个任务都由操作系统进行管理。 分时是指计算机采用时间片轮转的方式同时为几个、几十个、甚至几百个用户服务。
作业控制 Shell 是操作系统的用户界面，提供了用户与内核进行交互操作的一种接口。 它实际上是一个命令解释器，接收并解释用户输入的命令，然后把命令送入内核去执行。 Shell 有多种不同的版本，常用的 BASH 就是其中一种。
Shell 控制的不是进程而是作业。正在执行的一个或多个相关进程被称为作业（job），也有叫任务的。 作业是计算机操作者（可以是人也可以是程序）交给操作系统的执行单位。 作业控制指的是控制正在运行的进程的行为。比如，在 Shell 控制终端控制多个作业。
前台作业和后台作业 作业还分为前台作业和后台作业。用户直接操作的那个终端窗口就属于前台作业，前台作业独占终端窗口。 它可以直接接收用户输入的命令，而且一旦命令开始运行，除非命令运行结束或者强制终止命令，要不然是不能执行其他命令的。
前台作业运行结束，Shell 就会把自己提到前台。 比如，在终端窗输入 &ldquo;ls&rdquo; 命令之后，Shell 会启动一个进程去执行 &ldquo;ls&rdquo; 命令， &ldquo;ls&rdquo; 命令执行完之后会输出结果，然后这个进程退出，然后 Shell 把自己提到前台。
除了表面上看得到的前台作业的进程，还有很多正在运行的进程是表面上看不到的。 比如，那个直接和用户交互的作业背后，是需要操作系统做很多工作来提供支撑的。 这些进程就属于后台作业。Shell 可以运行一个前台作业和任意多个后台作业。
子进程 如果作业中的某个进程又创建了子进程，则子进程不属于作业。 作业运行结束时，如果这个子进程还没终止，那么它会变为后台进程。 比如，用 fork() 创建了一个子进程之后，父进程直接退出，这个时候子进程并不会终止，而是变成孤儿进程。
会话 Linux 是一个多用户多任务的分时操作系统。多用户是指多个用户可以在同一时间使用计算机系统。一个用户登录一次系统就形成一个会话。
会话（session）是多个进程组的集合，一个会话中可以包含一个前台进程组以及一个或多个后台进程组。 每个会话都有会话 id（session id、sid）。每个会话都有一个会话首进程（session leader），即创建会话的进程。
一个会话可以关联终端，也可以不关联终端，关联终端的时候只能关联一个。 这个终端一般由会话首进程建立连接。此时，会话首进程也叫控制进程，这个终端也叫控制终端。
一个会话关联了一个终端后，它至少有一个前台进程组，其它都是后台进程组。 在终端输入特殊字符，如：中断键（&ldquo;ctrl + c&rdquo;）、暂停键（&ldquo;ctrl + z&rdquo;）、退出键（&ldquo;ctrl + \&quot;）时，会产生中断信号。 中断信号会往前台进程组里的所有进程发送，但是不会给后台进程组里的进程发送。
通过 getsid() 可以获取会话 id，通过 setsid() 可以设置会话 id。 当一个进程调用 setsid() 时，会发生三件事：该进程会变成会话首进程（session leader）； 该进程会变成进程组的组长；该进程不会关联终端，就算父进程有终端也会断开（后面可以再关联终端）。 必须注意的是，只有当前进程不是进程组的组长时，才能创建一个新的会话，成为新会话的会话首进程。
控制进程 控制进程就是关联了终端的进程。比如，控制台黑窗口。可以通过 ps -l 命令看一下。
&gt; ps -l UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD 0 S 1000 2643 2625 0 80 0 - 3557 do_wai pts/0 00:00:00 bash 0 R 1000 2650 2643 0 80 0 - 3939 - pts/0 00:00:00 psF S 进程（PID）2643，是由 bash（/bin/bash）文件启动的，同时该进程关联了终端设备（TTY），这个终端设备是 pts/0（伪终端）。
切换前台作业和后台作业 这里准备了一个程序 for_job.c。程序每 5 秒，用 printf() 输出一次 pid。
想启动前台作业很简单，在终端窗口里直接执行命令就好了。比如，在终端窗口里直接运行这个程序。 这样程序就是一个前台作业，会占着终端窗口一直输出 pid。
&gt; ./for_job.elf [debug]:getpid()=11959 [debug]:getpid()=11959 一直输出。。。 这个时候可以按下 &ldquo;ctrl + z&rdquo;，可以停止进程并放入后台。这个时候，这个前台作业就变成后台作业了。
^Z [1]+ Stopped ./for_job.elf job 命令可以查看当前 Shell 环境中已启动的作业状态，这里用 &ldquo;job -l&rdquo; 命令查看一下。 可以看到刚才的 11959 进程，现在在后台而且处于停止状态。
&gt; jobs -l [1]+ 11962 Stopped ./for_job.elf &ldquo;[1]&rdquo; 表示作业号为 1。 &ldquo;+&rdquo; 表示最近一个放入后台的作业。如果这里是 &ldquo;-&rdquo; 则表示倒数第二个放入后台的工作， 倒数第三个以后的工作就没有 &ldquo;+&rdquo; 或者 &ldquo;-&rdquo; 标志了。 11962 就是 pid；Stopped 表示进程现在是停止状态。 最后的 &ldquo;./for_job.elf&rdquo; 表示进程是这个命令启动起来的。 bg 命令可以让最近一个暂停的后台任务继续执行。这里也可以用 &ldquo;bg %1&rdquo;，&quot;%1&rdquo; 就是指定了作业号。
&gt; bg [1]+ ./for_job.elf &amp; [debug]:getpid()=11962 [debug]:getpid()=11962 一直输出，而且不受控制 这里就要提到后台作业的两个特点：
继承当前会话的标准输出（stdout）和标准错误输出（stderr）。 因此，后台任务的所有输出依然会同步地打到终端窗口，也就是上面一直输出的原因。 不继承当会话的标准输入（stdin）。因此，无法再向这个任务输入指令了，也就是上面不受控制的原因。 如果后台作业试图读取标准输入，终端驱动会检测后台进程的这种举动并向后台作业发送一个 SIGTTIN 信号。 SIGTTIN 信号通常会暂停（halt）后台作业的执行。 所以，前台任务和后台任务的区别只有一个：是否继承标准输入。
如果这个时候继续在终端窗口里面输入命令，它是可以被执行的。 虽然这个时候后台任务的所有输出会同步地打到终端窗口，让窗口看上去非常的混乱，但是这并不影响输入的命令。 输入和输出的内容并不在一个地方，只是都显示到了一个地方。
比如，使用 fg 命令将后台运行的或挂起的作业切换到前台运行。这里也可以用 &ldquo;fg %1&rdquo;，&quot;%1&quot; 同样是指定了作业号。
&gt; fg %1 ./for_job.elf [debug]:getpid()=11962 一直输出。。。 另外，可以通过在命令的后面加一个 &ldquo;&amp;&rdquo; 符号，让程序直接以后台作业的方式启动。
&gt;./for_job.elf &amp; [1] 2228 这种方式启动起来的作业就是直接处于后台并且是运行状态的。
&gt; jobs -l [1]+ 2249 Running ./for_job.elf &amp; 守护进程 守护进程（Daemon 进程）最基本的特点就是运行在后台，并且不和终端关联。 这里的运行在后台和上文的后台作业或者后台进程组是有区别的。上文的后台作业或者后台进程组，进程依然是和会话进程关联的。 而守护进程的父进程是 1 号 init 进程，和启动它的会话进程不关联。 这里的不和终端关联的意思是，守护进程不接受标准输入也不会产生标准输出或者标准错误输出。
从终端开始运行的进程都会依附于这个终端，这个终端称为这些进程的控制终端。 当控制终端被关闭时，相应的进程都会被自动关闭。对于一般的前台进程，可以用 &ldquo;ctrl + c&rdquo; 的方式来停止运行，也可以直接关闭终端。 但是对于守护进程来说它的生命周期需要突破这种限制，它会一直运行直到整个系统关闭才会退出，因此守护进程不能依赖于终端。
编写守护进程的步骤 创建一个子进程 b，父进程 a 退出。因为调用 setsid() 的进程不能是组长进程。 子进程 b 调用 setsid() ，创建一个新的会话。 调用进程调用 setsid() 时，该调用进程会变成会话首进程，变成组长进程，而且不关联终端。 有些时候，在子进程 b 调用 setsid() 后，还会再创建一个子进程 c ，然后自己（会话首进程）退出。 修改子进程的工作目录，一般为根目录。fork() 使得子进程继承了父进程的工作目录。 调用 umask() 重设文件权限掩码。fork() 使得子进程继承了父进程的文件权限掩码，这会给子进程使用文件带来麻烦。 关闭不必要的文件描述符（主要是 0、1、2）。fork() 使得子进程继承了父进程一些打开的文件，但是子进程可能不需要，这会消耗系统资源。 打开黑洞文件（/dev/null），彻底的断开控制终端。 代码示例：{demo-c}/demo-in-linux/process02/daemon.c
程序运行之后会变成守护进程，不会在终端有输出。可以通过 &ldquo;ps -ely&rdquo; 命令查看进程状态。
&gt; ps -ely S UID PID PPID C PRI NI RSS SZ WCHAN TTY TIME CMD S 0 1 0 0 80 0 2824 2961 - pts/0 00:00:00 bash S 0 16 0 0 80 0 3064 2961 - pts/1 00:00:00 bash S 0 45 1 0 80 0 88 1058 - ? 00:00:00 daemon S 0 46 45 0 80 0 88 1058 - ? 00:00:00 daemon R 0 50 16 0 80 0 3076 12406 - pts/1 00:00:00 ps 可以看到进程 45 运行的 daemon 程序，它的父进程变成 1 号 init 进程了，这时进程 45 它就是一个守护进程。 从进程关联的标准输入设备（TTY）也可以看到进程 45 它值是 &ldquo;?&quot;，表示没有关联终端。 进程 45 还创建了一个子进程 46，这个虽然是后台进程，但是它的父进程不是1 号 init 进程，所以不算守护进程。
另外，也可以通过 daemon() 创建守护进程。
nohup 最常用的创建守护进程的方式是使用 &ldquo;nohup&rdquo; 命令加上 &ldquo;&amp;&rdquo; 符号。nohup ./for_job.elf &amp;。
&ldquo;nohup&rdquo; 命令的作用有：阻止 SIGHUP 信号发送给这个进程； 关闭 stdin 使得该进程不再能接收任何输入，即使进程是运行在前台的（没有加 &ldquo;&amp;&rdquo; 符号）； 重定向 stdout 和 stderr 到 nohup.out。
参考 百度百科-initLinux初始化init系统百度百科-Linux Shell百度百科-Linux进程管理及作业控制Linux-进程、进程组、作业、会话、控制终端详解APUE 2 - 进程组（process group） 会话（session） jobLinux会话、终端与进程组]]></content></entry><entry><title>终端和控制台</title><url>/post/computer-science/terminal_console/</url><categories><category>computer-science(计算机科学)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>linux</tag></tags><content type="html"><![CDATA[前言 交叉笔记：init 进程、进程间关系、作业、会话、守护进程资料 terminal_console.drawio.html 正文 终端 计算机终端（computer terminal）是与计算机相连的一种输入输出设备。
早期有一种叫电传打字机的设备，它是一台独立于计算机的机器，通过物理线缆与计算机连接，可以完成计算机的输入输出功能。 电传打字机的英文是 Teletype 或 Teletypewriter，缩写是 TTY，所以 TTY 也泛指计算机的终端设备。 后来，电传打字机被键盘和显示器取代。
但是不管是电传打字机还是键盘和显示器，都是作为计算机的终端设备存在的。 电传打字机属于物理终端。现在物理终端基本上已经不用了。 图形界面出现之前，键盘和显示器的组合属于软件仿真终端，也就是软件模拟出来的终端。 图形界面出现之后，键盘和显示器的组合演变成了伪终端，但是软件仿真终端还是可以用的。
控制台 这里以数控机床为例。 数控机床可能有一个独立出来一整块，然后上面有很多按钮的地方，这些按钮可以直接控制机床上的设备。 如果这地方是直接在机床表面的，就叫控制面板。如果这地方是被一个柜子锁起来的，就叫控制箱。如果这地方看上去像个台子，就叫控制台（console）。
控制台和终端其实不是一个东西。 控制台是计算机本身就有的设备，而终端不是计算机本身就有的设备。控制台应该只有一个，但是终端可以有多个。 计算机的控制台理论上应该是电源开关和电源灯那些玩意，电源开关是可以直接控制计算机的。 终端是通过接口接上去的，终端和计算机本身的运行没有关系，它就是个额外的输入输出设备。
这里用 ubuntu 系统和 windows 系统为例。 计算机刚启动的时候，是可以通过键盘直接控制计算机的，而且会输出内核的信息到显示器上。这个时候的键盘和显示器就类似于控制台。
当计算机启动完成，进入操作系统的桌面后，这时是可以开很多的命令行窗口的。 这些命令行窗口里面不会输出内核的信息，而且可以各自独立的接收命令输入，然后执行程序并返回输出。这个时候的键盘和显示器就是终端。
不过，现在的控制台和终端都由硬件概念逐渐演化成了软件的概念。 简单的说，第一个启动的，会输出内核的信息的那个终端就称为控制台，其他的终端就是终端。
物理终端 这里用电传打字机为例，画了基本的软硬件结构和交互。见图：terminal_console.drawio.html 2-2。
UART（通用异步接收器和发射器）和 UART driver（UART 驱动）的功能简单的理解就是，将电传打字机的信号转换为计算机可以识别的信号。 line discipline（行规范） 的功能简单的理解就是，提供一个编辑缓冲区和一些基本的命令。 比如：回车命令把缓冲区的数据发送给 TTY 驱动；退格命令清除一个字符。 TTY driver（终端驱动）的功能有两个：进行会话管理；处理终端设备的输入输出。 软件仿真终端 这里用键盘和显示器（注意这里是直连）为例，画了基本的软硬件结构和交互。见图：terminal_console.drawio.html 20-2。
差别在于用键盘驱动、显示器驱动、终端模拟器替换了 UART 和 UART 驱动。基本流程不变，只是输入输出从一个设备变成两个设备了。
在 linux 系统中，软件仿真终端在文件系统中的表示就是 /dev/tty1 ~ /dev/tty6。见图：terminal_console.drawio.html 20-4。
在 ubuntu 系统中，在图形界面的桌面按下 &ldquo;CTRL&rdquo; + &ldquo;ALT&rdquo; + &ldquo;F1&rdquo; ~ &ldquo;F6&rdquo; 就可以分别进入 tty1 ~ tty6 对应的软件仿真终端。软件仿真终端的界面是操作系统内核直接提供的，这种叫虚拟控制台（virtual console）。
按下 &ldquo;CTRL&rdquo; + &ldquo;ALT&rdquo; + &ldquo;F7&rdquo; 或者重新启动系统，就可以回到图形界面。 在图形界面也可以打开终端，这种叫终端窗口（terminal window），属于伪终端。 终端窗口就是常用的那个控制台黑窗口。
这两中终端在功能上其实没啥区别，如果哪天操作系统的图形界面炸掉了，但是别的地方没问题，那倒是可以切到软件仿真终端去救火。
伪终端 物理终端和软件模拟终端都需要直接连接外部设备，这两种方式对物理距离都是有限制的， 伪终端（pseudo terminal，pty）的出现解决了这个问题。 伪终端就是由终端模拟器提供的虚拟终端，终端模拟器是一种运行在用户空间的应用程序。
这里用 xterm 终端模拟器为例，画了基本的软件结构和交互。见图：terminal_console.drawio.html 40-2。
伪终端在操作系统内核中分为两部分：分别是不在 TTY 驱动中 PTY master side 和在 TTY 驱动中的 PTY slave side。 master side 是接近用户的一端；slave side 是在虚拟终端上运行的 CLI（Command Line Interface，命令行接口）程序。
连接 master side 和 slave side 的是伪终端驱动。见图：terminal_console.drawio.html 40-4。
伪终端驱动会把写入 master side 的数据转发给 slave side 作为程序的输入。程序输出时会写入 slave side。 伪终端驱动会把写入 slave side 的数据转发给 master side 作为可以读取的数据。
在 linux 系统中，当创建一个伪终端时。会调用 posix_openpt() 请求 ptmx 创建一个 pts。 ptmx 就是 &ldquo;/dev/ptmx&rdquo;，对应 master side。创建出来的 pts 在 &ldquo;/dev/pts/&rdquo; 目录下，对应 slave side。
ssh 类似 PuTTY 这类通过 SSH 的方式远程连接到 linux 系统的终端模拟程序。 如果从 linux 系统这边看的话，连接上来之后产生的用户进程， 就是图 terminal_console.drawio.html 40-4 中 xterm process 的位置，它和 master side 交互。
建立连接的过程：
客户端（PuTTY）请求和 sshd 建立连接。 sshd 验证通过后，会创建一个新的会话（session）。 sshd 调用 posix_openpt() 请求 ptmx 创建一个 pts。 如果创建成功，sshd 会得到一个连接到 ptmx 的文件描述符（fd）和一个 pts。 ptmx 会自动维护这个 fd 和 pts 的关系。 sshd 会把创建的会话和这个 fd（连接到 ptmx 的文件描述符）关联起来。 同时 sshd 会创建 bash 进程，将 pts 和 bash 进程关联起来。 用 lsof 命令可以查看 &ldquo;/dev/ptmx&rdquo; 被哪些进程打开了。如果 sshd 请求 ptmx 创建一个 pts 成功。 那么输出里应该会有像下面这样 &lsquo;COMMAND 为 sshd，NAME 为 &ldquo;/dev/ptmx&rsquo; 的行。
&gt; lsof /dev/ptmx COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME sshd 1191 dev 8u CHR 5,2 0t0 6531 /dev/ptmx ... 收发消息的过程：
客户端（PuTTY）收到键盘的输入，通过 ssh 协议将数据发往 sshd。 sshd 收到客户端的数据后，从自己管理的会话里找到该客户端对应的 fd，然后将数据写入 fd。 ptmx 收到 sshd 的数据后，从自己管理的关系里找到该 fd 对应的 pts，然后将数据写入 pts。 pts 收到 ptmx 的数据后，检查关联的前端进程组，将数据转发给前端进程组的组长进程。因为上面是创建 bash 进程和 pts 关联起来的，所以这里就是 bash 收到了数据。 bash 收到 pts 的数据后，会对输入的数据进行处理，然后输出处理结果，输出的处理结果会被写入 pts。 pts 收到 bash 的数据后，将数据写入 ptmx。 ptmx 收到 pts 的数据后，从自己管理的关系里找到该 pts 对应的 fd，然后将数据写入 fd。 sshd 收到 fd 的数据后，从自己管理的会话里找到该 fd 对应的客户端，然后将数据发往客户端。 见图：terminal_console.drawio.html 40-6。
键盘和显示器 图形界面出现之后，键盘和显示器的组合演变成了伪终端，整个结构和 ssh 的差不多。 只不过没有远程连接了，图形客户端需要把 ssh 客户端的功能也实现，然后直接和 master side 交互。 见图：terminal_console.drawio.html 40-8。
TTY TTY 也泛指计算机的终端设备，说 TTY 的时候可能是 tty 也可能是 pts，大部分情况下是 pts。
对于用户空间来说，这两个没有区别。 对于内核来说，tty 的另一端连接的是终端模拟器，pts 的另一端连接的是 ptmx，终端模拟器和 ptmx 都只负责维护会话和转发数据。 终端模拟器的另一端连接的是键盘和显示器这样等硬件。ptmx 的另一端连接的是用户空间的 xterm、sshd 等应用程序。
如果有多个终端连接上来的话，终端驱动会创建多个 TTY 与这些终端一一对应。见图：terminal_console.drawio.html 12-2。
在 linux 的终端窗口里使用 tty 命令可以查看当前 bash 关联到哪个 tty 或者 pts。
&gt; tty /dev/pts/0 然后用 lsof 命令可以查看这个 tty 或者 pts 被哪些进程打开了。
&gt; lsof /dev/pts/0 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME bash 2150 qqq 0u CHR 136,0 0t0 3 /dev/pts/0 bash 2150 qqq 1u CHR 136,0 0t0 3 /dev/pts/0 bash 2150 qqq 2u CHR 136,0 0t0 3 /dev/pts/0 bash 2150 qqq 255u CHR 136,0 0t0 3 /dev/pts/0 lsof 2163 qqq 0u CHR 136,0 0t0 3 /dev/pts/0 lsof 2163 qqq 1u CHR 136,0 0t0 3 /dev/pts/0 lsof 2163 qqq 2u CHR 136,0 0t0 3 /dev/pts/0 上面的 FD 这一列是文件描述符，0u、1u、2u 就是 stdin(0u)、stdout(1u)、stderr(2u)，即标准输入、标准输出、标准错误输出。
参考 Linux 终端(TTY)Linux 伪终端(pty)Linux TTY/PTS概述终端、虚拟终端、shell、控制台、tty的区别]]></content></entry><entry><title>中央处理器（Central Processing Unit、CPU）</title><url>/post/computer-science/hardware/cpu/</url><categories><category>hardware(硬件)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>hardware(硬件)</tag></tags><content type="html">前言 前置笔记：
算术逻辑单元（Arithmetic and Logic Unit、ALU）
内存（Memory）
资料 cpu.drawio.html 正文 程序 ALU 可以进行算数运算，内存可以存储数据。如果能把两个结合起来，那就可以处理复杂的逻辑了。ALU 有三个输入，这里假设有两个 8 bit 的二进制数和一个操作码，但是一个内存地址只能存储 8 bit，显然不可能把所有的东西都存在一个内存地址上，然后一股脑的扔给 ALU。
所以，这里就需要一种方式把需要执行的逻辑转化成一个一个的小步骤，每个内存地址存一个小步骤，然后依次执行。这里就可以引出指令的概念了。程序由一系列操作组成，这些操作就叫指令。
指令 指令（instruction）指示计算机要做什么。如：算数加法、算数减法、去内存中读、往内存中写数据等。指令由操作码（operation code）和数据来源（内存地址、寄存器 ID 等）组成。
上文的一个小步骤就是一次指令操作，操作码就是指令码，两个 8 bit 的二进制数就是操作数。指令明确 ALU 要干什么，数据就是 ALU 要处理的数据，指令和数据合起来就是程序了。
指令集 程序就是由程序指令和程序数据构成的。下面把一次加法操作，比如，0b1 + 0b1 = 0b10，转换成程序。首先需要依次加载两个数字，然后需要知道是加法，然后需要进行运算，最后需要存储运算结果。
这里面有几种不同的操作：加载、加法、存储。这三个操作囊括了一次加法操作所需要的全部操作，构成了一个操作集合。实际的运行过程中需要给每个操作设计对应的电路来实现，这些不同的电路可以用指令码来进行标记。那么和操作一样，这些指令码也属于一个指令码集合，这就是指令集的概念。
控制单元 有了指令集之后，就可以设计电路来识别这些指令了。比如，0b0001 表示加载、0b0010 表示加法、0b0011 表示存储。每一个指令码对应一个电路（见图：cpu.drawio.html 2-2），当输入一个指令码的时候，整个电路只有和这个指令码匹配的那一处电路会导通（见图：cpu.drawio.html 2-4）。
识别出指令码是哪一个之后，就可以进行后续的操作了。比如，让电路连接内存，写入或者读取数据；或者让电路连接 ALU 进行运算并得到运算结果。这块的电路可以和 ALU、内存等组件独立开来成为单独一个模块，这就是控制单元。
CPU 中央处理器（Central Processing Unit、CPU）是计算机的核心，负责执行程序。CPU 的核心部分由运算器（arithmetic unit）和控制器（control unit）组成。其他部分还有寄存器、CPU 高速缓存（CPU Cache）、总线等。
CPU 的强大之处在于它是可编程的（programmable），如果写入不同的指令，就会执行不同的任务。
运算器 运算器由算术逻辑单元（ALU）、累加寄存器（AC）、数据缓冲寄存器（DR）、状态条件寄存器（PSW）等组成。执行所有的算数和逻辑运算并进行逻辑测试。比如，与、或、非等。
ALU：对数据的算数和逻辑运算。 AC：运算结果或者源操作数的存放区。 DR：暂时存放内存的指令或数据。 PSW：保存指令运行结果的条件码，如溢出标志。 控制器 控制器由指令寄存器（IR）、程序计数器（PC）、地址寄存器（AR）、指令译码器（ID） 等组成。控制整个 CPU 的工作。
IR：暂存 CPU 执行指令。 PC：存放指令执行地址。 AR：保存当前 CPU 所访问的内存地址。 ID：分析指令操作码。 程序放到哪里 指令和数据都可以以二进制的形式存储在内存里。上文的那个一次加法操作的整个程序是可以存储在内存中的，比如，内存篇里面提到的那块可以存储 256 个字节的内存。
但是跑这个程序的时候，直接操作内存搞，搞起来会很复杂，所以会需要一些额外的空间临时存储一些数据，这些额外的空间通常由寄存器来实现。这里继续使用上文的一次加法操作来说明。
首先，构成一次加法操作的每一步指令是需要分析的。但是把内存线路直接接到控制单元上直接产生依赖显然不是一个好设计。可以从内存里把指令拿出来，暂存在控制单元里，然后再进行分析，这就是指令寄存器的概念。然后，程序跑到哪一步了也是需要记录的，这就是指令地址寄存器的概念。
两个操作数肯定是放在两个内存地址上的，这里肯定需要一个一个取出来，也就是需要两个能暂存操作数的地方。这里就是很普通的，用于存数据的寄存器，叫寄存器 A 和寄存器 B 好了。另外，ALU 计算的结果和标志位也需要处理。
最后，程序的每一次指令操作都需要电信号来触发，这个由时钟组件来控制，时钟会定时发射电脉冲。比如，每过一秒，就发射一次电脉冲，驱动整个系统运作一次。到这里，就可以画一个简单的结构图了，分为两部分：执行程序的 CPU 和存储程序的内存（见图：cpu.drawio.html 2-6）。
时钟 时钟（clock）负责管理 CPU 的工作节奏。时钟以精确的时间间隔触发脉冲信号，控制单元会用这个信号推进 CPU 的内部操作。节奏不能太快，因为电的传输需要时间。
时钟频率（clock rate），单位是赫兹（hertz、Hz），10 Hz 代表时钟 1 秒触发脉冲信号 10 次。
时钟周期（又叫振荡周期、clock cycle）：每一次脉冲信号高低电平的转换就是一个周期，时钟频率的倒数。
时钟频率越高，时钟周期越短，CPU 工作速度越快。
超频（overclocking）可以提升 CPU 的工作效率，但是会产生散热问题或因为跟不上时钟频率产生乱码。
降频（underclocking）可以省电，CPU 不需要时刻保持全速工作。
现代计算机都有动态频率调整（dynamic frequency scaling）的功能。
CPU 执行程序的过程 定义指令集和程序 这里假设这个 CPU 一次可以处理 8 bit 的数据，也就是一条指令是 8 bit。一条指令有包括指令码和操作数，这里假设前 4 bit 作为指令码，后 4 bit 作为操作数。
指令码属于指令集，这里假设指令集为：0b0001，从内存读取数据到寄存器 A；0b0010 从内存读取数据到寄存器 B；0b0011 把寄存器 A 和寄存器 B 的数据交给 ALU 做加法运算，然后把输出的结果放到寄存器 A，这个步骤不需要操作数；0b0100，把寄存器 A 的数据写入内存；
最后，假定指令的操作数都是内存地址。这样就可以把这个程序大概写出来了（见图：cpu.drawio.html 2-8）。假设两个数据都是 1，分别存储在内存地址 1100 和 1101 上。执行一次加法运算，然后把结果存储到内存地址 1110 上。
执行程序的过程 把存有程序的内存和 CPU 连接起来（见图：cpu.drawio.html 2-10-2），假设指令地址寄存器从 0 开始，那么程序的执行过程如下：
1、从 RAM 取数据放到寄存器 A。
将内存地址 0b0000 上的指令 0b00011100 加载到指令寄存器。分析指令的指令码，0b0001 表示从内存读取数据到寄存器 A。分析指令的操作数，0b1100 表示内存地址。于是去内存地址 0b1100 上，把数据 0b00000001 加载到寄存器 A。内存地址 0b0000 上的指令执行结束，指令地址寄存器 +1 得到 0b0001。（见图：cpu.drawio.html 2-10-4-2、2-10-4-4、2-10-4-6）
2、从 RAM 取数据放到寄存器 B。
将内存地址 0b0001 上的指令 0b00101101 加载到指令寄存器。分析指令的指令码，0b0010 表示从内存读取数据到寄存器 B。分析指令的操作数，0b1101 表示内存地址。于是去内存地址 0b1101 上，把数据 0b00000001 加载到寄存器 B。内存地址 0b0001 上的指令执行结束，指令地址寄存器 +1 得到 0b0010。（见图：cpu.drawio.html 2-10-6-2、2-10-6-4、2-10-6-6）
3、将内存地址 0b0010 上的指令 0b00110000 加载到指令寄存器。分析指令的指令码，0b0011 表示把寄存器 A 和寄存器 B 的数据交给 ALU 做加法运算，然后把输出的结果放到寄存器 A，这个步骤不需要操作数。（见图：cpu.drawio.html 2-10-8-2、2-10-8-4）
先把寄存器 A 和寄存器 B 的数据交给 ALU 做加法运算，得到 0b00000010。因为这个时候寄存器 A 还连着 ALU 呢，直接把数据给过去，数据就又传给 ALU 了。所以控制单元会先暂存运算结果，然后切断寄存器 A 和 ALU 的连接，然后再把运算的结果放到寄存器 A 上。内存地址 0b0010 上的指令执行结束，指令地址寄存器 +1 得到 0b0011。（见图：cpu.drawio.html 2-10-8-6、2-10-8-8）
4、将寄存器 A 中的数据存入 RAM。
将内存地址 0b0011 上的指令 0b01001110 加载到指令寄存器。分析指令的指令码，0b0100 表示把寄存器 A 的数据写入内存。分析指令的操作数，0b1110 表示内存地址。于是去内存地址 0b1101 上，把数据 0b00000010 存进去。内存地址 0b0011 上的指令执行结束，指令地址寄存器 +1 得到 0b0100。（见图：cpu.drawio.html 2-10-10-2、2-10-10-4、2-10-10-6）
到这里，这个程序就已经执行结束了，后面的内存地址上如果存储了指令，那属于另外一个程序。
一条指令的执行过程 执行一条指令一般分为三个步骤：取指令（instruction fetch、IF）、指令译码（instruction decode、ID）、执行指令（execute、EX）。CPU 会根据指令周期的不同阶段区分取指令还是取操作数。
初始化时，所有的寄存器都初始化为 0；RAM 中存入一段程序，假设地址从 0 开始。
取指令阶段，负责拿到指令。CPU 将指令地址寄存器连接到 RAM，寄存器的值为 0，因此 RAM 返回地址 0 上的数据。返回的数据会被复制到指令寄存器里。
指令译码阶段，搞清楚指令要干什么。CPU 用控制单元判断指令寄存器里的指令的操作码是哪一个。这里假设译码的结果为：&amp;ldquo;操作码：读取内存数据放入寄存器 A；地址：9&amp;rdquo;。
执行阶段，执行译码的结果。从 RAM 地址 9 的位置取出操作数，放到寄存器 A 里。执行完成后，关闭所有电路，指令地址寄存器 +1，本次指令流程结束。
机器周期和指令周期 机器周期（又叫 CPU 周期、machine cycle）是 CPU 完成一个基本操作所需的时间。指令周期（instruction cycle）是 CPU 执行一条指令所需的时间。一条指令的执行过程划分为若干个阶段，每一阶段完成一个基本操作。
程序的机器周期数 = 程序的指令数 x 指令平均时钟周期数（cycles per instruction、CPI） 程序的 CPU 执行时间 = 程序的机器周期数 x 时钟周期 指令流水线 指令流水线（instruction pipeline）是指把一条指令的操作分成多个小步骤，每个步骤由专门的电路完成。然后，再使用平行（parallelize）处理的方式提高指令的执行效率。
高级 CPU 会动态排序（dynamically reorder）有依赖（dependencies）关系的指令，然后乱序执行（out-of-order execution），这里的乱序是和原来的顺序相比较的。 高级 CPU 会使用分支预测（branch prediction）技术，提前把指令放入流水线。另外还有推测执行（speculative execution）技术。 其他提升性能的方法 超标量处理器（superscalar processors）：一个时钟周期完成多个指令。 多核处理器（multi-core processors）：一个 CPU 有多个内核，可同时处理多个指令流。 多个独立 CPU（multiple independent CPU）：多个独立 CPU 同时工作。 参考（reference） Crash Course Computer Science（计算机科学速成课） bilibili
CrashCourse 字幕组
Youtube 原视频
7、中央处理器(CPU)-The Central Processing Unit 8、指令和程序-Instructions &amp;amp; Programs 9、高级CPU设计-Advanced CPU Designs</content></entry><entry><title>存储器（Memory）</title><url>/post/computer-science/hardware/memory/</url><categories><category>hardware(硬件)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>hardware(硬件)</tag></tags><content type="html">前言 前置笔记：
算术逻辑单元（Arithmetic and Logic Unit、ALU）
资料 memory.drawio.html 正文 锁存器 锁存器（and-or latch）由与门、或门、非门组成。（见图：memory.drawio.html 2-2）可以存储 1 bit 的数据。
初始状态，set 线不通电，reset 线不通电（见图：memory.drawio.html 2-4-2），此时输出 0。 没有输入，整个结构也能持续输出 0，换句话说就是锁存器存储了 0。
当 set 线通电，reset 线不通电时（见图：memory.drawio.html 2-4-4-2），此时输出 1。 如果这个时候 set 线从通电变成不通电（见图：memory.drawio.html 2-4-4-4）， 没有输入，整个结构依然能持续输出 1，换句话说就是锁存器存储了 1。
想要把锁存器里面恢复成 0，只需要 reset 线通电即可。这个时候 set 线通不通电是无所谓的，都会输出 0。 （见图：memory.drawio.html 2-4-6-2、2-4-6-4、2-4-8-2、2-4-8-2）
门锁 锁存器已经可以实现存储 1 bit 的数据了，但是它有一点不好用。 第一，set 线用于输入 1，reset 线用于输入 0，输入数据需要两条线。 第二，没有安全机制，任意一条线通电了，就有可能改变里面存储的数据。
可以在锁存器的前面加上一些限制结构解决前面的两个问题，然后就可以得到 gated latch（门锁）（见图：memory.drawio.html 4-2）。
初始状态，data input 线不通电，write enable 线不通电（见图：memory.drawio.html 4-4-2），此时输出的是 0。
如果只给 data input 线通电，而 write enable 线不通电的话，1 这个数据是设置不进去的（见图：memory.drawio.html 4-4-4）。 只有当 data input 和 write enable 线都通电时，1 这个数据才能设置进去（见图：memory.drawio.html 4-4-6-2、4-4-6-4）。
想要把门锁里面恢复成 0，就需要给 write enable 线通电的同时保证 data input 线不通电， 这里就和锁存器那里 set 线通不通电无所谓不一样了（见图：memory.drawio.html 4-4-8-2、4-4-8-4）。
门锁可以做到一条线控制输入的数据，另一条线控制允不允许输入，操作的逻辑非常清晰。
寄存器 把 n 个门锁线性排列起来，就可以存储 n 个 bit 的数据了，寄存器（register）就是这种结构。 这里简单画一个 8 位的寄存器。（见图：memory.drawio.html 6-2）
寄存器的位宽指的是，寄存器能存储多少位数据。
二维的平面结构 如果需要存储的数据容量很大的话，寄存器这种一维的线性的结构就不合适了，导线数量太多。 所以需要排列更紧密的结构，让导线可以复用，从而减少导线的数量。比如，二维的平面结构，或者三维的立体结构。 但是这会带来新的问题，怎么找到众多门锁中的某一个门锁？这里用二维的平面结构举例。
门锁是没有位置信息的，但是二维的平面结构是可以放到坐标系里去的，这样二维的平面结构里的门锁就可以用行列坐标表示了。 把行列坐标和 write enable 线组合起来，就可以控制二维的平面结构里的某一个门锁了。 用同样的思路，还可以控制某一个门锁的输出，也就是图里的 read enable 线。 read enable 线结合二极管就可以把数据的输入输出都用一条线解决。（见图：memory.drawio.html 8-2）
这里简单画一下存入数据和读取数据的示意图。（见图：memory.drawio.html 8-4-2、8-4-4）
可寻址内存 这里把一个 2 行 2 列的二维的平面结构画出来（见图：memory.drawio.html 8-8-2）。 显然还有一个问题，行列的电路怎么控制？这里就要用到&amp;quot;多路复用器&amp;quot;结构。
多路复用器就是一堆不同逻辑门的组合，用于判断输入是不是满足某个条件。这里画一个输入为 2 位二进制树的多路复用器。 （见图：memory.drawio.html 8-8-4）举例，输入 0b10 的时候，多路复用器只有 01 对应的那个输出端会有电。
把多路复用器加到图里，行列两个方向上都放上一个多路复用器，（见图：memory.drawio.html 8-8-6）这样就可以控制所有的存储单元了。 举例，输入行 0b10、列 0b11 的时候，对应到图中，就是第 2 行、第 3 列的那个单元。
2 行 2 列的可以得到一个 16 bit 的内存。再扩展一下，从 2 行 2 列变成 16 行 16 列， 就可以得到一个 256 bit 的内存（见图：memory.drawio.html 8-8-10），每个内存地址只能存储 1 bit 的数据。
现在常用的内存，一个内存地址可以存储一个字节，也就是 8 bit 的数据，这是怎么做到的？这里用到的思路和寄存器那里是一样的， 把 8 个 256 bit 的内存线性排列起来（见图：memory.drawio.html 8-10-2），让一个地址对应 8 块内存里相同的位置。
假设，有一个字节的数据 0b10001000 要存储进去。这里用到的思路是拆开，把 0b10001000 拆成 1、0、0、0、1、0、0、0 分别存储。 第 0 位，放到第一块；第 1 位，放到第二块；以此类推。这样就可以让一个地址对应 8 块内存里相同的位置都存储了这个数据的一部分。 取数据的时候，把取出来的 8 个 1 bit 的数据，按照拆分规则再组合起来就可以了。
可寻址内存的一个重要特性就是可以随时访问任意位置。 可寻址内存的地址从 0 开始编号，然后，自增排列。 因为内存是线性结构而且有地址，所以理论上读写内存上任何一个数据的速度是一样的。
不同的 RAM 用不同的存储单元（电路）存取单个 bit，比如： 不同的逻辑门、capcitor（电容器）、charge traps（电荷捕获）、memristor（记忆电阻器）。
参考 Crash Course Computer Science（计算机科学速成课） bilibili
CrashCourse 字幕组
Youtube 原视频
6、寄存器 &amp;amp; 内存-Registers and RAM</content></entry><entry><title>算术逻辑单元（Arithmetic and Logic Unit、ALU）</title><url>/post/computer-science/hardware/alu/</url><categories><category>hardware(硬件)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>hardware(硬件)</tag></tags><content type="html"><![CDATA[资料 alu.drawio.html 正文 机械继电器 早期的计算机用机械结构来控制电路的状态，这个部件叫机械继电器。机械继电器主要由机械开关和电磁铁组成（见图：alu.drawio.html 2-2）。
当控制线不通电时，电磁铁不产生磁性，开关断开，输出端没有电，表示输出 0；当控制线通电时，电磁铁产生磁性，开关闭合，输出端有电，表示输出 1。（见图：alu.drawio.html 2-4-2、2-4-4）
二极管 随着技术的发展，后来用二极管替换了机械继电器来控制电路的状态。二极管通常由半导体材料制造，半导体是指在常温下导电性范围介于导体和绝缘体之间的材料，最关键的特点就是导电性可控。
这里画一个简单的二极管的示意图（见图：alu.drawio.html 4-2），里面最关键的部分是控制线和半导体。下文的逻辑电路都会用到这个简单的二极管。
当控制线不通电时，半导体不导通，输出端没有电，表示输出 0；当控制线通电时，半导体导通，输出端有电，表示输出 1。（见图：alu.drawio.html 4-4-2、4-4-4）
逻辑门 与门 与门（AND gate）就是实现了与运算的逻辑电路，串联两个二极管就可以实现（见图：alu.drawio.html 22-2）。
输入 1 输入 2 运算结果 示意图 0 0 0 alu.drawio.html 22-4-2 1 0 0 alu.drawio.html 22-4-4 0 1 0 alu.drawio.html 22-4-6 1 1 1 alu.drawio.html 22-4-8 或门 或门（OR gate）就是实现了或运算的逻辑电路，并联两个二极管就可以实现（见图：alu.drawio.html 24-2）。
输入 1 输入 2 运算结果 示意图 0 0 0 alu.drawio.html 24-4-2 1 0 1 alu.drawio.html 24-4-4 0 1 1 alu.drawio.html 24-4-6 1 1 1 alu.drawio.html 24-4-8 非门 非门（NOT gate）就是实现了非运算的逻辑电路，一个二极管加上短路的设计就可以实现（见图：alu.drawio.html 26-2）。
输入 运算结果 示意图 0 1 alu.drawio.html 26-4-2 1 0 alu.drawio.html 26-4-4 异或门 异或门（XOR gate，Exclusive-OR gate）就是实现了异或运算的逻辑电路，异或门由与门、或门、非门组成（见图：alu.drawio.html 28-2）。
输入 1 输入 2 运算结果 示意图 0 0 0 alu.drawio.html 28-4-2 1 0 1 alu.drawio.html 28-4-4 0 1 1 alu.drawio.html 28-4-6 1 1 0 alu.drawio.html 28-4-8 ALU 算术逻辑单元（arithmetic and logic unit、ALU）由算术单元（arithmetic unit、AU）和逻辑单元（logic unit、LU）组成。
ALU 一般都会支持的 8 个操作：加法（add）、带进位的加法（add with carry）、减法（subtract）、带借位的减法（subtract with borrow）、取消（negate）、增量（increment、可以理解为 +1）、减量（decrement、可以理解为 -1）、数字无改变通过（pass through）
简单的 ALU 没有乘法和除法，乘法就是多次加法。高级的 ALU 有专门做乘法的算术单元。
ALU 有三个输入：两个数据，一个操作码。操作码用于指示 ALU 做什么操作。
ALU 有多个输出：一个数据输出；多个标志（flag）输出。标志输出有很多。比如：溢出标志（OVERFLOW）、零测试电路（ZERO）、负标志（NEGATIVE），这三个是普遍使用的。
算术单元 算术单元由逻辑门、半加器、全加器、加法器等部件组成，主要的功能是进行算术运算。
半加器 半加器（half adder）由异或门、与门组成（见图：alu.drawio.html 42-2）。可以处理两个 1 位二进制数的加法运算，产生 2 个输出：一个 carry（进位）、一个 sum（和）。
输入 1 输入 2 运算结果 carry sum 示意图 0 0 00 0 0 alu.drawio.html 42-4-2 1 0 01 0 1 alu.drawio.html 42-4-4 0 1 01 0 1 alu.drawio.html 42-4-6 1 1 10 1 0 alu.drawio.html 42-4-8 全加器 全加器（full adder）由半加器、或门组成（见图：alu.drawio.html 44-2）。可以处理三个 1 位二进制数的加法运算，产生 2 个输出：一个 carry、1 个 sum。
输入 1 输入 2 输入 3 运算结果 carry sum 示意图 0 0 0 00 0 0 alu.drawio.html 44-4-2 1 0 0 01 0 1 alu.drawio.html 44-4-4 0 1 0 01 0 1 alu.drawio.html 44-4-6 0 0 1 01 0 0 alu.drawio.html 44-4-8 1 1 0 10 1 0 alu.drawio.html 44-4-10 1 0 1 10 1 0 alu.drawio.html 44-4-12 0 1 1 10 1 0 alu.drawio.html 44-4-14 1 1 1 11 1 1 alu.drawio.html 44-4-16 两个 2 位二进制数加法 实现运算的电路由半加器、全加器组成。（见图：alu.drawio.html 46-2）该电路可以处理两个 2 位二进制数加法运算，产生 3 个输出：一个 carry、2 个 sum（注意顺序）。
这里简要描述一下二进制加法运算的逻辑，用 0b11（A） + 0b11（B）举例。为了描述方便，这里借用 10 进制的个位、十位、百位的概念。先把 0b11 拆成十位的 1（A1、B1） 和个位的 1（A0、B0）。
在进行加法运算的时候，先进行个位和个位的加法，这里只有两个参数，两个个位（A0 和 B0），所以由半加器进行运算。1 + 1 = 10，产生 2 个输出：carry = 1、sum1 = 0。
然后进行十位和十位的加法，这里有三个参数，两个十位（A1 和 B1）还有个位相加的 carry，所以这里需要全加器进行运算。1 + 1 + 1 = 11，产生 2 个输出：carry = 1、sum2 = 1。所以最后的结果就是 0b110，carry = 1、sum2 = 1、sum1 = 0。
输入 A 输入 B 运算结果 carry sum2 sum1 示意图 00 00 000 0 0 0 alu.drawio.html 46-4-2 01 00 001 0 0 1 alu.drawio.html 46-4-4 00 01 001 0 0 1 alu.drawio.html 46-4-6 01 01 010 0 1 0 alu.drawio.html 46-4-8 10 00 010 0 1 0 alu.drawio.html 46-4-10 00 10 010 0 1 0 alu.drawio.html 46-4-12 10 01 011 0 1 1 alu.drawio.html 46-4-14 01 10 011 0 1 1 alu.drawio.html 46-4-16 10 10 100 1 0 0 alu.drawio.html 46-4-18 11 00 011 0 1 1 alu.drawio.html 46-4-20 00 11 011 0 1 1 alu.drawio.html 46-4-22 11 01 100 1 0 0 alu.drawio.html 46-4-24 01 11 100 1 0 0 alu.drawio.html 46-4-26 11 10 101 1 0 1 alu.drawio.html 46-4-28 10 11 101 1 0 1 alu.drawio.html 46-4-30 11 11 110 1 1 0 alu.drawio.html 46-4-32 行波进位加法器 参考&quot;两个 2 位二进制数加法&quot;的实现方式，就可以设计出&quot;两个 n 位二进制数加法&quot;的运算电路。比如，8 位行波进位加法器（8 bit ripple carry adder）。（见图：alu.drawio.html 48-2）可以处理两个 8 位二进制数的加法运算，产生 9 个输出：一个 carry、8 个 sum（注意顺序）。
现代计算机的加法器是超前进位加法器，超前进位加法器的电路结构和行波进位加法器不同，速度更快。
逻辑单元 逻辑单元由大量逻辑门组成，主要的功能是判断输入到底是哪一种输入。
判断是否为 0 这里用&quot;判断 4 位的二进制输入是不是 0&quot;举例。（见图：alu.drawio.html 60-2）4 位的二进制输入只有全是 0 时才输出 1；只要有一个非 0 就输出 0。（见图：alu.drawio.html 60-4-2 60-4-4）
ALU ALU 就是由算术单元和逻辑单元组成的，这里画一个简单的 ALU 的抽象示意图（见图：alu.drawio.html 80-2），真正的 ALU 会有更多的东西。
这里的抽象示意图对应的是一个可以处理两个 8 位二进制数的算术运算的 ALU。它有，两个数据输入（两个二进制数）、一个操作码（operation code）输入（加法还是减法）、一个数据输出（算数运算的结果）、3 个标志位（flag）输出（overflow 是否溢出、zero 是否为 0、negative 是否为负）。
下面举几个例子：
加法器的进位输出连接到溢出标志，如果溢出标志输出 true，表示有溢出。
计算 0b11111111 + 0b11111111。两个数据输入是 0b11111111 和 0b11111111、操作码输入假设是 0b0001（表示加法）。这个时候，因为 0b11111111 + 0b11111111 = 0b111111110，溢出了。所以数据输出会是 0b11111110、overflow 会是 1。
计算 A-B 时，如果零测试电路输出 true，表示 A 和 B 相等。
计算 0b11111111 == 0b11111111。计算机不会直接比较两个数字哪个大哪个小，计算机用的思路是让两个数字相减，然后和 0 比较。两个数据输入是 0b11111111 和 0b11111111、操作码输入假设是 0002（表示减法）。这个时候，因为 0b11111111 - 0b11111111 = 0b00000000，为 0。所以数据输出会是 0b00000000、zero 会是 1。
计算 A-B 时，如果负标志输出 true，表示 A 小于 B。
计算 0b11111111 &lt; 0b11111110。和上面那个例子的思路一样。两个数据输入是 0b11111111 和 0b11111110、操作码输入假设是 0002（表示减法）。这个时候，因为 0b11111111 - 0b11111110 = 0b00000001，大于 0。所以数据输出会是 0b00000001、negative 会是 0（表示 0b11111111 - 0b11111110 &gt; 0，0b11111111 更大）。
参考（reference） Crash Course Computer Science（计算机科学速成课） bilibiliCrashCourse 字幕组Youtube 原视频2、电子计算机-Electronic Computing 3、布尔逻辑 和 逻辑门-Boolean Logic &amp; Logic Gates 4、二进制-Representing Numbers and Letters with Binary 5、算术逻辑单元-How Computers Calculate-the ALU ]]></content></entry><entry><title>进程的创建、进程的运行、进程的内存资源、进程的退出、进程的回收</title><url>/post/computer-science/operating-system/linux/process/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>process(进程)</tag></tags><content type="html"><![CDATA[前言 前置笔记：运行 ELF 文件实践的环境：同 程序资料 {demo-c}/demo-in-linux/process/ 正文 进程的创建 笔记主要涉及 fock()、vfock()。
fock() fork() creates a new process by duplicating the calling process. The new process is referred to as the child process. The calling process is referred to as the parent process. &hellip;
fork() 通过复制调用进程创建一个新进程，新进程为子进程，调用进程为父进程。
RETURN VALUE On success, the PID of the child process is returned in the parent, and 0 is returned in the child. On failure, -1 is returned in the parent, no child process is created, and errno is set to indicate the error.
成功时，父进程拿到子进程的 pid，子进程拿到 0。可以根据这个判断哪个是父进程，哪个是子进程。 失败时，父进程拿到-1，子进程不会被创建，errno 会被设置用于表示错误。 代码示例：{demo-c}/demo-in-linux/process/fork.c
pid 和 ppid 在终端里使用 echo $$ 命令，可以打印当前进程的 pid。
getpid() 返回调用进程的 pid，getppid() 返回调用进程的父进程的 pid。 在使用时需要注意，必须让子进程先执行，父进程后执行，打印出来的 ppid 才是正确的。
代码示例：{demo-c}/demo-in-linux/process/pid_and_ppid.c
如果父进程在子进程执行前先跑完了，那么子进程打印出来的 ppid 就会变成 1。 因为父进程已经没了，子进程变成了孤儿进程。孤儿进程会被 1 号进程接管，有可能会变成后台进程。
1 号进程就是 init 进程。init 进程是所有其他进程的祖先进程， 它是 linux 系统启动过程中的第一个进程，也是系统在运行时的第一个用户级进程。 init 进程的 pid（进程标识符）是就是 1。
子进程和父进程的内存空间 DESCRIPTION &hellip; The child process and the parent process run in separate memory spaces. At the time of fork() both memory spaces have the same content. Memory writes, file mappings (mmap(2)), and unmappings (munmap(2)) performed by one of the processes do not affect the other. &hellip;
两个进程运行在不同的内存空间，进程间是隔离的。在 fork() 时，两个进程的内存空间的内容是一样的（程序数据和程序指令）。 两个进程进行写内存操作（定义新的变量并赋值，修改已定义的变量的值，定义新的函数）或者文件映射（进程间通信）时互不影响。
代码示例：{demo-c}/demo-in-linux/process/fork_separate_memory.c
在 fork() 时，子进程和父进程代码是一样的，子进程会从 fork() 的下一行代码开始继续执行。 一般是父进程先被调度，除非父进程被阻塞了。
copy on write（写时复制） 在 fork() 执行之后 exec() 执行之前，两个进程用的是相同的物理空间，子进程的代码段、数据段、堆栈都是指向父进程的物理空间。 两者的虚拟空间不同，但其对应的物理空间是同一个。当父子进程中有更改相应段的行为发生时，再为子进程相应的段分配物理空间。
如果没有执行 exec()，内核会给子进程的数据段、堆栈段分配相应的物理空间（两者有各自的进程空间，互不影响）。 而代码段继续共享父进程的物理空间（两者的代码完全相同）。 而如果执行了 exec()，由于两者执行的代码不同，子进程的代码段也会被分配单独的物理空间。
子进程和父进程的区别 DESCRIPTION &hellip; * The child has its own unique process ID, and this PID does not match the ID of any existing process group (setpgid(2)) or session. * The child&rsquo;s parent process ID is the same as the parent&rsquo;s process ID. * The child does not inherit its parent&rsquo;s memory locks (mlock(2), mlockall(2)). &hellip;
子进程有自己独立的唯一的进程标识（pid）。 子进程的父进程的 pid（ppid）和父进程的 pid 是一样的。 子进程不会继承父进程的内存锁。 vfork() Linux description vfork(), just like fork(2), creates a child process of the calling process. For details and return value and errors, see fork(2). &hellip; vfork() differs from fork(2) in that the calling thread is suspended until the child terminates (either normally, by calling_exit(2), or abnormally, after delivery of a fatal signal), or it makes a call to execve(2). Until that point, the child shares all memory with its parent, including the stack. &hellip;
vfork() 和 fork() 用法一样。区别在于，vfork() 创建子进程后，父进程会被阻塞，直到子进程退出。
代码示例：{demo-c}/demo-in-linux/process/vfork.c
而且 vfork() 创建出来的子进程和父进程共享内存，包括栈。
代码示例：{demo-c}/demo-in-linux/process/vfork_share_memory.c
vfork() 有 bug。当使用 return 0 结束或者执行到最后一行代码结束时， 有可能会报 &ldquo;Segmentation fault (core dumped)&rdquo; 错误。但是使用 exit(0)或者 _exit(0) 结束的时候不会。
通过 strace 命令追踪可以发现：报错时，子进程调用 exit_group(0) 退出，但是，父进程没有调用 exit_group(0)； 不报错时，两个进程都调用 exit_group(0) 退出。
这里猜测应该是共享内存的问题，如果子进程退出的时候把栈干碎了，那父进程被拉起来的时候，就没有栈，肯定会报错。
进程的运行 笔记主要涉及 execve()、exec 家族的六个函数。
程序被 execve() 加载到内存中时，需要操作系统分配内存资源。 准备工作做完后，下一步就是找到程序入口并开始执行。主进程默认会启动一个主线程去执行 main() 入口函数。
execve() DESCRIPTION execve() executes the program referred to by pathname. &hellip; pathname must be either a binary executable, or a script starting with a line of the form: #!interpreter [optional-arg] &hellip;
在当前正在运行的程序里，可以调用 execve() 通过另外一个新的程序的路径名执行它。 这个新的程序必须是一个二进制的可执行文件。或者是一个以 #!interpreter [optional-arg] 形式开始的脚本。 比如，shell 脚本文件开头的 #!/bin/bash。
DESCRIPTION &hellip; This causes the program that is currently being run by the calling process to be replaced with a new program, with newly initialized stack, heap, and (initialized and uninitialized) data segments. &hellip; execve() does not return on success, and the text, initialized data, uninitialized data (bss), and stack of the calling process are overwritten according to the contents of the newly loaded program.
execve() 在成功时不会返回。而是会导致当前正在运行的程序被另外一个新的程序所取代。 当前程序的 .test 段、.data 段、.bss 段、栈、堆等，都会被新的程序的数据覆盖。
exec DESCRIPTION The exec() family of functions replaces the current process image with a new process image. The functions described in this manual page are layered on top of execve(2).
简单理解，exec 家族的六个函数底层都是基于 execve() 实现的。
用 execl() 举例，代码示例：
{demo-c}/demo-in-linux/process/execl.c {demo-c}/demo-in-linux/process/call_by_exec.c 用 execv() 举例，代码示例：
{demo-c}/demo-in-linux/process/execv.c {demo-c}/demo-in-linux/process/call_by_exec.c 这个例子在 Ubuntu 22.04 环境中执行，会返回 Bad Address，不知道为什么。
进程的运行顺序 DESCRIPTION The scheduling priority of the process, process group, or user, as indicated by which and who is obtained with the getpriority() call and set with the setpriority() call. The process attribute dealt with by these system calls is the same attribute (also known as the &ldquo;nice&rdquo; value) that is dealt with by nice(2). &hellip; The prio argument is a value in the range -20 to 19 (but see NOTES below), with -20 being the highest priority and 19 being the lowest priority. Attempts to set a priority outside this range are silently clamped to the range. The default priority is 0; lower values give a process a higher scheduling priority. &hellip;
进程的运行（执行、调度）顺序受到 PRI（priority）值和 NI（nice）值控制，这两个值对应进程的同一个属性。 值的范围是 -20~19，值越小，进程优先级越高。这两个值可以通过 ps 命令（ps -ely）查看（PRI 和 NI 参数）， 也可以通过 top 命令查看（PR 和 NI 参数）。
在系统中，可以使用 nice 命令和 renice 命令调整进程的优先级。 nice 命令用于进程启动之前，renice 命令用于进程启动之后。
在代码中，getpriority() 可以查看进程优先级，setpriority()、nice() 可以调整进程优先级。 getpriority() 和 setpriority() 使用的时候需要注意的是，who 参数要和 which 参数对应。
代码示例：{demo-c}/demo-in-linux/process/nice.c
进程的内存数据 进程通过 execve() 将程序加载到内存中去执行，此时操作系统会它们分配相应的内存资源。分配的内存资源主要用于存储程序指令和程序数据。 还有额外的进程内存数据、进程标识、进程状态、哪个用户启动的、打开的文件等。这些数据主要存储在 /proc 目录中。
/proc 目录 DESCRIPTION The proc filesystem is a pseudo-filesystem which provides an interface to kernel data structures. It is commonly mounted at /proc. Typically, it is mounted automatically by the system, but it can also be mounted manually using a command such as: mount -t proc proc /proc Most of the files in the proc filesystem are read-only, but some files are writable, allowing kernel variables to be changed. &hellip;
proc 文件系统是一个伪文件系统，它提供了一个观察内核数据结构的接口。 一般来说，它会被操作系统自动挂载到 /proc 目录。proc 文件系统中的大多数文件都是只读的。 但是，有些文件是可写的，允许通过这些可写的文件改变内核变量。
DESCRIPTION &hellip; /proc/[pid] subdirectories Each one of these subdirectories contains files and subdirectories exposing information about the process with the corresponding process ID. &hellip;
/proc 目录存储了操作系统上所有进程的内存数据。进程对应的目录用进程标识（pid）命名。 比如，进程标识（pid）为 42 的进程，对应的目录就是 /proc/42。
/proc/[pid] 目录 cmdline This read-only file holds the complete command line for the process, unless the process is a zombie.
cmdline，记录进程是用什么命令启动的。如果进程已经变成僵尸进程了，那么这个文件就是空的。
environ This file contains the initial environment that was set when the currently executing program was started via execve(2).
environ，记录进程启动的时候的环境参数。就是调用 execve() 启动程序的时候，传给 execve() 的环境参数。
exe Under Linux 2.2 and later, this file is a symbolic link containing the actual pathname of the executed command. This symbolic link can be dereferenced normally; attempting to open it will open the executable. You can even type /proc/[pid]/exe to run another copy of the same executable that is being run by process [pid].
exe，包含被执行命令的实际路径名的软连接。可以直接通过它启动程序。
fd/ This is a subdirectory containing one entry for each file which the process has open, named by its file descriptor, and which is a symbolic link to the actual file. Thus, 0 is standard input, 1 standard output, 2 standard error, and so on.
fd 目录，记录进程打开的文件。这里面的内容就是常说的文件标识符。 程序启动的时候一般都会打开 0（标准输入）、1（标准输出）、2（标准错误）这三个。 也就是说，程序里通过代码打开的文件的文件标识符一般都是从 3 开始的。
limits This file displays the soft limit, hard limit, and units of measurement for each of the process&rsquo;s resource limits (see getrlimit(2)).
limits，记录进程的资源限制。
maps A file containing the currently mapped memory regions and their access permissions. See mmap(2) for some further information about memory mappings.
maps，记录进程的内存映射和对内存的访问权限。在里面可以找到，进程的堆栈对应的内存地址到底在哪。
net/ This directory contains various files and subdirectories containing information about the networking layer. The files contain ASCII structures and are, therefore, readable with cat(1). However, the standard netstat(8) suite provides much cleaner access to these files.
net 目录，记录进程和网络有关的数据。比如，和 socket 有关的东西。
stat Status information about the process. This is used by ps(1).
stat，记录进程状态信息。比如，进程状态、线程、信号等。这个文件是给 ps 命令用的。
statm Provides information about memory usage, measured in pages.
statm，以页为单位提供关于内存使用的信息。
status Provides much of the information in /proc/[pid]/stat and /proc/[pid]/statm in a format that&rsquo;s easier for humans to parse.
status，整合了 stat 和 statm 的内容。不过这个文件是给人看的，可读性更强。
进程内存布局 todo hkn linux 内存相关的会单独开一篇
进程的内存空间被分为内核空间（kernel space）和用户空间。 用户空间里面主要关注：栈（stack）、文件映射（里面有动态库的映射）、堆（heap）、 读写数据区（主要是程序数据，.bss 段、.data 段等）、 只读数据区（主要是程序指令，.text 段；也有程序数据 .rodata 段等。
进程的资源限制 DESCRIPTION The getrlimit() and setrlimit() system calls get and set resource limits. Each resource has an associated soft and hard limit, &hellip; The soft limit is the value that the kernel enforces for the corresponding resource. The hard limit acts as a ceiling for the soft limit: an unprivileged process may set only its soft limit to a value in the range from 0 up to the hard limit, and (irreversibly) lower its hard limit. A privileged process (under Linux: one with the CAP_SYS_RESOURCE capability in the initial user namespace) may make arbitrary changes to either limit value. &hellip;
getrlimit() 可以查看资源限制， setrlimit() 可以调整资源限制。 进程的资源限制包括软限制、硬限制等。其中软限制必须小于等于硬限制。
The resource argument must be one of: &hellip; RLIMIT_NOFILE This specifies a value one greater than the maximum file descriptor number that can be opened by this process. Attempts (open(2), pipe(2), dup(2), etc.) to exceed this limit yield the error EMFILE. (Historically, this limit was named RLIMIT_OFILE on BSD.) &hellip;
可以通过资源参数指定需要操作的资源。比如 RLIMIT_NOFILE 对应进程可以打开的文件个数。 这个参数很重要，因为 linux 上一切皆文件。
代码示例：{demo-c}/demo-in-linux/process/rlimit.c
另外，在生产环境中，应该优先在程序中动态修改资源限制，不要轻易修改操作系统的资源限制。
进程的退出 笔记主要涉及：exit()、_exit()、_Exit()、exit_group()、abort()。
代码示例：{demo-c}/demo-in-linux/process/exit.c
进程退出的方式 程序运行到最后一行代码。 主动调用 exit()、_exit()、_Exit()、exit_group() 主动 return 0。 主动调用 abort()，会导致进程异常终止，报 &ldquo;Aborted (core dumped)&rdquo; 错误。 进程收到了中断信号。 exit() DESCRIPTION The exit() function causes normal process termination and the least significant byte of status (i.e., status &amp; 0xFF) is returned to the parent (see wait(2)). All functions registered with atexit(3) and on_exit(3) are called, in the reverse order of their registration. &hellip; If one of these functions does not return (e.g., it calls _exit(2), or kills itself with a signal), then none of the remaining functions is called, and further exit processing (in particular, flushing of stdio(3) streams) is abandoned. All open stdio(3) streams are flushed and closed. Files created by tmpfile(3) are removed. &hellip;
exit() 会让进程正常终止，退出状态码会先和 0xFF 做与运算，然后返回给父进程。所有打开的 stdio(3) 流会被刷新然后关闭
_exit()、_Exit() DESCRIPTION _exit() terminates the calling process &ldquo;immediately&rdquo;. Any open file descriptors belonging to the process are closed. Any children of the process are inherited by init(1) (or by the nearest &ldquo;subreaper&rdquo; process as defined through the use of the prctl(2) PR_SET_CHILD_SUBREAPER operation). The process&rsquo;s parent is sent a SIGCHLD signal. The value status &amp; 0xFF is returned to the parent process as the process&rsquo;s exit status, and can be collected by the parent using one of the wait(2) family of calls. The function _Exit() is equivalent to _exit().
NOTES &hellip; The function _exit() is like exit(3), but does not call any functions registered with atexit(3) or on_exit(3). Open stdio(3) streams are not flushed. &hellip;
_exit() （_Exit()和 _exit() 是等价的）会让进程立即终止， 子进程退出时会向父进程发送 SIGCHLD 中断信号，退出状态码会先和 0xFF 做与运算，然后返回给父进程。 打开的 stdio(3) 流不会被刷新。
exit_group() SYNOPSIS Note: glibc provides no wrapper for exit_group(), necessitating the use of syscall(2).
DESCRIPTION This system call is equivalent to _exit(2) except that it terminates not only the calling thread, but all threads in the calling process&rsquo;s thread group.
退出状态码 [00007fdf9e51ea3d] exit_group(0) = ? [????????????????] +++ exited with 0 +++ 退出状态码会先和 0xFF 做与运算。这个的意思是说，加入退出状态码设置的是 300，那实际返回的是 300 &amp; 255 的结果，也就是 44。
[00007fb290aeaca1] exit_group(300) = ? [????????????????] +++ exited with 44 +++ 在终端里使用 echo $? 命令，可以打印上一个程序的退出状态码。
不同退出方式下 printf() 的区别 上面提到，过不同的退出方式，对打开的 stdio(3) 流的处理方式不一样。
程序运行到最后一行代码、主动 return 0、主动调用 exit() 时，会检查文件的打开情况，处理 I/O 缓冲区内的内容。 而主动调用 _exit()、_Exit()、exit_group 时不会。
也就是对于 printf(&quot;hello, world&quot;) （注意，没有 \n）来说，前面三个方式会输出 hello, world，而前面三个方式不会输出。
进程的回收 笔记主要涉及：wait()、waitpid()
wait()、waitpid() 这两个系统调用的声明如下。
pid_t wait(int *wstatus); pid_t waitpid(pid_t pid, int *wstatus, int options);
DESCRIPTION All of these system calls are used to wait for state changes in a child of the calling process, and obtain information about the child whose state has changed. A state change is considered to be: the child terminated; the child was stopped by a signal; or the child was resumed by a signal. If a child has already changed state, then these calls return immediately. Otherwise, they block until either a child changes state or a signal handler interrupts the call (assuming that system calls are not automatically restarted using the SA_RESTART flag of sigaction(2)). &hellip;
RETURN VALUE wait(): on success, returns the process ID of the terminated child; on failure, -1 is returned. waitpid(): on success, returns the process ID of the child whose state has changed; if WNOHANG was specified and one or more child(ren) specified by pid exist, but have not yet changed state, then 0 is returned. On failure, -1 is returned.
wait() 用于等待调用进程的一个子进程的状态变化，并获取状态发生变化的子进程的信息。 比如，子进程终止；子进程被信号停止；子进程被信号恢复。如果一个子进程已经改变了状态，那么调用进程调用 wait() 会立即返回。 否则，调用进程就会阻塞，直到子进程改变状态或信号处理程序中断调用。
DESCRIPTION The wait() system call suspends execution of the calling thread until one of its children terminates. The call wait(&amp;wstatus) is equivalent to: waitpid(-1, &amp;wstatus, 0) &hellip;
wait(&amp;status) 和 waitpid(-1, &amp;status, 0) 是等效的。
DESCRIPTION If wstatus is not NULL, wait() and waitpid() store status information in the int to which it points. This integer can be inspected with the following macros (which take the integer itself as an argument, not a pointer to it, as is done in wait() and waitpid()!): &hellip;
wait()、waitpid() 调用成功的时候，返回值是子进程的 pid，传进去的参数 wstatus 会记录子进程的退出信息。 退出信息可以用提供的宏函数确定是哪一种。
代码示例：{demo-c}/demo-in-linux/process/wait.c
宏函数 WIFEXITED(wstatus) returns true if the child terminated normally, that is, by calling exit(3) or _exit(2), or by returning from main().
如果子进程是正常退出的 WIFEXITED(wstatus) 会返回一个非零值。
WEXITSTATUS(wstatus) returns the exit status of the child. This consists of the least significant 8 bits of the status argument that the child specified in a call to exit(3) or _exit(2) or as the argument for a return statement in main(). This macro should be employed only if WIFEXITED returned true.
当 WIFEXITED() 返回非零值时，可以用 WEXITSTATUS() 来提取子进程的返回值。 如果子进程调用 exit(5) 退出，WEXITSTATUS(status) 就会返回 5。
代码示例：{demo-c}/demo-in-linux/process/waitpid_macros.c
僵尸进程 DESCRIPTION In the case of a terminated child, performing a wait allows the system to release the resources associated with the child; if a wait is not performed, then the terminated child remains in a &ldquo;zombie&rdquo; state (see NOTES below).
在子进程终止的情况下，调用进程执行等待可以让操作系统释放与子进程相关的资源。 如果调用进程不执行等待，那么被终止的子进程就会处于&quot;僵尸&quot;状态，也就是僵尸进程。 当父进程也结束的时候，操作系统会把父进程和回收僵尸进程一起回收。
代码示例：{demo-c}/demo-in-linux/process/for_zombie.c
这里运行一下，下面的是输出到终端上的内容。
&gt; ./for_zombie.elf [debug]:parent, getpid()=3592 [debug]:parent, getpid()=3592, forkResult=3593 [debug]:child, getpid()=3593, forkResult=0 然后通过 ps 命令看一下 for_zombie 的运行情况。进程 3593 后面那个 &ldquo;Z+&rdquo; 就表示，它已经是一个僵尸进程了。
qqq 3592 0.0 0.0 2772 944 pts/0 S+ 20:14 0:00 ./for_zombie.elf qqq 3593 0.0 0.0 0 0 pts/0 Z+ 20:14 0:00 [for_zombie.elf] &lt;defunct&gt; 当进程变成僵尸进程时，它的内存数据还驻留在内存中，/proc 目录下的相关文件也不会移除，这些东西依然在占用系统资源。 如果僵尸进程过多，会导致系统资源紧张，会影响操作系统的运行。所以必须要回收退出的子进程。
参考 Linux进程控制]]></content></entry><entry><title>Golang 实现简单的 Web 框架 -- middleware(中间件)</title><url>/post/computer-science/programming-language/framework/web/golang/middleware_v2/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>web</tag><tag>http</tag><tag>middleware(中间件)</tag><tag>golang</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64 资料 {demo-golang}/demo/web/middleware/ web.drawio.html 前置笔记：Golang 实现简单的 Web 框架 &ndash; router(路由)正文 前置（后置）工作成对出现 承接上一篇的问题，在前一篇里讨论前置（后置）工作的时候，都是以 &ldquo;前置（后置）工作是可以独立执行的整体&rdquo; 为前提讨论的。如果它们之间有合作关系，也就是需要相互传递数据，那么怎么办呢？这里可以使用封装的思路，设计一个全链路通用的数据结构。然后所有的前置（后置）工作和最终的处理方法都接收这个数据结构作为参数。
在最外层 ServeHTTP 方法最开始的地方创建一个这样的数据结构，先封装 ServeHTTP 方法的两个参数，然后在后面调用到的所有方法那里一层一层传下去。如果后面的工作需要前面的工作的数据，就可以借助这个数据结构进行传递。
type 全链路通用的数据结构 struct { // ServeHTTP 方法的两个参数 http.ResponseWriter *http.Request // 其他参数 } 这里沿用上一篇中，访问 &ldquo;/user/id&rdquo; 的时候的结果。结合上面说的全链路通用的数据结构，最终地执行逻辑可以总结成下面这样。注意一定是引用传递，值传递进去的是一个副本，方法里面修改副本是不会影响外面的这个本体的。这里画个代码块的示意图，见图：web.drawio.html 6-6-2，下面要用。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 构造一个全链路通用的数据结构，封装 ServeHTTP 方法的两个参数 // 前置工作 user (引用传递全链路通用的数据结构) // 前置工作 user-id (引用传递全链路通用的数据结构) // /user/id 的处理逻辑 (引用传递全链路通用的数据结构) // 后置工作 user (引用传递全链路通用的数据结构) } 这个结构可以解决需要互相传递数据的问题。比如，如果 &ldquo;后置工作 user&rdquo; 需要使用 &ldquo;前置工作 user&rdquo; 生成的数据，那就可以借助全链路通用的数据结构，&ldquo;前置工作 user&rdquo; 在执行的时候往里面塞点东西，这样后面的流程就可以用了。看上去没有什么大的漏洞。
处理异常 前面所有的流程里面，都是以代码正常执行为前提进行设计的，尚且没有考虑异常处理，因为异常处理本身确实就比较烦。
有 try-catch 结构的语言，直接一个大的 try-catch 包起来。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 构造一个全链路通用的数据结构，封装 ServeHTTP 方法的两个参数 try { // 前置工作 user (引用传递全链路通用的数据结构) // 前置工作 user-id (引用传递全链路通用的数据结构) // /user/id 的处理逻辑 (引用传递全链路通用的数据结构) // 后置工作 user (引用传递全链路通用的数据结构) } catch () { } } 没有 try-catch 结构的语言，只能在最后接收参数的地方判断一下返回值的内容，根据返回值的内容进行相应的处理。Golang 在最前面还可以加个 recover 恢复块。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 构造一个全链路通用的数据结构，封装 ServeHTTP 方法的两个参数 defer func(){ recover() } // 前置工作 user (引用传递全链路通用的数据结构) // 前置工作 user-id (引用传递全链路通用的数据结构) // /user/id 的处理逻辑 (引用传递全链路通用的数据结构) // 后置工作 user (引用传递全链路通用的数据结构) if x == 全链路通用的数据结构里的标记位 { // 标记位等于 x 就怎么怎么样 } else if y == 全链路通用的数据结构里的标记位 { // 标记位等于 y 就怎么怎么样 } } 屏蔽复杂度 前面的设计已经解决了绝大部分的问题。但是还有一点缺陷，全链路通用的数据结构里面会杂糅大量的数据。这些数据对于后面的整个流程来说是必须的，但是对于其中某一些流程来说，不是必须的。
比如，&ldquo;前置工作 user&rdquo; 和 &ldquo;后置工作 user&rdquo; 想要进行沟通，所以在全链路通用的数据结构里面放了一个值。但是，这个值对于 &ldquo;前置工作 user-id&rdquo; 和 &ldquo;/user/id&rdquo; 的处理逻辑来说就是没用的。
那么这里怎么优化呢？&ldquo;前置工作 user&rdquo; 和 &ldquo;后置工作 user&rdquo; 不是想要进行沟通嘛，那么能不能直接把这两个部分直接连起来呢？可以的，把中间的 &ldquo;前置工作 user-id&rdquo; 和 &lsquo;&quot;/user/id&quot; 的处理逻辑&rsquo; 看作一个整体的代码块。
那么这里需要的，就是以一整个方法作为参数的结构。代码（伪代码）就会变成类似下面这样的结构。这样的话，前面需要放到全链路通用的数据结构里的值是不是就不要了。上面那个代码块示意图会变成这样，见图：web.drawio.html 6-6-4。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 构造一个全链路通用的数据结构，封装 ServeHTTP 方法的两个参数 func 前置工作 user + 后置工作 user (引用传递全链路通用的数据结构) { // 前置工作 user 的处理逻辑 func 剩下的 (引用传递全链路通用的数据结构) { // 前置工作 user-id (引用传递全链路通用的数据结构) // /user/id 的处理逻辑 (引用传递全链路通用的数据结构) } // 后置工作 user 的处理逻辑 } } 这个结构怎么实现呢？首先需要注意到，这里需要传进去的已经不是那个全链路通用的数据结构了。需要传进去的是上面的伪代码中，中间的那个 &ldquo;func 剩下的&rdquo; 部分，也就是下面这部分.它是一个整体的代码块，或者说是一个完整的方法。
func 剩下的 (引用传递全链路通用的数据结构) { // 前置工作 user-id (引用传递全链路通用的数据结构) // /user/id 的处理逻辑 (引用传递全链路通用的数据结构) } 这个部分还有一个问题，&ldquo;func 剩下的&rdquo; 里面的 &ldquo;前置工作 user-id&rdquo; 不是处理逻辑的一部分。换句话说，上面这个操作只是个 &ldquo;前置工作 user&rdquo; 和 &ldquo;后置工作 user&rdquo; 恰好成对出现的特例，无法推广出一个通用的操作技巧。那么怎么办呢？
这里的 &ldquo;前置工作 user-id&rdquo; 如果能和 &ldquo;前置工作 user&rdquo; 一样，有一个 &ldquo;后置工作 user-id&rdquo; 和它配对是不是就行了。所以，补一个 &ldquo;后置工作 user-id&rdquo; 给 &ldquo;前置工作 user-id&rdquo;，这个 &ldquo;后置工作 user-id&rdquo; 什么都不做，单纯就是占个位置。
同样的如果只有后置工作，也可以补一个什么都不做的前置工作。这样就变得和上面 &ldquo;前置工作 user&rdquo; 和 &ldquo;后置工作 user&rdquo; 一样了。
func 剩下的 (引用传递全链路通用的数据结构) { // 前置工作 user-id (引用传递全链路通用的数据结构) // /user/id 的处理逻辑 (引用传递全链路通用的数据结构) // （补一个）后置工作 user-id (引用传递全链路通用的数据结构) } 然后，整个代码就可以变成这样了，一个类似套娃的结构。上面那个代码块示意图会变成这样，见图：web.drawio.html 6-6-6。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 构造一个全链路通用的数据结构，封装 ServeHTTP 方法的两个参数 func 前置工作 user + 后置工作 user (引用传递全链路通用的数据结构) { // 前置工作 user 的处理逻辑 func 前置工作 user-id + 空的后置工作 user-id (引用传递全链路通用的数据结构) { // 前置工作 user-id // /user/id 的处理逻辑 (引用传递全链路通用的数据结构) // （补一个）后置工作 user-id } // 后置工作 user 的处理逻辑 } } 这样，除了最里面的处理逻辑，外面的前置（后置）工作的部分，就都可以抽象成同一个结构了，是可以随意组合或者调整顺序的。
中间件 上面这玩意就是所谓的中间件（Middleware）的概念了，见图：web.drawio.html 6-2-2。也就是常听到的洋葱模型，见图：web.drawio.html 6-2-4。或者同心圆模型，见图：web.drawio.html 6-2-6。
本人更喜欢同心圆模型。前面两个模型的示意图，都没有明显的把嵌套的关系展现出来，更多的展示的是层层递进的关系。而同心圆模型，精准地反映了嵌套的关系，一层一层的进去之后，不管怎么走，都要再一层一层的原路出来。
中间件的设计（Golang） 代码结构设计 上面有两个部分需要定义：前置（后置）工作和处理逻辑。全链路通用的数据结构，上面已经定义过了，这里直接用。
// HTTPHandleFunc 处理逻辑 type HTTPHandleFunc func(ctx *HTTPContext) // HTTPMiddleware 前置（后置）工作 type HTTPMiddleware func(next HTTPHandleFunc) HTTPHandleFunc 处理逻辑没什么好说的，接收全链路通用的数据结构就行了。重点在于前置（后置）工作，它需要一个处理逻辑作为输入，然后再返回一个新的处理逻辑。
新的处理逻辑内部需要调用传入的那个处理逻辑，形成一个套娃的结构。具体的前置（后置）工作的实现方式，就像下面这样。
func DemoMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(ctx *HTTPContext) { // before DemoMiddleware next(ctx) // after DemoMiddleware } } } 这里假设定义两个前置（后置）工作。
func AMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { // before AMiddleware next(p7ctx) // after AMiddleware } } } func BMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { // before BMiddleware next(p7ctx) // after BMiddleware } } } 假设，具体的处理逻辑，定义成下面这样。
func UserId (p7ctx *HTTPContext) { // get user by id } 然后这么链起来，B 在内层，A 在外层。
// 最内层的处理逻辑 chain := func UserId() // 套第一层 mb := BMiddleware() chain = mb(chain) // 套第二层 ma := AMiddleware() chain = ma(chain) // 执行 chain(ctx) 怎么装起来的见图：web.drawio.html 6-4。最后的效果等价于下面这样的伪代码。
// before AMiddleware // before BMiddleware serve(p7ctx) // after BMiddleware // after AMiddleware 测试用例设计 这种结构没办法直接进行测试，可以使用一些间接方法。比如，让每个中间件都输出一个全局唯一的而且没有前缀冲突的字符串到全链路通用的数据结构里面。整个链路运行之后，从全链路通用的数据结构里面取出字符串，和测试用例相比较。下面举个例子。
func UserId (p7ctx *HTTPContext) { p7ctx.TestString = append(p7ctx.TestString, &#34;UserId;&#34;) } func AMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { p7ctx.TestString = append(p7ctx.TestString, &#34;beforeA;&#34;) next(p7ctx) p7ctx.TestString = append(p7ctx.TestString, &#34;afterA;&#34;) } } } func BMiddleware() HTTPMiddleware { return func(next HTTPHandleFunc) HTTPHandleFunc { return func(p7ctx *HTTPContext) { p7ctx.TestString = append(p7ctx.TestString, &#34;beforeB;&#34;) next(p7ctx) p7ctx.TestString = append(p7ctx.TestString, &#34;afterB;&#34;) } } } 测试用例 2 chain := func UserId() mb := BMiddleware() chain = mb(chain) ma := AMiddleware() chain = ma(chain) chain(ctx) 结果：&ldquo;beforeA;beforeB;UserId;afterB;afterA;&rdquo;
测试用例 4 chain := func UserId() ma := AMiddleware() chain = ma(chain) mb := BMiddleware() chain = mb(chain) chain(ctx) 结果：&ldquo;beforeB;beforeA;UserId;afterA;afterB;&rdquo;
可路由的中间件 上面实现的那个就是可路由的中间件。它就是在路由树的基础上，分别给每个路由树结点设置中间件。这样在匹配过程中，如果结点上设置了中间件，那么就把这些中间件记录下来。在路由匹配到某个路由结点获取到路由的处理方法之后，把最终的处理方法和这些中间件按照定义好的顺序套起来即可。
]]></content></entry><entry><title>Golang 实现简单的 Web 框架 -- router(路由)</title><url>/post/computer-science/programming-language/framework/web/golang/router_v2/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>web</tag><tag>http</tag><tag>router(路由)</tag><tag>golang</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64 资料 {demo-golang}/demo/web/router/ web.drawio.html 前置笔记：Golang 开启 HTTP 服务正文 Web 框架是什么 概念解释 简单的理解，Web 框架就是工程师们在反复开发 WEB 系统的后端服务时，对于 &ldquo;如何处理重复的代码&rdquo; 这个问题，想出的一种解决方案。Web 框架的核心目标主要有：减少重复的代码，提高代码的可维护性；提供常用的组件，提高编程的效率。
重复的代码分为两种。一种是，在一个工程中，多处都需要使用的代码。另一种是，在多个工程中，都需要使用的代码。Web 框架内部的设计是为了解决在一个工程中的重复的代码，Web 框架本体的设计是为了解决在在多个工程中的重复的代码。
在一个工程中的重复的代码是指，在一个工程中，有多处的逻辑是相同的，但是编码实现的时候，没有对逻辑进行封装，而是暴力的把代码复制粘贴。这么做会导致，如果这块逻辑有变化，那么所有复制粘贴的地方都需要修改。
在多个工程中都需要使用的代码是指，在多个项目中，可能都需要路由、中间件、参数校验、日志等常用的组件。这个时候就可以把这些常用的组件打包到一起，下次在需要构建类似的工程的时候，就可以直接拿过来用。
比喻解释 用比喻来理解，Web 框架就相当于毛坯房外加一堆事先准备好的建材。毛坯房是指，房屋的框架结构有了但是里面没有装修。事先准备好的建材是指，在房子外面事先准备好了砖头、水泥、石灰这类最基础的材料。毛坯房本体直接就可以用，如果使用者有别的需要，也对房屋进行不同的装修，添加不同的内饰。
比如，烘焙店和服装店内部装修肯定是不一样的。在进行装修的时候，可以直接使用事先准备好的建材。如果觉得事先准备好的建材不能满足需求，那就需要自行准备新的建材。比如，烘焙店和服装店如果想加一面墙，那可以直接用事先准备好的砖头、水泥。但是如果烘焙店想铺木地板或者服装店想贴墙纸，那就需要自行准备了。
这套逻辑套到 Web 框架上来是一样的，毛坯房对应的就是框架的核心组件，事先准备好的建材对应的就是常用的组件。对于 Web 系统来说，主要任务都是处理网络请求（毛坯房本体）。但是具体到不同的业务系统，它们内部处理的具体的业务逻辑肯定是不同的（不同的装修、不同的内饰）。比如，商城系统主要是处理商品和订单的，成绩管理系统主要是处理成绩的。但是有可能会使用相同的组件（事先准备好的建材）。比如，都需要登录、都需要记日志。
本人想到的最合理的解释 如果通过前面的概念和比喻还是不怎么好理解什么是 WEB 框架，那么还有一个更简单的理解，工程师们想偷懒，他们通过创造并使用 Web 框架这个工具，来达到偷懒的目的。
Web 框架是怎么被创造出来的 现在是知道有 Web 框架这么个工具了，但是这个工具是怎么被创造出来的呢？想要解释这个问题，就必须回到 Web 框架这个概念还没有出现的 &ldquo;蛮荒时代&rdquo; 去。下面将结合代码来说明这个问题，代码将会使用 Golang 处理 HTTP 1.1 的请求。
从 TCP 开始 别看见 TCP 就紧张，这里不要求深入了解 TCP 的细节，只需要知道 TCP 是一个字节流协议就可以了。字节流协议，它的意思就是说，传输数据的时候，它是以字节为单位的，传输的过程像流水一样，一个字节接着一个字节的。见图：web.drawio.html 2-2。
HTTP 1.1 是基于 TCP 协议实现的，所以 HTTP 1.1 也可以说是一种字节流协议。这里为什么要说这个呢？主要是想强调一下，在计算机的 &ldquo;眼里&rdquo;，HTTP 报文它不是一个整体，而是一个一个字符。HTTP 1.1 报文大概的格式见图：web.drawio.html 2-4-2、2-4-4。
既然发出去的 HTTP 报文就是一串字符，那么如果不说明这串字符怎么解读，那这串字符就毫无意义。所以客户端和服务端会通过约定请求行的 method 和 url 来区分不同的报文，method 和 url 的组合就是路由。
可以区分不同的报文之后，后面的请求头部和请求体才有意义。分析 HTTP 报文是什么类型，然后根据类型提取报文中的数据的过程就是解析 HTTP 报文的过程。
Golang 的 &ldquo;net&rdquo; 包和 &ldquo;net/http&rdquo; 包 在 net 包里，提供了对 TCP 的支持。而 &ldquo;net/http&rdquo; 包就是基于 net 包，实现了对 HTTP 协议的解析。这里就不费劲的从 TCP 开始搞了，怎么使用 TCP 和解析 HTTP 报文对理解 Web 框架其实没啥帮助。所以直接从 &ldquo;net/http&rdquo; 包开始。
再继续之前，建议先看一下 前置笔记：Golang 开启 HTTP 服务。下面会直接从 &ldquo;net/http&quot;包 的 Handler 接口的 ServeHTTP 方法切入。在 ServeHTTP 方法的第二个参数 &ldquo;*Request&rdquo; 里面，就可以拿到已经解析好的 HTTP 请求。
type Handler interface { ServeHTTP(ResponseWriter, *Request) } 从最简单的场景开始 假设，所有接口的处理逻辑都是一个完整的整体。
如果啥都不考虑，那大可以直接用 if-else 的结构去判断 method 和 url，然后在 if-else 分支里面写各自的处理逻辑。如果把处理逻辑封装到方法面去，那这样的代码的逻辑其实是非常清晰的。
func ServeHTTP(http.ResponseWriter, *http.Request) { if Request.Method == &#34;GET&#34; { if Request.URL == &#34;/user/id&#34; { // /user/id 的处理逻辑 } else if Request.URL == &#34;/user/name&#34; { // /user/name 的处理逻辑 } } else if Request.Method == &#34;POST&#34; { if Request.URL == &#34;/order/create&#34; { // /order/create 的处理逻辑 } else if Request.URL == &#34;/order/delete&#34; { // /order/delete 的处理逻辑 } } } 即使后面报文的类型越来越多，无非也就是 if-else 的分支多了一点。可以再对 url 的处理做一次封装，代码就可以拆开来了。
func ServeHTTP(http.ResponseWriter, *http.Request) { if Request.Method == &#34;GET&#34; { handleGet() } else if Request.Method == &#34;POST&#34; { handlePost() } } func handleGet(){ if Request.URL == &#34;/user/id&#34; { // /user/id 的处理逻辑 } else if Request.URL == &#34;/user/name&#34; { // /user/name 的处理逻辑 } else if xxx { } else if xxx { } } func handlePost(){ if Request.URL == &#34;/order/create&#34; { // /order/create 的处理逻辑 } else if Request.URL == &#34;/order/delete&#34; { // /order/delete 的处理逻辑 } else if xxx { } else if xxx { } } 就目前来看这种给 method 和 url 都写一个 if-else 的分支的写法，似乎并没有什么非常明显的弊端。这种结构也可以使用 map 结构代替。可以是一层的：map[method+url]处理方法，或者嵌套的：map[method]{map[url]处理方法}。
处理逻辑需要一些前置（后置）工作 但是实际上并不是 &ldquo;所有接口的处理逻辑都是一个完整的整体&rdquo;。比如，商城系统的下订单和取消订单的接口。下订单的接口的处理逻辑假设为，校验用户+下订单。取消订单的接口的处理逻辑假设为，校验用户+取消订单。
这里可以换一个角度，把下订单的接口的处理逻辑分成：前置工作 &ldquo;校验用户&rdquo; 和处理逻辑 &ldquo;下订单&rdquo;。把取消订单的接口的处理逻辑分成：前置工作 &ldquo;校验用户&rdquo; 和处理逻辑 &ldquo;取消订单&rdquo;。
这里讨论的是前置（后置）工作相同的情况。如果每个处理逻辑需要执行的前置（后置）工作不同，那就退回到 &ldquo;所有接口的处理逻辑都是一个完整的整体&rdquo; 那种情况去了。前置（后置）工作相同的情况有几种：所有的处理逻辑都需要，部分处理逻辑需要。
所有的处理逻辑都需要 这种场景非常好处理，直接在最外面写就好了。哪怕前置（后置）工作有多个或者它们之间有顺序要求的场景。
func ServeHTTP(http.ResponseWriter, *http.Request) { // 前置工作 a // 前置工作 b if Request.Method == &#34;GET&#34; { handleGet() } else if Request.Method == &#34;POST&#34; { handlePost() } // 后置工作 c } 部分处理逻辑需要 这种场景乍一看可以沿用 &ldquo;所有的处理逻辑都需要&rdquo; 的方案，把前置（后置）工作下放到每个 if-else 的分支里面去就好了。但是这么做是有问题的。
假设 &ldquo;/user/id&rdquo; 和 &ldquo;/user/name&rdquo; 都需要 &ldquo;前置工作 user&rdquo;，&quot;/user/id&rdquo; 自己还需要 &ldquo;前置工作 user-id&rdquo;，&quot;/user/name&quot; 自己还需要 &ldquo;后置工作 user-name&rdquo;。如果按照上面的写法，代码会写成下面这样子。
func handleGet(){ if Request.URL == &#34;/user/id&#34; { // 前置工作 user // 前置工作 user-id // /user/id 的处理逻辑 } else if Request.URL == &#34;/user/name&#34; { // 前置工作 user // /user/name 的处理逻辑 // 后置工作 user-name } } 乍一看问题不大，但是如果后面有 &ldquo;/user/a&rdquo;、&quot;/user/b&quot; 一直到 &ldquo;/user/z&rdquo; 呢？如果要求每个 &ldquo;/user/&rdquo; 开头的，都需要 &ldquo;前置工作 user&rdquo; 呢？这时候上面这种写法，&ldquo;前置工作 user&rdquo; 就要写 n 次，很麻烦。如果后面要求变了，要求每个 &ldquo;/user/&rdquo; 开头的都需要 &ldquo;前置工作 user2&rdquo;，或者这里就需要改 n 个地方，更麻烦。
所以要想办法，把这个公共的模块提取出去。比如，变成下面这样（这里写了个伪代码，用的是 SQL 的 LIKE 语法），把有这种要求的 url 前缀单独拿到一个 if-else 的分支里去。
func handleGet(){ if Request.URL like &#34;/user/%&#34; { // 前置工作 user if Request.URL == &#34;/user/id&#34; { // 前置工作 user-id // /user/id 的处理逻辑 } else if Request.URL == &#34;/user/name&#34; { // /user/name 的处理逻辑 // 后置工作 user-name } // 后置工作 user } else { if Request.URL == &#34;/order/id&#34; { // /order/id 的处理逻辑 } } } 乍一看问题不大，如果要求每个 &ldquo;/user/&rdquo; 开头的从都需要 &ldquo;前置工作 user&rdquo; 变成都需要 &ldquo;前置工作 user2&rdquo;，那么只需要改一处。但是如果前缀的层级很多呢？比如，加一个 &ldquo;/user/info/a&rdquo;，同时要求每个 &ldquo;/user/info/&rdquo; 开头的从都需要 &ldquo;前置工作 user-info&rdquo;。那上面这种写法就要变成。
func handleGet(){ if Request.URL like &#34;/user/%&#34; { // 前置工作 user if Request.URL like &#34;/user/info/%&#34; { // 前置工作 user-info if Request.URL == &#34;/user/info/a&#34; { // /user/info/a 的处理逻辑 } } else { if Request.URL == &#34;/user/id&#34; { // 前置工作 user-id // /user/id 的处理逻辑 } else if Request.URL == &#34;/user/name&#34; { // /user/name 的处理逻辑 // 后置工作 user-name } } // 后置工作 user } else { if Request.URL == &#34;/order/id&#34; { // /order/id 的处理逻辑 } } } 这样下去 if-else 的层级就会变得越来越深了。if-else 的层级太深，不利于代码的可读性和可维护性。更重要的是，这样的代码改的时候，找起来非常的麻烦，还要担心层级会不会改错了。所以这个问题是需要规避的。那么怎么规避呢？可以使用有层次的结构。
设想一个场景，图书馆里有大量的书需要分类管理。那么可以先按书内容的类别，分到不同的楼层去。然后再按书的作者，分到不同的书架上去。如果想处理某一类的书，可以只在某个楼层内操作，不会影响到别的楼层。如果想处理某一类的某个作者的书，可以只在某个楼层的某个书架上操作，不会影响到这个楼层的别的书架，更不会影响到别的楼层。
这里把这种结构画出来就很直观了。见图：web.drawio.html 4-2。这种结构在数据结构里对应的就是树形结构。把上面的 method、url、前置（后置）工作对应进去再画一张图。见图：web.drawio.html 4-4。
路由树 基本概念 到这里，所谓的路由树的概念就呼之欲出了。上面的那棵树的结点中记录了全路径，但是这其实是不需要的。当命中 &rsquo;like &ldquo;/user/%&rdquo;&rsquo; 分支往下走的时候，后面的 url 最前面的那段就肯定是 &ldquo;/user/&quot;。所以这里就可以借助前缀的思路，用 &ldquo;/&rdquo; 作为分隔标志，将上面的那棵树转化成前缀树。见图：web.drawio.html 4-6-2。注意有个根结点（&rdquo;/&quot; 结点）。
这样当一个 HTTP 请求过来的时候，先通过 method 判断应该到哪一棵路由树里去找。然后用 &ldquo;/&rdquo; 将 url 分开，依次去路由树里匹配，如果结点上有前置（后置）工作就需要记录下来。最后找到目标结点时，按照前置工作、处理逻辑、后置工作的顺序依次执行。
比如，在 web.drawio.html 4-6-2 这颗树里，访问 &ldquo;/user/id&rdquo; 的时候。依次会访问：&quot;/&quot; 结点；&ldquo;user&rdquo; 结点，记录下 &ldquo;前置工作 user&rdquo; 和 &ldquo;后置工作 user&rdquo;；id 结点，记录下 &ldquo;前置工作 user-id&rdquo; 和 &ldquo;/user/id&rdquo; 的处理逻辑。见图：web.drawio.html 4-6-4。
执行的时候，从逻辑上考虑的话，应该是前面的结点的前置任务应该在前面，前面的结点的后置任务应该在后面。所以上面就应该按照 &ldquo;前置工作 user&rdquo;、&ldquo;前置工作 user-id&rdquo;、&quot;/user/id&quot; 的处理逻辑、&ldquo;后置工作 user&rdquo; 的顺序依次执行。
路由树的设计（Golang） 代码结构设计 路由树，从名字里就可以知道，它首先是一个是树结构，所以，设计工作应该从树结点开始。这里用 web.drawio.html 4-6-2 里的那个路由树为例。
一条完整的路由会被拆成有父子关系的一系列结点。那么，树结点里面一定有一个数据用于标记它是路由中的哪一个部分。然后，还需要知道父子关系，所以，结点需要存储其子结点的信息。这里一般没有回溯的需求，如果需要支持路由的回溯匹配，那么结点就需要记录父结点的信息。
一条路由最后会对应一个处理方法，这个显然是需要记录的。另外，还有前置工作和后置工作，这部分属于中间件，放到后面说，这里先不搞。所以，代码结构目前应该差不多像下面这样。
// routingNode 路由结点 type routingNode struct { // part 这个路由结点代表的那段路径 part string // handler 命中路由之后的处理逻辑 handler HTTPHandleFunc // routingTree 路由子树，子结点的 path =&gt; 子树根结点 routingTree map[string]*routingNode } 测试用例设计 对于最基本的路由树结构，测试用例设计是非常简单的。
用例编号 测试用例 测试目标 2 /user 根结点（空结点） -&gt; 根结点有 1 个子结点（user） 4 /user + /user/info user 结点（空结点） -&gt; user 结点有 1 个子结点（info） 6 /user + /order 根结点有 1 个结点（user） -&gt; 根结点有 2 个结点（user、order） 这样最基本的几种情况就都测到了。
路径参数路由、正则匹配路由、通配符路由 静态的路由匹配可以用上面的 if-else 分支或者路由树解决。但是一些高级玩法，比如：路径参数路由、正则匹配路由、通配符路由，这样的就没办法整。
路径参数路由，一般长这样 &ldquo;user/:id&rdquo;，能把路由里的某一段提取出来，放到事先定义好的变量里面。
正则匹配路由一般长这样 &ldquo;user/:id(/\d/)&quot;，它和路径参数路由很像，区别在于，正则匹配路由在提取出路由里的某一段之后，还需要对数据的格式进行校验。
通配符路由一般长这样 &ldquo;/user/*&quot;，它就很暴力了，只要路由前面是 &ldquo;/user/&rdquo; 开头的，后面是什么都可以匹配上。
这里以路径参数路由为例。比如，定义 &ldquo;user/:id&rdquo; 这样一个路径参数路由，在对应的处理方法里，事先定义好了一个变量 id 用于接收 &ldquo;:id&rdquo; 这个位置对应的字符串。
最终达到的效果是：如果访问的是 &ldquo;user/1&rdquo;，那么变量 id 的值就是字符串 &ldquo;1&rdquo;；如果访问的是 &ldquo;user/2&rdquo;，那么变量 id 的值就是字符串 &ldquo;2&rdquo;；如果访问的是 &ldquo;user/a&rdquo;，那么变量 id 的值就是字符串 &ldquo;a&rdquo;。
对于这种 &ldquo;:id&rdquo; 的位置可以变的路由。if-else 分支或者 map 是无解的。因为，&quot;:id&rdquo; 对应的位置可变，意味着这里会对应无穷多个 if-else 分支。路由树有没有解呢？路由树可以解决，路由树只需要在 user 结点上增加一个特殊的 &ldquo;:id&rdquo; 结点，专门用于处理路径参数路由即可。见图：web.drawio.html 4-8-2。
访问 &ldquo;/user/1&rdquo; 的时候。依次会访问：&rdquo;/&quot; 结点；&ldquo;user&rdquo; 结点。到了 &ldquo;user&rdquo; 结点之后，按照默认逻辑下面要找的是 1 结点，但是 &ldquo;user&rdquo; 结点下面只有 &ldquo;info&rdquo; 结点、&ldquo;id&rdquo; 结点，无法匹配。这个时候就可以尝试匹配 &ldquo;:id&rdquo; 结点，看看 1 符不符合 &ldquo;:id&rdquo; 结点的要求。
这里 &ldquo;:id&rdquo; 的位置可以是任意的字符串，所以 1 是符合要求的，所以 &ldquo;/user/1&rdquo; 最终调用的就应该是 &ldquo;:id&rdquo; 结点的处理逻辑。见图：web.drawio.html 4-8-4。
但是需要注意的是，这三个玩意匹配的时候可能都能匹配上，所以需要人为的定义这三个特殊的路由，哪个优先匹配，哪个最后匹配。
最后，写代码的时候，路由注册和路由查询的逻辑建议分开。因为路由注册和路由查询的逻辑看似都是找结点，但是细节上还是有点区别的。路由注册的时候，是严格按照路由层级注册的，而路由查询的时候，需要考虑特殊结点。
路径参数路由、正则匹配路由、通配符路由的设计（Golang） 代码结构设计 路径参数路由、正则匹配路由、通配符路由的匹配逻辑和普通结点是不同的，需要能识别出它们。在树结构里，可以通过给结点打上标记来区分不同的结点。
在上面的设计中，把所有的结点都放到了一个 map 里面管理，这个操作在这里是行不通的。这三种特殊的结点没有实际上的 url，也就提取不出 map 的 key。所以，这三种特殊的结点需要专门的地方来存储。
而且这三种特殊结点理论上都是唯一的。比如，一个结点上不可能同时有两个路径参数路由。假设，同时存在 &ldquo;/user/:id&rdquo; 和 &ldquo;/user/:name&rdquo;，那么 &ldquo;/user/a&rdquo; 应该命中哪一个呢。另外，通配符结点的后面不应该有子结点，因为，全部都会被通配符结点截胡。
普通结点里用于标记它是路由中的哪一个部分的那个参数，在这三种结点里面是没啥用的。路径参数路由和正则匹配路由需要一个额外的参数存储参数的名字，正则匹配路由还需要一个参数存储正则表达式。
所以，上面的代码结构需要增加点东西，目前应该差不多像下面这样。
// routingNode 路由结点 type routingNode struct { // nodeType 结点类型 nodeType int // part 这个路由结点代表的那段路径 part string // path 从根路由到这个路由结点的全路径 path string // handler 命中路由之后的处理逻辑 handler HTTPHandleFunc // routingTree 路由子树，子结点的 path =&gt; 子树根结点 routingTree map[string]*routingNode // paramChild 路径参数结点 paramChild *routingNode // paramName 路径参数路由和正则表达式路由，都会提取路由参数的名字 paramName string // regexpChild 正则表达式结点 regexpChild *routingNode // regexp 正则表达式 regexp *regexp.Regexp // anyChild 通配符结点 anyChild *routingNode } 测试用例设计 三种特殊结点的测试用例设计就稍微复杂一点了。而且因为结点类型变多了，还需要考虑注册结点的时候的顺序的问题。三种特殊结点有可能会干扰注册普通结点时的结点查询逻辑。
用例编号 测试用例 测试目标 - 普通结点 + 参数路由结点 - 2 /user + /user/:id user 结点（空结点） -&gt; user 结点有 1 个参数路由子结点（:id） 4 /user + /user/info + /user/:id user 结点有 1 个子结点（info） -&gt; user 结点有 1 个子结点（info）和 1 个参数路由子结点（:id） 6 /user + /user/:id + /user/info user 结点有 1 个参数路由子结点（:id） -&gt; user 结点有 1 个子结点（info）和 1 个参数路由子结点（:id） 8 /user + /user/:id + /user/:id/info 参数路由结点（:id）（空结点） -&gt; 参数路由结点（:id） 有 1 个子结点（info）注意用例 8 和用例 6 的区别。 10 /user + /user/:id + /user/:name user 结点有两个参数路由子结点，报错 12 /user + /user/:id + /user/:id/:name 参数路由结点（:id）（空结点） -&gt; 参数路由结点（:id）有 1 个参数路由子结点（:name） - 普通结点 + 正则表达式结点 - 42 /user + /user/:id(/\d/) user 结点（空结点） -&gt; user 结点有 1 个正则表达式子结点（:id） 44 /user + /user/info + /user/:id(/\d/) user 结点有 1 个子结点（info） -&gt; user 结点有 1 个子结点（info）和 1 个正则表达式子结点（:id） 46 /user + /user/:id(/\d/) + /user/info user 结点有 1 个正则表达式子结点（:id） -&gt; user 结点有 1 个子结点（info）和 1 个正则表达式子结点（:id） 48 /user + /user/:id(/\d/) + /user/:id(/\d/)/info 正则表达式结点（:id）（空结点） -&gt; 正则表达式结点（:id） 有 1 个子结点（info）注意用例 48 和用例 46 的区别。 50 /user + /user/:id(/\d/) + /user/:name(/^[A-Za-z0-9]+$/) user 结点有两个正则表达式子结点，报错 52 /user + /user/:id(/\d/) + /user/:id(/\d/)/:name(/^[A-Za-z0-9]+$/) 正则表达式结点（:id）（空结点） -&gt; 正则表达式结点（:id）有 1 个正则表达式子结点（:name） - 普通结点 + 通配符结点 - 82 /user + /user/* user 结点（空结点） -&gt; user 结点有 1 个通配符子结点 84 /user + /user/info + /user/* user 结点有 1 个子结点（info） -&gt; user 结点有 1 个子结点（info）和 1 个通配符子结点 86 /user + /user/* + /user/info user 结点有 1 个通配符子结点 -&gt; user 结点有 1 个子结点（info）和 1 个通配符结点子结点 88 /user + /user/* + /user/*/info 通配符结点后面不能有子结点，报错 - 4 种结点混合，这里就不一个一个写了，场景太多了 - 前置（后置）工作成对出现 上面讨论前置（后置）工作的时候，都是以 &ldquo;前置（后置）工作是可以独立执行的整体&rdquo; 为前提讨论的。如果它们之间有合作关系，也就是需要相互传递数据，那么怎么办呢？这个放到下一篇里说：Golang 实现简单的 Web 框架 &ndash; middleware(中间件)]]></content></entry><entry><title>并发问题</title><url>/post/computer-science/concurrency_issues/</url><categories><category>computer-science(计算机科学)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>concurrent(并发)</tag></tags><content type="html"><![CDATA[正文 并行和并发 用概念解释 在操作系统中，并行（parallel）是指，一个时间段中，一组程序各自独立的异步的执行，每个程序都有自己的处理机。 任意一个时刻，这组程序都是正在执行的，无论从宏观还是微观。
在操作系统中，并发（concurrent）是指，一个时间段中，一组程序各自独立的异步的执行，这一组程序共用同一个处理机。 任意一个时刻，只有一个程序在正在执行，宏观上是同时执行，微观上是顺序执行。
用比喻解释 首先，假设有一个&quot;用手拿起桌子上的杯子&quot;的动作。 这个动作的内部被分成了 &ldquo;伸手-&gt;抓住杯子-&gt;拿起来&rdquo; 这样有先后关系的多个子动作，每一个子动作可以单独被执行。 现在，假设有一个人，就叫他慧，他有两个手（如果是触手怪的话就可以有好多手了）慧的面前有一张桌子，桌子上有两个杯子（多个杯子）。
并行是什么呢，慧的左右手同时做&quot;用手拿起桌子上的杯子&quot;的动作，两个手同时进行，各做各的互不干扰。 左手做 &ldquo;伸手&rdquo; 子动作的同时，右手也可以做 &ldquo;伸手&rdquo; 子动作。 并行强调，两个或以上的动作，从外面看上去是同时进行的，从内部看，每个时刻可以有多个子动作在进行。
并发是什么呢，慧的左右手同时做&quot;用手拿起桌子上的杯子&quot;的动作，两个手同时进行，但是每次只能完成一个子动作。 左手做 &ldquo;伸手&rdquo; 子动作的时候，右手是不能动的。 并发强调，两个或以上的动作，从外面看上去是同时进行的，但是从内部看，每个时刻只能有一个子动作在进行。
并发问题 用比喻解释 在上面的假设中，假设了两个手和两个杯子。两个手做动作的时候，各自拿一个杯子。 这是没有问题的，两个动作都可以独立完成。但是如果假设的时候，是两个手和一个杯子。 两个手做动作的时候，拿的是同一个杯子。这就有问题了，两个动作会冲突。
并行场景下，左右手都完成了抓住了杯子子动作，那么左手进行拿起来子动作的时候，右手怎么办。 并发场景下，左手完成了拿起来子动作，右手完成了伸手子动作，那么右手进行抓住杯子子动作的时候，抓什么。 这个场景中的冲突就是并发问题出现的原因。
用代码解释 用最典型的 i++ 再来解释一下并发问题。把上面的名词换一下就行了： 动作相当于程序代码；子动作相当于 CPU 指令；慧相当于 CPU；杯子相当于临界资源。
i++ 看上去是一条语句，但是在指令层面，它至少分为三步： 1、从变量 i 的内存地址上读取数据；2、对数据做 +1 运算；3、把运算结果放到变量 i 的内存地址上去。
假设 i 是个全局变量，内存地址是 0x10，值是 0。现在有两个线程：线程 a 和线程 b 同时执行 i++。 这里预期的结果应该是 i=2，但是实际执行过程中会发生下面这种情况。
时间流逝方向 线程 a 线程 b ↓ 等待 CPU 调度 等待 CPU 调度 ↓ 被给予 CPU 资源 等待 CPU 调度 ↓ 从 0x10 上读取数据（0） 等待 CPU 调度 ↓ 对数据做 +1 运算 等待 CPU 调度 ↓ 被剥夺 CPU 资源 被给予 CPU 资源 ↓ 等待 CPU 调度 从 0x10 上读取数据（0） ↓ 等待 CPU 调度 对数据做 +1 运算 ↓ 等待 CPU 调度 把运算结果（1）放到 0x10 上去 ↓ 被给予 CPU 资源 运行结束，归还 CPU 资源 ↓ 把运算结果（1）放到 0x10 上去 - ↓ 运行结束，归还 CPU 资源 - 因为线程 a 还没有把运算结果放到内存 0x10 上去，所以线程 b 从内存 0x10 上拿到的依然是 0。 假设线程 b 没有被剥夺 CPU 资源，完整地跑完了三条指令，那么 i 应该是 1。线程 b 结束运行，归还 CPU 资源。
线程 a 得到 CPU 资源，继续执行。这个时候线程 a 执行的是最后一步，把运算结果（1）放到内存 0x10 上去。 这样就出问题了，实际的结果是 i=1，和期望的结果 i=2 不一致。
所以并发问题一定要从指令层面保证不会出问题，而不是语句层面。
解决方案 并发问题的解决方案的基本思路都是保证临界资源在同一时刻只能被一个对象操作。 这个对象可以是多线程环境中的一个线程，分布式系统中的一个客户端（其实也可以认为是线程）。
加锁或者 CAS，都是一样的思路。加锁就是多线程抢同一把锁，CAS 就是多线程抢同一个标志位。 只有抢到锁或者标志位的线程，才能操作临界资源。这个时候临界资源就相当于是独享的，就不会出现并发问题。
锁机制 常用的锁机制有两种：悲观锁、乐观锁。
悲观锁假定会发生并发冲突，在操作数据之前，需要保证只有自己能操作数据。 如果有其他想要操作数据的，它们会被挡住。悲观锁大多依靠底层提供的锁机制。
乐观锁假定不会发生并发冲突，先假定只有自己在操作数据，需要提交的时候，再检查是不是真的只有自己在操作数据。 如果有其他在操作数据的，自己会被挡住。乐观锁大多是基于数据版本记录机制实现。
CAS CAS（Compare And Swap）操作是原子操作，包含三个操作数：内存中的值（内存位置 V）、原值（预期原值 A）、新值（新值 B）。 如果内存中的值与原值相等，那么处理器会将内存中的值更新为新值。如果内存中的值与原值不相等，处理器不做任何操作。
锁和 CAS+自旋 单纯地看一次操作的效率的话，CAS 的效率肯定是比锁高的。但是并发场景中，不能只看一次操作的效率，而是要看整体操作的效率。
如果并发量很少，也就是冲突不明显的时候。比如锁和 CAS 都是一次就成功。那么整体的效率，CAS 是比锁要高的。
如果并发量很大，也就是冲突明显的时候。锁一次不成功，就会阻塞，然后进入通知队列等着被唤醒了，CPU 就可以空出来干别的事情。 但是 CAS 一次不成功，会不停的重试，直到成功。
这个时候问题就来了，假设并发数量是 10000，那么 1 个成功了，那么剩下来的 9999 个，一定是不可能成功的。 但是它们依然在不停的重试，一直消耗 CPU 的资源。
并发安全 不会出现并发问题，那就可以说是并发安全的。
参考 {极客时间}/Go 实战训练营并发等待队列实现 ]]></content></entry><entry><title>队列（Golang 实现）</title><url>/post/computer-science/programming-language/golang/queue/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag><tag>queue(队列)</tag><tag>concurrent(并发)</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {demo-golang}/demo/queue/ queue.drawio.html 并发安全队列 并发安全队列就是不会出现并发问题的队列。
关于并发问题的一些东西在这篇里：并发问题阻塞队列和非阻塞队列 个人认为，一个队列是阻塞队列还是非阻塞队列，应该根据队列本身的设计判断。队列需不需要阻塞，是设计上决定的，和用锁还是用 CAS 是没关系的，这两个结构是为了解决并发问题的。
如果设计队列的时候，队列有最大容量。而且队列本身的设计中有阻塞的逻辑。这样的队列就是阻塞队列。比如，在入队阶段，判断队列容量已满的时候，不是直接返回入队失败，而是等待队列空出位置后在入队，那么这里就需要设计阻塞的逻辑。
反之，如果设计队列的时候，队列有最大容量，但是队列本身的设计中没有阻塞的逻辑，或者队列没有最大容量，那就是非阻塞队列。比如，在入队阶段，判断队列容量已满的时候，直接返回入队失败，那么这里就不需要设计阻塞的逻辑。
并发安全的有最大容量的队列 代码详见：
{demo-golang}/demo/queue/concurrent_blocking_queue.go。 {demo-golang}/demo/queue/wait_cond.go。 这里沿用上面的定义。想要一个并发安全的有最大容量的队列的两个要求：1、并发安全；2、有最大容量。这里用锁+环形数组实现。因为有最大容量的限制，所以肯定是需要阻塞的逻辑的。
从最简单的入队出队逻辑开始。入队：检查容量-&gt;(等待有空位：比如循环检查容量)-&gt;入队。出队：检查容量-&gt;(等待有数据：比如循环检查容量)-&gt;出队。这种结构可以满足有最大容量的要求，但是因为对临界资源（队列数据）的访问是没有限制的，所以这肯定不是并发安全的。
既然要保护临界资源，那么首先想到的肯定是加锁。Golang 里面就是 sync.Mutex 了。直接加锁行不行呢？入队：加锁-&gt;检查容量-&gt;(等待有空位：比如循环检查容量)-&gt;入队-&gt;解锁。出队：加锁-&gt;检查容量-&gt;(等待有数据：比如循环检查容量)-&gt;出队-&gt;解锁。这样的逻辑显然会在&quot;等待有空位&quot;和&quot;等待有数据&quot;这两个步骤产生死锁。
如果队列满了，&ldquo;等待有空位&quot;这里就无法入队，导致锁放不掉。这里锁放不掉，出队那里就加不了锁，无法出队。如果队列为空，&ldquo;等待有数据&quot;这里就无法出队，导致锁放不掉。这里锁放不掉，入队那里就加不了锁，无法入队。
所以加锁之后，&ldquo;等待有空位&quot;和&quot;等待有数据&quot;这个两步骤需要修改。&ldquo;等待有空位&quot;需要先解锁，这样出队那里就可以加锁。然后等待有空位。等到有空位之后，再加锁，然后入队。&ldquo;等待有数据&quot;需要先解锁，这样入队那里就可以加锁。然后等待有数据。等到有数据之后，再加锁，然后出队。
大概的过程见图：queue.drawio.html 2-2、2-4
Golang 里面提供了这种工具 sync.Cond。可以先看一眼官方提供的 sync.Cond.Wait() 里面的逻辑。执行逻辑很简单，大概是：获取一个用于等通知的结构；把拿着的锁放掉；阻塞，等通知；等到通知了，把锁加回来。
func (c *Cond) Wait() { c.checker.check() t := runtime_notifyListAdd(&amp;c.notify) c.L.Unlock() runtime_notifyListWait(&amp;c.notify, t) c.L.Lock() } 有了这个结构。出队的那个地方出队的时候，发一个信号给&quot;等待有空位&quot;就行。入队的那个地方入队的时候，发一个信号给&quot;等待有数据&quot;就行。这样并发问题也就解决了。加锁可以在并发场景中保护队列数据的正确性，但是用 sync.Mutex 和 sync.Cond 有一个缺点，这玩意无法控制超时。
用 sync.Mutex 执行 sync.Mutex.Lock() 之后，gorouting 就陷进去了，直到它拿到锁，否则是不会出来的。用 sync.Cond 也一样。执行 sync.Cond.Wait() 之后，gorouting 一样会陷进去，直到它被 sync.Cond.Signal() 或者 sync.Cond.Broadcast() 发出的信号唤醒，否则也是不会出来的。
所以这里需要的是一个可以被控制的等待加锁的结构。也就是说要一个 sync.Mutex.Luck(time) 或者 sync.Cond.Wait(time) 这样的东西。如果一定时间拿不到锁，或者等不到信号，要能从阻塞状态退出来。
仔细观察一下 Wait() 的代码。里面加锁和解锁的步骤是必须的，所以核心问题其实就找到了。需要修改原有的等通知的逻辑，让这里变成既可以等待信号，同时也可以被 context 超时控制的结构。在 Golang 里面，等待信号可以使用 channel（管道）。这玩意可以变相的做到，既可以被阻塞，也可以在需要的时候被唤醒。
可以把读一个空的管道理解成阻塞，把从管道里读到东西理解成唤醒。如果需要模拟阻塞，那么就读一个空的管道就可以了。唤醒这里需要一点技巧，这里不能用往管道里写数据的方式去唤醒阻塞中的 gorouting。因为不知道到底有多少个 gorouting 在等着读数据，也就是不知道要写多少次数据。写少了，会有等着的 gorouting 读不到数据，会泄露。写多了自己会阻塞，也会泄露。
这里可以用直接关闭管道的思路，读取已经关闭的管道会读到零值。那么关闭一个有很多 gorouting 都在读取的管道，就相当于完成了一次 Broadcast()。但是这种操作无法实现 Signal()。新的方法里面的逻辑大概就是下面这样（伪代码）。
func (p7this *Cond) WaitWithTimeout(ctx context.Context) error { // 获取一个用于等通知的 channel // 把拿着的锁放掉 select { case &lt;-ctx.Done(): // 超时，这里就不用把锁加回来了。外层应该拿到这里的异常，然后执行异常处理逻辑。 return ctx.Err() case &lt;-通知信号: // 等到通知了，说明有 gorouting 调用了 Broadcast() 关闭了 channel，把锁加回来。 // 这个地方并没有完全解决超时的问题，因为这里加锁的逻辑还是有可能被阻塞的。 } } 并发安全的没有最大容量的队列 代码详见：
{demo-golang}/demo/queue/concurrent_nonblocking_queue.go。 这里沿用上面的定义。想要一个并发安全的没有最大容量的队列的两个要求：1、并发安全；2、没有最大容量。这里用链表+CAS+自旋实现。因为没有最大容量，所以是不需要设计阻塞逻辑的。
还是从最简单的入队出队逻辑开始。因为没有最大容量，所以入队时是没有限制的。出队这里，和入队哪里保持一致，不设计阻塞逻辑。所以队列为空的时候，就直接返回一个异常就行。当然，出队如果想设计成一直等到有数据再出队的逻辑也不是不行。
所以基本的逻辑就可以定下来了。入队：入队。出队：检查队头-&gt;出队。和前面一样，因为对临界资源（队列数据）的访问是没有限制的，所以这肯定不是并发安全的。
如果选择用加锁的方式保护临界资源，那么基本思路就和前面的那个&quot;并发安全的有最大容量的队列&quot;是一样的。这里就不重复了，这里换另一个处理思路，用 CAS+自旋达到和锁一样的效果。改造后的步骤也不是很复杂。入队：准备好数据-&gt;使用 CAS 入队。出队：检查队头-&gt;使用 CAS 出队。
CAS 入队怎么入呢？入队的时候，最关心的是队尾，因为新结点会连接到原来的队尾结点上去，变成新的队尾结点。所以只要保护住&quot;替换队尾结点&quot;这个步骤，就能避免出现并发问题。所以 CAS 操作的目标就可以确定了，原来的队尾结点和新结点。
func (p7this *Queue) Enqueue(ctx context.Context, data) error { // 先把新的结点准备好 // 然后通过 CAS 操作挂到链表的尾部 for { // 通过原子操作把队尾拿出来 // CAS 操作，如果当前的队尾指针就是上面取到的指针，那么把队尾换成新的结点 if atomic.CompareAndSwapPointer(队尾, 取到的队尾, 新结点) { // CAS 返回成功，说明队尾没变，可以直接修改 // 把新结点接到原来的队尾结点上去 } // CAS 返回失败，说明队尾变了，其他想要入队的，已经抢先入队而且完成了，那就要重头再来 } } CAS 出队怎么出呢？出队的时候，最关心的是队头，因为队头结点出队之后，队头结点的下一个结点会接替原来的队头结点成为新的队头结点。所以只要保护住&quot;接替原来的队头结点&quot;这个步骤，就能避免出现并发问题。所以 CAS 操作的目标就可以确定了，原来的队头结点和队头结点的下一个结点。
func (p7this *Queue) Dequeue(ctx context.Context) (data, error) { for { // 检查队列是否为空 // 通过原子操作把队头拿出来 if atomic.CompareAndSwapPointer(队头, 取到的队头, 队头结点的下一个结点) { // CAS 返回成功，说明队头没变，可以直接修改 // 直接把结点上的数据取出来，然后出队就行了 } // CAS 返回失败，说明队头变了，其他想要出队的，已经抢先出队而且完成了，那就要重头再来 } } 思路比较简单，就是理解起来很不直观，这里需要借助调度时候的时序图来理解。详细的入队出队的调度过程见图。入队：queue.drawio.html 4-6、4-6-2、4-6-4、4-6-4-2、4-6-4-4。出队：queue.drawio.html 4-8、4-8-2、4-8-4、4-8-4-2、4-8-4-4。注意里面红色标记的结点，因为协程会在任意时刻被剥夺 CPU 资源，所以会出现部分步骤没完成的场景。
延迟队列 代码详见：
{demo-golang}/demo/queue/delay_queue.go {demo-golang}/demo/queue/priority_queue.go {demo-golang}/demo/queue/wait_cond_v2.go 延迟队列就是进入队列的元素有时间属性，在时间到之前不能出队。入队的时候没有什么限制，问题在出队这里。简单的搞法，直接整一个轮询不停地全量扫描，这是可以达到目的的，就是会占用 CPU 资源。
但是如果队列里面的元素很多，那全量扫描的时间，说不定队列里面已经有元素到时间了。所以最好对队列元素进行排序，搞成有优先级的，这样每次只需要检查第一个元素就行了。
这里借助时间属性给元素确定优先级，那么时间小的就应该排在前面。加上需要不停地进行插入和删除操作，普通的数组就不太合适了，比较合适的数据结构是小根堆。
优先队列可以解决全量扫描的问题，但是暴力轮询的问题还没有解决。如果不暴力轮询，那么中间就需要加入阻塞等待的机制，这个就稍微麻烦一点了。
首先，阻塞固定的时间是肯定不行的，在这段时间里面，队头元素说不定已经到时间了。所以阻塞的时间肯定要根据队头元素来，队头元素还有多久到时间，那就阻塞多久。这种思路可以解决队列元素不变的情况。但是如果等待过程中，入队了一个优先级更高的元素。那么这个思路也是有问题的，阻塞之后来不及出来了。
所以这里需要监听两种信号，一种是队头元素到时间的信号，另一种是入队信号。监听到入队信号之后，检查一下入队的元素的优先级，如果优先级更高就需要调整阻塞的时间。
整体思路和前面的那个&quot;并发安全的有最大容量的队列&quot;是一样的，就是队列数据的存储结构不一样，然后就是增加了针对延时的逻辑。大概的过程见图：queue.drawio.html 6-2、6-4
参考（reference） 极客时间Go实战训练营 并发等待队列实现 ]]></content></entry><entry><title>Golang 的 context 包的使用</title><url>/post/computer-science/programming-language/golang/context/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {demo-golang}
/demo/context/ context 也叫上下文，可用于携带数据或者控制调度流程。在常见的设计中，会把 context.Context 作为方法的第一个参数。
五个常用的方法 Background() 这个方法用于创建流程的第一个上下文。后续的上下文，如果没有特殊的情况，都是由它派生出来的。
WithValue() 这个方法用于挂载一个键值对到上下文上去。通常用于传递整条链路都需要用的参数。在使用的时候需要注意，WithValue() 的第三个参数的类型是 any。后面通过 Context.Value() 取出来的数据，需要进行类型转换后才能使用。
代码见：{demo-golang}/demo/context/context_test.go 的 f8ContextWithValue()
WithCancel() context.WithDeadline()，context.WithTimeout() 这三个方法一起看，它们的用途是差不多的，都是通过控制取消的信号，来控制流程。区别在于 WithCancel() 只能手动控制取消。WithDeadline() 和 WithTimeout() 可以设置到期时间，到期它会自动取消，也可以在到期之前手动控制取消。
代码见：{demo-golang}/demo/context/context_test.go 的 f8ContextWithCancel()
WithCancel() 在上下文取消之前 Context.Done() 和 Context.Err() 是拿不到信号的。取消之后 Context.Done() 可以读到信号，Context.Err() 会返回 context.Canceled。
这里看一下 WithDeadline()。WithTimeout() 里面其实是调了 WithDeadline()。
func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { return WithDeadline(parent, time.Now().Add(timeout)) } 代码见：{demo-golang}/demo/context/context_test.go 的 f8ContextWithDeadline() 和 f8ContextWithDeadlineV2()。
使用 WithDeadline() 的时候有一个时序的问题，超时和取消，哪个先发生。这个对 Context.Done() 没有影响，但是对 Context.Err() 是有的。如果超时发生在取消之前，那异常就是 context.DeadlineExceeded。如果超时发生在取消之后，那异常就是 context.Canceled。</content></entry><entry><title>Golang 的 sync 包的使用</title><url>/post/computer-science/programming-language/golang/sync/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag><tag>concurrent(并发)</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {demo-golang}
/demo/sync/ 调度器 代码见：{demo-golang}/demo/sync/goroutine_test.go
调度器在需要的时候，只会对正在运行的 goroutine 发出通知，试图让它停下来。但是调度器不会也不能强行让一个 goroutine 停下来。所以如果循环中的语句过于简单的话，那么当前的 goroutine 就可能不会正常响应（或者说没有机会响应）调度器的停止通知。
sync.Mutex sync.Mutex 就是互斥锁或者互斥量。sync.Mutex 使用过程中有几点需要注意：不要重复加锁、不要忘记解锁、不要对未锁定的锁解锁、不要对已解锁的锁解锁。
另外，sync.Mutex 是一个结构体类型，属于值类型中的一种。所以不要在多个函数之间直接传递。把它传给一个方法、将它从方法中返回、把它赋给其他变量、让它进入某个 channel，都会导致副本的产生。原值和它的副本，以及多个副本之间都是完全独立的，它们都是不同的 sync.Mutex。
sync.RWMutex sync.RWMutex 就是读写锁，可以单独加读锁或者写锁，其余的和 sync.Mutex 差不多。
sync.Cond 代码见：{demo-golang}/demo/sync/cond_test.go
sync.Cond 可以理解为条件变量，需要结合 sync.Mutex 或者 sync.RWMutex 一起使用。用于控制 goroutine 的动作。不满足条件时，阻塞 goroutine。满足条件时，唤醒一个阻塞中的 goroutine 或者唤醒全部阻塞中的 goroutine。
sync.Cond 主要有三个方法：Wait()、Signal()、Broadcast()
Wait() 会阻塞当前 goroutine，并当前的 goroutine 添加到通知队列的队尾，直到通知到来。阻塞时，会解锁当前条件变量基于的互斥锁。通知到来时，会唤醒当前 goroutine，重新锁定当前条件变量基于的互斥锁。
Signal() 从通知队列的队首开始，找第一个符合条件的 goroutine 唤醒。而 Broadcast() 则会唤醒通知队列所有符合条件的 goroutine。
另外，在使用时，应该使用 for 语句包裹条件变量的 Wait() 方法。这里有两个典型场景。
场景1：并发环境下，可能有多个 goroutine 在等待同一个共享资源。如果一个 goroutine 被唤醒后，发现拿不到共享资源，那么就应该再次调用 Wait()，继续等待。
场景2：需要的共享资源数量大于 1 个，也就是说只拿到一个共享资源是不满足条件的。这种情况下 goroutine 被唤醒后，需要先检查可以被占用的共享资源能不能满足自己的需求。如果不能满足需求，那么就应该再次调用 Wait()，继续等待。
比如需要的共享资源数量是 2。假设，现在有 goroutine0 到 0 个共享资源，goroutine2 拿到 1 个共享资源。这两个 goroutine 都不满足条件，都在等待。这个时候，goroutine4 释放了 1 个共享资源。
如果用的是 Signal()，假设它唤醒了 goroutine0，这个时候就算占用了 goroutine4 释放的 1 个共享资源，也是不能满足要求的，所以还是需要继续等待。不如唤醒 goroutine2，它就缺一个。所以这种情况就可以使用 Broadcast() 通知所有等待中的 goroutine。
WaitGroup 代码见：{demo-golang}/demo/sync/wait_group_test.go
WaitGroup 可以结合 channel 控制限制开启的 gorouting 数量。
用 channel 模拟令牌桶的思路，每次循环在开启 gorouting 之前需要先获取到令牌。gorouting 执行完之后，需要归还令牌，然后循环就可以继续创建新的 gorouting 了。</content></entry><entry><title>Docker Compose 怎么用</title><url>/post/computer-science/application/docker/compose/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>docker</tag><tag>docker-compose</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 Docker v20.10.17 正文 Docker Compose 是什么 Docker Compose 是用于定义和运行多个 Docker 容器的工具。 使用 YML 文件配置需要的所有服务后，可以同时创建并启动所有服务。
Docker Compose 怎么用 第一步：编辑 docker-compose.yaml services: mysql8: image: mysql:8.0 container_name: mysql8-dev # restart: always command: --default-authentication-plugin=mysql_native_password environment: MYSQL_ROOT_PASSWORD: root # volumes: # - ./script/mysql/init.sql:/docker-entrypoint-initdb.d/init.sql ports: - &#34;3306:3306&#34; redis7: image: redis:7.0 container_name: redis7-dev environment: - ALLOW_EMPTY_PASSWORD=yes ports: - &#39;6379:6379&#39; image：指定用哪个 docker 镜像，如果本地没有的话，启动的时候会去 DockerHub 拉。 container_name：指定容器名称。 如果不指定的话，当多个 docker compose 都需要创建同一个容器的时候，会报重名的错误。 如果指定的话，多个 docker compose 会共享那个指定了名称的容器。 restart：需不需要重启容器。 ports：指定端口映射。冒号前面的是本机的端口，冒号后面的是容器内的端口。 第二步：启动 打开 powershell，进入 docker-compose.yaml 文件所在的目录。
执行命令 docker compose up 或者命令 docker compose up -v 就可以启动了。
带 &ldquo;-v&rdquo; 参数表示命令在后台运行，不会再控制台输出日志。想要关闭的时候直接 Ctrl+C 就可以了。
]]></content></entry><entry><title>诺维科夫自洽性原则</title><url>/post/physics/time/novikov/</url><categories><category>time(时间)</category></categories><tags><tag>physics(物理学)</tag><tag>time(时间)</tag></tags><content type="html">诺维科夫自洽性原则 诺维科夫自洽性原则（Novikov self-consistency principle），是一个物理学术语。是由前苏联数学家，诺维科夫，在 1980 年代提出的，有关时间悖论的规则。
这个原则的核心概念是：人可以回到过去，但是不能因此改变历史的进程。我们的世界是已经被改变的最终结局。
我对这玩意的理解是 假设一个人 A 在时间节点 α 上，在某件事情 a 上，做了某个选择 1。然后在时间节点 β （α &amp;lt; β）上，他后悔了，选择用时间旅行，去把在时间节点 α 上，在某件事情 a 上做的选择 1，修正成选择 2。
到这里矛盾就出现了。如果在时间节点 α 上，选择 1 真的被修正成选择 2，那么 A 这个人观测到的历史就应该是，他在时间节点 α 上，在某件事情 a 上，做了某个选择 2。这样的话，他不会后悔，也就没有了时间旅行。
还有一种可能，A 在时间节点 α 上，在某件事情 a 上，做了某个选择 1，就是在时间节点 β 上的 A 进行时间旅行造成的，进行时间旅行的 A 变成了历史的一部分。
换个角度再来理解一下 假设在时间节点 β 上的 A（就叫他 Aβ），回到了时间节点 α 上，做选择的也不是他 Aβ 啊，做选择的是在时间节点 α 上的那个 A（就叫他 Aα）。所以如果时间旅行存在，在 Aβ 观测到的历史里应该有 Aβ 的存在，但是现在没有，到这里矛盾就出现了。
再换个角度理解一下 对于已经观测过过去的历史的人，过去的时间已经是确定的事实，而未来是不确定的。如果通过时间旅行，回到某段已经观测过的历史进程中。
虽然对于时间旅行者而言，从穿越时间点到未来这次穿越发生的时间点之间的这段时间都应该属于未来，但是由于其结果已经被时间旅行者观测过，所以即使时间旅行者试图改变历史，也会得到相同的结果。
所以诺维科夫自洽性原则也可以理解成：时间线是唯一的。
关于平行宇宙的问题 如果假设平行宇宙（多元宇宙、多重宇宙、世界泡）存在的话。宇宙从时间节点 α 上应该会分裂成两个宇宙，宇宙一和宇宙二。这里假设宇宙一对应选择 1，宇宙二对应选择 2。还是宇宙一中在时间节点 β 上的 A，进行了时间旅行。
结合上面的两个角度，如果想解决矛盾，那应该是从时间节点 α 上又分裂出了一个新的宇宙，宇宙三。在这个新的宇宙里，宇宙三的 Aα 能观测到宇宙一的 Aβ。但是这种情况，宇宙一什么都没有改变。
关于欺骗世界的说法 这种说法属于一种比较中二病的说法，故事情节看上去改变了世界，但是里面其实玩了一点花招。
如果某个故事的背景是设定在诺维科夫自洽性原则下的，那么这个故事的世界观就是过去不可变。但是人本身的感官是不能收集所有的信息的，也就是人通过感官获得的信息不一定就是真正的客观现实。所以以人的视角创造的历史就是可以被改变的。
所以在这种情况下，这类故事会先以人的视角观测一些现象，然后加上一些心理学上的预设，诱导读者 往某个看上去合理的历史上想，但是这其实不是真正的历史。然后当要开始所谓的欺骗世界的时候，就可以给之前给出的一些现象，另外一套解释。看上去就像是欺骗了世界，从而达到一种看上去像是改变了历史的表象。
比如，主角看到队友被捅了几刀，然后倒在血泊之中。队友临死之前让主角跑路，然后主角就头也不回的跑了。这种情况中，主角其实没有足够的信息判断队友死了没有。被捅了几刀，有没有可能是玩具刀；那个所谓的血泊，有没有可能是假的。
时间跳针 时间跳针是游戏《量子破碎》（《Quantum Break》）中的概念，类似 《JOJO的奇妙冒险》 里的绯红之王，或者很多作品里的形态各异但是本质上差不多的&amp;quot;时停&amp;quot;的概念。
时间已经经过了一段时间，但是没有能力的个体感觉到的只是一瞬。
reference（参考） 一个七年前的游戏，竟展现了2022年时间将彻底终结（量子破碎）〖游戏不止〗
预言2022年世界静止的游戏，最终的结局是什么样？（量子破碎）〖游戏不止〗
诺维科夫自洽性原则
诺维科夫
如何理解诺维科夫自洽性原则的解释？
蘑菇食草的回答</content></entry><entry><title>使用 WSL 和 Goland 进行 Golang 开发</title><url>/post/computer-science/application/wsl/golang/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>WindowsSubsystemForLinux(wsl)</tag><tag>linux</tag><tag>golang</tag><tag>goland</tag></tags><content type="html"><![CDATA[环境 CPU AMD64(x86_64) Windows 11 家庭版 WSL2 Ubuntu-20.04
安装 WSL Windows 里需要安装 Hyper-V 虚拟机。有没有安装 Hyper-V 可以通过在命令行窗口（CMD、PowerShell）里输入 systeminfo 命令查看。
... Hyper-V 要求: 已检测到虚拟机监控程序。将不显示 Hyper-V 所需的功能。 完全未安装 WSL 时，执行 wsl --install 才会一键安装，这里是手动安装。先以管理员模式运行 PowerShell。
可以通过 wsl --list --verbose 命令或者简写的 wsl -l -v 命令，查看机器上已经安装的 WSL
PS C:\WINDOWS\system32&gt; wsl -l -v NAME STATE VERSION * docker-desktop-data Stopped 2 docker-desktop Stopped 2 通过 wsl --list --online 命令，查看可用发行版列表。
以下是可安装的有效分发的列表。 请使用“wsl --install -d &lt;分发&gt;”安装。 NAME FRIENDLY NAME Ubuntu Ubuntu Debian Debian GNU/Linux kali-linux Kali Linux Rolling openSUSE-42 openSUSE Leap 42 SLES-12 SUSE Linux Enterprise Server v12 Ubuntu-16.04 Ubuntu 16.04 LTS Ubuntu-18.04 Ubuntu 18.04 LTS Ubuntu-20.04 Ubuntu 20.04 LTS 然后通过 wsl --install -d Ubuntu-20.04 命令安装 Ubuntu-20.04。
等着下载好，如果进度条不动或者出错了，Ctrl+C 然后重新执行就行。
正在下载: Ubuntu 20.04 LTS 安装过程中出现错误。分发名称: &#39;Ubuntu 20.04 LTS&#39; 错误代码: 0x80072eff 正在下载: Ubuntu 20.04 LTS 正在安装: Ubuntu 20.04 LTS 已安装 Ubuntu 20.04 LTS。 正在启动 Ubuntu 20.04 LTS… 装好后自动会打开一个命令行窗口。
Please create a default UNIX user account. The username does not need to match your Windows username. For more information visit: https://aka.ms/wslusers Enter new UNIX username: 这里需要设置用户名和密码，root 不能用，所以换 kelipute，密码就 123456。
Please create a default UNIX user account. The username does not need to match your Windows username. For more information visit: https://aka.ms/wslusers Enter new UNIX username: root adduser: The user `root&#39; already exists. Enter new UNIX username: kelipute New password: Retype new password: passwd: password updated successfully Installation successful! To run a command as administrator (user &#34;root&#34;), use &#34;sudo &lt;command&gt;&#34;. See &#34;man sudo_root&#34; for details. Welcome to Ubuntu 20.04 LTS (GNU/Linux 5.10.16.3-microsoft-standard-WSL2 x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage System information as of Thu Dec 8 13:04:08 CST 2022 System load: 0.0 Processes: 8 Usage of /: 0.4% of 250.98GB Users logged in: 0 Memory usage: 0% IPv4 address for eth0: 172.27.168.157 Swap usage: 0% 0 updates can be installed immediately. 0 of these updates are security updates. The list of available updates is more than a week old. To check for new updates run: sudo apt update This message is shown once once a day. To disable it please create the /home/kelipute/.hushlogin file. kelipute@keliputeC2021A:~$ 如果不关闭 Linux 子系统的话，在 Windows 的命令行窗口执行 wsl -l -v 命令，就可以看到刚才装的 Ubuntu-20.04，状态是 Running 的。
NAME STATE VERSION * docker-desktop-data Stopped 2 Ubuntu-20.04 Running 2 docker-desktop Stopped 2 Linux 子系统的命令行窗口，后续可以从 Windows 的开始菜单，搜索 Ubuntu 打开。
安装和配置 Golang 在 $HOME 目录（cd ~） 下载一个 Linux 环境的 go 安装包。
sudo wget https://studygolang.com/dl/golang/go1.19.4.linux-amd64.tar.gz 把下载下来的压缩包解压到 /usr/local/ 目录。这里不用自己建一个 go 目录，压缩包里有。
sudo tar zxf go1.19.4.linux-amd64.tar.gz -C /usr/local/ 打开配置文件：vim ~/.profile。在最后面追加 Golang 的环境配置。
export PATH=$PATH:$GOROOT/bin export GOROOT=/usr/local/go export GOPATH=$HOME/go export GO111MODULE=on export GOPROXY=https://goproxy.cn,direct 保存之后执行 source ~/.profile 命令，让配置生效。
这个时候理论上就可以使用 go 命令了，可以使用 go version 命令输出 go 的版本，测试一下。
go version go1.19.4 linux/amd64 配置 goland 菜单栏 File =&gt; Settings&hellip; =&gt; Build,Execution,Deployment =&gt; Run Targets
创建一个 WSL 的，这里创建的是 WSL Ubuntu-20.04。下面的配置，Go Executable 选 /usr/local/go/bin/go。GOPATH 选 /home/kelipute/go。都是上面在 WSL 里面配置的 go 的环境变量。
然后配置 Goland 右上角的 Run 和 Debug 按钮。偷懒的办法，先本地点一下 Run 或者 Debug。让 Goland 自动创建一个配置，然后进去 Edit Configurations&hellip; 修改。
选中对应的配置，右边 Run on 默认是 Local machine 这里改成刚才创建的 WSL Ubuntu-20.04，然后把下面的 Build on remote target 勾上。保存之后，这个时候再点 Run 或者 Debug 用的就是 WSL 里面的环境了。
build 报错 run 的时候报错 ... dial tcp 172.217.160.113:443: connect: connection refused ... 这个是 go mod 下不了包，在 WSL 里面改代理就行。
debug 报错 debug 断点调试的时候报错 ... # runtime/cgo cgo: C compiler &#34;gcc&#34; not found: exec: &#34;gcc&#34;: executable file not found in $PATH ... 这个提示表示没安装 gcc。使用 sudo apt install gcc 命令在 WSL 里面安装 gcc 就行。装完之后可以用 gcc -v 命令输出一下 gcc 版本，测试一下。
gcc -v Using built-in specs. COLLECT_GCC=gcc COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/9/lto-wrapper OFFLOAD_TARGET_NAMES=nvptx-none:hsa OFFLOAD_TARGET_DEFAULT=1 Target: x86_64-linux-gnu Configured with: ../src/configure -v --with-pkgversion=&#39;Ubuntu 9.3.0-10ubuntu2&#39; --with-bugurl=file:///usr/share/doc/gcc-9/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++,gm2 --prefix=/usr --with-gcc-major-version-only --program-suffix=-9 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib=auto --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none,hsa --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu Thread model: posix gcc version 9.3.0 (Ubuntu 9.3.0-10ubuntu2) reference（参考） WSL 2 安装Goland WSL2下开发调试goland配合wsl2直接调用wsl2里go环境的方法]]></content></entry><entry><title>Golang 实现简单的 ORM 框架 -- 其他辅助工具</title><url>/post/computer-science/programming-language/framework/orm/golang/middleware/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>orm</tag><tag>middleware(中间件)</tag><tag>mysql</tag><tag>golang</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {orm-go}
/v20/ orm.drawio.html 注意：orm.drawio.html 里面的这个类图和流程图都是和 v20 版本的代码对应的最终形态。 中间件 ORM 框架的中间件和 web 框架的中间件的原理是一样的，这里就不重复了。这里需要考虑的是中间件注册在哪里，查询构造器上显然是不合适的，这里可以考虑和方言抽象一样，放到数据库抽象上去。在执行查询之前，先去数据库实例上把中间件拿出来，然后把执行查询的逻辑放在最里面。
另外，需要定义中间件入参和出参的数据格式。这里和 web 框架一样，要不然套不起来。但是这里比 web 框架会复杂一点，在 web 框架那里入参和出参是一样的，整条链路上都只需要处理 TCP 连接的输入流和输出流。ORM 框架这里，输入的参数有 4 种，即 4 种查询构造器。输出的参数有两种，即数据库执行 SQL 返回的两大类结果。
所以需要把 4 中查询构造器封装到中间件入参里面，入参包括查询构造器的类型和查询构造器的本体。把数据库执行 SQL 返回的两大类结果封装到中间件出参里面，出参包括数据库执行 SQL 返回的两大类结果以及异常。这里又有一个问题了，SQL 语句执行完了，怎么处理返回回来的被封装的两大类结果。
可以注意到，SELECT 和 INSERT、UPDATE、DELETE 是分别对应数据库执行 SQL 返回的两类结果的，而且前面执行 SQL 的时候也是分别使用 query() 和 exec() 的。所以在最外面，也就是进入中间件链条的位置，是可以知道执行的到底是哪类 SQL 语句的。所以对于数据库返回的结果，就可以在这里进行类型断言。</content></entry><entry><title>Golang 实现简单的 ORM 框架 -- INSERT、UPDATE、DELETE</title><url>/post/computer-science/programming-language/framework/orm/golang/insert_update_delete/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>orm</tag><tag>mysql</tag><tag>sqlite3</tag><tag>golang</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {orm-go}
/v20/ orm.drawio.html 注意：orm.drawio.html 里面的这个类图和流程图都是和 v20 版本的代码对应的最终形态。 前言 这篇是接着 SELECT 后面的。INSERT、UPDATE、DELETE 三个加起来都没有 SELECT 复杂。其中 INSERT 因为涉及到不同数据库的方言的处理，相对 UPDATE 和 DELETE 会更复杂一点。
本篇主要涉及：INSERT 语句的构造过程、不同数据库 INSERT 语句不一样的问题的处理方式、UPDATE 语句的构造过程、DELETE 语句的构造过程。
分析 INSERT 语句的使用场景 和 SELECT 的分析套路一样。
这里实现的是一个简单的 ORM，INSERT 的部分就先处理下面这几种。
INSERT INTO 表(列) VALUES(值) INSERT INTO 表(列) VALUES(值1),(值2) INSERT INTO 表(列) VALUES(值) ON DUPLICATE KEY UPDATE 列=VALUES(值) INSERT INTO 表(列) VALUES(值) ON DUPLICATE KEY UPDATE 列=值 从上面的 SELECT 语句结构可以看出，SELECT 语句大致可以分成几个部分。
INSERT INTO 表(列) VALUES(值) ON DUPLICATE KEY UPDATE (表达式) 然后再去看一下 MySQL 的官方文档中对 INSERT 语句的定义和说明。
MySQL INSERT Statement MySQL 8 官方文档中，关于 INSERT 语句的描述：
13.2.6 INSERT Statement
把文档给出的结构和上面的那几种比较一下，提取出文档中相关的描述部分，大概是下面这部分。
INSERT [INTO] tbl_name [(col_name [, col_name] ...)] { {VALUES | VALUE} (value_list) [, (value_list)] ... } [ON DUPLICATE KEY UPDATE assignment_list] assignment: col_name = value | [tbl_name.]col_name assignment_list: assignment [, assignment] ... 构造 INSERT 语句 从最简单的开始 先从最简单的 INSERT INTO 表(列) VALUES(值) 开始。
表和列很熟悉了，直接从元数据里搞。值也是一样的，构建元数据的时候，只通过反射获取了结构体属性的类型，值就是把结构体属性上的值也拿出来。然后按照把语句拼起来就可以了。INSERT 单个值的搞定了，多个值的循环单个值的步骤就行了。
提取查询构造器 在构造 INSERT 语句的时候会发现，在构造 SELECT 语句的时候使用到的一些构造的方法，在构造 INSERT 语句的时候也会用的到。所以这里可以提取一个抽象出来，就叫它 SQL 查询构造器好了。这样后面 UPDATE 和 DELETE 语句构造的时候也可以用的上，不用重复的去写。创建 SELECT 查询构造器或者 INSERT 查询构造器这些具体的构造器的时候，组合一个 SQL 查询构造器进去就行了。
处理 ON CONFLICT ON CONFLICT 在 MySQL 里面就是指的 ON DUPLICATE KEY UPDATE 也可以叫 UPSERT。这里单独拿出来说它是因为 ORM 框架一般不会只支持一种数据库。当需要支持多种数据库的时候，不同数据库的 SQL 语法之间冲突的部分就需要处理。这里用 MySQL 和 SQLite3 做演示。
在 MySQL 里面，语句是这样的：
INSERT INTO 表(列) VALUES(值) ON DUPLICATE KEY UPDATE 列=VALUES(列) INSERT INTO 表(列) VALUES(值) ON DUPLICATE KEY UPDATE 列=值 SQLite 官方文档中，关于 INSERT 语句和 ON CONFLICT 的描述：
INSERT
The ON CONFLICT Clause
在 SQLite3 里面，语句是这样的：
INSERT INTO 表(列) VALUES(值) ON CONFLICT (列) DO UPDATE SET 列=excluded.列; INSERT INTO 表(列) VALUES(值) ON CONFLICT (列) DO UPDATE SET 列=值; 这两个数据库的 ON CONFLICT 语法结构是不一样的，所以在构造 SQL 语句的之后需要分开处理。这里需要对两个数据库的 ON CONFLICT 进行抽象。然后通过观察每个数据库的 SQL 语句，也就是 ON CONFLICT 后面的两种赋值方式，也会得到一个抽象。同样的，MySql 官方文档里也已经告诉你了，这个抽象叫 assignment_list（这里叫赋值表达式）。这个东西 UPDATE 语句里面也会用到，后面再说。
处理的时候先处理完 INSERT 前面一样的部分，然后再处理 ON CONFLICT 的部分。这个地方处理的时候，会有一个从处理公共部分的 INSERT 查询构造器跳到处理不同部分的 ON CONFLICT 查询构造器的步骤。这里可以用在 INSERT 查询构造器里面定义一个抽象的方式，然后构造 INSERT 查询构造器的时候把 ON CONFLICT 查询构造器传进来。
另外一个思路是，INSERT 查询构造器处理完公共部分之后，把自己交给一个 ON CONFLICT 查询构造器。完了 ON CONFLICT 查询构造器处理完之后，在把他自己交给刚才的 INSERT 查询构造器，由 INSERT 查询构造器继续后面的执行 SQL 和处理结果集的步骤。
关于方言抽象的注入 从上面的过程可以发现，方言抽象是需要注入到 INSERT 查询构造器里面的。这就意味着每次创建新的 INSERT 查询构造器的时候，都需要根据到底是生成哪个数据库的 SQL 语句进而注入对应的方言抽象的实例。这显然是非常麻烦的，有一个更好的位置可以放这个方言抽象，这个位置就是数据库抽象。
仔细想一下，不管是哪种具体的查询构造器，构造出来的语句最终都是要靠数据库实例去执行的。而且方言本身也是因为需要使用不同的数据库从而产生的设计，所以把方言放到数据库抽象里面是最合适的。查询构造器在构造 SQL 的时候，就可以直接调用数据库实例里面的方言实例去处理不同数据库里面冲突的部分。
INSERT 语句就差不多了 UPDATE UPDATE 就比较简单了。同样的，把文档放在这里，然后把相关的描述部分提取出来。
13.2.15 UPDATE Statement
UPDATE table_reference SET assignment_list [WHERE where_condition] table_reference 和 where_condition 在 SELECT 那里处理过，assignment_list 在 INSERT 那里处理过。
注意这个 assignment（赋值语句） assignment 接口有两种实现。一个是列，对应 列=VALUES(列) 这种语句。另一种是常规的赋值语句，对应 列=值 这种的。这里注意一下 列=VALUES(列) 这种的，这种语句在 INSERT 的不同的数据库方言里和 UPDATE 语句里面，它的实现又是各不相同的。目前的实现是先把 assignment 接口断言成列，然后不同的数据库方言和 UPDATE 自己实现自己的逻辑。
DELETE DELETE 更简单。同样的，把文档放在这里，然后把相关的描述部分提取出来。
13.2.2 DELETE Statement
DELETE FROM tbl_name [WHERE where_condition] table_reference 在 SELECT 那里处理过，assignment_list 在 INSERT 那里处理过。
执行语句 这三个语句的执行和 SELECT 不一样，它们是没有处理结果集一说的，都是返回影响了多少行。顶多 INSERT 有一个返回插入的行的 id 的功能。所以这里需要再写一套和数据库交互的逻辑，因为返回值不一样。如果是在 Golang 里面，执行 SQL 调用的方法就是不一样的，SELECT 用的是 query() 这三个用的是 exec()。
全流程结束 到这里，生成 INSERT、UPDATE、DELETE 语句、执行语句、处理返回值，就都处理完了。同样的，设计上的东西，看类图、流程图会更加直观。细节上的实现，直接看代码，这个靠说是说不太清楚的。</content></entry><entry><title>Golang 实现简单的 ORM 框架 -- SELECT</title><url>/post/computer-science/programming-language/framework/orm/golang/select/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>orm</tag><tag>mysql</tag><tag>golang</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
资料 {orm-go}/v20/ orm.drawio.html 注意：orm.drawio.html 里面的这个类图和流程图都是和 v20 版本的代码对应的最终形态。 前言 注意，这里实现的是一个简单的 ORM 框架，并不是一个完备的 ORM 框架，主要目的是研究原理和设计。
ORM 框架的核心功能主要有两个：1、把数据结构转换成 SQL 语句。2、处理 SQL 语句的执行结果。其他的功能，都是在这两个功能的基础上，再增加亿点点细节而已。
数据结构转换成 SQL 语句这没啥好说的，在这个简单的 ORM 框架里面就是把 Golang 的结构体转换成对应的 SQL 语句。处理 SQL 语句的执行结果主要指的是，简化手动操作，自动把 SELECT 语句执行的结果装到对应的结构体里去。
另外，这两个功能的实现过程都会用到反射操作和内存操作，需要先有这两个方面的知识。
本篇主要涉及：SELECT 语句的分析和抽象、SELECT 语句的构造过程、元数据的构造、结果集的处理。
分析 SELECT 语句的使用场景 这里实现的是一个简单的 ORM，SELECT 的部分就先处理下面这几种。
SELECT &hellip; FROM &hellip; SELECT &hellip; FROM &hellip; WHERE &hellip; SELECT &hellip; FROM &hellip; WHERE &hellip; GROUP BY &hellip; HAVING &hellip; SELECT &hellip; FROM &hellip; WHERE &hellip; ORDER BY &hellip; SELECT &hellip; FROM &hellip; WHERE &hellip; LIMIT &hellip; OFFSET &hellip; SELECT &hellip; AS &hellip; FROM &hellip; AS &hellip; WHERE &hellip; SELECT &hellip; FROM JOIN SELECT &hellip; FROM 子查询 SELECT &hellip; FROM &hellip; WHERE &hellip; IN &hellip; 从上面的 SELECT 语句结构可以看出，SELECT 语句大致可以分成几个部分。
SELECT {*|列|聚合函数} AS 别名 FROM {表|JOIN|子查询} AS 别名 WHERE 条件 GROUP BY 列 HAVING 条件 ORDER BY 列 LIMIT 数字 OFFSET 数字 这样大概的内容和处理流程就有了。就是构建 SELECT 语句需要哪些东西，构建的大概流程是什么样的。然后再去看一下 MySQL 的官方文档中对 SELECT 语句的定义和说明。
MySQL SELECT Statement MySQL 8 官方文档中，关于 SELECT 语句的描述：
13.2.10 SELECT Statement把文档给出的结构和上面的那几种比较一下，提取出文档中相关的描述部分，大概是下面这部分。
SELECT [DISTINCT] select_expr [, select_expr] ... [FROM table_references] [WHERE where_condition] [GROUP BY {col_name}, ...] [HAVING where_condition] [ORDER BY {col_name} [ASC | DESC], ...] [LIMIT {row_count | row_count OFFSET offset}] [FOR UPDATE] } 还需要关注以下关于别名的部分：
列的别名： A select_expr can be given an alias using AS alias_name.
表的别名： A table reference can be aliased using tbl_name AS alias_name or tbl_name alias_name. For each table specified, you can optionally specify an alias.
tbl_name [[AS] alias] 还需要关注一下 JOIN 的部分：
13.2.11.2 JOIN Clause主要是下面这部分，描述的是 JOIN 的结构。
table_reference: { table_factor | joined_table } table_factor: { tbl_name [[AS] alias] | table_subquery [AS] alias [(col_list)] | ( table_references ) } joined_table: { table_reference {JOIN} table_factor [join_specification] | table_reference {LEFT|RIGHT} JOIN table_reference join_specification | table_reference NATURAL [INNER | {LEFT|RIGHT} [OUTER]] JOIN table_factor } join_specification: { ON search_condition | USING (join_column_list) } 也就是说 JOIN 的结构大概可以描述成下面这几种，而且还可以嵌套。
表 JOIN 表 （表 JOIN 表） JOIN 表 表 JOIN 子查询 子查询 JOIN 子查询 还需要关注一下（Sub Query）子查询的部分：
13.2.13 Subqueries简单的理解，JOIN 和子查询都是构建了一个临时的表，和常规的表不同的是，这里的表名和表里的列都不是固定的，而是动态生成的。
到这里 SELECT 语句的构成分析的就差不多了，下面是对 SELECT 语句的构成进行合理的抽象。
分析和抽象 其实抽象的工作是比较容易的，官方文档中的描述已经把抽象给出来了。在这个简单的 ORM 框架里面，大概是下面这几个。
select_expr 对应列和聚合函数 table_references 对应表、JOIN、子查询 where_condition 对应查询条件 col_name 对应列 这里还需要再看一下关于表达式和聚合函数的部分：
9.5 Expressions12.20 Aggregate Functions到这里，在这个简单的 ORM 框架里需要实现的部分，就都差不多都了解了，下面就可以开始动手了。
构造语句 从最简单的开始 先从最简单的 SELECT 列 FROM 表 开始。首先需要构造一个处理 SELECT 语句的对象，封装相关的数据和方法，一般叫它查询构造器（这里叫 SELECT 查询构造器，为了和 INSERT、UPDATE、DELETE 区分开）。
这里上来就会遇到问题，语句里的列和表怎么来。在 ORM 框架中，这里的列和表，不是手动写入的，而是通过解析结构体得到的。既然是通过解析结构体，那么就需要有解析的规则。解析规则由 ORM 框架定义，是解析结构体的属性、还是解析结构体的属性的注释、还是解析 Golang 结构体的属性上的 tag、还是混合模式。
结构体需要按照 ORM 框架定义的解析规则去写，要不然 ORM 框架对着没有按规则来的结构体也是抓瞎的。虽然注释和 tag 可以自定义的随便写，但是结构体它至少会有属性，所以这里可以做一个兜底的策略。这个简单的 ORM 框架里的解析规则为：默认解析结构体的属性，如果结构体的属性上有 tag 就解析 tag。
解析出来的玩意，专业一点的叫法，叫 metadata（元数据），内容是结构体和数据库表的映射关系。包括结构体名和数据库表名的对应关系，结构体的属性名和数据库表的字段名的对应关系，里面还会有一些辅助的信息，这个后面再说。
元数据 在 Golang 里面，可以通过反射解析结构体。通过反射的一些列操作，可以得到结构体名、结构体的属性、还有挂在这些玩意上面的其他信息。这里通过转换结构体名得到数据库表名，拿到结构体名之后，直接驼峰命名转蛇形命名就行。
还可以通过解析注释或者定义接口的方式获取数据库表名。注释就不多说了，通过 AST 解析结构体的注释就行。定义接口，就是定义一个获取数据库表名的接口，然后具体对应数据库表的结构体去实现这个接口。
这样在 SQL 构建的过程中，通过类型断言可以确认结构体是否实现了这个接口，如果实现了这个接口就调用接口取获取自定义的数据库表名。
需要注意的是，元数据里关于结构体的属性名和数据库表的字段名的对应关系的数据，在两个方向上的都需要。因为元数据不止构造 SQL 语句的时候需要正向用，处理结果集的时候也需要用，只不过方向是反过来的，通过数据库字段名，找到对应的结构体属性名。
元数据这块的内容是独立的，可以和 SQL 语句构造的内容隔离开来，自己成为一个独立的模块，这里叫它元数据注册中心。
回到 SQL 语句的构造 解决完元数据的问题，那么语句里的列和表就都有了，这个语句就很好构造了。把传进来的结构体解析之后，把列和表捞出来塞到语句里就行。
对于列来说，后面还可以结合元数据，做一下列存不存在之类的校验。但是如果列写了别名或者是一个复杂查询啥的，校验起来会有点麻烦。
下面搞 WHERE 语句后面的 SELECT 列 FROM 表 WHERE 查询条件。
在动手设计之前，需要先观察一下查询条件的结构。这里列举几个常用的查询条件。
列{=|&gt;|&lt;|!=}值 列=值 AND 列=值 列=值 OR 列=值 列=值 AND (列=值 OR 列=值) 列 LIKE 值 列 IN (值) 这里可以观察到，查询条件的结构，大体上是嵌套起来的左中右的结构。中间是操作符，左边是列或者值，右边一般都是值。
这里看上去是一样的，但是实际上有两层抽象。第一层是：左=列，中间=操作符，右边=值；第二层是：左=第一层抽象 中间=操作符，右=第一层抽象。所以这里需要处理的对象不仅有第一层抽象的 column（列）和 value（值）。还有对第一层抽象的抽象，也就是 expression（表达式）。而且可以得出一个结论，列和值都是表达式的一种。由此可以推论，列和值可以是对象，但是表达式肯定是个接口。
这种左中右的结构，可以联想到树的结构，中间是一个根结点，左右是两个叶子结点。大概的形状见图：orm.drawio.html 2-0。常规的等于、大于、小于、不等于等数学运算和与、或两个逻辑运算可以直接通过这个结构表示。包括 LIKE 和 IN 也可以用这个结构。问题在于 NOT 逻辑运算和原生语句。NOT 只有一边，原生语句直接没有结构。其实这两个玩意，树形结构也是可以兼容的。
NOT 直接让他没有左边就可以了，处理的时候判断一下左边是不是空的就行。大概的形状见图：orm.drawio.html 2-2。
原生语句看上去是自定义的，不符合树的结构，但是可以换个思路，把语句拆开看，其实它已经包含了列和值，所以它就是一个完整的第一层抽象。只不过它只有左边，不需要中间和右边（语句放右边，不需要左边和中间也行）。大概的形状见图：orm.drawio.html 2-4。
代码中处理的时候用递归就行，先递归处理左边的非空叶子，然后处理中间的操作符，然后递归处理右边的非空叶子。每次递归的结果，两边加括号包起来，这样不容易出错。遇到空的位置，空格就不管了。括号和空格多了就多了，只要保证语法没问题就行。
基本的 WHERE 用这个结构就差不多了，需要注意 WHERE IN 那里不仅可以直接填数据，还可能涉及到子查询，这后面再说。
下面处理 GROUP BY SELECT 列 FROM 表 GROUP BY 列 HAVING 查询条件。
GROUP BY 其实很简单了，这玩意有两个部分。前面的列很简单了，没啥好说的。后面的 HAVING 和上面的 WHERE 是一样的。官方文档里面这两个位置都是 where_condition 把上面 WHERE 的逻辑直接拿过来复用就可以。
下面处理 ORDER BY SELECT 列 FROM 表 ORDER BY 列。
这玩意也没啥好说的，就是个列，加上升序或者降序的标志。
下面处理 LIMIT 和 OFFSET SELECT 列 FROM 表 LIMIT 20 OFFSET 100。
这两个也没啥好说的，就是两个数字。
处理 SELECT 后面的 SELECT 列 FROM 表。 SELECT 列 AS 新名字 FROM 表。 SELECT 聚合函数 FROM 表。 SELECT 聚合函数 AS 新名字 FROM 表。 SELECT 后面就两大类东西：列和聚合函数，还会涉及到别名。另外，这里还可以插入原生表达式。
从形态上看，列和聚合函数完全不一样，但是它们都可以放在 SELECT 后面，所以这里肯定有一个抽象。其实官方文档里也已经告诉你了，这个抽象叫 select_expr（这里叫查询表达式）。
这里分开处理这两个玩意。列很简单了，就是列。聚合函数需要一个单独的对象，对象里面放上聚合函数的名字还有聚合函数操作的那个列。别名就目前的场景而言其实很简单，就直接对象里给一个字符串设置一下就好了。加上表、JOIN、子查询的别名之后，这里的别名会变的复杂一点。原生表达式就更简单了，直接把表达式原封不动的放在这里就行了。
到这里，在单个表上的操作基本就都搞定了。下面开始搞 JOIN 和子查询。
JOIN SELECT 列 FROM JOIN。
实现简单的 JOIN 其实不怎么复杂，主要功能包括起别名、选择列、复杂一点的是 JOIN 可以嵌套。
常用的 JOIN 结构大概就是下面这几个：
表 A JOIN 表 B ON &hellip; 表 A AS 新名字 JOIN 表 B AS 新名字 ON &hellip; 表 A JOIN (表 B JOIN 表 C ON &hellip;) ON &hellip; 之前处理 FROM 后面那个位置的时候是直接用的数据库表名，但是那个位置其实可以放的玩意有表名、JOIN、子查询，这明摆了是要有一个抽象的，官方文档也告诉你了，叫 table_references（这里叫表表达式）。但是这三种对象的处理方式肯定是不一样的，语句形态差的都很远，基本没有共同点，所以铁定是分开各写各的。
观察一下上面的几个 JOIN 的样例，又是个左中右的结构，只不过这里的左右两边是一样的，都是 table_references。处理思路和上面的 WHERE 那里处理查询条件的思路是一样的，都是用递归，先处理递归左边的非空叶子，再递归处理右边的非空叶子。另外 JOIN 还有 ON 子句，官方文档里 ON 后面跟的是 search_condition。它和 WHERE 后面的 where_condition 是差不多的，这里不做复杂处理，所以直接拿过来复用。
这里可以换个思路理解，把带有 JOIN 的查询分成两块。JOIN 单独拿出来看，它最终其实就会变成个临时表。把别名当做表名，左右两个 table_references 的列就是临时表的列，这样问题就又回到了之前处理单个数据库表的问题。后面解决子查询的时候，思路也是这样的。
选择列和上面 SELECT 那里处理查询表达式的地方差不多。但是加入 JOIN 之后，列的处理会变得复杂一点，以前的列都是默认在同一个表里的，加入 JOIN 之后，表就不是一个了。所以列里面，必须把自己属于哪个表存着，这样构造列的时候，需要先构造前面的前缀，而且前缀这玩意可以有别名。也就是表和 JOIN 包括后面的子查询都要有别名，列从原来依托于元数据直接构造变成依托于 table_references 构造。
子查询 子查询看着很复杂，但是构成子查询的元素，上面都已经处理过了。前面说过，子查询就是一个临时表，把别名当做表名，左右两个 table_references 的列就是临时表的列，如果子查询设置了查询表达式，那么临时表的列就是查询表达式里面写的那些列。
整体思路和 JOIN 的思路是差不多的，区别的地方在于对列的处理方式不同。处理 JOIN 的时候，查询表达式里的列可能来自不同的表。但是在子查询这里，所有的列都来自子查询的临时表。
语句构建结束 在编码的时候使用 Builder 设计模式实现，基本思路就是将和 SELECT 语句有关的数据的填充和使用这些数据构造 SELECT 语句的部分隔离开。其最终形态就是常见的 ORM 框架的一堆用起来很流畅的链式调用，最后一个 First() 方法或者 Get() 方法，然后查询构造器构建 SQL、执行 SQL、处理结果集一气呵成之后返回结果集。
到这里简单的 SELECT 语句的构建思路就差不多了。下面就是执行语句和处理结果集了。
执行语句 执行语句分为两种，一种是直接执行，一种是事务执行。这两个的区别也很简单就是拿到数据库实例之后，要不要开事务。这个地方可以做两个抽象，一个是数据库的抽象，一个是事务的抽象。其中事务的抽象可以包括数据库的抽象，和装饰器有点像，事务对象可以理解成把数据库的抽象拿过来，用事务功能装饰一下。
这两个抽象其实可以再抽象出一个共同的部分，就是执行 SQL 的部分。无论是数据库的抽象还是事物的抽象，最后都会完成执行 SQL 的操作。这个部分可以再抽象一下，抽象成一个会话，一个会话就表示用户的一次数据库交互操作。
这样编码的时候可以使用依赖注入的方式，把数据库抽象或者事务抽象注入到 SELECT 查询构造器里面。SELECT 查询构造器在构造完 SQL 语句后，就可以继续使用链式调用的方式，调用会话抽象去执行语句。
处理结果集 结果集的处理也不难，前面构造的元数据里不是已经有反方向的映射关系了嘛。先通过数据库返回的结果集里面的结果的字段名，结合元数据，把所有的变量类型先确定好。然按照变量类型构造一个接收数据库返回的结构，接收的时候注意顺序。
成功接收到数据库的返回结果后，先通过元数据构造一个对应的空的结构体。然后通过数据库返回的字段名，结合元数据，反向去找结构体的属性。然后通过反射或者内存操作，把值塞到结构体对应的属性上去。
全流程结束 到这里，构造元数据、生成 SELECT 语句、执行语句、处理返回值，就都处理完了。设计上的东西，看类图、流程图会更加直观。细节上的实现，直接看代码，这个靠说是说不太清楚的。
]]></content></entry><entry><title>符号命名</title><url>/post/computer-science/programming-language/symbol_naming/</url><categories><category>programming-language(编程语言)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag></tags><content type="html">前言 实际开发中，符号命名规则应该和团队的风格保持统一，这套符号命名规则是我的个人喜好。 如果访客您非要说不符合哪里哪里的规范，怎么怎么有问题，那么访客您说的都对。
正文 实际的项目中有可能有出入，因为，前后改过好几次，同时，不排除以后还会继续改。
符号命名 我的符号（变量名、方法名）命名方式和主流的命名方式比起来有一些奇怪。区别主要在于各种各样标记类型的前缀。 声明的变量名和方法名、定义的类型名，都会带前缀。加前缀的目的，主要是为一些特殊的类型作标记，编码过程中引起重视。
前缀都是什么意思 a5，array，数组； c7，channel，管道； c5，const，常量； d9，dimension，维度； f8，function，函数、方法； g6，global，全局； i9，interface，接口； l5，local，局部； m3，map，map； p7，pointer，指针； s5，slice，切片； s6，struct，结构体； t4，temp，临时； 前缀用法举例 var a5UserID []int，声明一个切片，切片的内容是 int。
struct S6User {}、type S6User struct{}，声明一个结构体。
var m3s6user map[string]S6User，声明一个 map，map 的内容是结构体。
var m3s6p7user map[string]*S6User，声明一个 map，map 的内容是指向结构体的指针。
int t4status，声明一个 int 临时变量。
大写、小写、中划线、下划线 程序代码中的符号命名全部都用驼峰（camel case）。
缓存命名、数据库命名全部都用蛇形（snake case）。
命名目录时，两个或以上的单词用中划线连接。
如果变量需要对外开放（声明为 public），则前缀全部为大写。
如果变量不需要对外开放（声明为 protected、private），则前缀全部为小写。
如果变量名是一个单词，则单词首字母用小写（var username string）。
如果变量名是一个单词而且有前缀，则单词首字母用小写（var s5username []string）。
如果变量名是两个或以上的单词，则第一个单词首字母用小写，后面的单词首字母用大写（var userID int）。
如果变量名是两个或以上的单词而且有前缀，则单词首字母用大写（var s5UserID []int）。
golang 项目，目录里的 &amp;ldquo;hkn&amp;rdquo; 后缀，用于回避关键字，比如：maphkn。
golang 项目，import 引入时，两个或以上的单词用下划线连接。
版本号 我主要是各种原型验证项目会用到版本号，格式一般是 x.y，暂时达不到需要使用 x.y.z 这样的规模。 版本号从 0 开始，以 2 为步长递增，一般不会超过 10，常见的是：v00、v20、v22、v40、v42。</content></entry><entry><title>使用 Docker 启动 MySQL</title><url>/post/computer-science/application/docker/mysql/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>docker</tag><tag>database(数据库)</tag><tag>mysql</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 Docker v20.10.17 正文 拉取镜像 先去 DockerHub 找想要的容器。直接搜索 mysql 就能找到，链接在这。
如果不讲究，那直接用最上面提供的命令就可以了。如果想要某个版本，就点到 Tags 标签页里面去，找到想要的版本，然后用相应的命令。
这里用的是 mysql8，输入命令后等着下载就好了。
&gt; docker pull mysql:8.0 8.0: Pulling from library/mysql ... Digest: sha256:147572c972192417add6f1cf65ea33edfd44086e461a3381601b53e1662f5d15 Status: Downloaded newer image for mysql:8.0 docker.io/library/mysql:8.0 拉好之后，可以在 &ldquo;docker images&rdquo; 命令输出的列表里看到。
&gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE mysql 8.0 40b83de8fb1a 4 days ago 535MB 启动容器 通过 &ldquo;docker run&rdquo; 命令启动容器。
&gt; docker run -itd --name mysql8-dev -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:8.0 45804f67e3bf4b79735c308a8073131525c5fbc6f714e8fca5efb4f628127532 &ldquo;-itd&rdquo; 参数，在后台运行容器，并且打印容器的 ID。 &ldquo;&ndash;name mysql8-dev&rdquo;，设置容器的名字为 mysql8-dev。 &ldquo;-p 3306:3306&rdquo;，将本机的 3306 端口和容器的 3306 端口进行映射。 &ldquo;-e MYSQL_ROOT_PASSWORD=123456&rdquo;，设置 mysql 密码为 123456，用户名默认为 root。 &ldquo;mysql:8.0&rdquo;，使用 mysql:8.0 镜像启动容器。 启动好之后，可以通过 &ldquo;docker ps&rdquo; 命令，查看一下容器状态。
进入容器 使用 &ldquo;docker exec&rdquo; 命令进入容器。
&gt; docker exec -it mysql8-dev /bin/bash bash-4.4# mysql8-dev 就是上面设置的容器的名字，也可以用容器的 ID。
使用默认的用户名和上面设置的密码访问 mysql。
&gt; bash-4.4# mysql -uroot -p123456 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 10 Server version: 8.0.31 MySQL Community Server - GPL Copyright (c) 2000, 2022, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement. mysql&gt; ]]></content></entry><entry><title>使用 Docker 启动 MySQL</title><url>/post/computer-science/application/docker/rabbitmq/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>docker</tag><tag>database(数据库)</tag><tag>mysql</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 Docker v20.10.17 正文 拉取镜像 没啥特别的要求，这里直接拉最新的 RabbitMQ 镜像。
&gt; docker pull rabbitmq latest: Pulling from library/rabbitmq Digest: sha256:a64d81498c47681cb797ce56c775a95aab751ebc21e90f007fdb45553e391cf9 Status: Image is up to date for rabbitmq:latest docker.io/library/rabbitmq:latest 启动容器 docker run -itd --name rabbitmq-dev -p 5672:5672 -p 15672:15672 rabbitmq &ldquo;-p 5672:5672 -p 15672:15672&rdquo;，注意这里有两个端口，5672 是服务的端口，15672 是 Web 管理界面的端口。 RabbitMQ 的 Web 管理界面 管理界面默认不是开启的，需要进入容器，使用下面的命令启用管理插件。
&gt; rabbitmq-plugins enable rabbitmq_management Enabling plugins on node rabbit@c47a12f3024b: rabbitmq_management The following plugins have been configured: rabbitmq_delayed_message_exchange rabbitmq_management rabbitmq_management_agent rabbitmq_prometheus rabbitmq_web_dispatch Applying plugin configuration to rabbit@c47a12f3024b… The following plugins have been enabled: rabbitmq_management started 1 plugins. 插件激活后，无需重新启动节点，直接就可以通过浏览器进行访问了。默认的用户名和密码都是 &ldquo;guest&rdquo;。
]]></content></entry><entry><title>【过期，留做对比】Golang 实现复杂的 Web 框架</title><url>/post/computer-science/programming-language/framework/web/golang/complex/</url><categories><category>framework(框架)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>framework(框架)</tag><tag>web</tag><tag>http</tag><tag>router(路由)</tag><tag>middleware(中间件)</tag><tag>golang</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64
前言 在看这篇之前，建议先看下面这几篇：
Golang 开启 HTTP 服务Golang 实现简单的 Web 框架 &ndash; router(路由)Golang 实现简单的 Web 框架 &ndash; middleware(中间件)路由树是 web 框架的核心。其他的功能，都是在路由树的基础上，再增加亿点点细节而已。
资料 {web-framework-go}/v40 实现功能 主要实现： 路由树（静态、通配符、路径参数、正则表达式）、路由组 全局中间件、可路由的中间件 次要实现： 内存池（请求上下文对象复用） 服务管理（管理多个子服务） 优雅退出、退出时的回调方法 计划实现： 用户认证（中间件实现） 文件操作（上传、下载） 单元测试、集成测试、性能测试 设计文档 路由树 首先是路由树结点的设计。结点的基础数据包括：结点类型、这个路由结点代表的那段路径、命中路由之后的的处理逻辑。
静态路由子结点使用 map 结构存储，查询时直接就可以通过路由段查询子结点。
通配符子结点、路径参数子结点、正则表达式子结点，这三个结点属于特殊结点，而且存在冲突关系，所以单独存储。
为了支持可路由的中间件，路由结点上还需要有存储中间件的地方，这样就可以为每个结点单独设置中间件。
另外，服务在运行的时候只要命中的是同一个路由，那么用到的中间件一定也是相同的，在服务启动的时候就可以把中间件遍历好，然后缓存下来。
// routingNode 路由结点 type routingNode struct { // nodeType 结点类型 nodeType int // part 这个路由结点代表的那段路径 part string // path 从根路由到这个路由结点的全路径 path string // f4handler 命中路由之后的处理逻辑 f4handler HTTPHandleFunc // m3routingTree 路由子树，子结点的 path =&gt; 子树根结点 m3routingTree map[string]*routingNode // p7paramChild 路径参数结点 p7paramChild *routingNode // paramName 路径参数路由和正则表达式路由，都会提取路由参数的名字 paramName string // p7regexpChild 正则表达式结点 p7regexpChild *routingNode // p7regexp 正则表达式 p7regexp *regexp.Regexp // p7anyChild 通配符结点 p7anyChild *routingNode // s5f4middleware 结点上注册的中间件 s5f4middleware []HTTPMiddleware // s5f4middlewareCache 服务启动后，命中结点时，需要用到的所有中间件 s5f4middlewareCache []HTTPMiddleware } 路由树的构造和遍历并不复杂，使用递归逻辑处理即可。不用担心递归带来的性能问题。
对于路由树的递归操作，都发生在服务启动时，这个时候会遍历路由树然后将结果缓存下来。
服务启动后，当请求访问过来时，就可以直接使用缓存里的结果，而不用每次都去遍历路由树。
路由组 路由组就是个语法糖。相当于路由组方法会在路由组内的每个成员注册的时候，附加路由组的路由前缀和路由组定义的中间件。
// Group 添加一组路由 func (p7this *HTTPHandler) Group(path string, s5f4mw []HTTPMiddleware, s5routeData []RouteData) { for _, rd := range s5routeData { t4path := path if &#34;/&#34; != rd.Path { t4path = path + rd.Path } p7this.addRoute(rd.Method, t4path, rd.F4handle, s5f4mw...) } } 中间件 全局中间件和可路由中间件是分开放的。全局中间件存储在核心处理逻辑上。可路由中间件存储在路由树结点上。
// HTTPHandlerInterface 核心处理逻辑的接口定义 type HTTPHandlerInterface interface { http.Handler ... } // HTTPHandler 核心处理逻辑 type HTTPHandler struct { ... // s5f4middleware 全局中间件 s5f4middleware []HTTPMiddleware ... } 当请求访问过来时，第一站到的是核心处理逻辑，核心处理逻辑会完成全局中间件的组装和执行。
func (p7this *HTTPHandler) ServeHTTP(i9w http.ResponseWriter, p7r *http.Request) { ... // 倒过来组装，先组装的在里层，里层的后执行 // 最里层应该是找路由然后执行业务代码 t4chain := p7this.doServeHTTP for i := len(p7this.s5f4middleware) - 1; i &gt;= 0; i-- { t4chain = p7this.s5f4middleware[i](t4chain) } // 写入响应数据这个中间件应该由框架开发者处理 // 它是最后一个环节，应该在最外层 t4m := FlashRespMiddleware() t4chain = t4m(t4chain) t4chain(p7ctx) } 在通过全局中间件之后，进入查询路由树的步骤。查询结果里会有路由树结点上的可路由中间件。
使用和全局中间件一样的套路，完成一遍可路由中间件的组装和执行。最后调用路由上的处理逻辑，开始真正的业务逻辑。
func (p7this *HTTPHandler) doServeHTTP(p7ctx *HTTPContext) { ... p7ri := p7this.findRoute(p7ctx.P7request.Method, p7ctx.P7request.URL.Path) ... // 这里用同样的套路，处理路由上的中间件，最后执行业务代码 t4chain := p7ri.p7node.f4handler for i := len(p7ri.p7node.s5f4middlewareCache) - 1; i &gt;= 0; i-- { t4chain = p7ri.p7node.s5f4middlewareCache[i](t4chain) } t4chain(p7ctx) } 优雅退出 想实现优雅退出，程序就不能阻塞在不可控的位置。这里可以直接把服务丢到协程里去。
然后在最外面，实现一个信号等待的逻辑，这样就可以通过信号控制程序的运行状态。
func (p7this *ServiceManager) Start() { // 启动服务 log.Println(&#34;服务启动中。。。&#34;) for _, p7s := range p7this.s5p7HTTPService { t4p7s := p7s go func() { if err := t4p7s.Start(); nil != err { if http.ErrServerClosed == err { log.Printf(&#34;子服务 %s 已关闭\n&#34;, t4p7s.name) } else { log.Printf(&#34;子服务 %s 异常退出，err:%s\r\n&#34;, t4p7s.name, err) } } }() } log.Println(&#34;服务启动完成。&#34;) // 监听 ctrl+c 信号 c4signal := make(chan os.Signal, 2) signal.Notify(c4signal, os.Interrupt) select { case &lt;-c4signal: ... } } 在可以主动介入程序运行之后，就可以设计主动拒绝新请求的逻辑了。这样可以实现服务不完全停止的情况下，拒绝对外服务。
因为服务停止不仅仅是不对外服务这么简单，在服务真正的停止之前，还有很多善后的工作需要做。
// HTTPHandler 核心处理逻辑 type HTTPHandler struct { ... // isRunning 服务是否正在运行 isRunning bool } func (p7this *HTTPHandler) doServeHTTP(p7ctx *HTTPContext) { // 如果服务已经关闭了就直接返回 if !p7this.isRunning { p7ctx.I9writer.WriteHeader(http.StatusInternalServerError) _, _ = p7ctx.I9writer.Write([]byte(&#34;服务已关闭&#34;)) return } ... } 虽然服务停止前有很多善后的工作需要做，但是理论上不会持续很久。
为了防止意外卡死的情况出现，可以再加一层超时强制停止的逻辑。必要的时候，也可以设计主动强制关闭的入口。
func (p7this *ServiceManager) Start() { ... // 监听 ctrl+c 信号 c4signal := make(chan os.Signal, 2) signal.Notify(c4signal, os.Interrupt) select { case &lt;-c4signal: log.Printf(&#34;接收到关闭信号，开始关闭服务，限制 %d 秒内完成。。。\r\n&#34;, p7this.shutdownTimeOut/time.Second) // 再次监听 ctrl+c 信号 go func() { select { case &lt;-c4signal: log.Println(&#34;再次接收到关闭信号，服务直接退出。&#34;) os.Exit(1) } }() time.AfterFunc(p7this.shutdownTimeOut, func() { log.Println(&#34;优雅关闭超时，服务直接退出。&#34;) os.Exit(1) }) p7this.Shutdown() } } 在拒绝新请求之后，由于有可能还有旧的请求没有处理完，所以是不能立刻就关闭服务的，需要等待一段时间。
func (p7this *ServiceManager) Shutdown() { ... log.Println(&#34;停止接收新请求。&#34;) for _, p7hs := range p7this.s5p7HTTPService { p7hs.Stop() } log.Printf(&#34;等待正在执行的请求结束，等待 %d 秒。。。&#34;, p7this.shutdownWaitTime/time.Second) time.Sleep(p7this.shutdownWaitTime) ... } 服务正式关闭服务之后，可能还有一些收尾的工作需要处理，然后才能彻底退出程序。
比如：系统里如果有缓存的话，可能需要把缓存进行持久化处理；系统关闭时，需要上报数据其他服务等。
这个可以通过回调实现，和中间件的用法类似。不过最后执行的时候，是所有的回调是并发执行的，而不是像中间件一样套起来，一次执行的。
func (p7this *ServiceManager) Shutdown() { ... log.Println(&#34;开始执行子服务的关闭回调。。。&#34;) for _, p7hs := range p7this.s5p7HTTPService { log.Printf(&#34;执行子服务 %s 的关闭回调，限制 %d 秒内完成。。。&#34;, p7hs.name, p7this.shutdownCallbackTimeOut/time.Second) for _, f4cb := range p7hs.s5f4shutdownCallback { t4f4cb := f4cb wg.Add(1) go func() { defer wg.Done() t4ctx, t4cancel := context.WithTimeout(context.Background(), p7this.shutdownCallbackTimeOut) defer t4cancel() t4f4cb(t4ctx) }() } } wg.Wait() ... } 到这里核心的部分就差不多了，细节上的实现可以看代码。
]]></content></entry><entry><title>程序员的定位</title><url>/post/computer-science/programmer/</url><categories><category>computer-science(计算机科学)</category></categories><tags><tag>computer-science(计算机科学)</tag></tags><content type="html">正文 程序员的自我修养 原则一： 技术、语言、框架，本质都是工具。工具的价值，在于提升使用者的效率。
原则二: 如果一种语言或者一个框架很牛逼，那么荣耀属于创造它的人，与使用者没有半毛钱关系。 针对恰当的需求，使用恰当的技术、语言、框架，并且做到按时交付以及高质量，才是使用者的荣耀。
原则三: 大部分人并不是天生有选择恐惧症，也不是天生的杠精。所有关于选择的迷惑或者争吵，大都因为： 1、标准不唯一，没有设定清晰的标准；2、标准之间没有优先级或者权重。
参考 {慕课网}/{隔壁王校长}/
Go语言框架：Beego vs Gin</content></entry><entry><title>使用 Hugo 和 GitHub Pages 搭建站点</title><url>/post/computer-science/application/hugo/install_publish/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>Hugo</tag><tag>GitHub-Pages</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 hugo 0.103.1 正文 Hugo 文档 github - gohugoio/hugo英文文档中文文档安装 Hugo 在 Hugo Releases页面下载对应操作系统的版本。这里下载的是 hugo_0.103.1_windows-amd64.zip。
下载完成后，解压到想要的位置。这里使用的目录是 D:\hugo\bin。然后将这个目录添加到 系统变量 path 中（我的电脑 -&gt; 属性 -&gt; 高级系统设置 -&gt; 环境变量 -&gt; 系统变量 -&gt; path）。
搞定之后，可以打开控制台，输出一下版本信息，验证一下安装是否成功。或者试试 hugo help 命令，看看能不能输出帮助信息。
&gt; hugo version hugo v0.103.1-b665f1e8f16bf043b9d3c087a60866159d71b48d windows/amd64 BuildDate=2022-09-18T13:19:01Z VendorInfo=gohugoio 如果有需要的话，需要安装 extended 版本的。这里下载的是 hugo_extended_0.103.1_windows-amd64.zip。
&gt; hugo version hugo v0.103.1-b665f1e8f16bf043b9d3c087a60866159d71b48d+extended windows/amd64 BuildDate=2022-09-18T13:19:01Z VendorInfo=gohugoio 创建站点 使用命令创建一个站点，如果没问题的话，hugo 会在当前目录下创建一个名字是 project-name 的目录。
&gt; hugo new site {project-name} 新建的站点没有任何内容，可以使用命令创建一个内容页面。新创建的文件会在目录 content/ 里。创建内容页面的时候也可以带上目录。
&gt; hugo new helloworld.md &gt; hugo new posts/helloworld.md 安装主题 这里就是和别的站点工具不一样的地方了，比如 hexo 和 jekyll，如果没有安装主题的话，是会有一个默认的主题的。
但是 hugo 没有默认主题，需要去主题库下载一个，然后添加到站点里并配置好，这样才能启动站点。如果没有安装主题就启动的话，会报没有模板的错误。
可以去 官方的主题库找一个喜欢的。然后按照主题提供的文档配置一下。
Hugo NexT Hugo NexT这个主题是从 Hexo NexT 移植过来的。
GitHub 项目地址 hugo-next/hugo-theme-next。
按着 Hexo NexT 主题提供的的文档走，把主题配置到站点中。
别忘了先 git init，然后使用命令下载主题 git submodule add https://github.com/hugo-next/hugo-theme-next.git themes/hugo-theme-next。
如果需要升级主题的话，就进入 {path-to-project}/themes/github-style 目录，执行 git pull 命令，拉取最新的代码。
然后把 {path-to-project}themes/hugo-theme-next/exampleSite/ 目录下所有的文件复制到 {path-to-project}/ 目录下覆盖。
最后删除原来的配置文件 config.toml，然后就可以使用命令 hugo server 启动服务了。
另外需要注意的是，这个主题需要 hugo extended 版本，如果用的不是 extended 版本，启动的时候会报下面这样的错，提示去安装 extended 版本。
&gt; hugo server Start building sites … hugo v0.103.1-b665f1e8f16bf043b9d3c087a60866159d71b48d windows/amd64 BuildDate=2022-09-18T13:19:01Z VendorInfo=gohugoio WARN 2022/09/20 21:12:38 Hugo NexT 主题使用了 SCSS 框架，请到官方地址下载 Hugo Extended 版本：https://github.com/gohugoio/hugo/releases ERROR 2022/09/20 21:12:38 Because that use SCSS framework in Hugo NexT, Please download Hugo extended version on offical site: https://github.com/gohugoio/hugo/releases Error: Error building site: TOCSS: failed to transform &#34;main.scss&#34; (text/x-scss). Check your Hugo installation; you need the extended version to build SCSS/SASS.: this feature is not available in your current Hugo version, see https://goo.gl/YMrWcn for more information github-style（选看） github-style这个主题是 github 的页面风格。
GitHub 项目地址 MeiK2333/github-style。
按着 github-style 主题提供的的文档走，把主题配置到站点中。
别忘了先 git init，然后使用命令下载主题 git submodule add git@github.com:MeiK2333/github-style.git themes/github-style。
如果需要升级主题的话，就进入 {path-to-project}/themes/github-style 目录，执行 git pull 命令，拉取最新的代码。
在 content/ 里创建 post/ 目录，后面所有的内容页面都放到这个目录下面，要不然站点里不会展示。
最后在配置文件 config.toml 里设置主题 theme = &quot;github-style&quot;。然后就可以使用命令 hugo server 启动服务了。
站点是没有问题的，可以正常地跑起来。但是这个主题貌似没有实现标签分类，也可能是本人没有找到，所以就放弃继续使用了。
部署到 GitHub Pages 使用命令 hugo -t {theme-name} 来把发布用的目录编译出来。这里就是 hugo -t hugo-theme-next。
默认情况下会编译到 {path-to-project}/publish/ 目录。 可以通过编辑配置文件，在配置文件里添加 publishDir: docs，来修改这个目录。
push 到 github.io 的时候，如果使用的是 publish/ 目录。那么要 push publish/ 目录上去，然后设置 GitHub Pages 的 Branch 为 master 和 /(root)。
如果使用的是 docs/ 目录，那么就要 push 整个项目上去，然后设置 GitHub Pages 的 Branch 为 master 和 docs/。
文本头部信息 draft: true date: 2000-01-01 08:00:00 +0800 lastmod: 2002-01-01 08:00:00 +0800 title: &#34;title&#34; summary: &#34;summary&#34; toc: true categories: - categories(分类) tags: - tags1(标签1) - tags2(标签2) draft：是不是草稿，true=是；false=不是。启动的时候带 --buildDrafts 选项就可以看到草稿的内容。 date：创建时间 lastmod：最后修改时间 title：文本标题 summary：文本概述 toc：是不是显示文章目录，true=是；false=不是。 categories：文本分类，一般一个 tags：文本标签，可以多个 参考（reference） hugo个人博客搭建并部署到GitHub【 for Windows】]]></content></entry><entry><title>Golang 开启 HTTP 服务</title><url>/post/computer-science/programming-language/golang/http/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag><tag>http</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 go version go1.19 windows/amd64 资料 {demo-golang}/demo/web/http/ 正文 开启 HTTP 服务 在 Go 中有多种方式，可以开启 HTTP 服务。但是总的来说基本就下面两大类思路（本质上其实是一类）。
直接使用 net 包从 TCP 开始自行实现。 使用官方提供的封装好的 &ldquo;net/http&rdquo; 包。 使用 &ldquo;net/http&rdquo; 包的时候，需要关注的最核心的部分，就是 Handler 接口 (src/net/http/server.go)。
type Handler interface { ServeHTTP(ResponseWriter, *Request) } 开启 HTTP 服务和 HTTP 请求被处理的流程大致如下：
直接或间接地创建 Server 结构体 (src/net/http/server.go) 的实例。 调用 Server 的 ListenAndServe 方法。 ListenAndServe 方法调用 net.Listen 方法 (src/net/dial.go)，启动 TCP 服务。 net.Listen 方法返回一个 net.Listener 接口 (src/net/dial.go) 的实例。 调用 net.Listener 的 Accept 方法，就可以获取连接上来的 TCP 连接。 新开启一个协程，把这个 TCP 连接丢进去处理。自己则继续监听有没有别的 TCP 连接。 处理流程继续往下，会遇到这行代码：serverHandler{c.server}.ServeHTTP(w, w.req)。 这里调用的就是 Handler 接口的 ServeHTTP 方法。再往下就进入业务处理流程或者框架的入口了。 ]]></content></entry><entry><title>红黑树（red-black tree）</title><url>/post/computer-science/data-structure/red-black-tree/</url><categories><category>data-structure(数据结构)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>data-structure(数据结构)</tag><tag>binary-search-tree(二叉查找树)</tag></tags><content type="html">资料 red-black_tree.drawio.html 正文 红黑树 红黑树是更高级的二叉查找树。 红黑树和 2-3-4 树是等价的： 红黑树的黑色结点个数 = 2-3-4 树的结点个数。 把红黑树的红结点移动到和父结点同层，就会变成 2-3-4 树。 把 2-3-4 树的三结点和四结点拆开，就可以变成红黑树。 红黑树的性质 满足二叉查找树的基本性质。 树中的每个结点颜色不是红的，就是黑的 根结点的颜色是黑的。 所有为 nil 的叶子结点的颜色是黑的。 如果一个结点是红的，那么它的两个孩子结点全部都是黑的。 对于每个结点，从该结点到到该结点的所有子孙结点的所有路径上包含有相同数目的黑结点。 参考（reference） 红黑树（更高级的二叉查找树）算法详解
bilibili&amp;ndash;木子喵neko
【neko】红黑树/插入【算法编程#11】
【neko】红黑树/删除【算法编程#12】</content></entry><entry><title>2-3-4 树</title><url>/post/computer-science/data-structure/2-3-4_tree/</url><categories><category>data-structure(数据结构)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>data-structure(数据结构)</tag><tag>b-tree</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 Cygwin gcc version 11.2.0
前言 在看 2-3-4 树之前，建议先看 2-3 树。相似的操作在 2-3-4 树不会重复详细的描述。
资料 2-3-4_tree.drawio.html 2-3-4 树 2-3-4 树就是 4 阶 B-树 2-3-4 树和红黑树是等价的： 2-3-4 树的结点个数 = 红黑树的黑色结点个数。 把 2-3-4 树的三结点和四结点拆开，就可以变成红黑树。 把红黑树的红结点移动到和父结点同层，就会变成 2-3-4 树。 2-3-4 树的性质 1、满足二叉查找树的基本性质。
2、结点可以存放一个元素、两个元素。
假设结点结构从左到右分别为：子树 1、元素 1、子树 2、元素 2、子树 3、元素 3、子树 4。 对于存放一个元素的结点。其形态为：子树 1、元素 1、子树 2。 子树 1 存放比 元素 1 小的元素； 子树 2 存放比 元素 1 大的元素。 对于存放两个元素的结点，其形态为：子树 1、元素 1、子树 2、元素 2、子树 3。 子树 1 存放比 元素 1 和 元素 2 都小的元素； 子树 2 存放在 元素 1 和 元素 2 之间的元素； 子树 3 存放比 元素 1 和 元素 2 都大的元素。 对于存放三个元素的结点，其形态为：子树 1、元素 1、子树 2、元素 2、子树 3、元素 3、子树 4。 子树 1 存放比 元素 1、元素 2、元素 3 都小的元素； 子树 2 存放在 元素 1 和 元素 2 之间的元素； 子树 3 存放在 元素 2 和 元素 3 之间的元素； 子树 4 存放比 元素 1、元素 2、元素 3 都大的元素。 3、2-3-4 树是绝对平衡的二叉查找树，所有叶子结点都在同一层上。从根结点到任意一个叶子结点所经过的结点数是相同的。
2-3-4 树的插入 下面列举的情况并不一定覆盖所有的场景，但是典型场景都有了，没有提到的场景可以根据典型场景推导。
只上溢不旋转的情况 1、空树。（类似 2-3 树的第 1 种情况）
2、二结点。（类似 2-3 树的第 2 种情况）
3、三结点。
添加结点 =&gt; 变四结点。（见图：2-3-4_tree.drawio.html 2-2-6）
4、没有父结点的四结点。
添加结点 =&gt; 变五结点 =&gt; 上溢（层数增加）。（见图：2-3-4_tree.drawio.html 2-4-2）
5、有父结点的四结点（父结点不是四结点）。
添加结点 =&gt; 变五结点 =&gt; 上溢（层数不增加）。（见图：2-3-4_tree.drawio.html 2-4-4）
这种情况，四结点是父结点哪个子结点，都是一样的处理逻辑，上溢一次。
这里，父结点可以是二结点也可以是三结点。
6、有父结点的四结点（父结点是四结点）。
添加结点 =&gt; 变五结点 =&gt; 上溢（父结点变五结点）=&gt; 父结点上溢（层数增加）。（见图：2-3-4_tree.drawio.html 2-6）
这种情况，四结点是父结点哪个子结点，都是一样的处理逻辑，上溢两次。
可以通过旋转抵消上溢的情况 1、有父结点的四结点（父结点是四结点、兄弟结点不是四结点）。
添加结点 =&gt; 变五结点 =&gt; 兄弟结点有空位 =&gt; 旋转结点到兄弟结点（抵消上溢，层数不增加）。
这种情况，如果只上溢的话，会上溢两次（自己上溢一次、父结点上溢一次），树的深度增加了，可能影响查询效率。
但是这个时候其实 2-3-4 树是不满的，兄弟结点是有空位的。这时候就可以通过旋转，重新平衡 2-3-4 树。
根据 2-3-4 树有空位的兄弟结点的位置，旋转的情况分为六种，处理方式是差不多的：
向右旋转一次（见图：2-3-4_tree.drawio.html 4-2-2） 向左旋转一次（见图：2-3-4_tree.drawio.html 4-2-4） 向右旋转两次（见图：2-3-4_tree.drawio.html 4-6） 向左旋转两次（无图，参考向右旋转两次的图）。 向右旋转三次（无图，参考向右旋转两次的图）。 向左旋转三次（无图，参考向右旋转两次的图）。 2、有父结点的四结点（父结点是四结点、兄弟结点是四结点、祖父结点是四结点、叔叔结点不是四结点）。
添加结点 =&gt; 变五结点 =&gt; 父结点和兄弟结点都没有空位，无法旋转，只能上溢（父结点变五结点） =&gt; 叔叔结点有空位 =&gt; 旋转结点到叔叔结点（抵消上溢，层数不增加）。
这种情况，如果只上溢的话，会上溢三次（自己上溢一次、父结点上溢一次、祖父结点上溢一次），树的深度增加了，可能影响查询效率。
但是这个时候其实 2-3-4 树是不满的，叔叔结点是有空位的。这时候就可以通过旋转，重新平衡 2-3-4 树。
这里第一次的上溢是避免不了的。上溢之后，重新以父结点为参照，这时就可以看做上面第一种情况。
根据 2-3-4 树有空位的叔叔结点的位置，旋转的情况分为六种，处理方式是差不多的：
（上溢一次后）向右旋转一次（无图，参考向右旋转三次的图）。 （上溢一次后）向左旋转一次（无图，参考向右旋转三次的图）。 （上溢一次后）向右旋转两次（无图，参考向右旋转三次的图）。 （上溢一次后）向左旋转两次（无图，参考向右旋转三次的图）。 （上溢一次后）向右旋转三次（见图：2-3-4_tree.drawio.html 4-8） （上溢一次后）向左旋转三次（无图，参考向右旋转三次的图）。 2-3-4 树的删除 下面列举的情况并不一定覆盖所有的场景，但是典型场景都有了，没有提到的场景可以根据典型场景推导。
删除叶子结点 1、删除三结点的结点。（类似 2-3 树的第 1 种情况）
2、删除四结点的结点。
直接删掉就好了，不会破坏 2-3-4 树的性质。（见图：2-3-4_tree.drawio.html 6-2-4）
3、删除二结点的结点（父结点是二结点、兄弟结点是二结点）。（类似 2-3 树的第 2 种情况）
4、删除二结点的结点（父结点是三结点、兄弟结点是二结点）。（类似 2-3 树的第 3 种情况）
5、删除二结点的结点（父结点是四结点，兄弟结点是二结点）。（类似第 3 种情况）
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（其中一个结点，层次不变） =&gt; 下溢结点和兄弟结点融合。（见图：2-3-4_tree.drawio.html 6-4-6）
6、删除二结点的结点（父结点是二结点、兄弟结点是三结点）。（类似 2-3 树的第 4 种情况）
7、删除二结点的结点（父结点是三结点、兄弟结点是三结点）。（类似 2-3 树的第 5 种情况）
8、删除二结点的结点（父结点是四结点、兄弟结点是三结点）。（类似第 6 种情况）
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3-4_tree.drawio.html 6-6-6）
另外，还有向左旋转三次的情况（见图：2-3-4_tree.drawio.html 6-10-4），向右旋转三次的处理方式是一样的。
9、删除二结点的结点（父结点是二结点、兄弟结点是四结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3-4_tree.drawio.html 6-8-2）
这种情况，删掉结点之后，自己这个位置就是空的了。也就是父结点变得少一个子树，这会破坏 2-3-4 树的性质。
和上面第 3 种情况不同的是，在第 3 种情况中，兄弟结点是二结点，借不出结点。而这里可以借一个结点过来，把这个子树补上，这样就不破坏 2-3-4 树的性质了。
图里的例子是向左旋转一次的情况，向右旋转一次的处理方式是一样的。
10、删除二结点的结点（父结点是三结点、兄弟结点是四结点）。（类似第 9 种情况）
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3-4_tree.drawio.html 6-8-4）
11、删除二结点的结点（父结点是四结点、兄弟结点是四结点）。（类似第 9 种情况）
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3-4_tree.drawio.html 6-8-6）
12、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是二结点、叔叔结点是二结点）。（类似 2-3 树的第 6 种情况）
13、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是三结点、叔叔结点是二结点）。（类似 2-3 树的第 7 种情况）
祖父结点是四结点的处理逻辑是一样的。
14、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是三结点、叔叔结点是三结点）。（类似 2-3 树的第 8 种情况）
叔叔结点是四结点的处理逻辑是一样的。
删除的不是叶子结点 这种情况需和平衡二叉树一样，找到中序遍历的前驱结点或者后继结点，把这两个结点互换位置，这个时候要删除的结点会被换到叶子结点的位置，然后再删除。
2-3-4 树转换成红黑树 1、三结点其中一个元素转化为红黑树的红结点，左右哪个元素都可以。四结点中两边的元素转化为红黑树的红结点。 2、拆分三结点和四结点，和父结点连接的一定是黑结点 （见图：2-3-4_tree.drawio.html 12-2） reference（参考） 掌握了2-3-4树也就掌握了红黑树，不信进来看看，建议收藏！ 理解2-3-4树bilibili&ndash;木子喵neko【neko】红黑树/插入【算法编程#11】【neko】红黑树/删除【算法编程#12】]]></content></entry><entry><title>2-3 树</title><url>/post/computer-science/data-structure/2-3_tree/</url><categories><category>data-structure(数据结构)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>data-structure(数据结构)</tag><tag>b-tree</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 Cygwin gcc version 11.2.0
资料 2-3_tree.drawio.html 2-3 树 2-3 树就是 3 阶 B-树。 把 2-3 树的三结点拆开，就可以变成红黑树。 2-3 树的性质 1、满足二叉查找树的基本性质。
2、结点可以存放一个元素、两个元素。
假设结点结构从左到右分别为：子树 1、元素 1、子树 2、元素 2、子树 3。 对于存放一个元素的结点，其形态为：子树 1、元素 1、子树 2。 子树 1 存放比 元素 1 小的元素； 子树 2 存放比 元素 1 大的元素。 对于存放两个元素的结点，其形态为：子树 1、元素 1、子树 2、元素 2、子树 3。 子树 1 存放比 元素 1 和 元素 2 都小的元素； 子树 2 存放在 元素 1 和 元素 2 之间的元素； 子树 3 存放比 元素 1 和 元素 2 都大的元素。 3、2-3 树是绝对平衡的二叉查找树，所有叶子结点都在同一层上。从根结点到任意一个叶子结点所经过的结点数是相同的。
2-3 树的插入 下面列举的情况并不一定覆盖所有的场景，但是典型场景都有了，没有提到的场景可以根据典型场景推导。
只上溢不旋转的情况 1、空树。
添加结点 =&gt; 变二结点。（见图：2-3_tree.drawio.html 2-2-2）
2、二结点。
添加结点 =&gt; 变三结点。（见图：2-3_tree.drawio.html 2-2-4）
3、没有父结点的三结点。
添加结点 =&gt; 变四结点 =&gt; 上溢（层数增加）。（见图：2-3_tree.drawio.html 2-4-2）
4、有父结点的三结点（父结点不是三结点）。
添加结点 =&gt; 变四结点 =&gt; 上溢（层数不增加）。（见图：2-3_tree.drawio.html 2-4-4）
这种情况，三结点是父结点哪个子结点，都是一样的处理逻辑，上溢一次。
5、有父结点的三结点（父结点是三结点）。
添加结点 =&gt; 变四结点 =&gt; 上溢（父结点变四结点）=&gt; 父结点上溢（层数增加）。（见图：2-3_tree.drawio.html 2-6）
这种情况，四结点是父结点哪个子结点，都是一样的处理逻辑，上溢两次。
可以通过旋转抵消上溢的情况 1、有父结点的三结点（父结点是三结点、兄弟结点不是三结点）。
添加结点 =&gt; 变四结点 =&gt; 兄弟结点有空位 =&gt; 旋转结点到兄弟结点（抵消上溢，层数不增加）。
这种情况，如果只上溢的话，会上溢两次（自己上溢一次、父结点上溢一次），树的深度增加了，可能影响查询效率。
但是这个时候其实 2-3 树是不满的，兄弟结点是有空位的。这时候就可以通过旋转，重新平衡 2-3 树。
根据 2-3 树有空位的兄弟结点的位置，旋转的情况分为四种，处理方式是差不多的：
向右旋转一次（见图：2-3_tree.drawio.html 4-2-2） 向左旋转一次（见图：2-3_tree.drawio.html 4-2-4） 向右旋转两次（见图：2-3_tree.drawio.html 4-4） 向左旋转两次（无图，参考向右旋转两次的图）。 2、有父结点的三结点（父结点是三结点、兄弟结点是三结点、祖父结点是三结点、叔叔结点不是三结点）。
添加结点 =&gt; 变四结点 =&gt; 父结点和兄弟结点都没有空位，无法旋转，只能上溢（父结点变四结点） =&gt; 叔叔结点有空位 =&gt; 旋转结点到叔叔结点（抵消上溢，层数不增加）。
这种情况，如果只上溢的话，会上溢三次（自己上溢一次、父结点上溢一次、祖父结点上溢一次），树的深度增加了，可能影响查询效率。
但是这个时候其实 2-3 树是不满的，叔叔结点是有空位的。这时候就可以通过旋转，重新平衡 2-3 树。
这里第一次的上溢是避免不了的。上溢之后，重新以父结点为参照，这时就可以看做上面第一种情况。
根据 2-3 树有空位的叔叔结点的位置，旋转的情况分为四种，处理方式是差不多的：
（上溢一次后）向右旋转一次（见图：2-3_tree.drawio.html 4-6-2） （上溢一次后）向左旋转一次（无图，参考向右旋转一次的图） （上溢一次后）向右旋转两次（见图：2-3_tree.drawio.html 4-6-4） （上溢一次后）向左旋转两次（无图，参考向右旋转两次的图）。 2-3 树的删除 下面列举的情况并不一定覆盖所有的场景，但是典型场景都有了，没有提到的场景可以根据典型场景推导。
删除叶子结点 1、删除三结点的结点。
直接删掉就好了，不会破坏 2-3 树的性质。（见图：2-3_tree.drawio.html 6-2）
2、删除二结点的结点（父结点是二结点、兄弟结点是二结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（唯一的结点，层次减少） =&gt; 父结点和兄弟结点融合。（见图：2-3_tree.drawio.html 6-4-2）
这种情况，删掉结点之后，自己这个位置就是空的了。也就是父结点变得少一个子树，这会破坏 2-3 树的性质。
处理方式是，就把父结点放到下面一层去，和兄弟结点融合成一个结点，这样就不会破坏 2-3 树的性质了。
图里的例子是父结点的子树 1 被删空了，子树 2 被删空的情况是一样的处理方式。
3、删除二结点的结点（父结点是三结点、兄弟结点都是二结点）。（类似第 2 种情况）
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（其中一个结点，层次不变） =&gt; 下溢结点和兄弟结点融合。（见图：2-3_tree.drawio.html 6-4-4）
4、删除二结点的结点（父结点是二结点、兄弟结点是三结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3_tree.drawio.html 6-6-2）
这种情况，删掉结点之后，自己这个位置就是空的了。也就是父结点变得少一个子树，这会破坏 2-3 树的性质。
和上面第 2 种情况不同的是，在第 2 种情况中，兄弟结点是二结点，借不出结点。而这里可以借一个结点过来，把这个子树补上，这样就不破坏 2-3 树的性质了。
图里的例子是向左旋转一次的情况，向右旋转一次的处理方式是一样的。
另外，还有向左旋转两次的情况（见图：2-3_tree.drawio.html 6-10-2），向右旋转两次的处理方式是一样的。
5、删除二结点的结点（父结点是三结点、兄弟结点是三结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 兄弟结点可以借一个结点 =&gt; 旋转结点到删除结点的位置。（见图：2-3_tree.drawio.html 6-6-4）
图里的例子是向左旋转一次的情况，向右旋转一次的处理方式是一样的。
6、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是二结点、叔叔结点是二结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（父结点和兄弟结点融合） =&gt; 祖父结点少一个子树 =&gt; 祖父结点下溢（唯一的结点，层次减少） =&gt; 祖父结点和叔叔结点融合。（见图：2-3_tree.drawio.html 6-12-2）
这种情况，初始场景类似上面第 2 种情况，解决方案也是类似第 2 种情况的：下溢 + 融合。初始场景处理完之后，重新以父结点为参照，又是类似上面第 2 种情况，再来一遍就好了。
7、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是三结点、叔叔结点是二结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（父结点和兄弟结点融合） =&gt; 祖父结点少一个子树 =&gt; 祖父结点下溢（其中一个结点，层次不变） =&gt; 下溢结点和叔叔结点融合。（见图：2-3_tree.drawio.html 6-12-4）
这种情况，初始场景类似上面第 2 种情况，解决方案也是类似第 2 种情况的：下溢 + 融合。初始场景处理完之后，重新以父结点为参照，类似上面第 3 种情况，解决方案也是类似第 3 种情况的：下溢 + 融合。
8、删除二结点的结点（父结点是二结点、兄弟结点是二结点、祖父结点是三结点、叔叔结点是三结点）。
删除结点 =&gt; 父结点少一个子树 =&gt; 父结点下溢（父结点和兄弟结点融合） =&gt; 祖父结点少一个子树 =&gt; 叔叔结点可以借一个结点 =&gt; 旋转结点到祖父结点的删除结点的位置。（见图：2-3_tree.drawio.html 6-14）
这种情况，初始场景类似上面第 2 种情况，解决方案也是类似第 2 种情况的：下溢 + 融合。初始场景处理完之后，重新以父结点为参照，类似上面第 4 种情况，解决方案也是类似第 4 种情况的：旋转。
删除的不是叶子结点 这种情况需和平衡二叉树一样，找到中序遍历的前驱结点或者后继结点，把这两个结点互换位置，这个时候要删除的结点会被换到叶子结点的位置，然后再删除。
2-3 树转换成红黑树 1、三结点其中一个元素转化为红黑树的红结点，左右哪个元素都可以。 2、拆分三结点，和父结点连接的一定是黑结点。 （见图：2-3_tree.drawio.html 10-2） reference（参考） 二三树、B树(多路平衡查找树)、B+树二叉树，红黑树，23树，B树，B+树2-3树的删除bilibili&ndash;天羽神奈2-3树的定义与搜索图解2-3树插入节点方法2-3树删除节点图解及示例]]></content></entry><entry><title>AVL-Tree（平衡二叉树）</title><url>/post/computer-science/data-structure/avl_tree/</url><categories><category>data-structure(数据结构)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>data-structure(数据结构)</tag><tag>binary-search-tree(二叉查找树)</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 Cygwin gcc version 11.2.0
资料 {demo-c}/data-structure/balanced_binary_tree.c balanced_binary_tree.drawio.html 平衡二叉树 AVL-Tree（balanced binary tree、平衡二叉树）是一种特殊的二叉排序树。
平衡二叉树的性质 1、满足二叉查找树的基本性质。 2、每个结点的左右子树的高度之差的绝对值（平衡因子）最多为 1。 平衡二叉树的插入 左旋和右旋 （见图：balanced_binary_tree.drawio.html 2-2）
4 种需要平衡的场景 1、LL 型
LL 型，直接右旋 x 结点。（见图：balanced_binary_tree.drawio.html 4-2）
2、LR 型
LR 型，直接右旋 x 结点，依然不平衡。（见图：balanced_binary_tree.drawio.html 4-4-2）
需要先左旋 y 结点，再右旋 x 结点。（见图：balanced_binary_tree.drawio.html 4-4-4）
3、RR 型
RR 型，直接左旋 x 结点。（见图：balanced_binary_tree.drawio.html 6-2）
4、RL 型
RL 型，直接左旋 x 结点，依然不平衡。（见图：balanced_binary_tree.drawio.html 6-4-2）
需要先右旋 y 结点，再左旋 x 结点。（见图：balanced_binary_tree.drawio.html 6-4-4）
平衡二叉树的删除 平衡二叉树的删除和二插叉查找树的删除步骤是差不多的。
区别在于，平衡二叉树删除结点之后，需要依次向上检查每一个结点是否平衡。
reference（参考） 平衡二叉树（AVL树）及C语言实现</content></entry><entry><title>在 Go 项目中使用 Protocol Buffers</title><url>/post/computer-science/programming-language/golang/protobuf/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag><tag>protocol-buffers</tag></tags><content type="html"><![CDATA[在 Windows 11 中使用 准备工作 安装编译器：protoc 安装 go 插件：protoc-gen-go 安装编译器
https://developers.google.com/protocol-buffers/docs/downloads这个页面有怎么下载编译器的导航，按需求找对应的版本就行。
64 位的 windows 下载的应该是 protoc-xxx-win64.zip 这样命名的压缩文件，中间的 xxx 是版本号，解压出来是个安装程序。
安装完成之后，可以通过 protoc --version 命令，输出版本号验证一下。
&gt; protoc --version libprotoc 3.21.1 安装 go 插件
https://developers.google.com/protocol-buffers/docs/gotutorialhttps://developers.google.com/protocol-buffers/docs/reference/go-generated这两个页面都有说明怎么安装 go 插件，执行 go install 命令就行。
go install google.golang.org/protobuf/cmd/protoc-gen-go@latest
使用 https://developers.google.com/protocol-buffers/docs/gotutorialhttps://developers.google.com/protocol-buffers/docs/reference/go-generated这两个页面都有说明怎么使用，主要就是先编写 .proto 文件，然后执行 protoc 命令。
比如，在 .\api\v1\test\test.proto 文件中添加如下代码。
syntax = &#34;proto3&#34;; package test; import &#34;google/api/annotations.proto&#34;; option go_package = &#34;/v1/test;v1test&#34;; service Test { rpc TestGet (TestGetRequest) returns (TestGetReply) { option (google.api.http) = { get: &#34;/api/v1/test&#34; }; } } message TestGetRequest { string key = 1; } message TestGetReply { string key = 1; string val = 2; } 然后，再命令行执行： protoc --proto_path=.\api --go_out=.\api .\api\v1\test\test.proto。
这个时候不出意外会报错：Import &quot;google/api/annotations.proto&quot; was not found or had errors.。 这是因为代码里的 import &quot;google/api/annotations.proto&quot;; 这一行，引入了外部文件 annotations.proto。
annotations.proto 这个文件可以从 googleapis 这个项目里找到。https://github.com/googleapis/googleapis文件路径是 googleapis/google/api/annotations.proto。需要注意，annotations.proto 这个文件又引入了 http.proto。http.proto 文件的路径是 googleapis/google/api/http.proto。
把这两个文件下载下来，放到 .\api\google\api 目录下。 现在的目录结构变成这样：
.\api\google\api\annotations.proto .\api\google\api\http.proto .\api\v1\test\test.proto 这个时候执行 protoc --proto_path=.\api --go_out=.\api .\api\v1\test\test.proto。就会在 .\api\v1\test 目录下面生成 test.pb.go。test.pb.go 里面有根据 test.proto 文件中定义的实体生成的对应的 go 的结构体代码。
--go_out=.\api 表示文件生成到 .\api 目录下面。代码中的 option go_package = &quot;/v1/test;v1test&quot;;，表示文件会生成到 --go_out 指定的目录下面的 \v1\test 目录。后面的 v1test 表示生成的 go 文件的包名是 v1test。
到这里为止，并没有使用下面这段代码。
service Test { rpc TestGet (TestGetRequest) returns (TestGetReply) { option (google.api.http) = { get: &#34;/api/v1/test&#34; }; } } 这段代码可以用于生成 grpc 服务的代码和 http 服务的代码。在使用 protoc 时，加上 --go-grpc_out=.\api 选项，可以生成 grpc 服务的代码，文件名称是 test_grpc.pb.go。在使用 protoc 时，--go-http_out=.\api 选项，可以生成 http 服务的代码，文件名称是 test_http.pb.go。
生成的 http 服务的代码会导入 kratos 的包是因为，引用了 proto-gen-go-http，并且依赖 google api 定义了接口。这个是 kratos 提供的 proto-gen-go-http 生成的。
reference（参考） 概述：https://developers.google.com/protocol-buffers/docs/overviewprotobuf-go：https://github.com/protocolbuffers/protobuf-gogo 基础使用：https://developers.google.com/protocol-buffers/docs/gotutorial编译器下载：https://developers.google.com/protocol-buffers/docs/downloads编译器下载：https://github.com/protocolbuffers/protobuf/releasesgo 生成代码：https://developers.google.com/protocol-buffers/docs/reference/go-generatedproto编译引用外部包问题解决：Import googleapiannotations.proto was not found or had errorsgoogleapis/googleapis：https://github.com/googleapis/googleapisgrpc-ecosystem/grpc-gateway：https://github.com/grpc-ecosystem/grpc-gatewaygo-kratos/kratos：https://github.com/go-kratos/kratos另外，感谢极客时间 Go 进阶训练营的助教包子老师的解答。
在 Ubuntu 20.04 中使用 准备工作 安装编译器：protoc 安装 go 插件：protoc-gen-go 安装编译器
linux 需要通过源码安装，下载的应该是 Source code (tar.gz) 源码压缩文件。解压之后，编译安装。
# 安装需要的工具包 &gt; apt-get install autoconf automake libtool # 解压 &gt; tar xvf protobuf-21.1.tar.gz &gt; cd protobuf-21.1/ # 编译安装 &gt; ./autogen.sh &gt; ./configure &gt; make &gt; make install # 输出版本号验证一下 &gt; protoc --version 不成功的，可以试试再来一遍，说不定就成功了。不知道为什么，挺玄学的。
reference（参考） Ubuntu 20.04 配置 go 使用protobufubuntu20.04安装protobuf]]></content></entry><entry><title>在 Linux 中配置 Golang 开发环境</title><url>/post/computer-science/programming-language/golang/linux/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag></tags><content type="html"><![CDATA[准备工作 去官网下载压缩包。
https://golang.google.cn/dl/https://go.dev/dl/这里下载的过：
go1.17.6.linux-amd64.tar.gz go1.18.3.linux-amd64.tar.gz 把压缩包解压到 /usr/local/go 目录：
&gt; tar -zxvf go1.17.6.linux-amd64.tar.gz -C /usr/local/go &gt; tar -zxvf go1.18.3.linux-amd64.tar.gz -C /usr/local/go 设置系统环境变量 直接执行 export &gt; export GOROOT=/usr/local/go &gt; export PATH=$PATH:$GOROOT/bin &gt; export PATH=$PATH:$HOME/go/bin 这种操作方式只对当前的终端窗口生效，当前窗口关闭后就会恢复原有的 path 配置。
可以注意到有两个 bin 路径:
如果是 make install 编译安装的可能在 $GOROOT/bin，我这里的 protoc 就是这样的 如果是 go install 安装的 可能在 $HOME/go/bin 所以建议是两个 bin 路径都添加一下。
编辑 /etc/profile 文件 sudo vim /etc/profile，在 /etc/profile 文件最后添加：
export GOROOT=/usr/local/go export PATH=$PATH:$GOROOT/bin export PATH=$PATH:$HOME/go/bin 保存后，执行 source /etc/profile 刷新环境变量。
这种操作方式设置完后即使关闭终端窗口或者重启系统也是生效的。
验证 环境变量设置完成，应该就可以用了。
&gt; go version go version go1.17.6 linux/amd64 开启 go mod &gt; go env -w GO111MODULE=on &gt; go env -w GOPROXY=https://goproxy.cn,direct 参考 linux安装go环境ubuntu查看和修改PATH环境变量的方法]]></content></entry><entry><title>在 Linux 中安装 MySQL</title><url>/post/computer-science/application/vmware/mysql/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>vmware</tag><tag>vmware-workstation</tag><tag>linux</tag><tag>ubuntu</tag><tag>mysql</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 VMware Workstation Pro 16 Ubuntu 22.04
前言 没有 Linux 环境的，可以装个虚拟机，然后在里面玩玩： 在 VMware 虚拟机中安装 Linux更新源 &gt; apt update Reading package lists... Done E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied) E: Unable to lock directory /var/lib/apt/lists/ W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied) W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied) Permission denied，非生产环境，一般直接 sudo 就行。
&gt; sudo apt update ... Reading package lists... Done Building dependency tree... Done Reading state information... Done 159 packages can be upgraded. Run &#39;apt list --upgradable&#39; to see them. 看到这个就成功了。
安装 MySql 8 &gt; sudo apt install mysql-server ... mysqld will log errors to /var/log/mysql/error.log mysqld is running as pid 3171 Created symlink /etc/systemd/system/multi-user.target.wants/mysql.service → /lib /systemd/system/mysql.service. Setting up mysql-server (8.0.29-0ubuntu0.22.04.2) ... Processing triggers for man-db (2.10.2-1) ... Processing triggers for libc-bin (2.35-0ubuntu3) ... 看到这个就成功了。安装完成，会直接启动。
可以通过查看 MySQL 版本确认一下。
&gt; mysql -V mysql Ver 8.0.29-0ubuntu0.22.04.2 for Linux on x86_64 ((Ubuntu)) 也可以通过 ps 命令确认一下。
&gt; ps aux | grep mysql mysql 3357 0.2 9.8 1780000 391948 ? Ssl 22:46 0:04 /usr/sbin/mysqld 修改 MySQL 密码 安装 MySQL 的时候会生成一个默认密码。
&gt; sudo cat /etc/mysql/debian.cnf # Automatically generated for Debian scripts. DO NOT TOUCH! [client] host = localhost user = debian-sys-maint password = flP8kWluyyOyvs9Y socket = /var/run/mysqld/mysqld.sock [mysql_upgrade] host = localhost user = debian-sys-maint password = flP8kWluyyOyvs9Y socket = /var/run/mysqld/mysqld.sock 其中 user 和 password 就对应用户名和密码。
# 连接 MySQL &gt; mysql -udebian-sys-maint -pflP8kWluyyOyvs9Y # 修改密码 mysql&gt; use mysql; mysql&gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED WITH mysql_native_password BY &#39;root&#39;; 让 MySQL 可以远程访问 MySQL 配置文件 没有配置远程访问前，通过 netstat 命令查看 MySQL 的端口是这样的：
&gt; netstat -ano | grep 3306 tcp 0 0 127.0.0.1:33060 0.0.0.0:* LISTEN off (0.00/0/0) tcp 0 0 127.0.0.1:3306 0.0.0.0:* LISTEN off (0.00/0/0) 这里的 127.0.0.1:3306 表示 MySQL 只接收本地的连接。
打开 MySQL 配置文件：sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf。
... # Instead of skip-networking the default is now to listen only on # localhost which is more compatible and is not less secure. bind-address = 127.0.0.1 mysqlx-bind-address = 127.0.0.1 ... 找到 bind-address，原来是 127.0.0.1，改成 0.0.0.0。 然后重启 MySQL 服务：sudo service mysql restart。 配置远程访问后，通过 netstat 命令查看 MySQL 的端口是这样的：
&gt; netstat -ano | grep 3306 tcp 0 0 127.0.0.1:33060 0.0.0.0:* LISTEN off (0.00/0/0) tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN off (0.00/0/0) 这里的 0.0.0.0:3306 表示 MySQL 现在可以和外部建立连接。
MySQL 配置 登入 MySQL 实例，给 root 用户设置远程连接权限。
mysql&gt; use mysql; mysql&gt; select user,host from user; +------------------+-----------+ | user | host | +------------------+-----------+ | debian-sys-maint | localhost | | mysql.infoschema | localhost | | mysql.session | localhost | | mysql.sys | localhost | | root | localhost | +------------------+-----------+ 5 rows in set (0.00 sec) 没设置前 root 用户对应的 host 为 &ldquo;localhost&rdquo;。
mysql&gt; update user set host=&#39;%&#39; where user=&#39;root&#39; and host=&#39;localhost&#39;; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql&gt; select user,host from user; +------------------+-----------+ | user | host | +------------------+-----------+ | root | % | | debian-sys-maint | localhost | | mysql.infoschema | localhost | | mysql.session | localhost | | mysql.sys | localhost | +------------------+-----------+ 5 rows in set (0.00 sec) 将 root 用户对应的 host 设置为 &ldquo;%&rdquo; 表示可以进行远程连接。
mysql&gt; flush privileges; 别忘了，刷新数据库。
配置虚拟机防火墙 查看防火墙规则列表。
&gt; sudo iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 设置 3306 端口外部可以访问。
udo iptables -A INPUT -p tcp --dport 3306 -j ACCEPT 设置完会变成下面这样：
&gt; sudo iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT tcp -- anywhere anywhere tcp dpt:mysql Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 需要注意的是，用命令配置是即时生效的，重启以后规则会丢失。想要让配置永久有效，可以去修改 iptables 配置文件。命令 service iptables save 也可以让 iptables 设置长久有效，重启后不丢失。
虚拟机端口映射 选中需要修改的虚拟机 最上面的导航栏 &ndash;&gt; 点击 &ldquo;编辑&rdquo; &ndash;&gt; 点击 &ldquo;虚拟网络编辑器&rdquo; 打开命令行，使用 ifconfig 命令查看虚拟机在子网中的 IP。这里有可能会有很多个 IP，单看这里可能无法确定。
&gt; ifconfig ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.226.128 netmask 255.255.255.0 broadcast 192.168.226.255 inet6 fe80::7dd9:3248:6626:cde9 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:5c:43:29 txqueuelen 1000 (Ethernet) RX packets 607 bytes 57711 (57.7 KB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 283 bytes 28521 (28.5 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 1000 (Local Loopback) RX packets 266 bytes 22796 (22.7 KB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 266 bytes 22796 (22.7 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 虚拟网络编辑器 &ndash;&gt; 在最上面的列表里面找到 VMnet8（子网地址是 192.168.226.0 的那个）。从上面 ifconfig 命令的结果里面，找到在子网地址下的那个（这里就是 192.168.226.128） 在下面的 &ldquo;VMnet 信息&rdquo; 里面&ndash;&gt; 选择 &ldquo;NAT 模式&rdquo; &ndash;&gt; 点击右边的 &ldquo;NAT 设置&rdquo; 按钮。如果按钮不让点，就先点一下最下面的 &ldquo;更改设置&rdquo;。 端口转发 &ndash;&gt; 点击 &ldquo;添加&rdquo; &ndash;&gt; 添加一个主机端口和虚拟机端口的映射（这里把主机 3306 映射到虚拟机 3306），虚拟机 IP 地址就填上面的 192.168.226.128。 测试 搞完上面的步骤，如果没问题的话，理论上就可以从主机访问虚拟机的 MySQL 服务了。连接有点慢，应该和虚拟机环境有关系。
参考 Ubuntu安装mysql8, 修改mysql密码，配置远程连接虚拟机端口映射提供mysql远程服务如何在Ubuntu20.04上安装MySQL以及如何配置MySQL的远程连接Ubuntu 开启Mysql 3306端口远程访问]]></content></entry><entry><title>在 VMware 虚拟机中安装 Linux</title><url>/post/computer-science/application/vmware/linux/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>vmware</tag><tag>vmware-workstation</tag><tag>linux</tag><tag>ubuntu</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 VMware Workstation Pro 16 Ubuntu 22.04
安装 Ubuntu 22.04 下载页面在哪 官网的下载路径：
官网官网 &ndash;&gt; 最上面的导航栏 &ndash;&gt; 点击 &ldquo;Download&rdquo; &ndash;&gt; 选择 &ldquo;Ubuntu Desktop&rdquo; &ndash;&gt; 然后页面就会变成 &ldquo;Download Ubuntu Desktop&rdquo; 的页面，一般都是一个 LTS 版本，如果没有特别需求，直接点旁边的 &ldquo;Download&rdquo; 按钮就行了。 如果有特别的需求，在 &ldquo;Download&rdquo; 按钮的下面有一个 &ldquo;see our alternative downloads&rdquo; 链接，点击进入 Alternative downloads页面。 如果 &ldquo;Alternative downloads&rdquo; 页面还不能满足需求，在 &ldquo;Alternative downloads&rdquo; 页面的最下面，有一个 &ldquo;Past releases and other flavours&rdquo; 板块 &ndash;&gt; 板块里面有一个 Past releases，可以在里面找需要的版本。 中文官网的下载路径：
中文官网官网 &ndash;&gt; 最上面的导航栏 &ndash;&gt; 点击 &ldquo;下载&rdquo; &ndash;&gt; 选择 &ldquo;桌面&rdquo; &ndash;&gt; 然后页面就会变成 &ldquo;下载Ubuntu桌面系统&rdquo; 的页面，一般都是一个 LTS 版本，如果没有特别需求，直接点旁边的 &ldquo;下载&rdquo; 按钮就行了。 如果有特别的需求，在 &ldquo;下载&rdquo; 按钮的下面有一个 &ldquo;其他下载&rdquo; 链接，点击进入 其他下载页面。 如果 &ldquo;其他下载&rdquo; 页面还不能满足需求，在 &ldquo;其他下载&rdquo; 页面的最下面，有一个 &ldquo;历史版本和其他风味版&rdquo; 板块 &ndash;&gt; 板块里面有一个 查看历史版本，可以在里面找需要的版本。 下载和安装 在刚才的下载页面，下载 Ubuntu 22.04 LTS 的安装包。
新建虚拟机：
打开 VMware Workstation Pro。 最上面的导航栏 &ndash;&gt; 点击 &ldquo;文件&rdquo; &ndash;&gt; 点击 &ldquo;新建虚拟机&rdquo; &ndash;&gt; 一般一路下一步就行，中间需要选择上面下载的 Ubuntu 的安装包作为虚拟机的操作系统。 新建虚拟机完成后，启动虚拟机。 第一次进入操作系统，会弹出 Install（正常安装） 页面：
Install &ndash;&gt; 语言选择 English(US)（英语） &ndash;&gt; 点击 Continue。 Updates and other software &ndash;&gt; 选择 Normal installation（正常安装） &ndash;&gt; 其他的默认 &ndash;&gt; 点击 Continue。 Installation type &ndash;&gt; 选择 Erase disk and install Ubuntu（清除硬盘并安装） &ndash;&gt; 点击 Install Now &ndash;&gt; 点击 Continue。 Where are you? &ndash;&gt; 选择 Shanghai &ndash;&gt; 点击 Continue。 Who are you? &ndash;&gt; 填：计算机名称、用户名、密码 &ndash;&gt; 选择 Log in automatically（自动登录） &ndash;&gt; 点击 Continue。 其余直接点击下一步，然后等待安装完成。 共享文件夹 最上面的导航栏 &ndash;&gt; 点击 &ldquo;虚拟机&rdquo; &ndash;&gt; 点击 &ldquo;设置&rdquo;。 最上面的选项卡 &ndash;&gt; 点击 &ldquo;选项&rdquo; &ndash;&gt; 在下面的列表里找到 &ldquo;共享文件夹&rdquo; &ndash;&gt; 点击 &ldquo;共享文件夹&rdquo;。 右边的 &ldquo;文件夹共享&rdquo; 里选择 &ldquo;总是启用&rdquo; &ndash;&gt; 右边的 &ldquo;文件夹&rdquo; 里点击 &ldquo;添加&rdquo;。 点 &ldquo;下一步&rdquo; &ndash;&gt; 命名共享文件夹 &ndash;&gt; 主机路径就是本机的目录，名称就是映射到 Ubuntu 里的目录。 启动虚拟机，共享文件夹应该会被映射到 /mnt/hgfs/上面的名称对应的目录。如果没有 hgfs 目录就创建一个。如果看不到共享文件夹，就执行下面两条命令，然后再次进入 hgfs 目录就能看见了。
&gt; vmware-hgfsclient &gt; sudo vmhgfs-fuse .host:/ /mnt/hgfs -o allow_other 上面这样的操作是一次性的，下次开机又要重复操作。如果想让系统每次开机的时候自动挂载，需要编辑 /etc/fstab。这样系统启动时会自动将文件挂载到指定位置。
sudo vim /etc/fstab，使用管理员权限打开 /etc/fstab。在最后添加一行：.host:/ /mnt/hgfs fuse.vmhgfs-fuse allow_other 0 0。这样下次系统启动时就会自动挂载了。
常用软件 gcc # 这个命令将会安装一系列软件包，包括 gcc、g++、make # 一路 y 就行 &gt; sudo apt install build-essential # 可以通过输出 gcc 版本来检查是否安装成功 &gt; gcc --version gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0 git &gt; sudo apt-get update # 安装依赖 &gt; sudo apt-get install libcurl4-gnutls-dev libexpat1-dev gettext libz-dev libssl-dev # 安装 git &gt; apt-get install git # 可以通过输出 git 版本来检查是否安装成功 &gt; git --version netstat &gt; sudo apt-get install net-tools vim # 一路 y 就行 &gt; sudo apt-get install vim-gtk reference（参考） Download Ubuntu DesktopVMware虚拟机安装Ubuntu详解VMware虚拟机Ubuntu共享文件夹vmware ubuntu /mnt/hgfs 没有权限查看 找不到共享文件夹如何在 Ubuntu 20.04 上安装 GCC(build-essential)Ubuntu上 git的安装与使用]]></content></entry><entry><title>在 Windows 中安装 VMware 的产品</title><url>/post/computer-science/application/vmware/windows/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>windows</tag><tag>vmware</tag><tag>vmware-workstation</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 VMware Workstation Pro 16
安装 VMware Workstation 下载页面在哪 官网的下载路径：
官网官网 &ndash;&gt; 最上面的导航栏 &ndash;&gt; 点击 &ldquo;Resources&rdquo; &ndash;&gt; 在 &ldquo;Tools &amp; Training&rdquo; 下面 &ndash;&gt; 找到 &ldquo;Product Downloads&rdquo; &ndash;&gt; 点击后进入 下载页面最上面的标签页 -&gt; 选择 &ldquo;ByCategory&rdquo;，不选也行。 然后在下面找到 &ldquo;Desktop &amp; End-User Computing&rdquo;，然后在列表里找到 &ldquo;VMware Workstation Pro&rdquo; 那一行，在那一行最右边点击 &ldquo;Download Product&rdquo; 进入 &ldquo;Download VMware Workstation Pro&rdquo; 的下载页面。 中文官网的下载路径：
中文官网中文官网 &ndash;&gt; 最上面的导航栏 &ndash;&gt; 点击 &ldquo;资源&rdquo; &ndash;&gt; 在 &ldquo;工具和培训&rdquo; 下面 &ndash;&gt; 找到 &ldquo;产品下载&rdquo; &ndash;&gt; 点击后进入 下载页面最上面的标签页 -&gt; 选择 &ldquo;按类别&rdquo;，不选也行。 然后在下面找到 &ldquo;Desktop &amp; End-User Computing&rdquo;，然后在列表里找到 &ldquo;VMware Workstation Pro&rdquo; 那一行，在那一行最右边点击 &ldquo;Download Product&rdquo; 进入 &ldquo;Download VMware Workstation Pro&rdquo; 的下载页面。 下载和安装 在刚才的下载页面，切换 VMware Workstation Pro 的版本，选择 16.0 版本，然后下载 &ldquo;for Windows&rdquo; 的版本。
下载好之后执行安装，一般一路下一步就行。安装完成后，理论上应该购买正版然后激活。但是找个激活码也不是不行，不过建议经济允许的情况下，买一个正版，然后在心安理得的用激活码。
VMware Tools 这玩意应该是自动装好的，不需要手动安装。如果用不了，那再说。
]]></content></entry><entry><title>error</title><url>/post/computer-science/programming-language/golang/error/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag></tags><content type="html"> plan for failure, not success
panic 和 recover 不要用 panic 和 recover 模拟 try 和 catch。
异常和错误是不同的，异常需要处理，意外错误或者致命错误（fatal error）才需要用 panic。
定义错误 尽可能避免 sentinel error（使用特定的值来表示错误）。 尽可能避免 error type（使用结构体来表示错误），虽然它可以提供更多的上下文。 handle errors once You should only handle errors once
错误只应该处理一次，要么记日志，要么报错，只处理一次。
github.com/pkg/errors 用 github.com/pkg/errors 包装 error。
errors.New()：创建一个带堆栈信息的错误 errors.Wrap()：包底层的或者第三方的错误 errors.Cause()：获取错误最底层的原始错误 具有最高重用性的包，只能返回原始错误或者自定义错误，不应该包装错误。
Go 1.13 errors.Is()：可以一层层的 Unwrap() 展开 error 寻找原始错误。 errors.As()：判断一个错误能不能被转换成指定的错误。 fmt.Errorf(&amp;quot;%w&amp;quot;,err)：Errorf 底层会包装 err。</content></entry><entry><title>goroutine</title><url>/post/computer-science/programming-language/golang/goroutine/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag></tags><content type="html">并行和并发 并行：多个程序在多个核心同时跑 并发：多个程序看上去在同时跑 进程 操作系统会为应用程序创建一个进程。进程会包含应用程序运行的资源，如：线程、内存、文件描述符等。
一个进程从主线程开始，当该线程终止时，进程终止。线程可以启动更多的线程。
线程是操作系统调度的一种执行路径，用于在处理器执行我们在函数中编写的代码。
操作系统调度线程在可用处理器上运行，Go 运行时调度 goroutine 在绑定到单个操作系统线程的逻辑处理器（P）中运行。
goroutine 使用 goroutine 的两个注意点：
什么时候结束 有没有强制结束的手段 如果函数启动 goroutine，则必须向调用方提供显式停止该 goroutine 的方法。
并发环境下，要保证只有写的一方可以关闭 chan。
串行化 sync Mutex RWMutex sync/atomic channel happen-before 编译器和 CPU 在不改变 goroutine 的行为前提下，为了更高的性能可能修改读和写的执行顺序。由于存在重排，a=1、b=2 两条语句，在两个 goroutine 中可能会看到不同的执行顺序。
并发不加锁的场景下，i++ 都不一定能得到争取的结果，i++ 最终在执行的时候会变成 3 条汇编指令。并发不加锁时，多个 CPU 核心的 CPU 高速缓存和内存会出现类似缓存不一致的问题。
machine word 对于 single machine word 的变量的读写操作应该是原子的。比如 64 位的机器，把 int 指针从 int a 指向 int b 这个操作应该是原子的。如果是把 20 字节的字符串从 a 赋值给 b，因为一次最多处理 64 位的数据，所以这个赋值操作可能存在中间状态。
数据争用（data race）和竞态条件（race condition） go build -race go test -race 检测到数据争用之后，程序会直接停止。
没有安全的数据争用（safe data race）。程序要么没有数据争用，要么未定义原子性和可见性。
给 slice、map、interface 赋值，不是原子操作。比如 interface 底层是两个指针。
几种锁的实现 barging：持有锁的 goroutine 释放锁后，唤醒等待队列的第一个 goroutine，然后就不管了。锁会被等待队列的第一个 goroutine 或者第一个请求锁的 goroutine 获取。
handsoff：持有锁的 goroutine 释放锁后，会一直持有锁，直到把锁交给等待队列的第一个 goroutine。
spinning（自旋）：获取锁的 goroutine 获取不到锁时，会原地重试几次。
barging 可以提高吞吐量，但是会产生锁饥饿问题。
handsoff 可以解决锁饥饿问题，但是效率不高。
spinning 会占用 CPU 资源。但是相比 goroutine 的 parking 和 unparking，自旋要更快。
Go 1.8 使用了 Barging 和 Spining 的结合实现。当试图获取已经被持有的锁时，如果本地队列为空并且 P 的数量大于1，goroutine 将自旋几次（用一个 P 旋转会阻塞程序）。自旋后，goroutine park。
Go 1.9 通过添加一个新的饥饿模式来解决先前解释的问题，该模式将会在释放时候触发 handsoff。所有等待锁超过一毫秒的 goroutine（也称为有界等待）将被诊断为饥饿。当被标记为饥饿状态时，unlock 方法会 handsoff 把锁直接扔给第一个等待者。在饥饿模式下，自旋也被停用，因为传入的 goroutine 将没有机会获取为下一个等待者保留的锁。
waitgroup errgroup sync.Poll channel（通道） 无缓冲通道：读写必须都准备好，否则阻塞 有缓冲通道：写时，可以缓存一些数据，满则阻塞。读时，空则阻塞。 无缓冲通道或缓冲太小，导致 goroutine 频繁阻塞和唤醒，会消耗性能。但是有缓冲通道用空间换时间也有极限。
向一个已经关闭的通道写数据会 panic。
常用模型：
timing out moving on pipeline fan-out，fan-in cancellation context context 可用于管控 goroutine 生命周期，级联取消可用于快速取消整条链上的 goroutine。
context 是请求级别的，只有和请求有关系的数据才可以挂到上下文中使用。
在需要向 context 添加数据时，应该先深拷贝一份，然后修改数据继续向下传递。因为别的 goroutine 可能在并发访问这个 context 。</content></entry><entry><title>redis benchmark</title><url>/post/computer-science/cache/redis/benchmark/</url><categories><category>redis</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>cache(缓存)</tag><tag>redis</tag></tags><content type="html"><![CDATA[支持的参数 Usage: redis-benchmark [-h &lt;host&gt;] [-p &lt;port&gt;] [-c &lt;clients&gt;] [-n &lt;requests]&gt; [-k &lt;boolean&gt;] -h &lt;hostname&gt; Server hostname (default 127.0.0.1) -p &lt;port&gt; Server port (default 6379) -s &lt;socket&gt; Server socket (overrides host and port) -a &lt;password&gt; Password for Redis Auth -c &lt;clients&gt; Number of parallel connections (default 50) -n &lt;requests&gt; Total number of requests (default 100000) -d &lt;size&gt; Data size of SET/GET value in bytes (default 2) --dbnum &lt;db&gt; SELECT the specified db number (default 0) -k &lt;boolean&gt; 1=keep alive 0=reconnect (default 1) -r &lt;keyspacelen&gt; Use random keys for SET/GET/INCR, random values for SADD Using this option the benchmark will expand the string __rand_int__ inside an argument with a 12 digits number in the specified range from 0 to keyspacelen-1. The substitution changes every time a command is executed. Default tests use this to hit random keys in the specified range. -P &lt;numreq&gt; Pipeline &lt;numreq&gt; requests. Default 1 (no pipeline). -q Quiet. Just show query/sec values --csv Output in CSV format -l Loop. Run the tests forever -t &lt;tests&gt; Only run the comma separated list of tests. The test names are the same as the ones produced as output. -I Idle mode. Just open N idle connections and wait. -h：连接地址 -p：连接端口 -d：执行 SET/GET 的数据量（bytes） -q：每秒能处理的请求数 测试 SET/GET 在不同数据量下的性能 redis-benchmark -h 127.0.0.1 -p 6379 -q -d {bytes} bytes 10 20 50 100 200 1000 5000 10000 15000 PING_INLINE 54436.58 57504.31 58582.31 54229.93 54914.88 60204.70 59523.81 58309.04 57770.08 PING_BULK 58719.91 57670.13 59276.82 55803.57 59594.76 60753.34 60642.81 60975.61 61652.28 SET 59880.24 57570.52 59382.42 56657.22 58997.05 60532.69 58207.21 54824.56 51652.89 GET 59417.71 58513.75 57339.45 55586.44 58105.75 62344.14 61957.87 59952.04 62189.05 INCR 58823.53 59311.98 55555.56 58892.82 57670.13 62539.09 61652.28 61614.29 63051.70 LPUSH 61996.28 59101.65 54975.26 56561.09 58038.30 59488.40 53879.31 54436.58 51124.75 RPUSH 58616.65 59031.88 52938.06 56785.91 56433.41 59701.50 57208.24 53134.96 51599.59 LPOP 59241.71 59844.41 57971.02 57504.31 55803.57 58892.82 61462.82 62421.97 62774.64 RPOP 61881.19 57636.89 57208.24 57971.02 59665.87 59988.00 61804.70 61349.70 62344.14 SADD 61919.50 57339.45 57208.24 56785.91 57971.02 60975.61 62617.41 57570.52 60901.34 HSET 60204.70 60864.27 60204.70 58377.11 58479.53 60096.15 58858.15 51867.22 52056.22 SPOP 58479.53 60168.47 60096.15 58927.52 59559.26 62893.08 60422.96 55679.29 63131.31 LPUSH 59737.16 59241.71 54024.85 58582.31 60277.27 60569.35 54259.36 51894.13 52219.32 LRANGE_100 61274.51 60422.96 54914.88 54884.74 60938.45 58275.06 60060.06 58892.82 59737.16 LRANGE_300 57603.69 57208.24 54259.36 57273.77 60168.47 58072.01 60975.61 58377.11 61957.87 LRANGE_500 58997.05 57537.40 54704.60 59382.42 61804.70 59594.76 60277.27 57175.53 59523.81 LRANGE_600 60132.29 59772.86 56657.22 59171.59 59665.87 59844.41 60716.46 58445.36 60496.07 { &#34;type&#34;: &#34;line&#34;, &#34;data&#34;: { &#34;labels&#34;: [ &#34;10&#34;,&#34;20&#34;,&#34;50&#34;,&#34;100&#34;,&#34;200&#34;,&#34;1000&#34;,&#34;5000&#34;,&#34;10000&#34;,&#34;15000&#34; ], &#34;datasets&#34;: [ { &#34;label&#34;: &#34;PING_INLINE&#34;, &#34;data&#34;: [54436.58,57504.31,58582.31,54229.93,54914.88,60204.70,59523.81,58309.04,57770.08], &#34;borderColor&#34;: &#34;rgba(0,0,255,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;PING_BULK&#34;, &#34;data&#34;: [58719.91,57670.13,59276.82,55803.57,59594.76,60753.34,60642.81,60975.61,61652.28], &#34;borderColor&#34;: &#34;rgba(0,0,255,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;SET&#34;, &#34;data&#34;: [59880.24,57570.52,59382.42,56657.22,58997.05,60532.69,58207.21,54824.56,51652.89], &#34;borderColor&#34;: &#34;rgba(0,255,0,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;GET&#34;, &#34;data&#34;: [59417.71,58513.75,57339.45,55586.44,58105.75,62344.14,61957.87,59952.04,62189.05], &#34;borderColor&#34;: &#34;rgba(0,255,0,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;INCR&#34;, &#34;data&#34;: [58823.53,59311.98,55555.56,58892.82,57670.13,62539.09,61652.28,61614.29,63051.70], &#34;borderColor&#34;: &#34;rgba(0,255,255,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;LPUSH&#34;, &#34;data&#34;: [61996.28,59101.65,54975.26,56561.09,58038.30,59488.40,53879.31,54436.58,51124.75], &#34;borderColor&#34;: &#34;rgba(255,255,0,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;RPUSH&#34;, &#34;data&#34;: [58616.65,59031.88,52938.06,56785.91,56433.41,59701.50,57208.24,53134.96,51599.59], &#34;borderColor&#34;: &#34;rgba(255,255,0,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;LPOP&#34;, &#34;data&#34;: [59241.71,59844.41,57971.02,57504.31,55803.57,58892.82,61462.82,62421.97,62774.64], &#34;borderColor&#34;: &#34;rgba(255,0,0,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;RPOP&#34;, &#34;data&#34;: [61881.19,57636.89,57208.24,57971.02,59665.87,59988.00,61804.70,61349.70,62344.14], &#34;borderColor&#34;: &#34;rgba(255,0,0,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;SADD&#34;, &#34;data&#34;: [61919.50,57339.45,57208.24,56785.91,57971.02,60975.61,62617.41,57570.52,60901.34], &#34;borderColor&#34;: &#34;rgba(160,32,240,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;HSET&#34;, &#34;data&#34;: [60204.70,60864.27,60204.70,58377.11,58479.53,60096.15,58858.15,51867.22,52056.22], &#34;borderColor&#34;: &#34;rgba(255,165,0,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;SPOP&#34;, &#34;data&#34;: [58479.53,60168.47,60096.15,58927.52,59559.26,62893.08,60422.96,55679.29,63131.31], &#34;borderColor&#34;: &#34;rgba(160,32,240,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;LPUSH&#34;, &#34;data&#34;: [59737.16,59241.71,54024.85,58582.31,60277.27,60569.35,54259.36,51894.13,52219.32], &#34;borderColor&#34;: &#34;rgba(255,181,197,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;LRANGE_100&#34;, &#34;data&#34;: [61274.51,60422.96,54914.88,54884.74,60938.45,58275.06,60060.06,58892.82,59737.16], &#34;borderColor&#34;: &#34;rgba(255,181,197,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;LRANGE_300&#34;, &#34;data&#34;: [57603.69,57208.24,54259.36,57273.77,60168.47,58072.01,60975.61,58377.11,61957.87], &#34;borderColor&#34;: &#34;rgba(255,181,197,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;LRANGE_500&#34;, &#34;data&#34;: [58997.05,57537.40,54704.60,59382.42,61804.70,59594.76,60277.27,57175.53,59523.81], &#34;borderColor&#34;: &#34;rgba(255,181,197,1)&#34;, &#34;fill&#34;: false }, { &#34;label&#34;: &#34;LRANGE_600&#34;, &#34;data&#34;: [60132.29,59772.86,56657.22,59171.59,59665.87,59844.41,60716.46,58445.36,60496.07], &#34;borderColor&#34;: &#34;rgba(255,181,197,1)&#34;, &#34;fill&#34;: false } ] } } 从图表上看，从 1KB 开始，SET、HSET、LPUSH、RPUSH 有明显的下降趋势。
测试不同长度 value 占用内存的情况 本地使用 redis-cli 工具连接 redis 客户端，然后使用 info memory 命令，查看内存占用情况。
如果报错：NOAUTH Authentication required.。就先使用 auth 命令，输入密码。
下面的测试，key 始终是 test_str_200000...test_str_400000（15 byte）。
used_memory:763320 used_memory_human:745.43K # 添加 20w 个：max int32 used_memory:15660512 used_memory_human:14.00M used_memory:763472 used_memory_human:745.58K # 添加 20w 个：10 个 a used_memory:18860624 used_memory_human:17.00M used_memory:763624 used_memory_human:745.73K # 添加 20w 个：50 个 a used_memory:26860816 used_memory_human:25.00M used_memory:763776 used_memory_human:745.88K # 添加 20w 个：100 个 a used_memory:38060928 used_memory_human:36.00M used_memory:763928 used_memory_human:746.02K # 添加 20w 个：1000 个 a used_memory:222558232 used_memory_human:212.00M time data len per len ext len 9.3s 4b 74b 56b 9.4s 10b 90b 65b 9.2s 50b 130b 65b 9.0s 100b 186b 71b 9.4s 1000b 1108b 93b $ext len（除去有效数据的大小） = per len（用内存信息计算出来的平均大小） - data len（数据的大小） - key len（key 的大小）$
从图表上看，value 变大时，会额外占用更多的空间。
参考 Redis benchmark]]></content></entry><entry><title>linux 进程的内存布局</title><url>/post/computer-science/operating-system/memory/linux_memory/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>memory(内存)</tag></tags><content type="html"><![CDATA[资料 linux_memory.drawio.html 页式管理 Linux 内存主要采用的是页式内存管理，但是由于 Intel 处理器的发展史，Linux 无法避免分段管理。
因为操作系统必须按照硬件结构设计，所以 Linux 的内核必须服从 CPU 的硬件结构。
虚拟地址空间 linux 进程的虚拟内存会对内存空间进行划分，不同的区域存储不同的数据，有不同的权限。
大概长这样：
内核空间（kernel space） 栈（stack） 动态库的映射 堆（heap） 读写数据区，主要是程序数据，.data、.bss 等 只读数据区，主要是程序指令，.text、.init、.rodata 等 保留区 可执行文件运行的时候，代码和数据会被读取到内存中。 可执行的指令存储在代码区（&quot;.text&quot;）、全局变量和静态变量存储在数据区（&quot;.data&quot;）。
静态分配（statically allocated）的内存在栈区，比如，函数里面的局部变量。 动态分配（dynamically allocated）的内存在堆区，比如，给指针申请一块内存。
在 Linux 中，虚拟地址空间被分为内核空间和用户空间。
32 位系统，内核空间占用 1G，位于最高处，剩下的 3G 是用户空间。 （见图：linux_memory.drawio.html 2-2） 64 位系统，内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。 （见图：linux_memory.drawio.html 2-4） 进程在用户态时，只能访问用户空间内存。只有进入内核态后，才可以访问内核空间的内存。
虽然每个进程都各自有独立的虚拟内存，但是虚拟内存中的内核地址，关联的是相同的物理内存。
这样，进程切换到内核态后，就可以很方便地访问内核空间内存。
用户空间分布 32 位系统的用户空间分布的情况：
程序文件段（.text），包括二进制可执行代码。 已初始化数据段（.data），包括静态常量。 未初始化数据段（.bss），包括未初始化的静态变量。 堆段，包括动态分配的内存，从低地址开始向上增长。 文件映射段，包括动态库、共享内存等，从低地址开始向上增长。 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便自定义大小. （见图：linux_memory.drawio.html 2-6） 在这 6 个内存段中，堆和文件映射段的内存是动态分配的。
比如，使用 C 标准库的 malloc() 或者 mmap()，就可以分别在堆和文件映射段动态分配内存。
malloc malloc() 不是系统调用，而是 C 库里的函数，用于动态分配内存。
malloc 申请内存的时候，会有两种方式向操作系统申请堆内存:
通过 brk() 系统调用从堆分配内存，通过 brk 将堆顶指针向高地址移动，获得新的内存空间。 （见图：linux_memory.drawio.html 4-2） 通过 mmap() 系统调用在文件映射区域分配内存，也就是从文件映射区拿一块内存。 （见图：linux_memory.drawio.html 4-4） malloc 源码默认定义了一个阈值：如果用户分配的内存小于 128 KB，则使用 brk；如果用户分配的内存大于 128 KB，则使用 mmap。
分类内存采用两种方式的原因有两个：1、避免堆内存碎片；2、避免频繁的进行系统调用。
malloc 分配的是虚拟内存。如果分配后的虚拟内存没有被访问的话，是不会将虚拟内存不会映射到物理内存，这样就不会占用物理内存了。
只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断。然后操作系统会建立虚拟内存和物理内存之间的映射关系。
堆内存碎片 假设，先 malloc 2+2+2 K 的内存，然后 free 2+2 K。因为通过 brk 从堆空间分配的内存，并不会归还给操作系统。所以，这时 malloc 内存池就有 4K 的空闲。
如果这个时候 malloc 小于 4K ，就可以直接从内存池分配，如果 malloc 大于 4K，就必须再从堆上申请。
如果程序后来的 malloc 都大于 4K ，那么这个空闲的 4K 就变成了无法使用到的内存碎片。（见图：linux_memory.drawio.html 4-6）
生产环境的程序通常会长时间运行，所以这样的碎片有可能会越积越多，尤其是如果频繁的 malloc 和 free 小块内存。
malloc 在分配内存的时候，并不是按用户预期申请的字节数来分配内存空间大小，而是会预分配更大的空间作为内存池。具体会预分配多大的空间，跟 malloc 使用的内存管理器有关系。
内存池 brk 和 mmap 都是系统调用。执行系统调用是要进入内核态的，然后在回到用户态，运行态的切换会耗费不少时间。 如果都用 mmap 来分配内存，等于每次都要执行系统调用。
另外，因为 mmap 分配的内存每次释放的时候，都会归还给操作系统，于是每次 mmap 分配的虚拟地址都是缺页状态的，然后在第一次访问该虚拟地址的时候，就会触发缺页中断。
频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大。
为了改进这两个问题，malloc 通过 brk 系统调用在堆空间申请内存的时候，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放的时候，就缓存在内存池中。
等下次在申请内存的时候，就直接从内存池取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还存在，这样不仅减少了系统调用的次数，也减少了缺页中断的次数，这将大大降低 CPU 的消耗。
/proc/{pid}/maps 程序运行后可以通过 /proc/{pid}/maps 文件查看进程的内存分布情况。
02dc7000-02de8000 rw-p 00000000 00:00 0 [heap] 02de8000 - 02dc7000 = 21000，也就是在 heap（堆上）分配了 21000 字节。如果 malloc 是通过 mmap 分配的，右边显示 [heap] 的那个位置就啥都没有。
需要注意的是，程序中返回的地址应该是 02dc7010 而不是 02dc7000。前面的 16 字节（0x10）是内存块的头信息。内存块头信息在 《Linux\Unix 系统编程手册》 第 7 章里有提到。
图片：linux-memory.drawio/6-2、内存块头信息 free 如果 malloc 通过 brk 方式申请的内存，free 内存后，堆内存还存在。这是因为内存会被放入 malloc 的内存池里，当进程再次申请内存时就可以直接复用。当进程退出后，操作系统就会回收进程的所有资源。
如果 malloc 通过 mmap 方式申请的内存，free 释放内存后就会立刻归还给操作系统。也就是，如果是通过 brk 方式申请的内存，free 后，依然可以在 /proc/{pid}/maps 文件里看到，因为内存还没有被归还给操作系统。如果是通过 mmap 方式申请的内存，free 后，就看不到了。
free 函数使用的时候只传入一个内存地址，没有传入内存大小。内存大小被存在了这个指针指向的内存块的内存块的头信息里。
reference（参考） Crash Course Computer Science（计算机科学速成课） bilibiliCrashCourse 字幕组Youtube 原视频19、内存&amp;储存介质-Memory &amp; Storage Linux 文档malloc(3) - allocate and free dynamic memoryproc(5) - process information pseudo-filesystem《Linux\Unix 系统编程手册》 第 7 章 ]]></content></entry><entry><title>在 Windows 11 中，安装和配置 Visual Studio Code</title><url>/post/computer-science/application/visual-studio-code/windows/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 Visual Studio Code 1.77.1 正文 Visual Studio Code 在笔记中，会简写为 VSCode。
安装 VSCode 去 VSCode 官网下个安装包，然后装一下就好了。可能需要使用管理员权限运行安装包。
工作区配置 建议 VSCode 按工作区去配置，这样不同项目互不影响。
打开 &ldquo;设置&rdquo; 标签页。下面两种方式都可以。
在最上面的菜单栏，点击 &ldquo;文件&rdquo;，在出现的下拉菜单中，点击 &ldquo;首选项&rdquo;。然后，在出现的菜单中，点击 &ldquo;设置&rdquo;。 使用快捷键 &ldquo;Ctrl+,&quot;。 在设置标签页最上面，默认选中的是用户标签页。往下翻，随便找一个 &ldquo;在 settings.json 中编辑&rdquo; 点一下。
这个时候会打开一个 settings.json 文件，我的这个文件的位置在 C:\Users\kelipute\AppData\Roaming\Code\User\settings.json。它是当前 Windows 用户的配置，也就是说它是全局配置文件。
如果想给当前工作区配置的话。在设置标签页最上面，先切换到工作区标签页。往下翻，随便找一个 &ldquo;在 settings.json 中编辑&rdquo; 点一下。
这个操作会自动在项目根目录的 &ldquo;.vscode/&rdquo; 目录（没有会自动创建）下，创建一个 settings.json 文件。这个 settings.json 文件，就是这个工作区自己的设置文件了。
常用设置 在设置标签页上面的输入框中可以输入设置项的名字进行搜索。
Editor: Font Size。控制字体大小(像素)。
Debug › Console: Font Size。控制调试控制台中的字号(以像素为单位)。
Terminal › Integrated: Font Size。控制终端的字号(以像素为单位)。
Editor: Word Wrap。控制折行的方式。
Editor: Detect Indentation。控制在基于文件内容打开文件时是否自动检测 Editor: Tab Size 和 Editor: Insert Spaces。
Editor: Insert Spaces。按 Tab 时插入空格。当 Editor: Detect Indentation 打开时，将根据文件内容替代此设置。
Editor: Tab Size。一个制表符等于的空格数。当 Editor: Detect Indentation 打开时，将根据文件内容替代此设置。
Editor: Render Whitespace。控制编辑器在空白字符上显示符号的方式。
Editor: Format On Save。在保存时格式化文件。格式化程序必须可用，延迟后文件不能保存，并且编辑器不能关闭。
Editor: Code Actions On Save。要在保存时运行的代码操作种类。点了 &ldquo;在 settings.json 中编辑&rdquo; 会跳到 settings.json 文件并弹出可供选择的设置项列表，设置项都有注释可以看。
Editor › Suggest: Snippets Prevent Quick Suggestions。控制活动代码段是否阻止快速建议。
把设置项从默认值改成自定义值之后，就会在 settings.json 文件里面添加一条对应的参数。
有些设置项可以根据语言进行不同的配置。那种的就不是点 &ldquo;在 settings.json 中编辑&rdquo; 而是 &ldquo;编辑 {语言} 的设置&rdquo;。
安装 VSCode 扩展 打开左侧的 &ldquo;扩展&rdquo; 工具栏。下面三种方式都可以。
在最上面的菜单栏，点击 &ldquo;文件&rdquo;，在弹出的菜单中，点击 &ldquo;首选项&rdquo;，在弹出的菜单中，点击 &ldquo;扩展&rdquo;。 在最左边的一列按钮里，找到并点击 &ldquo;扩展&rdquo;。 使用快捷键 &ldquo;Ctrl+Shift+X&rdquo;。 搜索并安装扩展。可以直接在列表里找组件，也可以在扩展工具栏最上面的输入框输入组件的名字进行搜索。
调出命令面板 下面两种方式都可以。
在最上面的菜单栏，点击 &ldquo;查看&rdquo;，在弹出的菜单中，点击 &ldquo;命令面板&rdquo; 使用快捷键 &ldquo;Ctrl+Shift+P&rdquo;。 配置 Code Runner 组件 历史笔记，最新的配置过程，这个步骤可以跳过。
在最上面的菜单栏，点击 &ldquo;文件&rdquo;，在出现的下拉菜单中，点击 &ldquo;首选项&rdquo;。然后，在出现的菜单中，点击 &ldquo;扩展&rdquo;，打开 &ldquo;设置&rdquo; 标签页。在设置标签页最上面的输入框中，输入 &ldquo;@ext:formulahendry.code-runner&rdquo;。
也可以先打开扩展工具栏。在扩展工具栏中，选择 Code Runner。在弹出的 C/C++ 组件的标签页，点击的标题下面的设置图标，在弹出的下拉菜单中，选择扩展设置，打开设置标签页。
这两个方式都可以找到 Code Runner 的设置。找到之后，勾选 Code-runner: Ignore Selection 和 Code-runner: Run In Terminal 这两项。
]]></content></entry><entry><title>在 Visual Studio Code 中，配置 C 语言开发环境</title><url>/post/computer-science/application/visual-studio-code/c/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>ccpp</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 x86_64-pc-cygwin gcc 版本 11.2.0 (GCC) Visual Studio Code 1.77.1 公共的操作放在这篇里面：在 Windows 11 中，安装和配置 Visual Studio Code正文 安装 C/C++ 编译器 先把 C 语言开发环境装好：在 Windows 11 中，配置 C 语言开发环境安装 VSCode 扩展 （可选）安装 Chinese (Simplified) (简体中文) Language Pack for Visual Studio Code 组件（简体中文语言包）。 安装 C/C++ 组件。 安装 Code Runner 组件。 （可选）安装 CMake 组件。 （可选）安装 CMake Tools 组件。 （可选）安装 Clang-Format 组件（代码格式化）。 （可选）安装 Git Graph 组件（查看 Git 树，执行 Git 操作）。 （可选）安装 Git History 组件（查看 Git 历史）。 （可选）安装 GitLens 组件（查看代码作者）。 （可选）安装 Markdown All in One 组件。 配置 C/C++ 组件 调出命令面板。在命令面板的输入框中，输入 &ldquo;C/C++&quot;。然后，在下面的列表中，找到并点击 &ldquo;C/C++: 编辑配置(UI)&quot;（没安装简体中文语言包的话，应该是 &ldquo;C/C++: Edit Configurations(UI)&quot;），进入 &ldquo;IntelliSense 配置&rdquo; 标签页。
配置 &ldquo;编译器路径&rdquo;，我这里是 &ldquo;C:\cygwin64\bin\gcc.exe&rdquo;。配置 &ldquo;IntelliSense 模式&rdquo;，我这里选的是 &ldquo;windows-gcc-x64&rdquo;。
配置完成后，会自动在项目根目录的 &ldquo;.vscode/&rdquo; 目录（没有会自动创建）下，创建一个 c_cpp_properties.json 文件，文件的内容如下。这文件一般不需要改。
{ &#34;configurations&#34;: [ { &#34;name&#34;: &#34;Win32&#34;, &#34;includePath&#34;: [ &#34;${workspaceFolder}/**&#34; ], &#34;defines&#34;: [ &#34;_DEBUG&#34;, &#34;UNICODE&#34;, &#34;_UNICODE&#34; ], &#34;compilerPath&#34;: &#34;C:\\cygwin64\\bin\\gcc.exe&#34;, &#34;cStandard&#34;: &#34;c17&#34;, &#34;cppStandard&#34;: &#34;gnu++17&#34;, &#34;intelliSenseMode&#34;: &#34;windows-gcc-x64&#34;, &#34;configurationProvider&#34;: &#34;ms-vscode.cmake-tools&#34; } ], &#34;version&#34;: 4 } 配置 C/C++ 任务文件 先编辑一个 C 源码文件。比如，我在根目录下，写了一个 hello_world.c。然后，在这个文件的编辑页面里。注意，这里一定要在 C 源码文件的编辑页面里。要不然下面的操作，一些选项出不来。
在命令面板的输入框中，输入 &ldquo;Tasks&rdquo;。然后，在下面的列表中，找到并点击 &ldquo;任务: 配置默认生成任务&rdquo;（没安装简体中文语言包的话，应该是 &ldquo;Tasks: Configure Default Build Task&rdquo;）。
然后，在下面的列表中，找到并点击 &ldquo;C/C++: gcc.exe 生成活动文件&rdquo;（没安装简体中文语言包的话，应该是 &ldquo;C/C++ gcc.exe build active file&rdquo;）。
或者，在最上面的菜单栏，点击 &ldquo;终端&rdquo;，在弹出的菜单中，点击 &ldquo;配置任务&rdquo;。然后，在弹出的列表中，找到并点击 &ldquo;C/C++: gcc.exe 生成活动文件&rdquo;。
这两个操作的效果是一样的。会自动在项目根目录的 &ldquo;.vscode/&rdquo; 目录（没有会自动创建）下，创建一个 tasks.json 文件，文件的内容如下。鼠标移动到键名上会显示备注。
{ &#34;version&#34;: &#34;2.0.0&#34;, &#34;tasks&#34;: [ { &#34;type&#34;: &#34;cppbuild&#34;, &#34;label&#34;: &#34;C/C++: gcc.exe 生成活动文件&#34;, &#34;command&#34;: &#34;C:\\cygwin64\\bin\\gcc.exe&#34;, &#34;args&#34;: [ &#34;-fdiagnostics-color=always&#34;, &#34;-g&#34;, &#34;${file}&#34;, &#34;-o&#34;, &#34;${fileDirname}\\${fileBasenameNoExtension}.exe&#34; ], &#34;options&#34;: { &#34;cwd&#34;: &#34;${fileDirname}&#34; }, &#34;problemMatcher&#34;: [ &#34;$gcc&#34; ], &#34;group&#34;: &#34;build&#34;, &#34;detail&#34;: &#34;编译器: C:\\cygwin64\\bin\\gcc.exe&#34; } ] } label，任务名称。可以改的，launch.json 里面要用。 command，执行编译的编译器或脚本的路径。改成 gcc 编译器的路径。 args，其他要传递给编译器或编译脚本的参数。就是传给 gcc 命令的参数。 在最上面的菜单栏，点击 &ldquo;终端&rdquo;，在弹出的菜单中，点击 &ldquo;运行任务&rdquo;。然后，在弹出的列表中，找到并点击 &ldquo;C/C++ gcc.exe build active file&rdquo;。
然后，就会执行 tasks.json 里面的内容。并在 hello_world.c 文件所在的目录下，生成一个 hello_world.exe 可执行文件。在最下面的 &ldquo;终端&rdquo; 子窗口里面，会输出以下内容。
正在执行任务: C/C++: gcc.exe 生成活动文件 正在启动生成... C:\cygwin64\bin\gcc.exe -fdiagnostics-color=always -g D:\workspace\demo-c\hello_world.c -o D:\workspace\demo-c\hello_world.exe 生成已成功完成。 * 终端将被任务重用，按任意键关闭。 这里执行的命令，就对应上面 tasks.json 里面的内容。
${file} 表示当前选中的文件名。对应 &ldquo;D:\workspace\demo-c\hello_world.c&rdquo;。 ${fileDirname} 表示当前选中的文件所在的目录。对应 &ldquo;D:\workspace\demo-c&rdquo;。 ${fileBasenameNoExtension} 表示当前选中的文件去掉文件后缀。对应 &ldquo;hello_world&rdquo;。 其他的也可以对应上，这里就不多说了。 然后，在最下面的 &ldquo;终端&rdquo; 子窗口里面，使用 .\hello_world 命令（Windows 里面是右斜线），就可以在运行刚才生成的 hello_world.exe 可执行文件。
断点调试 找一个源码文件，打上断点。
在最上面的菜单栏，点击 &ldquo;运行&rdquo;，在弹出的菜单中，点击 &ldquo;添加配置&rdquo;。然后，在弹出的列表中，找到并点击 &ldquo;C++ GDB/LLDB&rdquo;。
这个操作会自动在项目根目录的 &ldquo;.vscode/&rdquo; 目录（没有会自动创建）下，创建一个 launch.json 文件，文件的内容如下。
{ // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 &#34;version&#34;: &#34;0.2.0&#34;, &#34;configurations&#34;: [] } 然后，在最上面的菜单栏，点击 &ldquo;运行&rdquo;，在弹出的菜单中，点击 &ldquo;添加配置&rdquo;。然后，在弹出的列表中，找到并点击 &ldquo;C/C++: (gdb) 启动&rdquo;。
这个操作会自动在 launch.json 文件里添加配置代码。鼠标移动到键名上会显示备注。
{ // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 &#34;version&#34;: &#34;0.2.0&#34;, &#34;configurations&#34;: [ { &#34;name&#34;: &#34;(gdb) 启动&#34;, &#34;type&#34;: &#34;cppdbg&#34;, &#34;request&#34;: &#34;launch&#34;, &#34;program&#34;: &#34;输入程序名称，例如 ${workspaceFolder}/a.exe&#34;, &#34;args&#34;: [], &#34;stopAtEntry&#34;: false, &#34;cwd&#34;: &#34;${fileDirname}&#34;, &#34;environment&#34;: [], &#34;externalConsole&#34;: false, &#34;MIMode&#34;: &#34;gdb&#34;, &#34;miDebuggerPath&#34;: &#34;/path/to/gdb&#34;, &#34;setupCommands&#34;: [ { &#34;description&#34;: &#34;为 gdb 启用整齐打印&#34;, &#34;text&#34;: &#34;-enable-pretty-printing&#34;, &#34;ignoreFailures&#34;: true }, { &#34;description&#34;: &#34;将反汇编风格设置为 Intel&#34;, &#34;text&#34;: &#34;-gdb-set disassembly-flavor intel&#34;, &#34;ignoreFailures&#34;: true } ] } ] } 需要根据自己的配置，对配置代码做一些修改。
{ &#34;configurations&#34;: [ { &#34;name&#34;: &#34;C/C++: gcc.exe 调试活动文件&#34;, &#34;type&#34;: &#34;cppdbg&#34;, &#34;request&#34;: &#34;launch&#34;, &#34;program&#34;: &#34;${fileDirname}\\${fileBasenameNoExtension}.exe&#34;, &#34;args&#34;: [], &#34;stopAtEntry&#34;: false, &#34;cwd&#34;: &#34;${fileDirname}&#34;, &#34;environment&#34;: [], &#34;externalConsole&#34;: true, &#34;MIMode&#34;: &#34;gdb&#34;, &#34;miDebuggerPath&#34;: &#34;C:\\cygwin64\\bin\\gdb.exe&#34;, &#34;setupCommands&#34;: [ { &#34;description&#34;: &#34;为 gdb 启用整齐打印&#34;, &#34;text&#34;: &#34;-enable-pretty-printing&#34;, &#34;ignoreFailures&#34;: true }, { &#34;description&#34;: &#34;将反汇编风格设置为 Intel&#34;, &#34;text&#34;: &#34;-gdb-set disassembly-flavor intel&#34;, &#34;ignoreFailures&#34;: true } ], &#34;preLaunchTask&#34;: &#34;C/C++: gcc.exe 生成活动文件&#34; } ] } name，配置名称。可以改的。 program，程序可执行文件的完整路径。这里改成和 tasks.json 里的 args 一样。 miDebuggerPath，MI 调试程序(如 gdb)的路径。改成 gdb 的路径。 添加 preLaunchTask 配置，调试会话开始前要运行的任务。改成 tasks.json 里对应任务的 label。 多文件编译 上面配置的 tasks.json 只能编译单个文件。想编译多个文件可以通过修改 tasks.json 的 args 实现。直接把要编译的文件写进去，就和手写 gcc 命令差不多。
&#34;args&#34;: [ &#34;-g&#34;, &#34;${fileDirname}\\hello1.c&#34;, &#34;${fileDirname}\\hello2.c&#34;, &#34;-o&#34;, &#34;${fileDirname}\\hello.exe&#34; ], 直接写 makefile。 用 CMake 工具。VSCode 的扩展里有 CMake 插件和 CMake Tools 插件。 代码格式化 LLVM 先安装 LLVM。去 官网页面左边 Download 那里，点击 &ldquo;All Releases&rdquo;，进入 [发布页面] (https://releases.llvm.org/)。
发布页面往下滑，就直接点最新的版本后面的 download 链接，这里是 16.0.0 版本的 链接。它会跳到 github 的发布页面。找对应的版本就好了，我这里是 LLVM-16.0.0-win64.exe。
安装结束后，需要配置环境变量。这里和安装 GCC 的时候一样，就不重复了。
在环境变量窗口下面的 &ldquo;系统变量&rdquo; 里找到 path，然后点击 &ldquo;编辑，打开 &ldquo;编辑环境变量&rdquo; 窗口&rdquo;。 添加 &ldquo;LLVM 的安装目录下的 bin 目录的路径&rdquo;。我这里，这个目录是 &ldquo;C:\Program Files\LLVM\bin&rdquo;。 配置 VSCode 打开设置标签页。设置 Editor: Default Formatter 为 Clang-Format。
然后在扩展工具栏中，选择 Clang-Format。在弹出的 Clang-Format 组件的描述标签页，会介绍怎么配置，主要是下面这个部分。
Specifying the location of clang-format This extension will attempt to find clang-format on your PATH. Alternatively, the clang-format executable can be specified in your vscode settings.json file:
{ &#34;clang-format.executable&#34;: &#34;/absolute/path/to/clang-format&#34; } 我这里就是在 settings.json 里，把这个配置改成 &ldquo;C:\Program Files\LLVM\bin\clang-format.exe。
打开 C/C++ 组件的设置标签页。下面这两个方式都可以。
在扩展工具栏中，选择 C/C++。在弹出的 C/C++ 组件的描述标签页，点击的标题下面的设置图标，在弹出的下拉菜单中，选择扩展设置。 在设置标签页上面的输入框中，输入 &ldquo;@ext:ms-vscode.cpptools&rdquo;。 在 C/C++ 组件的设置标签页中。
检查一下 C_Cpp: Formatting 设置项是不是 default 或者 clangFormat，这个是默认配置一般不会变。 检查一下 C_Cpp: Clang_format_style 设置项是不是 file，设置为 file 表示格式化的时候会先寻找 Clang-Format 组件的格式化配置文件。 最后，我的 settings.json 是下面这样的。
{ &#34;editor.formatOnSave&#34;: true, &#34;editor.defaultFormatter&#34;: &#34;xaver.clang-format&#34;, &#34;clang-format.executable&#34;: &#34;C:\\Program Files\\LLVM\\bin\\clang-format.exe&#34; } 接着在项目根目录新建一个 &ldquo;.clang-format&rdquo; 文件，这个文件就是上面说的格式化配置文件。详细的配置方式可以去 Clang-Format 的文档里去看，Clang-Format 组件的描述标签页就可以找到链接。
#每行字符的限制，0表示没有限制 ColumnLimit: 0 #缩进宽度 IndentWidth: 2 #连续空行的最大数量 MaxEmptyLinesToKeep: 1 #缩进case标签 IndentCaseLabels: true 配置完成就可以格式化代码了，默认快捷键是 &ldquo;Shift+Alt+F&rdquo;。也可以在需要格式化的文件的编辑窗口里，点击鼠标右键，在弹出的菜单里，选择 &ldquo;格式化文档&rdquo;。
使用 Code Runner 运行代码 安装 Code Runner 组件后，右上角的 &ldquo;运行按钮&rdquo; 那里，会多一个 Run Code 的选项。
选中 hello_world.c 文件，然后，点击右上角的运行按钮，选择 Run Code 选项。这个操作，会在下面的 &ldquo;终端&rdquo; 子窗口里面，输出以下内容，相当于编译了 hello_world.c 文件，然后执行了生成的 hello_world.exe 可执行文件。
[Running] cd &#34;d:\workspace\demo-c\&#34; &amp;&amp; gcc hello_world.c -o hello_world &amp;&amp; &#34;d:\workspace\demo-c\&#34;hello_world hello, world 参考 Vscode配置C/C++环境vscode调试c++断点失效解决方法]]></content></entry><entry><title>在 Windows 11 中，配置 C 语言开发环境</title><url>/post/computer-science/programming-language/c/windows/</url><categories><category>ccpp</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>ccpp</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 x86_64-pc-cygwin gcc 版本 11.2.0 (GCC) 正文 下载安装包 访问 MinGW 的主页。在页面左侧的导航中，找到 Downloads。点击 Downloads，进入下载页，可以看见很多开发包。
我以前用的是 MingW-W64-builds，一般在 SourceForge 上下载（下载页面）。但是，新版的玩不明白，就放弃了。
所以，这里推荐 Cygwin。下载页有 Cygwin 主页的 链接。在页面左侧的导航中，找到 Cygwin 下面的 Install Cygwin。点击 Install Cygwin，进入下载页，下载 64 位 windows 版本的安装包（setup-x86_64.exe）。
安装 cygwin 我这里是 Windows 11 家庭版。建议使用管理员权限运行安装包 setup-x86_64.exe。
运行 setup-x86_64.exe，下一步。 Choose A Download Source 界面，选 Install from Internet，下一步。 Select Root Install Directory 界面，设置安装目录，选 All Users，下一步。 Select Root Package Directory 界面，设置文件下载目录，下一步。 Select Your Internet Connection 界面，选 Use System Proxy Settings，下一步。然后，会有一个界面让你选下载源镜像，我这里选的华为的（&ldquo;https://mirrors.huaweicloud.com/cygwin/"）。 Progress 界面，等待下载完成，下一步。 Select Packages 界面，在 Search 输入框里，分别搜索 gcc-core、gcc-g++、make、gdb、binutils。然后，在下拉列表选择版本。本人选的各自列表的倒数第 1 个非测试版本。下一步。 然后，等待安装结束。 安装结束后，需要配置环境变量。
在 Windows 桌面，鼠标右击 &ldquo;我的电脑&rdquo;，在弹出的菜单中，点击 &ldquo;属性&rdquo;，打开 &ldquo;设置&rdquo; 窗口。 在设置窗口中，找到并点击 &ldquo;高级系统设置&rdquo;，打开 &ldquo;系统属性&rdquo; 窗口。 在系统属性窗口中，切换到 &ldquo;高级&rdquo; 标签页，然后点击标签页最下面的 &ldquo;环境变量&rdquo;，打开 &ldquo;环境变量&rdquo; 窗口。 在环境变量窗口下面的 &ldquo;系统变量&rdquo; 里找到 path，然后点击 &ldquo;编辑，打开 &ldquo;编辑环境变量&rdquo; 窗口&rdquo;。 添加 &ldquo;cygwin 的安装目录下的 bin 目录的路径&rdquo;。我这里，这个目录是 &ldquo;C:\cygwin64\bin&rdquo;。 配置完环境变量之后，可能需要重启一下 Windows。
验证能不能用 打开命令行窗口，CMD 或者 PowerShell 都可以。分别检查 gcc 和 gdb 命令是否可用。输出一下版本信息即可。
&gt; gcc -v Using built-in specs. COLLECT_GCC=gcc COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-pc-cygwin/10/lto-wrapper.exe Target: x86_64-pc-cygwin Configured with: /mnt/share/cygpkgs/gcc/gcc.x86_64/src/gcc-10.2.0/configure --srcdir=/mnt/share/cygpkgs/gcc/gcc.x86_64/src/gcc-10.2.0 --prefix=/usr --exec-prefix=/usr --localstatedir=/var --sysconfdir=/etc --docdir=/usr/share/doc/gcc --htmldir=/usr/share/doc/gcc/html -C --build=x86_64-pc-cygwin --host=x86_64-pc-cygwin --target=x86_64-pc-cygwin --without-libiconv-prefix --without-libintl-prefix --libexecdir=/usr/lib --with-gcc-major-version-only --enable-shared --enable-shared-libgcc --enable-static --enable-version-specific-runtime-libs --enable-bootstrap --enable-__cxa_atexit --with-dwarf2 --with-tune=generic --enable-languages=c,c++,fortran,lto,objc,obj-c++ --enable-graphite --enable-threads=posix --enable-libatomic --enable-libgomp --enable-libquadmath --enable-libquadmath-support --disable-libssp --enable-libada --disable-symvers --with-gnu-ld --with-gnu-as --with-cloog-include=/usr/include/cloog-isl --without-libiconv-prefix --without-libintl-prefix --with-system-zlib --enable-linker-build-id --with-default-libstdcxx-abi=gcc4-compatible --enable-libstdcxx-filesystem-ts Thread model: posix Supported LTO compression algorithms: zlib zstd gcc version 10.2.0 (GCC) &gt; gdb -v GNU gdb (GDB) (Cygwin 10.2-1) 10.2 Copyright (C) 2021 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. ]]></content></entry><entry><title>TCP</title><url>/post/computer-science/protocol/tcp/tcp/</url><categories><category>protocol(协议)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>protocol(协议)</tag><tag>tcp</tag></tags><content type="html">TCP TCP（Transmission Control Protocol、传输控制协议）由 IETF（The Internet Engineering Task Force、国际互联网工程任务组） 的 RFC 793 定义。
https://www.rfc-editor.org/rfc/rfc793
https://datatracker.ietf.org/doc/html/rfc793
TCP 是一种面向连接的、可靠的、基于字节流的传输层通信协议，为连接到计算机通信网络的计算机中的成对进程之间提供可靠的通信服务。适用于需要建立连接，保证数据交付的场景，如：HTTP、FTP 等。
字节流形式的数据像水流一样，没有边界，但是有顺序。如果前面的字节没收到，那么后面的字节一定也没收到。
TCP 负责保障数据的可靠性。因为 IP 不能保证数据交付、不能保证数据按序交付、不能保证数据完整性，是不可靠的。
Header Format（头部格式） 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Source Port | Destination Port | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Acknowledgment Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data | |U|A|P|R|S|F| | | Offset| Reserved |R|C|S|S|Y|I| Window | | | |G|K|H|T|N|N| | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Checksum | Urgent Pointer | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Options | Padding | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | data | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Source Port：源端口号，16 bit Destination Port：目标端口号，16 bit Sequence Number：序列号，32 bit Acknowledgment Number：确认应答号，32 bit Data Offset：首部长度，4 bit Reserved：保留位，6 bit URG、ACK、PSH、RST、SYN、FIN：控制位，1*6 bit Window：窗口大小，16 bit Checksum ：校验和，16 bit Urgent Pointer：紧急指针，16 bit Options、Padding：选项和填充，长度可变 data：数据，长度可变 为了网络设备硬件设计和处理方便，首部长度需要是 4 字节的整数倍。
序列号 在建立连接时，会生成一个随机数作为序列号的初始值，通过 SYN 报文传给对端。后续每发送一次数据，就累加一次该数据字节数的数值，以此解决数据包乱序的问题.
一方面，序列号可以判断报文的时效性，防止旧连接的历史报文被新连接接收了。另一方面，因为序列号是随机生成的，不容易伪造，可以一定程度上保证安全性。
初始序列号 ISN 的随机产生算法
一开始的 ISN ⽣成算法是基于时钟的，每 4 毫秒 + 1，转一圈 4.55 个小时。RFC 1948 中提出了⼀个更好的 ISN 随机⽣成算法。
$ISN = M + F (localhost, localport, remotehost, remoteport)$
M 是⼀个计时器，这个计时器每隔 4 毫秒 +1。 F 是⼀个 Hash 算法，根据源 IP、源端口、目标 IP、目标端口生成⼀个随机数值。 两个不同的报文的序列号是有可能一样的。因为 seq 的计算方式是 $seq = seq + 数据长度$。 比如，第三次握手，发送端如果没有携带数据，这个时候的 seq num 就和第一次握手的 seq num 是一样的。
确认应答号 确认应答号用于解决数据包丢包的问题。
确认应答号是下一次期望收到的数据包的序列号。发送端收到确认应答号后可以认为，在这个序列号以前的数据都已被接收端正常接收。如果下一个期望收到的数据包没有收到，那么确认应答号就不会发生变化。
确认应答号存在累积确认机制。当接收端收到多个数据包时，只需要应答最后一个包的 ACK 报文就可以了。当接收端收到比期望序列号大的报文时，会重复应答最近一次的应答报文的确认应答号。
控制位 ACK：ACK 为 1 时，确认应答号字段变为有效。 TCP 规定，除了最初建立连接时的 SYN 包之外，该值必须为 1。 RST：RST 为 1 时，表示 TCP 连接出现异常，必须强制断开连接。 SYN（Synchronize Sequence Numbers、同步序列号）：SYN 为 1 时，表示希望建立连接，同时序列号字段会设置初始值。 FIN：FIN 为 1 时，表示希望断开连接。 数据长度 $TCP 数据长度 = IP 数据包总长度 - IP 头部长度 - TCP 头部长度$
报文的数据段过大时，按 MSS（TCP 最大报文长度）分成 TCP Segment（TCP 块）。MSS 的值，在建立连接时，由双方协商得出。
让 TCP 处理分块，避免 IP 层分片，可以提高传输性能。IP 没有超时重传机制，超时重传机制由 TCP 负责。如果让 IP 来分片，那么其中任意一个 IP 分片有问题，都要重传整个 IP 报文。TCP 分块后，当中间某个分块有问题时，只需要重传这个分块。
参考 https://www.rfc-editor.org/rfc/rfc793
小林coding
图解网络</content></entry><entry><title>UDP</title><url>/post/computer-science/protocol/udp/udp/</url><categories><category>protocol(协议)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>protocol(协议)</tag><tag>udp</tag></tags><content type="html">UDP UDP（User Datagram Protocol，用户数据报协议）由 IETF（The Internet Engineering Task Force、国际互联网工程任务组） 的 RFC 768 定义。
https://www.rfc-editor.org/rfc/rfc768
https://datatracker.ietf.org/doc/html/rfc768
UDP 是一种无连接的传输层协议。提供面向事务的简单不可靠信息传送服务。
UDP 协议不保证数据包的可靠性。基于 UDP 协议的网络通信的可靠性由应用层实现。 UDP 协议的数据包没有顺序，不重传，不进行流量控制，无法得知是否完整到达。 UDP 适用于不需要连接、可随时发送数据或者数据量巨大的场景：如：DNS、TFTP、视频、音频等多媒体通信、广播通信等。
UDP 报文格式 0 7 8 15 16 23 24 31 +--------+--------+--------+--------+ | Source | Destination | | Port | Port | +--------+--------+--------+--------+ | | | | Length | Checksum | +--------+--------+--------+--------+ | | data octets ... +---------------- ... Source Port：源端口号，16 bit Destination Port：目标端口号，16 bit Length：包长度，16 bit。保存了 UDP 首部的长度跟数据的长度之和。 Checksum：校验和，16 bit。是为了提供可靠的 UDP 首部和数据而设计。</content></entry><entry><title>使用 Jekyll 主题</title><url>/post/computer-science/application/jekyll/theme/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>Ruby</tag><tag>Jekyll</tag><tag>GitHub-Pages</tag></tags><content type="html">环境 CPU AMD64(x86_64) Windows 11 家庭版 Ruby 3.1.2 RubyGems 3.3.7 Jekyll 4.2.2
jekyll-TeXt-theme Github：
https://github.com/kitian616/jekyll-TeXt-theme
官方文档：
https://tianqi.name/jekyll-TeXt-theme/
第 1 步，从 Github 上把项目下载下来。
第 2 步，安装 Ruby 依赖包。
&amp;gt; bundle install --path vendor/bundle [DEPRECATED] The `--path` flag is deprecated because it relies on being remembered across bundler invocations, which bundler will no longer do in future versions. Instead please use `bundle config set --local path &amp;#39;vendor/bundle&amp;#39;`, and stop using this flag 一大堆输出。。。 Using jekyll-text-theme 2.2.6 from source at `.` Bundle complete! 3 Gemfile dependencies, 41 gems now installed. Bundled gems are installed into `./vendor/bundle` Post-install message from html-pipeline: ------------------------------------------------- Thank you for installing html-pipeline! You must bundle Filter gem dependencies. See html-pipeline README.md for more details. https://github.com/jch/html-pipeline#dependencies ------------------------------------------------- 安装完成后，可以使用 Jekyll 集成的那个开发用的服务器，然后使用浏览器在本地进行预览。
这里同样会遇到 webrick 无法加载的那个异常情况，解决方法是一样的。
jekyll-theme-chirpy Github：
https://github.com/cotes2020/jekyll-theme-chirpy
官方文档（同时也是个 Demo）：
https://chirpy.cotes.page/
个人感觉，这个主题比上面那个正在用的要好看不少。
但是无奈，按照官方文档走流程的时候，在发布流程的 Github Action 步骤卡住了。而且没有找到解决方案，遂遗憾放弃。</content></entry><entry><title>使用 Jekyll 和 GitHub Pages 搭建站点</title><url>/post/computer-science/application/jekyll/install_publish/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>Ruby</tag><tag>Jekyll</tag><tag>GitHub-Pages</tag></tags><content type="html"><![CDATA[环境 CPU AMD64(x86_64) Windows 11 家庭版 Ruby 3.1.2 RubyGems 3.3.7 Jekyll 4.2.2
安装 Jekyll 在官方文档中有详细的安装 Jekyll 的流程说明。
Jekyll 官方文档的中文版：http://jekyllcn.com/。
第 1 步，安装 Ruby。
Ruby 官方网站的中文版：http://www.ruby-lang.org/zh_cn/。
进入 Ruby 下载页面：http://www.ruby-lang.org/zh_cn/downloads/下载页面的文档指出，Windows 可以用 RubyInstaller：https://rubyinstaller.org/。
安装 Ruby 的方法
每个流行的平台都有多种工具可用于安装 Ruby：
Linux/UNIX 平台，可以使用第三方工具（如 rbenv 或 RVM）或使用系统中的包管理系统。 macOS 平台，可以使用第三方工具（如 rbenv 或 RVM）。 Windows 平台，可以使用 RubyInstaller。 进入 RubyInstaller 下载页面，页面右侧的说明会告诉你该下哪一个版本的。
Which version to download?
If you don’t know what version to install and you’re getting started with Ruby, we recommend that you use the Ruby+Devkit 3.1.X (x64) installer.
下载 Ruby+Devkit 3.1.2-1 (x64) 完成后，双击运行，启动 Ruby 安装向导，然后一路 next 即可。
记得勾选 Add Ruby executables to your PATH，把 Ruby 的运行目录添加到 Windows 的环境变量 PATH 里，要不然在命令行窗口（CMD）里不能直接用命令。
安装过程中，安装向导可能会卡住，等一会就行。RubyInstaller 会把 Ruby 和 RubyGems 一起装了。RubyGems 是一个 Ruby 程序，用来管理 Ruby 包的。
安装完成后，可以在命令行里使用命令输出一下版本信息，看看安装是否成功。
&gt; ruby -v ruby 3.1.2p20 (2022-04-12 revision 4491bb740a) [x64-mingw-ucrt] &gt; gem -v 3.3.7 第 2 步，安装 Jekyll。
使用 RubyGems 安装 Jekyll。
&gt; gem install jekyll 一大堆输出。。。 Done installing documentation for unicode-display_width, terminal-table, safe_yaml, rouge, forwardable-extended, pathutil, mercenary, liquid, kramdown, kramdown-parser-gfm, ffi, rb-inotify, rb-fsevent, listen, jekyll-watch, sassc, jekyll-sass-converter, concurrent-ruby, i18n, http_parser.rb, eventmachine, em-websocket, colorator, public_suffix, addressable, jekyll after 24 seconds 26 gems installed 安装过程需要几分钟，等它装完即可。如果长时间没有反应，可以在命令行按一下回车，不排除可能是 Windows 命令行卡住了没输出信息。
安装完成后，可以在命令行里使用命令输出一下版本信息，看看安装是否成功。
&gt; jekyll -v jekyll 4.2.2 生成模板 使用 jekyll 生成模板。
这里是在 D 盘的 workspace/github.io 目录里生成模板。
&gt; jekyll new github.io Running bundle install in D:/workspace/github.io... 一大堆输出。。。 New jekyll site installed in D:/workspace/github.io. Bundler 可以认为是一个针对项目的包管理程序。它通过项目目录下的 Gemfile 文件来管理项目依赖。Bundler 在安装依赖时，会使用 RubyGems。
开发服务器 Jekyll 集成了一个开发用的服务器，可以使用浏览器在本地进行预览。
&gt; jekyll serve Configuration file: D:/workspace/github.io/_config.yml Source: D:/workspace/github.io Destination: D:/workspace/github.io/_site Incremental build: disabled. Enable with --incremental Generating... Jekyll Feed: Generating feed for posts done in 0.808 seconds. Please add the following to your Gemfile to avoid polling for changes: gem &#39;wdm&#39;, &#39;&gt;= 0.1.0&#39; if Gem.win_platform? Auto-regeneration: enabled for &#39;D:/workspace/github.io&#39; Server address: http://127.0.0.1:4000/ Server running... press ctrl-c to stop. 正常情况应该是输出上面的内容，然后就用浏览器访问 http://localhost:4000/ 查看博客了。
异常情况 &gt; jekyll serve Configuration file: D:/workspace/github.io/_config.yml Source: D:/workspace/github.io Destination: D:/workspace/github.io/_site Incremental build: disabled. Enable with --incremental Generating... Jekyll Feed: Generating feed for posts done in 0.827 seconds. Please add the following to your Gemfile to avoid polling for changes: gem &#39;wdm&#39;, &#39;&gt;= 0.1.0&#39; if Gem.win_platform? Auto-regeneration: enabled for &#39;D:/workspace/github.io&#39; ------------------------------------------------ Jekyll 4.2.2 Please append `--trace` to the `serve` command for any additional information or backtrace. ------------------------------------------------ C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve/servlet.rb:3:in `require&#39;: cannot load such file -- webrick (LoadError) from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve/servlet.rb:3:in `&lt;top (required)&gt;&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:179:in `require_relative&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:179:in `setup&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb💯in `process&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `block in process_with_graceful_fail&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `each&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `process_with_graceful_fail&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:86:in `block (2 levels) in init_with_program&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `block in execute&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `each&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `execute&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/program.rb:44:in `go&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary.rb:21:in `program&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/exe/jekyll:15:in `&lt;top (required)&gt;&#39; from C:/Ruby31-x64/bin/jekyll:32:in `load&#39; from C:/Ruby31-x64/bin/jekyll:32:in `&lt;main&gt;&#39; 输出的信息提示使用 --trace 参数，看看执行过程中发生了什么。但是实际上下 1 行已经提示了，webrick 无法加载。
------------------------------------------------ Jekyll 4.2.2 Please append `--trace` to the `serve` command for any additional information or backtrace. ------------------------------------------------ C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve/servlet.rb:3:in `require&#39;: cannot load such file -- webrick (LoadError) 这里用一下 --trace 参数，输出没啥变化，依然提示 webrick 无法加载。
&gt; jekyll serve --trace Configuration file: D:/workspace/github.io/_config.yml Source: D:/workspace/github.io Destination: D:/workspace/github.io/_site Incremental build: disabled. Enable with --incremental Generating... Jekyll Feed: Generating feed for posts done in 0.747 seconds. Please add the following to your Gemfile to avoid polling for changes: gem &#39;wdm&#39;, &#39;&gt;= 0.1.0&#39; if Gem.win_platform? Auto-regeneration: enabled for &#39;D:/workspace/github.io&#39; C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve/servlet.rb:3:in `require&#39;: cannot load such file -- webrick (LoadError) from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve/servlet.rb:3:in `&lt;top (required)&gt;&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:179:in `require_relative&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:179:in `setup&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb💯in `process&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `block in process_with_graceful_fail&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `each&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/command.rb:91:in `process_with_graceful_fail&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/lib/jekyll/commands/serve.rb:86:in `block (2 levels) in init_with_program&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `block in execute&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `each&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `execute&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary/program.rb:44:in `go&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/mercenary-0.4.0/lib/mercenary.rb:21:in `program&#39; from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/jekyll-4.2.2/exe/jekyll:15:in `&lt;top (required)&gt;&#39; from C:/Ruby31-x64/bin/jekyll:32:in `load&#39; from C:/Ruby31-x64/bin/jekyll:32:in `&lt;main&gt;&#39; 这时可以回到上面使用 jekyll 生成模板的地方，从输出的信息中可以发现 Bundler 并没有安装 webrick。所以这里手动执行命令安装 webrick。
&gt; bundle add webrick Fetching gem metadata from https://rubygems.org/.......... Resolving dependencies... Fetching gem metadata from https://rubygems.org/.......... Resolving dependencies... 等待安装完成，应该就可以使用 jekyll serve 命令了。
推送项目到 GitHub Pages GitHub Pages 官方文档：https://pages.github.com/按照要求建一个名字叫 {username}.github.io 仓库，然后把项目推上去就行了。
然后就可以通过 https://{username}.github.io 访问了。
]]></content></entry><entry><title>信号</title><url>/post/computer-science/operating-system/linux/signal/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>signal(信号)</tag></tags><content type="html"><![CDATA[前言 前置笔记： 进程的创建、进程的运行、进程的内存资源、进程的退出、进程的回收实践的环境：同 程序资料 {demo-c}/demo-in-linux/signal/ 正文 硬件中断 硬件中断（hardware interrupt）是一个由硬件设备产生的信号，它需要 CPU 关注。 硬件中断用于允许硬件设备与 CPU 进行通信，而不需要一直轮询或者等待 CPU 关注。
当一个硬件设备产生一个中断时，它向中断控制器发送一个信号。 然后，中断控制器（interrupt controller）向 CPU 发送一个信号，中断其当前任务并处理该设备的请求。 然后，CPU 将停止执行其当前任务并处理中断，这包括暂时保存 CPU 的状态和执行中断处理例程（interrupt handler routine）。
中断处理例程是一段由 CPU 响应中断而执行的代码。 它负责确定是哪个设备产生了中断，处理来自该设备的请求，并恢复 CPU 的状态，以便它能够恢复其先前的任务。
硬件中断对于计算机系统的正常运行至关重要，因为它们允许硬件设备与 CPU 进行交互，而不会垄断 CPU 的资源。 产生中断的硬件设备的常见例子包括键盘、鼠标、网卡和硬盘。
硬件中断可以大概分为下面几部分：中断请求，中断响应，保护现场，中断处理，恢复现场，中断返回。
比如，CPU 正在跑一个程序。这时，按一下键盘（产生中断请求）。这个中断请求被发给 CPU 之后，CPU 会做出反应（中断响应）。
这时，CPU 会先停下正在跑的程序，把程序现在的状态记下来（保护现场）。 然后，过来处理这个中断请求（中断处理）。这个时候 CPU 里跑的是另外一个程序（中断处理例程）。
中断处理例程执行结束之后，需要把状态恢复到刚才停下的那个时候（恢复现场）。 这次中断就完事了，从中断处理例程中退出来（中断返回）。然后，就可以继续执行程序了。
软件中断 软件中断（software interrupt）也被称为陷阱（trap）或异常（exception），是一个由程序产生的信号。 它使 CPU 中断其当前任务并执行一个特定的例程（routine）来处理中断。 与由外部硬件设备产生的硬件中断不同，软件中断是由 CPU 上运行的程序产生的。
有两种主要的软件中断类型：同步（synchronous）和异步（asynchronous）。 同步中断是由 CPU 响应程序中的指令而产生的，比如，除以 0 或无效的内存访问。 异步中断是由外部事件产生的，比如，一个定时器或来自另一个进程的信号。
当一个软件中断产生时，CPU 会保存程序的当前状态，包括指令指针和寄存器值，并跳转到一个特定的例程，称为中断处理程序或异常处理程序。 中断处理程序负责处理中断，其中可能涉及错误处理、内存管理或 I/O 操作等任务。
中断处理完毕后，CPU 恢复程序的保存状态，并在被中断的地方恢复执行。 软件中断是程序与操作系统进行通信和执行需要特权访问的任务的重要机制，比如，系统调用或中断另一个进程。
中断处理例程和中断处理程序的区别 中断处理例程（interrupt handler routine）和中断处理程序（interrupt handler）的关键区别在于， 中断处理例程是响应硬件设备的中断信号而执行的代码，而中断处理程序是管理中断信号并调用适当的中断处理例程的代码。
信号对进程的影响 signal(7) Linux supports both POSIX reliable signals (hereinafter &ldquo;standard signals&rdquo;) and POSIX real-time signals. Signal dispositions Each signal has a current disposition, which determines how the process behaves when it is delivered the signal. The entries in the &ldquo;Action&rdquo; column of the table below specify the default disposition for each signal, as follows: &ndash; Term:Default action is to terminate the process. &ndash; Ign:Default action is to ignore the signal. &ndash; Core:Default action is to terminate the process and dump core (see core(5)). &ndash; Stop:Default action is to stop the process. &ndash; Cont:Default action is to continue the process if it is currently stopped. A process can change the disposition of a signal using sigaction(2) or signal(2). (The latter is less portable when establishing a signal handler; see signal(2) for details.)
Using these system calls, a process can elect one of the following behaviors to occur on delivery of the signal: perform the default action; ignore the signal; or catch the signal with a signal handler, a programmer-defined function that is automatically invoked when the signal is delivered.
每个信号都有一个当前处置，它决定了进程在收到信号时如何进程在收到信号时的行为。 下面是每种信号的默认处理方式：Term：进程终止；Ign：进程忽略； Core：进程终止并产生 &ldquo;core dump&rdquo; 文件；Stop：进程停止；Cont：进程继续执行
进程可以更改信号的设置，信号发生时可以选择下面三种行为。 执行默认动作（default action，SIG_DFL）；忽略信号（ignore，SIG_IGN）；使用信号处理程序捕捉信号（signal hanlder）
信号的产生 终端按下 Ctrl+C，产生 SIGINT 信号；终端按下 Ctrl+\ 产生 SIGQUIT 信号；终端按下 Ctrl+Z 产生 SIGSTOP 信号。 进程访问一些不存在的内存或是非法内存，会产生 SIGSEGV 中断信号 在终端中，使用 kill 命令发送 在进程中，使用 raise()、kill()、alarm() 等发送中断信号 子进程退出时会产生中断信号 Linux 中的信号 在 Linux 中，中断信号有64个，分位标准信号和实时信号。 可以通过 &ldquo;kill -l&rdquo; 命令可以查看 Linux 中的 64 个中断信号。其中，带 RT（real time）的就是实时信号。
1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1 11) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP 21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ 26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR 31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3 38) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+8 43) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12 53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-7 58) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-2 63) SIGRTMAX-1 64) SIGRTMAX 信号的使用 进程可以更改信号的设置。进程在收到信号后，如果编写了信号处理函数就执行信号处理函数，如果没有编写信号处理函数就会执行默认动作。
代码示例：{demo-c}/demo-in-linux/signal/signal_handler.c
程序运行起来之后，我们通过 &ldquo;kill -s&rdquo; 命令向进程发送信号。
如果向程序发送 SIGUSR1，进程会执行默认动作，输出 &ldquo;User defined signal 1&rdquo;，然后停止。 如果向程序发送 SIGUSR2，进程会忽略信号，什么反应都没有。 如果向程序发送 SIGINT，进程会执行处理函数，输出 &ldquo;[info]:signal_no=2&rdquo;，然后继续执行。 测试信号处理函数时，当测试的是信号是 SIGSTOP 时，并不会像预期的那样输出 SIGSTOP 信号的值。 因为进程收到 SIGSTOP 后已经停止作业（并没有退出）。 如果这时再向进程发送 SIGCONT 信号。这时进程会恢复作业，并输出signal no=18，也就是收到的 SIGCONT 信号的值。
通过 strace 命令追踪，可以得到下面的内容。进程确实收到了 SIGSTOP 信号和 SIGCONT 信号。
--- SIGSTOP {si_signo=SIGSTOP, si_code=SI_USER, si_pid=84, si_uid=0} --- --- stopped by SIGSTOP --- --- SIGCONT {si_signo=SIGCONT, si_code=SI_USER, si_pid=84, si_uid=0} --- write(1, &#34;signal no=18\r\n&#34;, 14) = 14 信号和 waitpid() 父进程调用 waitpid() 的时候可以获得子进程推出的状态码。
把状态码传给宏函数 WIFSIGNALED()，可以判断子进程是不是被信号终止的。 如果子进程是被信号终止的，WIFSIGNALED() 会返回一个非零值。
当 WIFSIGNALED() 返回非零值时，可以用宏函数 WTERMSIG() 宏来提取信号的编号。
代码示例：{demo-c}/demo-in-linux/signal/signal_and_waitpid.c
信号和系统调用 signal(7) Interruption of system calls and library functions by signal handlers If a signal handler is invoked while a system call or library function call is blocked, then either: &ndash; the call is automatically restarted after the signal handler returns; or &ndash; the call fails with the error EINTR. &hellip; If a blocked call to one of the following interfaces is interrupted by a signal handler, then the call is automatically restarted after the signal handler returns if the SA_RESTART flag was used; otherwise the call fails with the error EINTR:
如果进程正在执行一些系统调用，此时进程收到了一个信号，则该系统调用将会停止并返回错误， 错误码（errno）一般是 -1，错误（error）一般是 EINTR。
如果进程正在执行系统调用，而且这个系统调用被阻塞。这时来了一个信号，结果会有两种。 第一种，进程的信号处理函数已经执行返回，但是系统调用返回错误，错误码为 EINTR。 第二种，进程的信号处理函数已经执行返回，这时系统调用会重新开始。
系统调用返回错误 代码示例：{demo-c}/demo-in-linux/signal/sigaction_default.c
[debug]:getpid()=4475 [info]:signal_no=2 [debug]:byte=-1,errno=4,error=Interrupted system call 这是终端的输出，我们可以看到，先执行了处理函数，然后 read() 系统调用输出了错误，然后进程就终止了。 我们用 strace 再观察一下。
[00007febcad14992] read(0, 这是没有发送信号的时候。进程阻塞在 read() 系统调用这里。
[00007febcad14992] read(0, 0x7ffd2b0b9ed0, 128) = ? ERESTARTSYS (To be restarted if SA_RESTART is set) &lt;5.907470&gt; [00007febcad14992] --- SIGINT {si_signo=SIGINT, si_code=SI_USER, si_pid=2304, si_uid=1000} --- [00007febcad14a37] write(1, &#34;[info]:signal_no=2\n&#34;, 19) = 19 &lt;0.000019&gt; [00007febcac42529] rt_sigreturn({mask=[]}) = -1 EINTR (Interrupted system call) &lt;0.000005&gt; [00007febcad14a37] write(1, &#34;[debug]:byte=-1,errno=4,error=Interrupted system call\n&#34;, 54) = 54 &lt;0.000006&gt; [00007febcaceaca1] exit_group(0) = ? [????????????????] +++ exited with 0 +++ 这是发送信号之后。进程收到信号之后，先执行了处理函数。 处理函数返回时，是 EINTR 错误。然后 read() 系统调用拿到了这个 EINTR 错误。
系统调用重新开始 代码示例：{demo-c}/demo-in-linux/signal/sigaction_restart.c
[debug]:getpid()=4491 [info]:signal_no=2 这是终端的输出，可以看到，先执行了处理函数，然后 read() 系统调用并没有和上面一样输出错误，而是继续执行。 我们用 strace 再观察一下。
[00007f08c8714992] read(0, 这是没有发送信号的时候。进程阻塞在 read() 系统调用这里。
[00007f08c8714992] read(0, 0x7ffcdcb49bd0, 128) = ? ERESTARTSYS (To be restarted if SA_RESTART is set) &lt;4.457116&gt; [00007f08c8714992] --- SIGINT {si_signo=SIGINT, si_code=SI_USER, si_pid=2304, si_uid=1000} --- [00007f08c8714a37] write(1, &#34;[info]:signal_no=2\n&#34;, 19) = 19 &lt;0.000077&gt; [00007f08c8642529] rt_sigreturn({mask=[]}) = 0 &lt;0.000074&gt; [00007f08c8714992] read(0, 这是发送信号之后。进程收到信号之后，先执行了处理函数。处理函数返回时，没有错误。然后 read() 系统调用重新执行了。
信号屏蔽和未决信号 signal(7) A signal may be blocked, which means that it will not be delivered until it is later unblocked. Between the time when it is generated and when it is delivered a signal is said to be pending.
信号可以被阻塞，这时信号不会交付（执行默认动作或者被交给信号处理函数），直到它不被阻塞。 信号处于生成和交付之间的状态，被称为未决。
代码示例：{demo-c}/demo-in-linux/signal/signal_block.c
程序大体的逻辑是，在 10 秒之内阻塞 SIGINT 信号，第 10 秒的时候解开 SIGINT 信号的阻塞。 然后，分别在 10 秒之内和 10 秒以后向进程发送 SIGINT 信号。
[debug]:getpid()=4774 [info]:pendingSet:0000000000000000000000000000000 [info]:pendingSet:0000000000000000000000000000000 [info]:pendingSet:0000000000000000000000000000000 [info]:pendingSet:0000000000000000000000000000000 [info]:pendingSet:0100000000000000000000000000000 [info]:pendingSet:0100000000000000000000000000000 [info]:pendingSet:0100000000000000000000000000000 [info]:pendingSet:0100000000000000000000000000000 [info]:pendingSet:0100000000000000000000000000000 [info]:pendingSet:0100000000000000000000000000000 [info]:signal_no=2 [info]:pendingSet:0000000000000000000000000000000 [info]:pendingSet:0000000000000000000000000000000 [info]:signal_no=2 [info]:pendingSet:0000000000000000000000000000000 [info]:pendingSet:0000000000000000000000000000000 可以看到，在 10 秒之内和向进程发送 SIGINT 信号的时候，信号处理函数并没有输出。 未决信号里面从没有数据变成有数据，说明 SIGINT 信号被阻塞了。
第 10 秒的时候，因为 SIGINT 信号的阻塞被解开，所以，信号处理函数开始工作了。处理完之后，未决信号里面就变成空的了。
10 秒以后向进程发送 SIGINT 信号的时候，信号不会被阻塞，信号处理函数直接开始工作，未决信号里面不会有数据。
小的知识点 SIGKILL、SIGSTOP signal(7) The signals SIGKILL and SIGSTOP cannot be caught, blocked, or ignored.
SIGKILL 和 SIGSTOP 这两个信号不能被捕捉、阻止、忽略。
SIGALRM 用 alarm() 定时触发 SIGALRM 信号，可以实现类似定时任务的结构。
观察进程数据 signal(7) The /proc/[pid]/task/[tid]/status file contains various fields that show the signals that a thread is blocking (SigBlk), catching (SigCgt), or ignoring (SigIgn). (The set of signals that are caught or ignored will be the same across all threads in a process.) Other fields show the set of pending signals that are directed to the thread (SigPnd) as well as the set of pending signals that are directed to the process as a whole (ShdPnd). The corresponding fields in /proc/[pid]/status show the information for the main thread.
和信号有关系的进程数据，可以通过 &ldquo;/proc/{pid}/status&rdquo; 文件观察。 SigQ：当前进程待处理信号数。SigPnd；线程的未决信号。ShnPnd；线程组的未决信号。 SigBlk；阻塞的信号。SigIgn；忽略的信号。SigCgt；捕捉的信号。
这里观察一下上面的 {demo-c}/demo-in-linux/signal/signal_block.c 的运行情况。 为了观察方便可以拉长 signal_block.c 中的等待时间，方便进行操作。
刚开始运行的时候是这样的。
SigQ:	0/15243 SigPnd:	0000000000000000 ShdPnd:	0000000000000000 SigBlk:	0000000000000002 SigIgn:	0000000000000000 SigCgt:	0000000000000002 向进程发送 SIGINT 信号之后，变成了这样。
SigQ:	1/15243 SigPnd:	0000000000000000 ShdPnd:	0000000000000002 SigBlk:	0000000000000002 SigIgn:	0000000000000000 SigCgt:	0000000000000002 解开 SIGINT 信号的阻塞之后，变成了这样。
SigQ:	0/15243 SigPnd:	0000000000000000 ShdPnd:	0000000000000000 SigBlk:	0000000000000000 SigIgn:	0000000000000000 SigCgt:	0000000000000002 ]]></content></entry><entry><title>hosts 文件</title><url>/post/computer-science/operating-system/windows/hosts/</url><categories><category>windows</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>windows</tag></tags><content type="html">hosts 文件所在的目录：C:\Windows\System32\drivers\etc。
hosts 文件是一个没有扩展名的系统文件，用于储存计算机网络中各节点信息，负责将主机名称映射到相应的 IP 地址。简单地说它的作用就是用来存储一些常用的网络域名和与其对应的 IP 地址。
hosts 文件通常用于补充或取代网络中 DNS 的功能。和 DNS 不同的是，计算机的用户可以直接对 hosts 文件进行控制。
当用户输入一个需要登录的网址时，系统就会先去 hosts 文件中查找。如果找到了就立即打开该网址，如果找不到就去 DNS 域名解析服务器中查找。</content></entry><entry><title>进程间通信（IPC）</title><url>/post/computer-science/operating-system/linux/ipc/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>ipc(进程间通信)</tag></tags><content type="html"><![CDATA[前言 前置笔记：运行 ELF 文件实践的环境：同 程序正文 进程间通信 进程间通信（Inter Process Communication，IPC）指的是在同一台机器上的不同进程之间传播或交换信息。
ipc 的方法主要包括 pipe（管道）和 ipc 对象（消息队列、信号量、共享内存）。管道包括匿名管道和命名管道。
ipc 对象有两个标准，一个是比较老的 &ldquo;SYSTEM V&rdquo; 标准的消息队列、信号量、共享内存， 另一个是比较新的 POSIX 标准的消息队列、信号量、共享内存。
管道 pipe(7) Pipes and FIFOs (also known as named pipes) provide a unidirectional interprocess communication channel. A pipe has a read end and a write end. Data written to the write end of a pipe can be read from the read end of the pipe.
管道提供了一个单向的进程间通信通道。一个管道有一个读取端和一个写入端。 写入管道写入端的数据的数据可以从该管道的读取端读出。数据只能单向流动，数据从写入端流向读取端。
管道依赖 linux 内核实现，管道的本质是在内核中的一块内存（也叫内核缓冲区）， 这块缓冲区中的数据存储在一个环形队列中，由于管道在内核区，我们不能直接对其操作。
本质上是文件 I/O 操作。内核中管道两端分别对应两个文件描述符， 通过写端的文件描述符把数据写入管道中，通过读端的文件描述符将数据从管道中读出来， 读写管道的函数就是 linux 中的文件 I/O 函数。
管道分为匿名管道和命名管道。匿名管道，没有可以提供给外部的标识，所以，一般用于父子进程之间。 命名管道，有可以提供给外部的标识，所以，可以用于非父子进程之间。
匿名管道 pipe(7) A pipe is created using pipe(2), which creates a new pipe and returns two file descriptors, one referring to the read end of the pipe, the other referring to the write end. Pipes can be used to create a communication channel between related processes; see pipe(2) for an example.
示例代码：{demo-c}/demo-in-linux/ipc/unnamed_pipe/unnamed_pipe.c
命名管道 示例代码：
父子进程：{demo-c}/demo-in-linux/ipc/named_pipes/parent_child.c 非父子进程读取：{demo-c}/demo-in-linux/ipc/named_pipes/pipe_read.c 非父子进程写入：{demo-c}/demo-in-linux/ipc/named_pipes/pipe_write.c &gt; file fifo fifo: fifo (named pipe) 可以使用 file 命令查看 fifo 的文件类型，可以看到这是个命名管道。
在 win10 环境的 docker 环境的 linux 环境中创建 fifo 文件时会出现 &ldquo;Input/output error&rdquo; 报错。 这是因为 docker 目录是 win10 目录映射来的，创建不了 fifo 文件。 解决办是用 linux 环境中的目录，测试的时候可以先用 &ldquo;/tmp&rdquo; 目录。
IPC 对象 ipc(2) ipc() is a common kernel entry point for the System V IPC calls for messages, semaphores, and shared memory. call determines which IPC function to invoke; the other arguments are passed through to the appropriate call.
ipc 对象包括消息队列、信号量、共享内存。创建 ipc 对象时需要指定一个 key（键，标识符）。 key 是指 ipc 对象在操作系统内部的唯一标识，在多个进程通信时用作关联。
ipc 相关的 linux 命令：ipcs、ipcrm。
消息队列 消息队列的实现依赖 linux 内核，并且它的数据存储在内核中。
示例代码：
创建：demo_c/demo_linux_c/ipc/message_queue/msgget.c 发送：demo_c/demo_linux_c/ipc/message_queue/msgsnd.c 接收：demo_c/demo_linux_c/ipc/message_queue/msgrcv.c 控制：demo_c/demo_linux_c/ipc/message_queue/msgctl.c 创建一个消息队列。
&gt; ./msgget.elf [debug]:mqId=0, errno=0, error=Success 消息队列创建完成后，可以通过 ipcs 命令查看，通过 key 字段可以找到创建的消息队列。 向消息队列发送消息后，used-bytes 字段会显示消息队列使用的大小，messages 字段会显示未处理消息的条数。
&gt; ipcs ------ Message Queues -------- key msqid owner perms used-bytes messages 0x00001000 0 qqq 666 1024 0 发送一条消息。
&gt; ./msgsnd.elf [debug]:msgsndResult=0 查看消息队列的情况，可以看到，里面有一条消息。
&gt; ./msgctl.elf [debug]:msgctlResult=0, buf.msg_qnum=1 通过 ipcs 命令查看，可以看到，未处理消息的条数变成 1 了。
&gt; ipcs ------ Message Queues -------- key msqid owner perms used-bytes messages 0x00001000 0 qqq 666 1024 1 接收一条消息。
&gt; ./msgrcv.elf [debug]:msgrcvResult=1024, msg.mtext=hello, msg.mtype=1 查看消息队列的情况，可以看到消息已经被取走了。
&gt; ./msgctl.elf [debug]:msgctlResult=0, buf.msg_qnum=0 通过 ipcs 命令查看，可以看到，未处理消息的条数变成 0 了。
&gt; ipcs ------ Message Queues -------- key msqid owner perms used-bytes messages 0x00001000 0 qqq 666 0 0 信号量 信号量本质上是个计数器，linux 内核有相应的数据结构来维护。
注意，这里操作的是信号量集合，信号量集合里面可以由一个或多个信号量。
示例代码：
创建：demo_c/demo_linux_c/ipc/semaphores/semget.c 控制：demo_c/demo_linux_c/ipc/semaphores/semctl.c 操作：demo_c/demo_linux_c/ipc/semaphores/semop.c 创建有一个信号量的信号量集合：
&gt; ./semget.elf [debug]:semId=0, errno=0, error=Success 信号量创建完成后，可以通过 ipcs 命令查看，通过 key 字段可以找到创建的信号量。 设置信号量后，nsems 字段对应信号量集中信号量的个数。
&gt; ipcs ------ Semaphore Arrays -------- key semid owner perms nsems 0x00001000 0 qqq 666 1 设置和读取信号量集合里的信号量：
&gt; ./semctl.elf [debug]:SETVAL, semctlResult=0 [debug]:GETVAL, semctlResult=3 和消息队列的 msgctl 一样，信号量的 semctl 也有 IPC_STAT 、IPC_RMID 这两个参数，这里就不演示了。
操作信号量集合里的信号量：
&gt; ./semop.elf [debug]:SETVAL, semctlResult=0 [debug]:GETVAL, semctlResult=10 [debug]:semopResult=0 [debug]:GETVAL, semctlResult=8 一般最常用的信号量是二值信号量（0 和 1），用于进程间同步或是互斥操作。 二值信号量主要特点就是集合里只有一个信号量，并且信号量的值只有 0 和 1 这两个。
对信号量进行加 1 叫做 V（vrijgeven），对它进行减 1 操作叫做 P（passeren）。 和操作系统信号量的 pv 操作是一样的。二值信号量主要用于进程间同步，保证数据的一致性，对关键核心代码做临界，控制共享内存。
示例代码：demo_c/demo-in-linux/ipc/semaphores/passeren_vrijgeven.c
共享内存 申请一块内存，进程间通过关联这块内存从而达到进程间通信的目的，它是 IPC 进程间通信中最快的。
示例代码：
创建：demo_c/demo_linux_c/ipc/shared_memory/shmget.c 连接、写入：demo_c/demo_linux_c/ipc/shared_memory/shmat.c 连接、读取、断开连接：demo_c/demo_linux_c/ipc/shared_memory/shmdt.c 创建共享内存：
&gt; ./shmget.elf [debug]:shmId=2, errno=0, error=Success 共享内存创建完成后，可以通过 ipcs 命令查看，通过 key 字段可以找到创建的共享内存。
&gt; ipcs ------ Shared Memory Segments -------- key shmid owner perms bytes nattch status 0x00001000 2 qqq 666 1024 0 连接共享内存、写入数据：
&gt; ./shmat.elf [debug]:shmId=2, errno=0, error=Success 连接共享内存、读取数据、断开连接：
&gt; ./shmdt.elf [debug]:shmId=2, errno=0, error=Success [info]:msg=hello [debug]:shmdtResult=0 参考 {CSDN}/{富贵的编程日记}/Linux快速入门之 管道（11）]]></content></entry><entry><title>命令行参数和环境参数</title><url>/post/computer-science/operating-system/cmd_env_param/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>linux</tag><tag>c-programming-language</tag></tags><content type="html">前言 实践的环境：
amd64（x86_64） windows 11 vmware workstation pro 16 ubuntu 22.04 linux version 5.19.0-41-generic gcc version 11.3.0 前置笔记：
运行 ELF 文件
资料 {demo-c}
/demo-in-linux/cmd-env-param/ 正文 命令行参数和环境参数这两个东西不止 linux 系统里有，windows 系统里也有。这里在 linux 系统里进行演示。
命令行参数就是在终端输入命令的时候，跟在后面的那一串东西，经常要用的。 环境参数这个一般是安装环境的时候直接配置好的，比如：windows 系统和 linux 系统里的 path 环境变量。
命令行参数 ./cmd_param.elf aaa bbb ccc argc=4 argc=./cmd_param.elf argc=aaa argc=bbb argc=ccc main() 的 argc 参数的值就是命令行参数，包括执行命令和跟在后面的三个参数。
环境参数 ./env_param.elf argc=1 envp=SHELL=/bin/bash envp=SESSION_MANAGER=local/qqq-virtual-machine:@/tmp/.ICE-unix/1155,unix/qqq-virtual-machine:/tmp/.ICE-unix/1155 envp=QT_ACCESSIBILITY=1 envp=COLORTERM=truecolor envp=XDG_CONFIG_DIRS=/etc/xdg/xdg-ubuntu:/etc/xdg envp=SSH_AGENT_LAUNCHER=gnome-keyring envp=XDG_MENU_PREFIX=gnome- envp=GNOME_DESKTOP_SESSION_ID=this-is-deprecated envp=LANGUAGE=en_US: envp=LC_ADDRESS=zh_CN.UTF-8 envp=GNOME_SHELL_SESSION_MODE=ubuntu envp=LC_NAME=zh_CN.UTF-8 envp=SSH_AUTH_SOCK=/run/user/1000/keyring/ssh envp=XMODIFIERS=@im=ibus envp=DESKTOP_SESSION=ubuntu envp=LC_MONETARY=zh_CN.UTF-8 envp=GTK_MODULES=gail:atk-bridge envp=PWD=/mnt/hgfs/demo-c/demo-in-linux/cmd-env-param envp=LOGNAME=qqq envp=XDG_SESSION_DESKTOP=ubuntu envp=XDG_SESSION_TYPE=wayland envp=SYSTEMD_EXEC_PID=1192 envp=XAUTHORITY=/run/user/1000/.mutter-Xwaylandauth.AJ0Q61 envp=HOME=/home/qqq envp=USERNAME=qqq envp=IM_CONFIG_PHASE=1 envp=LC_PAPER=zh_CN.UTF-8 envp=LANG=en_US.UTF-8 envp=LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36: envp=XDG_CURRENT_DESKTOP=ubuntu:GNOME envp=VTE_VERSION=6800 envp=WAYLAND_DISPLAY=wayland-0 envp=GNOME_TERMINAL_SCREEN=/org/gnome/Terminal/screen/0895c5d6_5be1_4421_80fb_ba99d979e290 envp=GNOME_SETUP_DISPLAY=:1 envp=LESSCLOSE=/usr/bin/lesspipe %s %s envp=XDG_SESSION_CLASS=user envp=TERM=xterm-256color envp=LC_IDENTIFICATION=zh_CN.UTF-8 envp=LESSOPEN=| /usr/bin/lesspipe %s envp=USER=qqq envp=GNOME_TERMINAL_SERVICE=:1.115 envp=DISPLAY=:0 envp=SHLVL=1 envp=LC_TELEPHONE=zh_CN.UTF-8 envp=QT_IM_MODULE=ibus envp=LC_MEASUREMENT=zh_CN.UTF-8 envp=XDG_RUNTIME_DIR=/run/user/1000 envp=LC_TIME=zh_CN.UTF-8 envp=XDG_DATA_DIRS=/usr/share/ubuntu:/usr/local/share/:/usr/share/:/var/lib/snapd/desktop envp=PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin envp=GDMSESSION=ubuntu envp=DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1000/bus envp=LC_NUMERIC=zh_CN.UTF-8 envp=OLDPWD=/mnt/hgfs/demo-c/demo-in-linux envp=_=./env_param.elf main() 的 envp 参数的值就是环境参数，环境参数也可以通过 env 命令输出。</content></entry><entry><title>系统调用</title><url>/post/computer-science/operating-system/system_call/</url><categories><category>operating-system(操作系统)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>linux</tag><tag>c-programming-language</tag></tags><content type="html"><![CDATA[前言 前置笔记：运行 ELF 文件实践的环境：同 运行 ELF 文件正文 什么是系统调用 对于应用软件的开发人员来说，一般都是基于操作系统进行开发的。 一般来说，开发人员开发的应用程序是不能直接操作操作系统的，使用的是操作系统提供的系统接口。 开发人员通过操作系统提供的系统接口实现应用程序的功能。
系统调用为用户级程序访问特权服务和资源提供了一种受控的安全方式，同时保持了操作系统的完整性和安全性。 它们在用户模式和内核模式的执行之间建立了一个界限，使用户程序能够以一种受控的方式与底层操作系统进行交互。
用户进程通过系统调用才能去调用系统资源，当调用系统调用时，用户空间运行的程序会切换到内核空间中去运行。 当启动一个程序之后，程序必须借助操作系统提供的系统接口（系统调用、syscall）才能使用系统的相关资源（一般是硬件资源）。 通常需要系统调用的任务包括文件操作、网络通信、进程管理、内存分配和设备输入输出。
进行系统调用的过程包括以下几个步骤：
用户级程序在程序在用户模式下执行其代码，该模式下的权限受到限制，对系统资源的访问也受到限制。 当程序需要执行一个特权操作或访问一个系统资源时，就会触发一个系统调用。这通常是通过调用一个特定的系统调用来实现的。 系统调用触发了从用户模式到内核模式的过渡。在内核模式下，程序获得了对操作系统的全部权限和资源的访问权。 操作系统内核收到系统调用请求并验证其有效性。然后，内核会执行程序所要求的特定操作或服务。 一旦系统调用完成，操作系统将控制权返回给用户级程序，过渡到用户模式。 用户级程序从一个指定的位置（比如：特定的寄存器或内存位置），检索系统调用的结果或状态，然后，继续其执行自己的代码。 linux 中的系统调用 系统调用是在 linux 内核的源代码中定义的，而不是专门针对 Ubuntu 的。 linux 内核的源代码，包括系统调用的定义，可以在 &ldquo;/usr/src/linux&rdquo; 目录下找到。
c 库的系统调用通常位于 &ldquo;/usr/include/unistd.h&rdquo; 文件中。 这个头文件包含了系统调用的函数原型和定义。它会根据系统的架构，加载不同的头文件。
汇编语言、高级语言（c/c++、java、golang）、脚本语言（php、python、nodejs）在运行的时候最终都是调用的系统调用。 这些系统调用看上去是 c 语言风格的定义，但是，程序最终变成汇编代码、机器码的时候是一样的。 这点反过来想比较好理解，芯片是固定的，不可能应付各式各样的编程语言，所以，只能是各式各样的编程语言最终都变成一样的机器语言。
下面是从头文件中节选的一部分部分，就是 read() 和 write() 的定义，和在线文档上是一样的。
/* Read NBYTES into BUF from FD. Return the number read, -1 for errors or 0 for EOF. This function is a cancellation point and therefore not marked with __THROW. */ extern ssize_t read (int __fd, void *__buf, size_t __nbytes) __wur __fortified_attr_access (__write_only__, 2, 3); /* Write N bytes of BUF to FD. Return the number written, or -1. This function is a cancellation point and therefore not marked with __THROW. */ extern ssize_t write (int __fd, const void *__buf, size_t __n) __wur __attr_access ((__read_only__, 2, 3)); 我这里把在线文档上的内容也放到这里，可以对比起来看一下。
read(2) read - read from a file descriptor #include &lt;unistd.h&gt; ssize_t read(int fd, void *buf, size_t count);
write(2) write - write to a file descriptor #include &lt;unistd.h&gt; ssize_t write(int fd, const void *buf, size_t count);
]]></content></entry><entry><title>win10 升级 win11</title><url>/post/computer-science/operating-system/windows/win10-to-win11/</url><categories><category>windows</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>windows</tag></tags><content type="html"><![CDATA[1、首先，win10 需要是已经激活的。
2、然后，需要把 win10 升级到最新版本。位置在：开始菜单=&gt;设置=&gt;更新和安全=&gt;Windows 更新=&gt;检查更新。一直升级到提示可以更新 win11 为止，这个页面上会提示电脑已满足升级的要求。
3、去 microsoft（微软）官网的 win11 下载页面下一个 &ldquo;Windows 11 安装助手&rdquo;（Windows11InstallationAssistant.exe）。
4、双击 &ldquo;Windows 11 安装助手&rdquo;（Windows11InstallationAssistant.exe），按照提示一路安装就行。大概流程是：下载=&gt;安装=&gt;重启。下载和安装两个步骤都很花时间，最后会重启好几次。
5、安装流程结束后，第一次进系统的时候是黑屏，这是因为壁纸没了。
]]></content></entry><entry><title>BT 种子和磁力链接</title><url>/post/computer-science/protocol/bit-torrent/</url><categories><category>protocol(协议)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>protocol(协议)</tag></tags><content type="html">BT 种子 BT 种子，实际上指的是由 BitTorrent 协议所生成的一个包含资源信息的文件。
与传统的网络传输协议不同，BitTorrent 协议是一种以 P2P（peer-to-peer、用户对用户）模式为主的资源分享协议。采用的是一种去中心化的思想，不需要一个专门的文件发布者或者发布平台。
从理论上来说，一个 BT 种子只要发布了，种子所包含的资源就永远存在于互联网上。
平常所使用的 HTTP、FTP 等协议需要一个中心发布者在网络上发布文件，即一种点对多的模式。当然，如果中心发布者由于某种原因被封了或者发布者删除了资源，那么就无法下载资源了。
BitTorrent BitTorrent 协议的思想是将一个文件划分为大小相等的 n 块，每块大小必须为 2 的整数次方。
例如一个 100M 的文件，按照每块 1024kb 的大小被分为 100 个小块，每块中包含索引信息和 Hash 值，而我们的下载过程实际上就是块的交换过程。
BitTorrent 协议的资源发布者会根据要求，制作一个包含资源下载信息，例如 Tracker 服务器地址、文件大小、文件名、块文件大小等信息的 .torrent 文件，这个过程也就是平时说的做种。
如果要下载 BT 资源，首先要得到对应的 .torrent 文件，然后用专门的下载软件，例如 BitComet（比特彗星），下载过程大概为：
1、读取 .torrent 文件信息，载入内存。 2、得到文件内的 Tracker 地址，连接 Tracker 服务器。 3、Tracker 服务器回应下载请求，记录你的 IP 并告知其它下载者的 IP 地址。 4、你与其他在线的下载者连接，交换各自没有的块。 5、验证得到的块信息，若不同，则需要重新下载。 磁力链接 由上文可以看出，Tracker 是很重要的一个东西。一但 Tracker 服务器被封，就无法进行下载了。由此，Magnet URI scheme（磁力链接）诞生了。
磁力链接，是对等网络中进行信息检索和下载文档的电脑程序。和基于位置连接的统一资源定位符不同，磁力链接是基于 metadata（元数据）文件内容，属于统一资源名称。
也就是说，磁力链接不基于文档的IP地址或定位符，而是在分布式数据库中，通过散列函数值来识别、搜索来下载文档。
因为不依赖一个处于启动状态的主机来下载文档，所以特别适用没有中心服务器的对等网络。
磁力链接利用 DHT（distributed hash table、分布式哈希表）和 PEX（peer exchange、节点信息交换）实现了资源的随意传播，根本无法禁止。
磁力链接下载的本质是将每一个人都变为 Tracker 服务器，将资源与下载者对应起来，每位下载者保存部分信息。这样，在下载资源时，只需寻找拥有所需资源的下载者。
简单理解就是，A 认识 B，B 认识 C，C 认识 D 和 E。如果 A 想认识 E，就可以通过 B 和 C 的介绍来认识 D，不需要 A 一个个去寻找 E。
magnet:?xt=urn:btih:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 上面是一个常见的磁力链接。
magnet：为协议名。 xt：exact topic，资源定位点。 urn：Uniform Resource Name，资源名。 btih：BitTorrent info hash，表示种子散列函数。 最主要的就是 btih 后面唯一的一串 16 进制的数字。 图种 图种就是把包含 BT 种子的压缩文件隐藏在图片中。
下面的操作是在 windows 11 系统环境下操作的。
需要准备一张图片 1.jpg 和一个压缩文件 2.rar。然后新建一个 .bat 后缀的批处理文件，把下面的代码放进去。
copy /b 1.jpg+2.rar 3.jpg copy /b 是一个基础的 DOS 命令，作用是合并文件。
把图片、压缩文件、批处理文件放在同一个目录。然后执行批处理文件，执行完成后就会得到一张图片 3.jpg。
这个图片实际上同时文件含了图片和压缩文件。如果把图片 3.jpg 的后缀名改成 .rar，这个时候图片就变成了压缩文件。
这个压缩文件是可以解压的，压缩文件的内容就是 2.rar 的内容。</content></entry><entry><title>在 Windows 环境安装和配置 Git</title><url>/post/computer-science/application/git/install_config/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>git</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 git 2.34.0
下载和安装 去 Git 官方网站下一个 Windows 环境的安装包。这里下载到的安装包是 Git-2.34.0-64-bit.exe。运行安装包，一路下一步即可。本体安装应该是自动配好的，可以输出版本检查一下有没有安装好。
&gt; git version git version 2.34.1.windows.1 全局配置用户名和邮箱 &gt; git config --global user.name &#34;xxx&#34; &gt; git config --global user.email &#34;xxx@xxx.com&#34; 执行命令后，会在目录 C:\Users\用户名\ 下创建一个 .gitconfig 文件用于保存配置。
记住密码 永久记住密码：
&gt; git config --global credential.helper store 临时记住密码：
&gt; git config –global credential.helper cache &gt; git config –global credential.helper &#39;cache –timeout=3600&#39; 这两条命令执行后，会在目录 C:\Users\用户名\ 下创建一个 .gitconfig 文件用于保存配置。第一次提交任然需要输入用户名和密码。提交成功后，同一个用户就不需要再输入了。提交成功后会在目录 C:\Users\用户名\ 下创建一个 .git-credentials 文件用于保存密码。
Github 配置 SSH 打开 Github 的账号设置页面，在左侧边栏里找到 Access-&gt;SSH and GPG keys。最后要把生成的 SSH 的公钥配置在这里。
第 1 步，在自己的终端上生成 SSH SSH 目录一般都在 ~/.ssh，对应到 win11 上就是 C:\Users\用户名\.ssh 目录。 进入 ~/ 目录，对应到 win11 上就是 C:\Users\用户名\ 目录。 这里建议用 Git 提供的那个 Git Bash 命令行窗口操作。它会自动的把 ~ 目录对应到 win11 的用户目录。 然后使用命令生成 SSH，一般一路回车即可。 &gt; ssh-keygen -t rsa -C &#34;xxx@xxx.com&#34; -f ~/.ssh/github_rsa Generating public/private rsa key pair. Enter passphrase (empty for no passphrase): 直接回车 Enter same passphrase again: 直接回车 Your identification has been saved in /c/Users/Administrator/.ssh/github_rsa Your public key has been saved in /c/Users/Administrator/.ssh/github_rsa.pub ... -t rsa：表示使用 rsa 算法。 -C &quot;xxx@xxx.com&quot;：指定 SSH 的名字，不一定非要是邮箱，但是一般用邮箱。 -f ~/.ssh/github_rsa：指定了生成出来的文件的目录和文件名。 如果不指定文件名，则会用默认的文件名，如果想要配置多个 SSH 就需要指定文件名。
第 2 步，获取和配置公钥 生成 SSH 的步骤完成后，用 cat 获取公钥。
&gt; cat ~/.ssh/github_rsa.pub ssh-rsa 一大串 xxx@xxx.com 然后把上面 cat 到的公钥内容贴到代码仓库配置 SSH 公钥的地方。
第 3 步，配置 SSH 如果第 1 步用的是默认的文件名，那第 3 步是不需要配置的，直接默认配置就生效了。 但是如果第 1 步指定了文件名，也就是需要配置多个 SSH 的时候，就需要进行下面的配置。 即使用 ssh-add 添加私钥。如果需要配置多个 SSH，那么每个 SSH 都要配置。
&gt; ssh-add ~/.ssh/github_rsa Identity added: /c/Users/Administrator/.ssh/github_rsa (xxx@xxx.com) 如果遇到报错：Could not open a connection to your authentication agent.。 就先执行 ssh-agent bash，这命令没有输出。然后再执行 ssh-add 命令。
ssh-add -l：查看私钥。 ssh-add -D：删除全部私钥。 私钥添加完成后，在 ~/.ssh/ 目录创建文件名为 config 的配置文件。 在 config 文件中添加以下配置内容，如果需要配置多个 SSH，那么每个 SSH 都要写一个。
# Github Host github.com HostName github.com IdentityFile ~/.ssh/github_rsa User xxx 符号 # 开头表示这行是注释。 Host：识别模式。和主机名一样就行。 HostName：主机名 Port：端口号。如果不是默认的 22 就需要指定。 IdentityFile：秘钥文件路径 User：用户名 第 4 步，测试 如果配置成功，则执行 ssh -T 命令后会，有下面提示成功的输出。
&gt; ssh -T git@github.com Hi xxx! You&#39;ve successfully authenticated, but GitHub does not provide shell access. 配置多个 SSH 这里给 Github 和 Gitee 两个代码仓库配置 SSH。
第 1 步、第 2 步是一样的。都是生成 SSH 然后到对应的仓库去配置。 第 3 步、第 4 步不一样。ssh-add 需要执行多次，把每个 SSH 都添加。config 文件的配置也需要配多个。
如果有第 3 个、第 4 个、或者更多的仓库，依葫芦画瓢即可。
Gitee 配置 SSH Gitee 的帮助中心有关于 配置 SSH 的文档打开 Gitee 的账号设置页面，在左侧边栏里找到 安全设置-&gt;SSH 公钥。最后要把生成的 SSH 的公钥配置在这里。
生成 SSH，这里除了用的是 ed25519 算法，其他的差不多。
&gt; ssh-keygen -t ed25519 -C &#34;xxx@xxx.com&#34; -f ~/.ssh/gitee_rsa Generating public/private ed25519 key pair. Enter passphrase (empty for no passphrase): 直接回车 Enter same passphrase again: 直接回车 Your identification has been saved in /c/Users/kelipute/.ssh/gitee_rsa Your public key has been saved in /c/Users/kelipute/.ssh/gitee_rsa.pub ... 生成 SSH 的步骤完成后，用 cat 获取公钥。
&gt; cat .ssh/gitee_rsa.pub ssh-ed25519 一大串 xxx@xxx.com 然后把上面 cat 到的公钥内容贴到代码仓库配置 SSH 的地方。
使用 ssh-add 添加私钥。
&gt; ssh-add ~/.ssh/gitee_rsa Identity added: /c/Users/Administrator/.ssh/gitee_rsa (xxx@xxx.com) 在 config 文件添加以下配置内容。
# Gitee Host gitee.com HostName gitee.com IdentityFile ~/.ssh/gitee_rsa User xxx 测试。
&gt; ssh -T git@gitee.com 阿里云云效配置 SSH 打开 云效的个人设置页面，在左侧边栏里找到 SSH 公钥。最后要把生成的 SSH 的公钥配置在这里。
生成 SSH，阿里云云效要求使用 ed25519 算法，其他的差不多。
&gt; ssh-keygen -t ed25519 -C &#34;xxx@xxx.com&#34; -f ~/.ssh/yun2xiao4_ed25519 Generating public/private ed25519 key pair. Enter passphrase (empty for no passphrase): 直接回车 Enter same passphrase again: 直接回车 Your identification has been saved in /c/Users/Administrator/.ssh/yun2xiao4_ed25519 Your public key has been saved in /c/Users/Administrator/.ssh/yun2xiao4_ed25519.pub ... 生成 SSH 的步骤完成后，用 cat 获取公钥。
&gt; cat ~/.ssh/yun2xiao4_ed25519.pub ssh-ed25519 一大串 xxx@xxx.com 然后把上面 cat 到的公钥内容贴到代码仓库配置 SSH 的地方。
使用 ssh-add 添加私钥。
&gt; ssh-add ~/.ssh/yun2xiao4_ed25519 Identity added: /c/Users/Administrator/.ssh/yun2xiao4_ed25519 (xxx@xxx.com) 在 config 文件添加以下配置内容。
# Gitee Host codeup.aliyun.com HostName codeup.aliyun.com IdentityFile ~/.ssh/yun2xiao4_ed25519 User xxx 腾讯云 Coding 配置 SSH Coding 的帮助中心有关于 配置 SSH 的文档打开 Coding 的个人账户页面，在左侧边栏里找到 SSH 公钥。最后要把生成的 SSH 的公钥配置在这里。
生成 SSH，腾讯云 Coding 的文档里给了命令，直接用就好了。
&gt; ssh-keygen -m PEM -t ed25519 -C &#34;huiyu.xue@ly.com&#34; -f ~/.ssh/coding_ed25519 Generating public/private ed25519 key pair. Enter passphrase (empty for no passphrase): 直接回车 Enter same passphrase again: 直接回车 Your identification has been saved in /c/Users/kelipute/.ssh/coding_ed25519 Your public key has been saved in /c/Users/kelipute/.ssh/coding_ed25519.pub ... 生成 SSH 的步骤完成后，用 cat 获取公钥。
&gt; cat ~/.ssh/coding_ed25519.pub ssh-ed25519 一大串 xxx@xxx.com 然后把上面 cat 到的公钥内容贴到代码仓库配置 SSH 的地方。
使用 ssh-add 添加私钥。
&gt; ssh-add ~/.ssh/coding_ed25519 Identity added: /c/Users/kelipute/.ssh/coding_ed25519 (xxx@xxx.com) 在 config 文件添加以下配置内容。
# Coding Host e.coding.net HostName e.coding.net IdentityFile ~/.ssh/coding_ed25519 User {xxx} 测试
&gt; ssh -T git@e.coding.net Are you sure you want to continue connecting (yes/no/[fingerprint])? 输入 yes，回车 CODING 提示: Hello xxx, You&#39;ve connected to coding.net via SSH. This is a Personal Key. ... ]]></content></entry><entry><title>Git 常用命令</title><url>/post/computer-science/application/git/common_command/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>git</tag></tags><content type="html"> CPU AMD64(x86_64) Windows 11 家庭版 git 2.34.0
创建 git init，初始化 git 仓库。
初始化之后就会在当前目录创建 .git/ 目录。
修改 git add .，添加所有文件到缓冲区。
git status，查看 git 库的状态。
当前在哪个分支，还有文件的变化情况，哪些文件被新增、修改、删除了。
git diff，用于文件修改了，但是还没有提交时，比较文件修改前后的差异。
git diff，默认比较全部的文件。
git diff {filename}，可以指定文件 filename 进行比较。
提交 git commit -m &amp;quot;message&amp;quot;，提交缓冲区的所有修改到本地仓库。
如果修改了但是没有 add 到缓冲区的，是不会被提交的。
git reset，回退版本。
git reset HEAD^，回退所有内容到上一个版本。
git reset {code}，回退所有内容到指定版本。
上面的 code 参数填的是 git log 输出的信息中，每个提交最前面的那一串。
--hard 参数，撤销工作区中所有未提交的修改内容，将暂存区与工作区都回退，并删除之前的所有的提交信息。
git reset --hard HEAD^，强行回退所有内容到上一个版本。
git reset --hard {code}，强行回退所有内容到指定版本。
git reset --hard origin/master，强行将本地分支回退到和远程 master 分支一样。
谨慎使用 --hard 参数。
日志 git log，查看历史记录，主要是提交信息。
--oneline 参数，查看历史记录的简洁的版本。
--graph 参数，查看历史记录中的分支和合并。
远程仓库 git remote，操作远程仓库
git remote -v，显示所有远程仓库。
git remote add {name} {url}，添加远程仓库 name 并设置地址为 url。
常用的：git remote add origin {url}，添加远程仓库 origin 并设置地址为 url。
git remote set-url origin {url}，修改远程仓库 origin 的地址为 url。如果未指定协议，则默认为 SSH。
git remote rm {name}，删除远程仓库 name 。
获取代码 git fetch，从远程仓库获取代码。
git fetch origin，从远程仓库 origin 获取代码。
获取代码并合并 git pull，从远程获取代码并合并。
git pull 其实是 git fetch 和 git merge FETCH_HEAD 的简写。
git pull {name} {remote branch}:{locol branch}，将远程仓库 name 的 remote branch 分支拉取过来，与本地的 locol branch 分支合并。
常用的：git pull origin master，将远程仓库 origin 的 master 分支拉取过来，与本地的当前分支合并。
上传代码并合并 git push,将本地的分支上传到远程并合并。
git push {name} {remote branch}:{locol branch}，将本地的 locol branch 分支推送到远程仓库 name 的 remote branch 分支。
如果本地的 locol branch 分支和远程仓库 name 的 remote branch 分支名字一样，可以简化成 git push {name} {branch}。
git push origin master:master，将本地的 master 分支推送到远程仓库 origin 的 master 分支。
常用的：git push origin master 是 git push origin master:master 的简写。
-u 参数，记录 push 到远端分支的默认值，下次想要继续 push 这个分支的时候，推送命令就可以简写成 git push。
执行 git push -u origin master 之后，下次在想推送 master 分支的时候，直接 git push 即可。
--force 参数，强制推送。
git push --force master，将本地的 master 分支强制推送到远程仓库 origin 的 master 分支并覆盖。
git push --force master 可以简写为 git push -f master。
谨慎使用 --force 参数。
git push origin -d {name}，删除远程仓库 origin 的 name 分支。
分支 git branch，列出本地分支。星号 * 标记当前在哪个分支下。
git branch -a，列出本地和远端的所有分支。星号 * 标记当前在哪个分支下。
git branch {name}，创建 name 分支。
git branch -d {name}，删除本地 name 分支。如果该分支有提交未进行合并，则会删除失败。
git branch -D {name}，强制删除本地 name 分支。如果该分支有提交未进行合并，也会删除成功。
git checkout {name}，切换到 name 分支。
git checkout -b {name}，创建 name 分支并切换到 name 分支。
git checkout .，把本地所有修改的，但是没有提交的，都回退到原来的状态。
合并 git merge {name}，合并 name 分支到当前分支。
如果合并时发生冲突，则会将有冲突的文件的文件名输出到命令行。
进入文件解决冲突后，需要执行 git add 命令通知 git 冲突已解决。
暂存 git stash，把所有没有提交的修改暂存。
git stash pop，恢复到 git stash 之前。
提交一个本地仓库到多个远程仓库 这里提交一个本地仓库到 Github 和 Gitee 两个远程仓库。
git remote add origin git@github.com:xxx/demo_project.git git push origin master git remote add gitee git@gitee.com:xxx/demo_project.git git push gitee master</content></entry><entry><title>使用 Git 时遇到的一些异常和解决方案</title><url>/post/computer-science/application/git/exception/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>git</tag></tags><content type="html"><![CDATA[ CPU AMD64(x86_64) Windows 11 家庭版 git 2.34.0
无法拉取代码 使用 git pull 命令拉取代码时卡住，并输出如下信息：
&gt; git pull Auto packing the repository in background for optimum performance. See &#34;git help gc&#34; for manual housekeeping. fatal: failed to run repack 这是因为，git 本地仓库如果长时间不进行清理，会导致本地 dangling commit 太多，从而造成拉取代码失败。 可以使用 git fsck 命令查看本地的 dangling commit。
&gt; git fsck --lost-found Checking object directories: 100% (256/256), done. Checking objects: 100% (110393/110393), done. dangling commit 01039c0c1efcc232be342aacc928af72df82503b dangling blob 5b0bd062917d784486756ef941a7446b1aa5e340 dangling commit 4a1c18fa0803db6d64e9cffded496beb686aeaa7 dangling commit f528f06bd9739511bf962e32636697f807764cf8 dangling commit ea5fb0909b71b997c3feb5c436a150f745e40886 dangling commit c76448818640c1b0a3c00546abf16e5b4dff94e4 dangling commit d27fd8f73e071d3a629348f40d079888e821b10f dangling commit 9a84703a10972d28e784d26417d6f53193b7ef78 dangling blob e7841cedb8d8a5b2cb02814cd9a2af06c5f46e00 dangling commit 6e8cf4714bc2ebb4d866a0aa046766598a1bcaf6 dangling blob fa990caae09e8d23923aed1d303e56272f6c8587 dangling commit 269e6c37f2208841d904577cd6e70d36f8ab0283 dangling commit 1ca1f0e7aafa762a675076fbc25ff6ff7048e41b ... 使用 git gc 命令清理后，就可以正常拉取代码了。
&gt; git gc --prune=now Enumerating objects: 93146, done. Counting objects: 100% (93146/93146), done. Delta compression using up to 12 threads Compressing objects: 100% (28200/28200), done. Writing objects: 100% (93146/93146), done. Total 93146 (delta 67637), reused 88951 (delta 64013), pack-reused 0 Removing duplicate objects: 100% (256/256), done. ]]></content></entry><entry><title>在 Visual Studio Code 中，配置 Golang 开发环境</title><url>/post/computer-science/application/visual-studio-code/golang/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>golang</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 go1.19 windows/amd64 Visual Studio Code 1.77.1 公共的操作放在这篇里面：在 Windows 11 中，安装和配置 Visual Studio Code正文 建议 VSCode 按工作区去配置，这样不同项目互不影响。
安装 Golang 先把 go 开发环境装好：在 Windows 11 中，配置 Golang 开发环境常用设置 Go: Format Tool。格式化工具。 扩展 （可选）安装 Chinese (Simplified) (简体中文) Language Pack for Visual Studio Code 组件（简体中文语言包）。 安装 Go 组件。 安装 Code Runner 组件。 （可选）安装 Git Graph 组件（查看 Git 树，执行 Git 操作）。 （可选）安装 Git History 组件（查看 Git 历史）。 （可选）安装 GitLens 组件（查看代码作者）。 （可选）安装 Markdown All in One 组件。 其他的工具是 go 提供的，会在右下角弹出提示框，点击安装即可。 工作区设置 有些设置项可以根据语言进行不同的配置。那种的就不是点 &ldquo;在 settings.json 中编辑&rdquo; 而是 &ldquo;编辑 {语言} 的设置&rdquo;。
比如，Editor: Code Actions On Save 这个设置。点击 &ldquo;在 settings.json 中编辑&rdquo; 不会出现下面的 &quot;[go]&quot;: {} 那样的参数。点击 &ldquo;编辑 go 的设置&rdquo; 的时候才会出现。
{ &#34;editor.codeActionsOnSave&#34;: { &#34;source.organizeImports&#34;: true } } &#34;[go]&#34;: { &#34;editor.codeActionsOnSave&#34;: { &#34;source.organizeImports&#34;: true } } 断点调试 找一个源码文件，打上断点。
在最上面的菜单栏，点击 &ldquo;启动调试&rdquo;。第一次点的时候，会在右下角弹出提示框，提示安装 go dlv。
安装好之后，点击 &ldquo;启动调试&rdquo;，理论上就可以了。
代码格式化 设置 Go: Format Tool 为 goformat。其他的理论上不用改，go 提供的格式化工具自己有一套代码格式标准。
使用 Code Runner 运行代码 安装 Code Runner 组件后，右上角的 &ldquo;运行按钮&rdquo; 那里，会多一个 Run Code 的选项。go 这里应该是本来没有这个按钮，现在会多一个按钮出来。
选中 hello_world.go 文件，然后，点击右上角的运行按钮，选择 Run Code 选项。这个操作，会在下面的 &ldquo;终端&rdquo; 子窗口里面，输出以下内容，相当于编译并运行了 hello_world.go 文件。
[Running] go run &#34;d:\workspace\demo-golang\demo\helloworld\main.go&#34; hello, world ]]></content></entry><entry><title>在 Windows 11 中，配置 Golang 开发环境</title><url>/post/computer-science/programming-language/golang/windows/</url><categories><category>golang</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>programming-language(编程语言)</tag><tag>golang</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 go1.19 windows/amd64 正文 下载 去 Golang 的 官方网站下一个 Windows 环境的安装包。官方网站打不开就用 这个网站。我这里下载到的安装包是 1.19 版本的 go1.19.3.windows-amd64.msi。
安装 我这里是 Windows 11 家庭版。建议使用管理员权限运行安装包。选个合适的安装目录，然后一路下一步即可。
安装结束后，需要配置环境变量。
在 Windows 桌面，鼠标右击 &ldquo;我的电脑&rdquo;，在弹出的菜单中，点击 &ldquo;属性&rdquo;，打开 &ldquo;设置&rdquo; 窗口。 在设置窗口中，找到并点击 &ldquo;高级系统设置&rdquo;，打开 &ldquo;系统属性&rdquo; 窗口。 在系统属性窗口中，切换到 &ldquo;高级&rdquo; 标签页，然后点击标签页最下面的 &ldquo;环境变量&rdquo;，打开 &ldquo;环境变量&rdquo; 窗口。 在环境变量窗口下面的 &ldquo;系统变量&rdquo; 里找到 path，然后点击 &ldquo;编辑，打开 &ldquo;编辑环境变量&rdquo; 窗口&rdquo;。 添加 &ldquo;go 的安装目录下的 bin 目录的路径&rdquo;。我这里，这个目录是 &ldquo;C:\go\bin&rdquo;。 配置完环境变量之后，可能需要重启一下 Windows。
验证能不能用 打开命令行窗口，CMD 或者 PowerShell 都可以。检查 go 命令是否可用。输出一下版本信息即可。
&gt; go version go version go1.19 windows/amd64 环境配置 go env 命令，输出当前 go 开发包的环境变量。 go env -w 命令，设置当前 go 开发包的环境变量。 &gt; go env set GO111MODULE=on set GOARCH=amd64 set GOBIN= set GOCACHE=C:\Users\kelipute\AppData\Local\go-build set GOENV=C:\Users\kelipute\AppData\Roaming\go\env set GOEXE=.exe set GOEXPERIMENT= set GOFLAGS= set GOHOSTARCH=amd64 set GOHOSTOS=windows set GOINSECURE= set GOMODCACHE=C:\Users\kelipute\go\pkg\mod set GONOPROXY= set GONOSUMDB= set GOOS=windows set GOPATH=C:\Users\kelipute/go set GOPRIVATE= set GOPROXY=https://goproxy.cn,direct set GOROOT=C:\go1.19 set GOSUMDB=sum.golang.org set GOTMPDIR= set GOTOOLDIR=C:\go1.19\pkg\tool\windows_amd64 set GOVCS= set GOVERSION=go1.19 set GCCGO=gccgo set GOAMD64=v1 set AR=ar set CC=gcc set CXX=g++ set CGO_ENABLED=1 set GOMOD=NUL set GOWORK= set CGO_CFLAGS=-g -O2 set CGO_CPPFLAGS= set CGO_CXXFLAGS=-g -O2 set CGO_FFLAGS=-g -O2 set CGO_LDFLAGS=-g -O2 set PKG_CONFIG=pkg-config set GOGCCFLAGS=-m64 -mthreads -Wl,--no-gc-sections -fmessage-length=0 -fdebug-prefix-map=C:\Users\kelipute\AppData\Local\Temp\go-build3774566253=/tmp/go-build -gno-record-gcc-switches GOARCH：处理器架构。 GOROOT：go 开发包的安装目录。 GOPATH：当前工作目录，在安装的时候会配置默认的。建议不要全局设置，而是随项目设置。 GOPROXY：代理。 GOPRIVATE：私有库，不走代理。 设置代理 受网络影响，默认的代理可能连不上。使用命令 go env -w GOPROXY=https://goproxy.cn,direct 设置为七牛云的代理。
go modules 使用命令 go env -w GO111MODULE=on 开启 go modules。go modules 是用于依赖管理的，以前的项目用的是 go path。现在，新的项目基本不用 go path 了，go modules 更方便。
]]></content></entry><entry><title>使用 Docker 启动 EasySwoole</title><url>/post/computer-science/application/docker/easyswoole/</url><categories><category>application(应用)</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>application(应用)</tag><tag>docker</tag><tag>php</tag><tag>EasySwoole</tag></tags><content type="html"><![CDATA[前言 实践的环境：
CPU AMD64(x86_64) Windows 11 家庭版 Docker v20.10.17 正文 拉取 Swoole 镜像 想启动 EasySwoole 框架需要先安装 Swoole 扩展。这里直接用 Swoole 提供的 docker 镜像。Swoole 的文档中就有 链接。
EasySwoole 官方文档中提到：&ldquo;如果没有特殊需求，请选择最新稳定版本开始下载(我这里是稳定版v4.4.23)&quot;。所以，这里也使用 v4.4.23 版本的 Swoole。
&gt; docker pull phpswoole/swoole:4.4.23-php7.4 4.4.23-php7.4: Pulling from phpswoole/swoole ... Digest: sha256:5bd895677cbc73a06ea33239459bc4a07486d15025c1d1c805438a61c839dd32 Status: Downloaded newer image for phpswoole/swoole:4.4.23-php7.4 docker.io/phpswoole/swoole:4.4.23-php7.4 启动容器 &gt; docker run -it -p 9501:9501 -v E:\code:/code phpswoole/swoole:4.4.23-php7.4 /bin/bash &ldquo;-it&rdquo; 参数加上最后的 &ldquo;/bin/bash&rdquo;，运行容器，并且以命令行模式进入容器。 &ldquo;-p 9501:9501&rdquo;，将本机的 9501 端口和容器的 9501 端口进行映射。 &ldquo;-v E:\code:/code&rdquo;，将本机的 &ldquo;E:\code&rdquo; 目录和容器的 &ldquo;/code&rdquo; 目录进行映射。 php 版本
&gt; php -v PHP 7.4.13 (cli) (built: Dec 18 2020 21:12:27) ( NTS ) Copyright (c) The PHP Group Zend Engine v3.4.0, Copyright (c) Zend Technologies composer 版本
&gt; composer -V Composer version 1.10.19 2020-12-04 09:14:16 这个镜像安装了 pecl，可以用 pecl 安装需要的扩展
&gt; pecl help version PEAR Version: 1.10.12 PHP Version: 7.4.13 Zend Engine Version: 3.4.0 Running on: Linux 2bc0c5d254d5 5.10.25-linuxkit #1 SMP Tue Mar 23 09:27:39 UTC 2021 x86_64 异常处理 WARNING swManager_check_exit_status: worker#18[pid=642] abnormal exit, status=255, 遇到这样的报错是因为，swoole 和 xdebug 冲突了，需要关掉 docker 镜像中的 xdbug 扩展。
在这个镜像中，配置文件的路径是 &ldquo;/usr/local/etc/php/conf.d/sdebug.ini-suggested&rdquo;。把里面都注释掉就行了。
]]></content></entry><entry><title>【Linux Shell 脚本】laravel 的 artisan 进程</title><url>/post/computer-science/operating-system/linux/shell/laravel_artisan/</url><categories><category>shell</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>linux</tag><tag>shell</tag><tag>laravel</tag></tags><content type="html"><![CDATA[正文 保证只有一个 schedule 再跑 #!/bin/bash # 进入项目目录 cd {project path} # 查看是否有名字是 schedule 的进程，有说明上一个还没跑完 ps auwx | grep &#39;schedule&#39; | grep -v grep # 如果没有查到结果，说明没有在跑，就并执行 schedule if [ &#34;$?&#34; != &#34;0&#34; ]; then php artisan schedule run &gt; /dev/null 2&gt;&amp;1 &amp; fi 重启所有的 queue #!/bin/bash # 进入项目目录 cd {project path} # 平滑关闭所有的 queue php artisan queue:restart # 停 2 秒，这里不是必须的 sleep 2 # 需要处理的队列名 queue_name_list=(&#34;queue1&#34; &#34;queue2&#34; &#34;queue3&#34;) # 循环依次把队列拉起来 for queue_name in ${queue_name_list[@]}; do echo &#34;start $queue_name ...&#34; nohup php artisan queue:work database --queue=$queue_name &gt;&gt; /tmp/$queue_name.log &amp; echo &#34;start $queue_name done&#34; done exit; 确保 queue 存活 #!/bin/bash # 进入项目目录 cd {project path} # 停 30 秒，这里是为了和整点的 shell 错开 sleep 30 # 需要处理的队列名 queue_name_list=(&#34;queue1&#34; &#34;queue2&#34; &#34;queue3&#34;) # 循环依次检查 for queue_name in ${queue_name_list[@]}; do # 查看是否有名字是 $queue_name 的进程，有说明进程还活着 ps auwx | grep $queue_name | grep -v grep # 如果没有查到结果，说明进程挂掉了，重新拉起来 if [ &#34;$?&#34; != &#34;0&#34; ]; then nohup /usr/local/php/bin/php artisan queue:work database --queue=$queue_name &gt;&gt; /tmp/$queue_name.log &amp; fi done exit; ]]></content></entry><entry><title>【Linux Shell 脚本】压缩日志</title><url>/post/computer-science/operating-system/linux/shell/zip_log/</url><categories><category>shell</category></categories><tags><tag>computer-science(计算机科学)</tag><tag>operating-system(操作系统)</tag><tag>linux</tag><tag>shell</tag></tags><content type="html">正文 每天压缩前一天的日志 #!/bin/bash # 获取前一天的 yyyy-mm-dd 格式的日期 dir_date=$(date -d yesterday +%Y-%m-%d) # 进入日志目录对应日期的目录 cd /tmp/logs/$dir_date/ # 查找所有以 .log 为后缀名的文件，并压缩 find ./ -name &amp;#39;*.log&amp;#39; | xargs -i gzip {} exit;</content></entry><entry><title/><url>/post/computer-science/hardware/cache/</url><categories/><tags/><content type="html">CPU 高速缓存 CPU 高速缓存（CPU cache）：在 CPU 里放一块内存用来暂存数据。
依据局部性（locality）原理，高速缓存从 RAM 拿数据时，一次拿一个缓存块（cache line、cache block）大小的数据而不是一个数据。
在 Linux 中，/sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size 可以查看 L1 缓存块的大小。
局部性原理 局部性原理有三个：时间局部性（temporal locality）、空间局部性（spatial locality）、顺序局部性（order locality）。
时间局部性是指如果一个数据正在被访问，那么近期它可能还会被再次访问。程序循环、堆栈等是产生时间局部性的原因。
空间局部性是指在最近的将来将用到的数据很可能与正在使用的数据在空间地址上是临近的。
顺序局部性是指在大多数普通的程序中，除转移类指令外，大部分指令是顺序进行的。此外，对大型数组的访问，很多时候也是顺序的。指令的顺序执行、数组的连续存放等是产生顺序局部性的原因。
一级缓存 一级缓存（L1 Cache）可分为指令缓存（I-Cache）和数据缓存（D-Cache）。每个 CPU 核心都有属于自己的一级缓存。在 Linux 中：/sys/devices/system/cpu/cpu0/cache/index0/size 可以查看 L1 数据缓存的大小； /sys/devices/system/cpu/cpu0/cache/index1/size 可以查看 L1 指令缓存的大小。
二级缓存 每个 CPU 核心都有属于自己的二级缓存（L2 Cache）。在 Linux 中，/sys/devices/system/cpu/cpu0/cache/index2/size 可以查看 L2 的大小。
三级缓存 三级缓存（L3 Cache）通常是多个 CPU 核心共用。在 Linux 中，/sys/devices/system/cpu/cpu0/cache/index3/size 可以查看 L3 的大小。
缓存命中率（cache hit rate） 缓存命中（cache hit），缓存未命中（cache miss）
数据缓存的命中率：尽量顺序访问数据。 指令缓存的命中率：尽量访问有序的数据（让分支预测更准确）。 多核 CPU 缓存命中率：把计算密集型程序的线程绑定在某个 CPU 核心上。对于多核心 CPU，线程可能在不同 CPU 核心来回切换，这对属于每个核心的 L1 和 L2 不利，但是对 L3 没影响。 在 Linux 中，提供了 sched_setaffinity，来实现将线程绑定到某个 CPU 核心这一功能。
缓存一致性 缓存一致性（cache coherence）有两个解决方案：写直达（write through）、写回（write back）。
写直达：当发生写操作时，把数据同时写入缓存和内存。
CPU 写入前先判断缓存里有没有数据。如果缓存里有，就先更新到缓存，再写入内存。如果缓存里没有，就直接更新到内存。
写回：当发生写操作时，新的数据只被写入到缓存块里，只有当修改过的缓存块被替换时，才需要写到内存中。
如果发生写操作时，数据已经在缓存里，则把数据更新到缓存，同时标记缓存里的这个缓存块为 Dirty（脏）的。这个脏的标记代表这个时候，缓存里面的这个缓存块的数据和内存是不一致的。
如果发生写操作时，要写入数据的缓存块里存放的是别的内存地址的数据，就要检查这个缓存块有没有被标记为脏的。
如果是脏的话，就要把这个缓存块里的数据写回到内存，然后再把当前要写入的数据，先从内存读入到缓存里，然后把数据写入到缓存块，最后把它标记为脏的。 如果不是脏的话，就直接将数据写入到这个缓存块里，然后把这个缓存块标记为脏的。 多核心缓存一致性 多核心 CPU 的每个核心都有自己的 L1 和 L2。写直达和写回方案，只能解决单核心的问题。
要解决多核心的问题，需要做到下面两点：
写传播（wreite propagation）：某个核心里的缓存更新时，必须传播到其他核心。用于解决下面的情况 1。 事务串形化（transaction serialization）：某个核心里对数据的操作顺序，在其他核心看起来必须是一样的。用于解决下面的情况 2。 总线嗅探（bus snooping）：当某个核心更新了缓存，要把该事件广播到其他核心。核心需要每时每刻监听总线上的一切活动，不管别的核心的缓存是否缓存相同的数据，都需要发出一个广播事件。
总线嗅探并不能保证事务串形化。要实现事务串形化，需要做到下面两点：
CPU 核心对于缓存中数据的操作，需要同步给其他 CPU 核心。 引入锁的概念，如果两个 CPU 核心里有相同数据的缓存，那么只有拿到了锁，才能进行对应的数据更新。 MESI 协议 基于总线嗅探机制实现了事务串形化，同时利用状态机机制降低了总线带宽压力。
MESI 是 4 个单词的缩写：Modified（已修改）、Exclusive（独占）、Shared（共享）、Invalidated（已失效）。
已修改状态就是前面提到的脏标记，代表缓存块上的数据已经被更新，但还没有写到内存。
已失效状态表示的是这个缓存块里的数据已经失效了，不可以读取该状态的数据。
独占和共享状态都代表缓存块里的数据是干净的，和内存里面的数据是一致性的。
独占状态的时候，数据只存储在一个 CPU 核心的缓存里，而其他 CPU 核心的缓存没有该数据。这个时候，不存在缓存一致性的问题。所以可以直接自由地写入，而且不需要通知其他 CPU 核心。
在独占状态下的数据，如果有其他核心从内存读取了相同的数据到各自的缓存，那么这个时候，独占状态下的数据就会变成共享状态。
共享状态代表着相同的数据在多个 CPU 核心的缓存里都有，所以当要更新缓存里面的数据的时候，不能直接修改，而是要先向所有的其他 CPU 核心广播一个请求，要求先把其他核心的缓存中对应的缓存块标记为已失效状态，然后再更新当前缓存里面的数据。</content></entry><entry><title/><url>/post/computer-science/operating-system/memory/ptrace/</url><categories/><tags/><content type="html">在用ptrace跟踪另外一个进程，寻找目标数据时，可能会在目标进程内存中多个位置找到目标数据，可能会有3个地方
变量本体，就是变量所在的位置； 堆栈框架，比如当这个变量定义在main函数里面的时候，main函数的堆栈框架里也可能会出现； 寄存器，在执行过程中，数据可能会暂时存储在cpu的寄存器中
当使用ptrace读取和修改目标进程的内存时，需要注意，读取和写入数据的单位是一个long 读取的时候想要读的是一个int，但是返回的时候会带着这个int后面的四个字节 修改的时候也需要注意，先把目标位置上的8个字节读出来，然后修改需要修改的部分，然后把八个字节完整的放回去，要不然会出错</content></entry><entry><title/><url>/post/computer-science/programming-language/assembly/%E5%86%85%E8%81%94%E6%B1%87%E7%BC%96/</url><categories/><tags/><content type="html"></content></entry><entry><title/><url>/post/computer-science/programming-language/framework/web/golang/beego/</url><categories/><tags/><content type="html"><![CDATA[beego框架 2021-11-17 go-1.17 bee-v1.12.3 beego-v1.12.3 安装bee工具 bee工具是一个为了协助快速开发beego项目而创建的项目。
通过bee，可以很容易的进行beego项目的创建、热编译、开发、测试、和部署。
&gt; go get github.com/beego/bee go: downloading github.com/beego/bee v1.12.3 go: downloading gopkg.in/yaml.v2 v2.3.0 go: downloading github.com/fsnotify/fsnotify v1.4.9 go: downloading github.com/gadelkareem/delve v1.4.2-0.20200619175259-dcd01330766f go: downloading github.com/gorilla/websocket v1.4.2 go: downloading github.com/lib/pq v1.7.0 go: downloading github.com/davecgh/go-spew v1.1.1 go: downloading github.com/flosch/pongo2 v0.0.0-20200529170236-5abacdfa4915 go: downloading github.com/pelletier/go-toml v1.7.0 go: downloading github.com/smartwalle/pongo2render v1.0.1 go: downloading github.com/spf13/viper v1.7.0 go: downloading github.com/astaxie/beego v1.12.1 go: downloading golang.org/x/sys v0.0.0-20191005200804-aed5e4c7ecf9 go: downloading github.com/hashicorp/hcl v1.0.0 go: downloading github.com/magiconair/properties v1.8.1 go: downloading github.com/mitchellh/mapstructure v1.1.2 go: downloading github.com/spf13/afero v1.1.2 go: downloading github.com/spf13/cast v1.3.0 go: downloading github.com/spf13/jwalterweatherman v1.0.0 go: downloading github.com/spf13/pflag v1.0.3 go: downloading github.com/subosito/gotenv v1.2.0 go: downloading gopkg.in/ini.v1 v1.51.0 go: downloading go.starlark.net v0.0.0-20190702223751-32f345186213 go get: installing executables with &#39;go get&#39; in module mode is deprecated. To adjust and download dependencies of the current module, use &#39;go get -d&#39;. To install using requirements of the current module, use &#39;go install&#39;. To install ignoring the current module, use &#39;go install&#39; with a version, like &#39;go install example.com/cmd@latest&#39;. For more information, see https://golang.org/doc/go-get-install-deprecation or run &#39;go help get&#39; or &#39;go help install&#39;. go get: added github.com/beego/bee v1.12.3 安装beego &gt; go get github.com/astaxie/beego go: downloading github.com/astaxie/beego v1.12.3 go: downloading golang.org/x/net v0.0.0-20190620200207-3b0461eec859 go: downloading github.com/prometheus/procfs v0.1.3 go: downloading golang.org/x/sys v0.0.0-20200615200032-f1bc736245b1 go: downloading github.com/cespare/xxhash v1.1.0 go: downloading github.com/peterh/liner v1.0.1-0.20171122030339-3681c2a91233 go get: upgraded github.com/astaxie/beego v1.12.1 =&gt; v1.12.3 ]]></content></entry><entry><title/><url>/post/computer-science/programming-language/golang/module/</url><categories/><tags/><content type="html"><![CDATA[使用 go module 2021-07-16 go-1.15 go module是官方自带的go依赖管理库，在1.13版本正式推荐使用。
go1.13+的版本，判断module开不开启的依据是，根目录下有没有go.mod文件。
使用go env -w GO111MODULE=on命令可以设置module全局开启。
如果使用了go module，那产生的依赖包放置在$GOPATH/pkg/mod目录下
初始化 在模块根目录下使用go mod命令进行初始化，初始化完成后会在模块根目录下生成go.mod文件。
go mod init {module_name} 导入本地包 目录结构
- hello/ - hello1/ - helloworld1.go - hello2/ - helloworld2.go - main.go - go.mod go.mod
module hello go 1.15 main.go
package main import ( &#34;go0yang4li4/hello1&#34; &#34;go0yang4li4/hello2&#34; ) func main() { hello1.FHelloWorld() hello2.FHelloWorld() } helloworld1.go
package hello1 import &#34;fmt&#34; func FHelloWorld() { fmt.Println(&#34;hello world1&#34;) } helloworld2.go
package hello2 import &#34;fmt&#34; func FHelloWorld() { fmt.Println(&#34;hello world2&#34;) } ]]></content></entry><entry><title/><url>/post/philosophy/about_shop/</url><categories/><tags/><content type="html"></content></entry><entry><title/><url>/post/philosophy/english_vocabulary/</url><categories/><tags/><content type="html">画质 masterpiece(杰作)、ultra-detailed(超详细的)、quality(品质)、
highres(高分辨率)、4k、8k、details(细节)、features(特征)、
contrast(对比度)、illumination(照明)、shadow(阴影)、
可选形容词：
best、high、intricate(复杂的)、elaborate(制作精美的)、
风格 photo(照片)、portrait(画像)、illustration(插图)、anime(动画)、
wallpaper(壁纸)、cg、game cg、3d、unity(会生成 unity 建模的渲染图)、
upper body(上半身)、full body(全身)、
x-ray(x-射线)、x-ray view(x-射线视图)、cross-section(截面图)、
darkness(黑暗)、focus(聚焦于)、
可选形容词：
extremely(极度的)、detailed(有细节的)、intricate(复杂的)、elaborate(制作精美的)、
主题（这里主要是人物） 1girl、2girl、1boy、female、male、solo(独奏)、
nun(修女)、demon(恶魔)、succubus(梦魔)、
形容词：
mature(成熟的)、
主题的细节 头发：（发型、发色、头盔、帽子）
braids(辫子)、tentacle hair(触手头发)、
streaked hair(挑染的头发)、hair ornament(发饰)、
hat(帽子)、
头：（五官、瞳色、眼镜、眼泪、兽耳、面甲）
face(脸)、eyes、tears(眼泪)、
animal ears、fake animal ears(假的动物耳朵)、rabbit ears(兔耳朵)、
earring(耳环)、choker(吊饰)、
颈：
necklace(项链)、choker(颈圈)、
衣服：（裸体、整体的服装、铠甲、装甲、机甲、触手）
nude(裸体)、torn clothes(撕裂的衣服)、
sweat(汗水)、
nuns clothing(修女服)、
crop-top(圆领衫)、
panties(内裤)、pantyhose(连裤袜)
lite armor(轻型装甲)、heavy armor(重型装甲)、
tentacles(触手)、tentacle sex、
身体：
body&amp;rsquo;s back(背后)
胸：
breasts(胸部)、no bra(没有胸罩)、
手臂：
sleeveless(无袖)、armlet(臂环)、
手：
wrist cuffs(腕带)、hands(手)、fingers(手指)、
腹：
waist(腰)、navel(肚脐)、waist wings(腰上的翅膀)、tails(尾巴)、twin tails、
tattoo(纹身)、under-stomach tattoo(肚脐下的纹身)、uterus tattoo(子宫位置的纹身)、crotch tattoo(下腹至私处之间的纹身)、tramp stamp(后腰的纹身)、
阴：
pussy(阴部)、pubic hair(阴毛)、artificial vagina(人造阴部)、
pussy juice(阴部汁液)、pussy juice trail(阴部汁液痕迹)、pussy juice stain(阴部汁液污渍)、
vaginal(阴道)、cervix(子宫颈)、uterus(子宫)、
hips(臀部)、ass(屁股)、anus(肛门)、
penis(阴茎)、
腿：
legs(腿)、
脚：
feet(脚)、toes(脚趾)、soles(脚底)、
no shoes、anklet(脚环)、
形容词：
little、small、medium、large、big、
perfect(完美的)、beautiful(美丽的)、detailed(有细节的)、multicolored(五彩缤纷的)、
busty(丰满的)、curvaceous(曲线优美的)、wide(宽大的)、
artificial(人造的)、
loose(宽松的)、
主题的表情 ahegao(啊嘿颜)、shy(害羞)、
主题的姿势 基础姿势：
standing(站立)、lying(躺)、hug each other(相互拥抱)、trembling(颤抖)
头：
facing away(朝向远处)、looking back(回头看)、looking at viewer(看向观察者)、
close one&amp;rsquo;s eyes(闭上眼睛)、close one eye(闭上一只眼睛)、rolling eyes(翻白眼)、
grin(咧嘴笑)、tongue out(伸出舌头)、
胸：
breast grab,grabbing from behind(从后面抓胸)
手臂：
cast a spell(施法)
腹：
waist grab(抓住腰部)
阴：
presenting(呈现)、pussy peek(阴部窥视)、spread pussy(掰开阴部)
cum(精液、射精)、cum in pussy(射进阴部)、cum on body(射身体上)、cum on stomach(射肚子上)、cum on back(射背上)、ejaculation(射精)、internal cumshot(内射精液)、cumdrip(精液滴下)
implied sex(隐性性行为)、bukkake(颜射)、doggystyle(后背位)、penis hitting uterus(阴茎撞击子宫)、fucked silly(被干傻了)、
腿：
spread legs(张开双腿)
复合动作：JOJO 立
背景 室内场景：
indoors(室内)、
tentacle pit(触手坑洞)、cum pool(精液池)
室外场景：
outdoors(室外)、
water、water drop(水滴)、in water(在水中)、
tree(树)、rock(岩石)
天气：
其他 nsfw(not safe for work，淫秽物品)、hentai(变态)
EasyNegative
error(错误)、logo(标志)、title、text(文本)、mosaic(马赛克)、watermark(水印)、
username(用户名)、artist name(作者名字)、signature(签名)
jpeg artifacts(假影，jpeg 压缩次数多了会糊)、cropped(裁剪过的)、card(卡片)、
画质 blurry(模糊的)、depth of field(景深)、bokeh(虚化)、
worst quality(最差的品质)、low quality(低品质)、(worst quality, low quality:1.4)、normal quality
lowres(低分辨率)、low resolution(低分辨率)、low picture anime(低画质动画)、
monochrome(单色)、wrong colors(错误的颜色)、
主题 face(脸)、cloned face(克隆脸)、neck(脖子)、
body(身体)、limb(肢体)、humpbacked(驼背的)、
multiple breasts(多个乳房)、more than 2 nipples(超过2个乳头)、rib(肋骨)、
arms(手臂)、hands(手)、badhandv4、bad-hands-5、fingers(手指)、
abs(腹肌)、anus(肛门)、legs(腿)、thighs(大腿)、
形容词：
bad、long、too long、huge、
missing(缺失)、mutilated(残缺的)、extra(多余的)、more than(多余)、too many(太多)、
disfigured(毁容的)、malformed(畸形的)、morbid(畸形的)、mutated(变异的)、multiple(多重)、fused(融合的)、
anatomy(解剖学)、proportions(比例)、
poorly drawn(画得不好的)、ugly(丑陋)、fat(肥胖)、muscular(肌肉发达的)、</content></entry><entry><title>站点示例</title><url>/flinks.html</url><categories/><tags/><content type="html">如想交换本站友情链接，请在评论区留下你的站点信息，格式参考如下：
- name: Hugo-NexT desc: Hugo NexT 官方预览网站。 avatar: https://hugo-next.eu.org/imgs/hugo_next_avatar.png link: https://hugo-next.eu.org</content></entry></search>