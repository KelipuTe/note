---
draft: false
title: "负载均衡"
summary: "负载均衡；"
toc: true

categories:
  - 架构

tags:
  - 计算机
  - 架构

date: 2024-03-18 08:00:00 +0800
---

## 反向链接

[哈希](/计算机/算法/哈希)；

## 正文

### 负载均衡

负载均衡（load balance）：将任务（负载）均匀分摊到多个操作单元。

当下游服务由多台服务器组成时，上游服务应该把请求发给哪一台服务器。
理论上最好把请求发给能够最快响应的服务器，但是实际操作没有那么准确。

负载均衡算法分两大类：静态负载均衡算法、动态负载均衡算法。

静态负载均衡算法基于统计学。
当各种请求的消耗差不多，总请求数量足够大时，比较合适。
算法：轮询和加权轮询、随机和加权随机、哈希与一致性哈希。

动态负载均衡算法基于实时监测。
上游服务通过监测数据判断下游服务状态，依此选择服务器。
算法：最快响应时间、最少活跃请求数、最少连接数。

### 静态负载均衡算法

#### 轮询和加权轮询

轮询，把所有服务器排成队列，遍历队列依次发请求。
在每轮遍历中，每台服务器只会被请求一次。

加权轮询在轮询的基础上，增加了差异化的功能。可以给服务器加权重。
因为服务器存在性能差异，有的服务器性能更好，可以负担更多的请求。
比如，在队列里面多放几个这台服务器的副本。
这样在每轮遍历中，这台服务器就会被请求多次。

这里涉及到请求分配问题。

因为副本的存在，列表中的有可能会出现连续几个都是同一台服务器。
这时需要把列表中的服务器尽量均匀地打散，减少同一台服务器连续出现的情况。

上面就是举个例子，如果其他的手段可以实现也可以。

#### 随机和加权随机

随机，随机数算法算个随机数，映射算法把随机数和某个服务器对上。
比如，把所有服务器排成队列，随机数对服务器总数取余，得到下标。

加权随机在随机的基础上，增加了差异化的功能。可以给服务器加权重。
比如，在队列里面多放几个这台服务器的副本。
这样随机数对服务器总数（本体加副本）取余时。
副本多的服务器（权重高的服务器）就有更大的概率被选中。

上面就是举个例子，如果其他的手段可以实现也可以。

#### P2C

P2C（pick of 2 choices）是一种改进的随机算法，可以避免选到最差的节点。
从所有可用节点中随机选两个节点进行打分（判断负载情况），然后选择分数更高的节点。

#### 哈希

如果分布式系统节点数据有差异的话，轮询和随机就不好用了。
比如，分布式缓存系统，某个 key 在哪个节点上是确定的。
不是访问任意一个节点都可以找到这个 key 的。
类似这种场景，就需要用哈希或者一致性哈希了。

哈希，用请求中的特征值算哈希值，映射算法把哈希值和某个服务器对上。
相同的特征值得到相同的哈希值，相同的哈希值对应相同的节点，满足负载均衡的需求。

这里涉及到请求分布问题和扩缩容问题。

分布问题：如果算出来的哈希值分布不均匀，那么服务器的压力也会不均匀。

扩缩容问题：节点数量变化时，映射算法的结果也会变化，历史数据就用不了了。
想要解决就需要迁移数据，最坏的情况下，要迁移所有数据，数据迁移规模是 O(n)。

#### 一致性哈希

一致性哈希（consistent hashing）算法可以解决负载均衡扩缩容时，数据迁移过多的问题。

映射算法不是对节点总数进行取模运算，而是对 $2^{32}$ 进行取模运算，其结果是固定值。

要将节点和数据都映射到一个首尾相连的哈希环上。假设哈希环顺时针是从 0 到 $2^{32}$。
第一步，计算节点的哈希值。比如根据节点的 IP 地址。这时哈希环上就会有几点对应节点了。
第二步，计算数据的哈希值。数据的哈希值大概率打不中节点，这时顺时针找第一个节点就行。

一致性哈希算法不能保证节点能在哈希环上均匀分布。
虽然扩缩容时，仅影响环上顺时针的相邻节点，其它节点均不受影响。
但是如果扩缩容的节点数据很多，给相邻节点的压力过大，会导致雪崩式的连锁反应。

要想解决节点在哈希环上分布不均匀的问题，就要有大量的节点。
节点数量越多，哈希环上的节点分布就越均匀。但是，实际中没有那么多节点。
这时可以在哈希环上加入节点本体的副本（虚拟节点），副本再映射到本体。

虚拟节点除了会提高节点的均衡度，还会提高系统的稳定性。
扩缩容时，会有不同的节点共同分担变化，因此稳定性更高。
而且有了虚拟节点后，加权的逻辑也可以使用了。

一致性哈希还有有界负载一致性哈希这种方案。当某个节点过载时，数据会顺位使用下一个节点。

### 动态加权

权重可以代表节点的处理能力，也可以代表节点的可用性。
要点在于体现节点的差异性，根据实际情况来设置就可以。

加权可以是动态的。比如根据调用结果来动态调整权重。
调用成功了，就增加权重；调用失败了，就减少权重。

这里的成功与否是非业务相关的概念，拿到了失败的响应，但是调用是成功的。
调用失败是指网络异常、请求超时等，还可以给不同的失败配不同的权重变化幅度。

需要特别注意的是，权重的调整要设置好上限和下限。
比如，下调到 0 了，永远选不中；上调的非常大，一直被选中。
还需要注意存储权重的数据类型的范围，防止溢出变成负数。

动态加权这里还有一些别的概念，主要是防止权重变化幅度过大导致负载均衡失效的。

对新节点使用常量惩罚（penalty），使用探针的方式（最小化放量）进行预热，让节点指标逐渐恢复。

权重较低的节点，使用统计衰减，让节点指标逐渐恢复到初始状态，避免永久进入黑名单无法恢复。

### 动态负载均衡算法

#### 最快响应时间

客户端采集每个节点的响应时间，每次选响应时间最短的。

响应时间可以是平均响应时间，也可以是 99 线之类的。
响应时间是一种综合性指标，用来代表节点的负载比较准确。

计算的时候要注意时效性。采集的数据的权重应该随着时间衰减。

#### 最少活跃请求数

客户端记录每个节点的活跃请求数，每次选请求数最少的。

活跃请求就是已经接收但是还没有返回的请求，数据由服务端上报。

活跃请求数不能代表节点的实际负载。1个写请求和5个读请求的压力不一定哪个大。

#### 最少连接数

客户端记录每个节点的连接数，每次选请求数最少的。数据由服务端上报。

连接数不能代表节点的实际负载。1个长链接和5个短连接的压力不一定哪个大。

#### 自行设计

比如，CPU 密集型的应用，每次选 CPU 负载最低的。

### 请求本身的问题

大多数负载均衡算法都没有考虑请求本身。
列表查询和订单创建，小体量商家的列表和大体量商家的列表，复杂度是不一样的。

这种问题一般需要结合实际场景解决。常用的思路有拆分和隔离。

列表查询和订单创建分别分配到读节点和写节点上去。订单创建依然很慢，但是读节点的资源不受订单创建的影响。

列表查询限制最多 100 个，这样小体量商家的列表和大体量商家，即使复杂度不一样，极限差距也就是 100 个。

大客户分配到专门的节点上去。虽然大客户依然很慢，但是其他的客户不会在受到大客户的影响了。

## 参考

- [The power of two choices in randomized load balancing](https://ieeexplore.ieee.org/document/963420)